{"/":{"title":"jzhao.xyz","content":"\nWelcome to my little [garden](posts/networked-thought.md) on the [internet](thoughts/Internet.md) -- I'm Jacky! I spend a lot of time here [playing](posts/play.md), [[thoughts/writing|writing]], and [building out in the open](thoughts/building%20in%20public.md). It's a little unkempt in places, but I think it gives it a little charm.\n\nCurrently, I do [[thoughts/Rhizome Research Log|independent research]] focused on better ways of relating and coexisting on the web; [[posts/towards-data-neutrality|one without platform lock-in]]. In my spare time, I create and [[thoughts/maintenance|maintain]] a number of widely used open-source [projects](thoughts/Projects.md).\n\nI'm curious about how we can better [incentivize](thoughts/incentives.md) [public goods](thoughts/public%20goods.md) [funding](thoughts/funding.md), support better [interactions](thoughts/interaction%20design.md) with computers and [[thoughts/Rhizome Proposal|data]], and be more responsible stewards of technology.\n\nIn this era of my life, I’m working towards being someone who is [unabashedly excited and curious about the world](https://www.youtube.com/watch?v=Khfe3jBuq8c\u0026list=PLMs_JcuNozJbxC91R5skgPpL7cnJuICun).\n\nThough I can't quite yet provide you a guided tour of this digital garden, I can leave you a list of places to explore as suggestions.\n\n- [The fruit garden out back](/posts): a collection of my favourite writing;\n- [The hand-crafted oak workbench](thoughts/Projects.md): a collection of projects I've hacked on;\n- [The crumpled pages in the recycling bin](posts/a-failure-resume.md): my failure resume;\n- [The bookshelf on the far wall](/books): books that are in some state of read, reading, or want to read.\n","lastmodified":"2023-02-15T01:38:21.169820744Z","tags":null},"/books":{"title":"Booklist","content":"\nA (mostly) up-to-date list of books I at some point, have wanted to read, am reading, or finished reading. Links are to pages/blog posts/ideas that were inspired by the book that's linked!\n\n## To Read\n\u003e What is an [antilibrary](https://nesslabs.com/antilibrary)? To put it simply, an antilibrary is a private collection of unread books. Instead of a celebration of everything you know, an antilibrary is an ode to everything you want to explore.\n\n### Fiction\n* **Accelerando** by Charles Stross\n* **Homo Ludens** by Johan Huizinga\n\n### Non-fiction\n* **Dealers of Lighting** by Michael A. Hiltzik\n* **Creation: Life and How to Make it** by Steve Grand\n* **The Utopia of Rules** by David Graeber\n* **Where Is My Flying Car?** by J. Storrs Hall\n* **The Dream Machine** by M. Mitchell Waldrop\n* **The Limits to Capital** by David Harvey\n* **Inventing the Medium** by Janet J. Murray\n* **Designing an Internet** by David D. Clark\n* **Playing Software** by Miguel Sicart\n\n## Current\n- **Foundation** Series by Isaac Asimov\n\n## Past\n### 2023\n- **[[thoughts/Tomorrow, and Tomorrow, and Tomorrow|Tomorrow, and Tomorrow, and Tomorrow]]** by Gabrielle Zevin\n* **Project Hail Mary** by Andy Weir\n\n### 2022\n* **[[thoughts/Seeing like a State|Seeing Like A State]]** by James C. Scott\n* **[[thoughts/Games Agency as Art]]** by C. Thi Nguyen\n* **Permutation City** by Greg Egan\n* **[[thoughts/Weaving the Web|Weaving the Web]]** by Tim Berners-Lee\n* **[[thoughts/The Writing Life|The Writing Life]]** by Annie Dillard\n* **[[thoughts/Tools for Conviviality|Tools for Conviviality]]** by Ivan Illich\n* **[[thoughts/visualization|Envisioning Information]]** by Edward R. Tufte\n* **The Book of Form and Emptiness** by Ruth Ozeki\n* **Walden Two** by B. F. Skinner\n* **[In Over Our Heads: The Mental Demands of Modern Life](thoughts/In%20Over%20Our%20Heads.md)** by Robert Kegan\n* **Ghost Work** by Mary L. Gray and Siddharth Suri\n* [**The Midnight Library**](thoughts/The%20Midnight%20Library.md) by Matt Haig\n* [**Archipelago**](thoughts/Archipelago.md) by Édouard Glissant\n* **Unflattening** by Nick Sousanis\n\n### 2021\n* [**How to Do Nothing**](thoughts/How%20to%20do%20Nothing.md) by Jenny Odell\n* [**A Tale for the Time Being**](thoughts/A%20Tale%20for%20the%20Time%20Being.md) by Ruth Ozeki\n* [**Atlas of AI**](thoughts/Atlas%20of%20AI.md) by Kate Crawford\n* **Klara and the Sun** by Kazuo Ishiguro\n* [**The Grasshopper: Games, Life and Utopia**](thoughts/The%20Grasshopper,%20Games,%20Life%20and%20Utopia.md) by Bernard Suits\n* **The Anthropocene Reviewed** by John Green\n* **Never Let Me Go** by Kazuo Ishiguro\n* [**From Counterculture to Cyberculture**](thoughts/From%20Counterculture%20to%20Cyberculture.md) by Fred Turner\n* [**Design Justice**](thoughts/Design%20Justice.md) by Sasha Costanza-Chock\n* [**Mindstorms**](thoughts/Mindstorms.md) by Seymour A. Papert\n* **Half of a Yellow Sun** by Chimamanda Ngozi Adichie\n* **1984** by George Orwell\n* **On Earth We're Briefly Gorgeous** by Ocean Vuong\n* [**The Making and Maintenance of Open Source Software**](thoughts/Making%20and%20Maintenance%20of%20OSS.md) by Nadia Eghbal\n* **When Breath Becomes Air** by Paul Kalanithi\n* **Kafka on the Shore** by Haruki Murakami\n* **The Art of Thinking Clearly** by Rolf Dobelli\n* **21 Lessons for the 21st Century** by Yuval Noah Harari\n\n### 2020\n* **Sapiens** by Yuval Noah Harari\n* **Measure What Matters** by John Doerr\n* **A Beautifully Foolish Endeavour** by Hank Green\n* **The Uninhabitable Earth** by David Wallace-Wells\n* **The Subtle Art of Not Giving a Fuck** by Mark Manson\n* **The Death of Ivan Ilyich** by Tolstoy\n","lastmodified":"2023-02-15T01:38:21.169820744Z","tags":null},"/newsletters/issue-0":{"title":"Hello world!","content":"\nHi there and thanks for signing up for my newsletter!\n\nI’ll try to keep these in a rough 3-2-1 fashion in each issue, with 3 things I’ve found interesting from others, 2 things I’ve been wondering about, and 1 thing I’ve done.\n\n## 3 things I’ve found interesting\n\n1. Found out about [100 Rabbits](https://100r.co/site/about_us.html), a tag-team of two people sailing around the world making open-source software\n2. OpenAIs recent work with [DALL-E](https://openai.com/blog/dall-e/) and [CLIP](https://openai.com/blog/clip/). Some really revolutionary stuff in combining text and image domains.\n3. Vlogbrothers on [How To Change What you Want](https://www.youtube.com/watch?v=salgtCpST3A). Interesting video on how content we consume steers our wants and what we want to want affects our actual wants. Hank says it in a way that makes a lot more sense so give it a watch.\n\n## 2 things I’ve been wondering about\n\n1. Why didn’t I start writing earlier? Writing has always been a way to help me organize my own thoughts. Now that I’ve started writing more frequently, I feel like I’m able to better put the jumble of thoughts inside my brain onto paper (or I guess a Markdown file in this case).\n2. Promoting healthier [hacking culture](/thoughts/hackathons). Conversation inspired by [this tweet](https://twitter.com/sarahbdhsn/status/1347666496718213120). What can we do as hackathon organizers to make events less stressful/hypercompetitive for attendees (especially those who are differently-abled)?\n\n## 1 thing I’ve done\n\nI wrote a [reflection piece about my 2020](/posts/2020) as well as set some goals for the upcoming year! A few interesting tidbits on paratelic vs telic goal setting.","lastmodified":"2023-02-15T01:38:21.169820744Z","tags":null},"/newsletters/issue-1":{"title":"A request for coffee chats","content":"\nThis month of January went by with blazing speed. I can't say if it's because of school starting back up or just the massive amounts of s t u f f going on in the world right now. \n\nOn an unrelated note, I'm currently working on stepping outside my comfort zone and meeting new people so feel free to email back if you'd be interested in a coffee chat! I'd be happy to learn about all the cool things y'all are working on :)\n\n## 3 things I’ve found interesting\n\n1. [Velocity vs Acceleration based execution](https://www.samsonzhang.com/2021/01/19/how-to-innovate-and-create-a-culture-of-innovation.html). Insightful read on how orgs can be [moving fast but not be innovating](thoughts/move%20fast%20and%20break%20things.md). How do we have a high acceleration org rather than just a high velocity one?\n2. [Switch Transformers: Larger than GPT-3](https://venturebeat.com/2021/01/12/google-trained-a-trillion-parameter-ai-language-model).  An interesting approach to deal with huge language models by 'sparsly' activating certain subsets of the network. Interesting to see modern ML techniques going back to expert systems of the early 90's.\n3. [Suspension of Internet in Uganda](https://blog.cloudflare.com/uganda-january-13-2021-internet-shut-down/). During an election at that. Curious how something of this scale was orchestrated, let alone agreed to. Something that feels so close to [infrastructure](/thoughts/infrastructure) shouldn't be freely shutdown so easily.\n\n## 2 things I’ve been wondering about\n\n1. How can we make policy more accessible? Idea has been festering in my head after reading Eva Zhang's post on '[Request for Startups](https://evaz.substack.com/p/rfs)'. Is there a better way we can track what policy makers are up to during non-election years? Maybe some sort of data mesh or platform that simplifies policy or makes it easier to view updates? Decided to take a stab at this problem during HTN2020++ this year. [Devpost](https://devpost.com/software/legist).\n2. Digital Gardening. After reading Joel Hook's blog post on his own [digital garden](https://joelhooks.com/digital-garden), I've been thinking and reflecting on my own processes for managing my garden. It's culminated into a blog post which you can read [here](/posts/digital-gardening).\n\n## 1 thing I’ve done\nI presented a technical workshop for the first time at Hack the North 2020++! I've always been a little spooked of public speaking but it was really empowering to be able to go up in front of so many people (albeit virtually) and talk about something I'm passionate about. My workshop was on a gentle introduction to Docker and you can view the recording [here](https://www.youtube.com/watch?v=ONNQ5EDhXUk) (it's not a Rick Roll, I promise).\n\n","lastmodified":"2023-02-15T01:38:21.169820744Z","tags":null},"/newsletters/issue-2":{"title":"Spider-man neurons, hearing fractals, and fulfilment","content":"\nI can't believe we're approaching a time of year when I can wait until *after* dinner to turn on my desk light. In the almost two months since my last newsletter, I've been doing a lot of [reading](/books), having 1:1s with some pretty rad people, [learning Rust](https://github.com/jackyzha0/rs-openai/), and of course surviving school. Surviving, in this case, is a questionable word choice.\n\n## 3 things I’ve found interesting\n\n1. [Multimodal Neurons in Neural Networks](https://openai.com/blog/multimodal-neurons/). First off, Spider-Man neuron. This paper is an interesting exploration on how neural networks can appear to have an understanding of abstract higher-level concepts that are *composable*. A lot of really interesting potential here.\n2. [Sounds of the Mandelbrot Set](https://www.youtube.com/watch?v=GiAj9WW1OfQ). Is mayonaisse an instrument? Yes, and fractals are too. A really cool look into doing an auditory visualization of things we wouldn't normally associate with sound.\n3. [Jazz Messages](https://jazzkeys.plan8.co/?msg=-MVYtMespmT9iNLyKnqO). Send notes to your friends in style with **j a z z**.\n\n## 2 things I’ve been wondering about\n\n1. What does it mean to find fulfilment in what you do? I've found myself involved with an overabundance of projects in the past year and only a select handful have truly been fulfilling to work on. I'm doing a bit of introspection in hopes of maybe figuring out why I love doing the things I love and maybe an answer to who I am.\n2. [What's not in the frame](https://www.youtube.com/watch?v=ZRZuEGuU_es). In which Hank talks about the [metaphorical 'frame'](posts/context-collapse.md), or the context in which people present themselves. People choose to present themselves a certain way in front of others and in doing so, leave a lot of what's *actually* going on outside the frame. If all we ever see are other people's frames, how do we remind ourselves of what's going on outside of it and normalize being 'out-of-frame'?\n\n## 1 thing I’ve done\nPretty slow month in terms of personal projects/pieces, mostly either working on patching up older projects (finally got around to updating [Docker Explained](https://github.com/jackyzha0/docker-explained)). I did end up finishing Working in Public: The Making and Maintenance of Open Source Software by Nadia Eghbal and found some really interesting ideas that I wanted to explore and flesh out a bit. I had a few convos with a friend on Twitter and ended up writing a piece on [why Open Source should be funded](posts/paid-open-source.md).\n\nStay tuned for next month(s) and don't forget to be awesome :)","lastmodified":"2023-02-15T01:38:21.169820744Z","tags":null},"/newsletters/issue-3":{"title":"Sun sneezing, infrastructure moderation, and why bikes are better than tricycles","content":"\nHello there and welcome back to another issue of some mildly coherent ramblings. It's been yet another couple busy weeks, but I've just wrapped up my second decade on this crazy planet! I have a lot of really exciting life updates that I want to share with all of you soon, but without further ado: the content you subscribed for.\n\n## 3 things I’ve found interesting\n\n1. [Context Collapse](https://www.rewire.org/context-collapse-online/). Follow up to last issue's ['What's not in the frame'](posts/context-collapse.md) question, I was finally able to put a name to a concept I've had floating around! The TLDR is the experience when all your different personalities or frames from different contexts (e.g. work, friend group, family) all intermingle. In a place where so many of your social groups intersect, it becomes difficult to decide how to behave or 'be yourself'.\n2. [Emergent Behaviour and Cellular Automata](https://www.youtube.com/watch?v=X-iSQQgOd1A). Mesmerizing video by [Sebastian Lague](https://www.youtube.com/user/Cercopithecan) on [how complex (and beautiful) behaviour can arise out of simple rules.](thoughts/emergent%20behaviour.md) I've been wanting to get into experimenting with shaders and graphics stuff and this *might* just be the slight nudge I needed.\n3. [Sun Sneezing](https://www.youtube.com/watch?v=e69XZJ9DEj0). When people ask me what I'm allergic to, my two answers are 1) pollen and 2) the sun. Yes, I sneeze when I look at the sun.\n\n## 2 things I’ve been wondering about\n\n1. [Moderation in Infrastructure](https://stratechery.com/2021/moderation-in-infrastructure/). I've been thinking a lot about [infrastructure](/thoughts/infrastructure). How do we draw the line between an end product and infrastructure? How should infrastructure regulate usage on its platform (if at all)? Been thinking about AWS's decision to remove Parler recently and whether it was warranted for AWS to do so. At what level of infrastructure should something become a '[public good](thoughts/public%20goods.md)'? As more and more of our digital infrastructure is built out under private companies, does it change how we govern content on top of it?\n2. [Are 'easy-to-use' products always better?](https://www.dougengelbart.org/content/view/348/000/) Interesting read about the 'seductive, destructive appeal of ease of use': the belief that \"ease of use\" is somehow conflated with better products. I always hear that complex tools and apps being not implemented because user research proved that it was 'too difficult to use' but is this costing us in the long run? One great example the article talks about is the tricycle/bicycle analogy. \"It is clear that for an unskilled user, the tricycle is much easier to use. But, as we know, the payoff from investing in learning to ride on two wheels is enormous.\" Related: [building tools around workflows](thoughts/workflows.md)\n\n## 1 thing I’ve done\n\nI spent some time last weekend rewriting the frontend of [ctrl-v](http://ctrl-v.app/), my open-source Pastebin clone to use Next.js instead of React + React Router! Wrote up a blog post on my process here: [https://blog.jzhao.xyz/posts/ctrlv-next/](/posts/ctrlv-next). The weather has been nice in Vancouver the past couple of days so I've had the chance to just go outside and read in a park which has been a really nice change of pace from my usual go-go-go-get-shit-done daily schedule. Looking forward to finishing up this semester, I have a lot of really cool projects I want to work in the next month and a bit!\n\nUntil next time, don't forget to be awesome :)","lastmodified":"2023-02-15T01:38:21.169820744Z","tags":null},"/newsletters/issue-4":{"title":"The bookstore with a single book, knowledge distillation, and tight feedback loops","content":"\nI am writing this newsletter edition as NYC is being bombarded by hail. The sounds of little balls of ice ricocheting off of the roof has a sort of din to it that feels oddly comforting? In any case, your (bi) monthly dose of links from yours truly:\n\n## 3 things I’ve found interesting\n\n1. [The bookstore with a single book.](https://www.takram.com/projects/a-single-room-with-a-single-book-morioka-shoten/) This is a tiny bookstore in Tokyo that sells a single book at a time in a small room. I really love the emphasis on getting to know a single book and author intimately -- especially in an age of [digital consumerism](thoughts/attention%20economy.md).\n2. [Beware of tight feedback loops.](https://brianlui.dog/2020/05/10/beware-of-tight-feedback-loops/) I've always believed that rapid [feedback](thoughts/feedback%20loops.md) is always necessarily good. Yet, Brian warns about relying too much on these tight feedback loops -- feedback in life is almost always noisy. Only focusing on rapid feedback can lead one to ignore the larger scale trends.\n3. [Why Algorithmic Systems Create Absurd Outcomes](https://ali-alkhatib.com/papers/chi/utopia/utopia.pdf) (or if you prefer the [video version](https://www.youtube.com/watch?v=6KLAa62h1E0). Loved how accessible this paper/video was in explaining some pretty complex topics. I've often found myself having trouble putting into words why 'big tech' and monopolies in general are bad other than the generic \"we need competition for innovation\" excuse and this humanistic approach really resonated with me.\n\n## 2 things I’ve been wondering about\n\n1. [The role of knowledge distillation.](https://distill.pub/2017/research-debt/) After finishing *The Making and Maintenance of Open Source Software*, I have been seeing parallels between software maintenance and systems of knowledge. So much emphasis nowadays is on creation rather than maintenance; it would be interesting to see if we can shift the emphasis from creation of new knowledge to maintenance of existing knowledge. I think there's lots of work that can be done to improve how we go about [distillation of knowledge](thoughts/knowledge%20distillation.md) through teaching and giving children agency to explore ideas (more on this in *Mindstorms*).\n2. [The double bind of developing tech.](https://en.wikipedia.org/wiki/Collingridge_dilemma) Still trying to wrap my head fully around this idea, but the main gist is that there are two opposing facts that seem to make developing tech ethically very difficult. The first is that it's hard to figure out what impact technology will make until *after* one develops and releases it to the public to use. The second is that regulating and/or changing technology is extremely difficult after the technology becomes entrenched within society. No thoughts on this yet, but just wondering if there's any way to get out of this [double-bind](thoughts/catch%2022.md) (or at least productively avoid it).\n\n## 1 thing I’ve done\nLots of change in my personal life too! I finally worked up the courage to cut out a few commitments from my life in an effort to reclaim some time to just explore some ideas I have + enjoy life in NYC :') Reach out if you're around!","lastmodified":"2023-02-15T01:38:21.169820744Z","tags":null},"/posts/2020":{"title":"2020: An Imperfect Palindrome","content":"\n## A year of 'almosts'\n2020 is:\n* about 9.5 times longer than a Rick Roll in seconds\n* about 54 times longer than the number of minutes I listened to Spotify this year\n* about how many contributions I made on GitHub this year\n* roughly the amount of pages I've read this year\n* almost a palindrome\n\nNow there's nothing super fascinating about almost-palindromes but it is also very fitting given the number of 'almosts' in my year. Here's an imperfect recollection of what I've been up to this year.\n\n### nwPlus\nI help to do event logistics at nwPlus! This year, Allison and Anne somehow convinced me to take on a director role for HackCamp (or what was previously known as UBC Local Hack Day). \n\nTo be completely frank, I had no clue what that really entailed and jumped into it head-first. Along the way, I struggled with figuring out how to effectively lead a team of 4 older teammates, balancing nwPlus with all my other commitments, and being confident in my work as director. We had a bunch of logistical wrenches thrown our way, from figuring out how to bring our hackathon to the virtual stage to and navigating an entire event rebrand. It was honestly amazing to have even been able to hold the event at all, let alone attract over 900+ registrations, 500+ attendees, 3.2k+ livestream viewers, and $1200 in donations to charities. To say I was completely blown away by the turnout would be a massive understatement. We didn't get to hold the in-person event we were hoping for, but the next-best thing was almost just as good.\n\n![Post-HackCamp feels](/posts/images/2020/post-hc.png)*Post-HackCamp Feels*\n\n### A poorly played game of Tetris\nDue to a combination of poor planning, luck, and FOMO, I made the poor decision to take on an internship at Hootsuite along with the open-source fellowship at MLH, all the while trying to juggle my mental sanity and health. Spoiler alert: it was a bad idea.\n\nMy calendar ended up looking a lot like a poorly played game of Tetris as I tried to stack hackathon onto after-work social onto tech talk. Unfortunately in this version of Tetris, there was no line clearing when I fully packed a week. You don't need more than two braincells to realize that a schedule like that just isn't sustainable. I was often working upwards of 80+ hours a week and I felt like death reincarnate. I think the lowest point of the summer was sitting on the couch after working an 8 hour day at Hootsuite followed by another 6 hours on fellowship things and realizing that I only had oatmeal in the morning. \"I should learn to play the ukelele.\"\n\nIn order to get through the summer, I had to develop healthier coping methods to deal with the stress, anxiety, and general lack-of-time-to-do-anything that came along with it. Though I by no means have claimed to have solved any of these things, I've found a few things to be really helpful in maintaining some semblance of mental sanity:\n\n1. **Time Blocking** -- COVID had eliminated any physical boundaries I already had; no 15 minute transit to separate work and home, no physical walk required to go from home to school. As a result, everything started to meld together. If it only takes me 3 clicks to go from my club meeting to my work tickets, I can just work just a little longer, right? I found that time blocking really let me regain a little bit of control back in my life. I could tell myself to only spend *x* hours doing *y*. It had the added benefit of allowing me to *actually block off time for myself* and to enjoy life a little bit.\n2. **Exercise** -- although I've known this fact for a while now, this is the year I've really decided to actually apply it to my life. Feeling like garbage? Go for a run to feel more like garbage for a good hour before feeling better! I've had the privilege of being really close to nature so I get to enjoy the subtle crunching of leaves and brisk autumn air with each step.\n3. **Quality time with quality people** -- 2020 was not a kind year to most, myself included and I'm not going to pretend otherwise. However, the presence of a select few individuals in my life really helped to make the year slightly less of a dumpster fire. You know who you are :')\n\n### Independent living\nI finally moved out from on-campus housing into my own place! I've definitely felt tinges of loneliness during the pandemic but I've learned to fill the silence with music, podcasts, reading, or questionable arts and crafts. I've also somehow managed to get by the past few months without giving myself food poisoning in my transition from campus food to homecooked food.\n\nNo fancy photos here but enjoy a few pictures of my workspace and the view from my balcony.\n\n![Home sweet 127.0.0.1](/posts/images/2020/home.png)*Home sweet 127.0.0.1*\n\n## An imperfect retrospective\nIt would be sort of naive to try to list out everything that went well/didn't go well this year. Too much happened this year to fully give each bit of my year the respect it deserves, so in the spirit of this 'almost' year, enjoy this 'almost' retrospective.\n\n### Things that sparked joy\n- **Surrounding myself with genuine people who care.**\n- **Picking up old hobbies and books** -- Heraclitus said, \"No man steps in the same river twice.\" The second time around, both man and river are different than they were before. The paints and books are the same, but we change between reads and brushstrokes. The world changes, too. I've found it really rewarding to be able to pick up old hobbies like watercolour, crocheting, and [reading](/thoughts/reading) and discover it for the second time.\n- **Exercising more and enjoying nature** -- not everyday you get to read during sunset at the top of a peak with some of your closest friends.\n### Things that didn't spark to joy\n- **Learning to block out time better** -- although I did improve on this, I've definitely told myself \"ah, another few hours couldn't hurt\" far too many times this year. I need to work on prioritizing my time more and saying no to things.\n- **Balancing intake and output** -- How does one balance learning/intake of information intake with processing and thinking about that information? This year felt like trying to drink information through a firehose and spitting it right back out using a paper straw. I'm trying to work on better processes for choosing what information to explore more and to spend more time thinking and marinating thoughts (see: [exploit explore](thoughts/exploit%20explore.md) tradeoff). [Tweet.](https://twitter.com/_jzhao/status/1328399991950307328)\n\n## Goal setting\nWhen [[thoughts/writing|writing]] up the first few drafts for this post, I realized that just having goals with cold hard numbers on them without any motivating reason feels very empty. I'm not setting these goals just to achieve some number, but rather to enjoy the act of doing it or to develop a habit. I had a conversation with [Emre](https://twitter.com/AlcaEmre) about this and he brought up Reversal Theory as a way to understand our motivations and goals. In particular, one of the four domains of Reversal Theory is the means-ends domain. Motivations in this domain lie somewhere on the telic to paratelic action scale.\n\n**Telic Actions** are more serious in nature, motivated by wanting to achieve something or reach a goal. This would be like writing an essay to get a good mark. Most telic actions are a means to an end rather than the actual end themselves.\n\n**Paratelic Actions** are more [playful](thoughts/play.md) in nature and involve enjoying the process in the moment. This is more akin to reading for enjoyment and for the pleasure of learning. Hopefully, these are the actual end goals that telic actions will help achieve. With that in mind, here are my 2021 goals!\n### Paratelic Goals\n- Acknowledging my privilege and use it to help those who are less fortunate\n- Have impact with my work, whether that be through writing, projects, or just conversations\n- Lead a more physically healthy lifestyle\n- Learn more about the world through a [feedback loops](thoughts/feedback%20loops.md) of reading, writing, and talking to people\n\n### Telic Goals\n- Donate 5% of pre-tax income to charity\n- Reach 50k people through projects and blog posts\n- Read 10 books\n- Set aside 10 hours a week for personal projects, learning, and writing\n- Be able to run from my apartment to Stanley Park and back (~10km) in one go\n- Have 1:1s with 50 new people in 2021\n\nI've been waiting almost 2 years to say this pun but,\n\n\u003e hindsight is 2020.\n\n(no I didn't plan on releasing this right at midnight, I just take a long time to write)","lastmodified":"2023-02-15T01:38:21.169820744Z","tags":null},"/posts/2021":{"title":"2021: A Letter to my Past and Future selves","content":"\n\u003e Have you been writing those letters to yourself?\n\u003e \"Dear Evan Hansen, This is gonna be a good day and here’s why.\"\n\nThis post comes to you in 3 parts: a letter to my past self, a reflection on goals, and a letter to my future self.\n\nOne reminiscent and nostalgic, one a neutral review, and the last a brutally honest dump of aspirations and feelings.\n\n---\n\n*To my 2021 self,*\n\nLittle do you know you'll start off the year making a charcuterie board of tofu, snowshoe trips with friends, and making a masking tape Christmas tree that still stands to this day.\n\n![](/thoughts/images/2021-collage-1.png)\n\nMaybe not the most usual start to a year but fitting considering the year that is ahead of you.\n\nYou tried lots of new things! Some you liked and some you didn't. It was full of meeting lots of really wonderful new people, [[thoughts/writing|writing]] lots, reading lots, getting incredibly digital-garden-pilled, and (admittedly) being on Twitter a bit too much. \n\nYou learned how to drive, maybe a few years later than usual, but hey you got it done. Not many people may trust your driving skills from New York but that's reasonable given the only thing between you and a license was a 7-minute long stroll down the road. In learning to drive, you spent some extended time with the family for the first time in a while and all of the pains and joys that brings.\n\nAnd maybe the most surprising of them all, you decided to say 'fuck it' and decided to move to a co-living house with 15 other people in New York for the summer. Let's just say you learned the importance of personal time pretty quickly. Yet, amidst the hustle-and-bustle of the millions in New York, you were able to find solace in the [books](/books), the parks, and the few close friends made. There is a really nice bench near the Guggenheim under a blooming Crabapple tree that sags *just* the right amount to be extra comfortable. I suggest bringing some nice bread and a book to spend a few afternoons here and really just bask in its serenity.\n\n![](/thoughts/images/2021-collage-2.png)\n\nLuckily, COVID calmed down enough in the second half of 2021 to be able to see old classmates again in-person for the first time. Being able to laugh at dumb jokes in the same room or just working in amiable silence may feel quite distant but I assure you it will happen and it will be just as good as you remembered it being.\n\nYou had cozy picnic dates, 20-person AirBnB rentals on Victoria Island, and a crazy hackathon all the way down in Austin, Texas. You and Anson finally celebrated your first anniversary together and, lo and behold, got each other the exact same thing. Disgustingly cheesy, you two.\n\n![](/thoughts/images/2021-collage-3.png)\n\nTo summarize, this was a year of understanding yourself and opening up to the world. You learned that, maybe, it wasn't so bad to be vulnerable and to express yourself in full to the people around you. You learned the joys of meeting wonderfully passionate people who talk about their craft with stars in their eyes and the deep gratitude of getting to more fully know the people you choose to surround yourself with.\n\nThe biggest part of this year were the friends and loved ones that stuck with me through the best and worst of it.\n\n\u003e \"Who are the people, ideas, and books that magnify your spirit? Find them, hold on to them, and visit them often.\" -- Maria Popova\n\nI hope you cherish these people and make sure they know just how much they are appreciated, and excited for you to live this year like I did.\n\nKindly,\n*Your present self*\n\n---\n\nI set a few goals at the end of my [last end-of-year reflection](posts/2020.md).\n\n- Donate 5% of pre-tax income to charity\n\t- I made a total pre-tax income of around ~30k and total donation amount tallying up to 2.2k to Project for Awesome, Asian Mental Health, Nonprofit Foundation, Heart and Stroke Foundation, and bootstrapping for the reflect apprenticeship.\n\t- There were a few times this year I felt stretched thin financially due to lack of financial planning. I don't regret giving though. I love giving in a way that feels local and impactful. I would be interested in expanding this to start a mini grants program using [Moth Minds](https://www.mothminds.com/) or something, but this would involve first improving my own financial management and budgeting :))\n- Reach 50k people through projects and blog posts\n\t- Done! Surprisingly prolific year in terms of [projects](thoughts/Projects.md) and writing. Got really into digital gardening and CLIs for a bit over the summer and even ended up doing a few [workshops](https://www.youtube.com/watch?v=1PFXBpJjjoc) too. Happy with the amount of technical growth that happened this year.\n\t- As a side note, it's been so so cool watching a little community grow around [Quartz](https://github.com/jackyzha0/quartz/network/members) and all the different types of people from all around the world giving it a chance to be a part of their daily workflow. (And all the growing pains that come along with open-source maintenance and community management)\n- Read 10 books\n\t- Actually pretty proud of this one! Not just because I crushed the number (18 whole books!! A whole 3x more than last year) but I felt like I had a really good diet of the different types of content I was consuming. Did a lot of online link collecting and book reading of both fiction and non-fiction. I found out that I surprisingly liked both dense academic text as well as soft scifi. I love the nuance and depth of takes that longer texts afford as well as the elaborate and at times poetic world building that happens in heavier fiction reads. I always remember reading under the covers with a flashlight because I wanted to finish the last book in a trilogy but lost that itch quite a while ago. Missing your bus stop because a chapter was just so good is not quite the same but close.\n- Set aside 10 hours a week for personal projects, learning, and writing\n\t- One particularly hard week in March ruined this streak unfortunately :((\n\t- Otherwise, I would consider this a success! This year, I had the wonderful chance of meeting some people who don't make me feel ashamed of but genuinely excited about niche [interaction design](thoughts/interaction%20design.md) reads, weirdly technical blogs, and [digital gardening](posts/networked-thought.md).\n\t- I feel like I finally have a group of people to just 'nerd snipe' each other and be ok with just sharing cool things I am working on. Eternally grateful to [curius.app](https://curius.app/), the whole gang at @verses, and the whole 'snipe city' group chat.\n- Be able to run from my apartment to Stanley Park and back (~10km) in one go\n\t- Sadly, the one actual physical goal I had I did not meet. In reality, I didn't take as good care of my body as I would've liked, often skimping on meals to get just a little bit more done.\n\t- I often blamed my weird class schedule for my lack of consistent physical activity this term but I know that that is no real excuse. I'm going to do better on this next year.\n- Have 1:1s with 50 new people in 2021\n\t- This is a goal that actually really surprised me as to how easy it became. When setting it, I surely thought that if there was one goal in this list I wouldn't meet, it would be this one. \n\t- At the start of last year, meeting people was not something I generally looked forward to. Yet, I found myself actually really enjoying each conversation after a while. Each call and meeting was a chance to quickly glimpse into the life of another, an offering of their incredibly valuable time in order to just *talk.*\n\t- To all 56 who offered just a little bit of your time to talk, I thank you. Many of my thoughts build off of our conversations and I am forever grateful for your thought-gifts.\n\n---\n\n*To my future self,*\n\nI am writing to you with the highs of new years optimism wearing off. *'Tis the time of new years resolutions!*\n\nMaybe it's the residual headache from the booster shot speaking or maybe its just me being a little tired but I hope you are doing well. More than anything I hope you are taking good care of yourself.\n\nI've never really written a letter to my self before, let alone one to my future self. I'm not quite sure what the tone of this piece is and quite certain that you will look back on this and laugh a little and just how bad it is.\n\nTo be honest, I know I've been saying that I'm working on being candidly excited about everything but I'm a little scared about the future.\n\nI care a lot about the people around me right now. These are an absolutely wonderful group of people who care about the world, endlessly curious, and inspire me to be better people. Yet it seems that everyone is headed in slightly different directions. I don't want to lose these people to a few measly miles and timezones. I really hope that, despite life choosing to move us in different paths physically, we'll be able to consciously choose to band together and stay close.\n\nI know it would be unreasonable to set super concrete goals given the whole *waves hand*. So I leave you not with a list of goals that I hope you will have accomplished, but a list of qualities I hope you'll have grown into.\n\n![My long term Bento](/thoughts/images/long%20term%20bento.png)*My long term [Bento](https://bentoism.org/)*\n\nI recently found out about the philosophy of [Bentoism](thoughts/Bentoism.md), a way of planning with a wider view of interests than just what we want right now, like our future selves, the people we care about, and the future of our children.\n\nI really like this way of thinking about self-interest as not just our current selves but as a community that spans across time. I've been thinking a lot about about what long-term success for me would look like. I don't think I've settled on anything concrete but there are certain aesthetics I would like it to embody:\n\n- I would like to be emotionally and physically well. I would like to be able to reach deep focus in whatever work I do and have the resources to be able to choose the work I find enjoyable.\n- I would like to be a great friend, family member, partner, and community member. I want to have the bandwidth to be generous to the people around me and the clarity to prioritize the important people in my life.\n- I want to be authentic and unabashedly excited about the world. I want to be able to help others create spaces of [local abundance](thoughts/play.md).\n- I hope you are ambitious in your dreams, projects, and [[thoughts/writing|writing]]. I want to embody a sort of [quiet confidence](https://www.spencerchang.me/experiments/100posts/quiet-confidence/) in my own abilities and interests.\n- I hope you are steadfast in the values you believe in, cherish the people around you, and grow into the person you've been wanting to become.\n\nTo concretize, I hope you end each day saying you've embodied these:\n- If it's not a FUCK YES, it's a no. We are not half-assing anything in 2022\n- Eat well, sleep consistently, and exercise often\n- Be intentional about the people you care about\n\nI hope you are honest with yourself. Be kind.\n\nKindly,\n*Your present self*","lastmodified":"2023-02-15T01:38:21.169820744Z","tags":null},"/posts/2022":{"title":"2022: A year lived earnestly","content":"\n*tw: abuse. This reflection serves as a sort of public journal entry. It talks about a lot of sensitive topics. If you choose to read, please do so with care and tenderness and treat it as if I shared it in confidence with you*\n\n![[thoughts/images/snowfall.png|400]]\n\n\u003e \"Yet I live earnestly, building the most beautiful sandcastles I can, knowing they will be washed away. And getting others on the beach to build with me, at times even suspending our belief of the fact that it will disappear; letting ourselves be fooled for a moment that it will last.\" [Source](https://altered.substack.com/p/dust)\n\n*To my 2022 self*,\n\nYou'll be pleased to know that I'm continuing the tradition of writing [[posts/2021|letters]] to you (myself?) every year! This letter in particular, took me a really long time to figure out how to write properly.\n\nYou get to spend the first part of the year in some truly beautiful places with some wonderful company. You start the year in Montreal with some close friends from Verses, doing everything from talking grand plans about what the web might look like in the future to soaking in an outdoor hot tub on a freezing day. Hold these people close, they are a wonderfully thoughtful and quirky bunch that will feel like one big extended family.\n\nBack in Vancouver, you convinced your friends to regularly make a trek down to the beach to enjoy sunset with you despite the hundreds of steps needed to get there. You became close with this little ragtag bunch and cried a bit when most of them graduated, knowing that it would be the last time you spend in close company for a while.\n\nFor perhaps the first time in your life, you felt a level of quiet confidence that allowed you to try something [[posts/the-fools-who-dream|foolish and new]]. This conviction brought you to the South Bay to live with a motley crew of people. You decide to do a spontaneous writing trip down in Monterey Bay, road-tripped from SF to LA, and even hosted a small [hackathon](https://twitter.com/thesfcommons/status/1559333852627079168) (I guess your days of event organizing never *truly* go away).\n\nThe theme, as you can probably tell, is [good company matters](https://www.youtube.com/watch?v=SzldFlBeGZo). These people will inspire you to look deeper and notice all the [[posts/casual magic|casual magic]] in the world. They indulge your childlike curiosities and help bring out your favourite parts about yourself.\n\n---\n\nBut, what's a story without a little plot twist? Life has a certain way of throwing wrenches into your well crafted plans.\n\nVisiting relatives for the first time in a while highlighted that certain people can also bring out the worst parts of yourself, sticking them out like welts on rotting skin. September to November happened to be periods of intense self-reckoning around your own self-worth as a person, friend, and partner.\n\nPeople who claim they love you will tear at the very quiet confidence you worked so hard to build up over the year. They claim to do things out of love, but refuse to learn the way you want to be loved. It's terrifying to realize that someone who claims to love you hurt you in ways that take advantage of that very fact. Sometimes the worst abuse happens under the guise of love and care.\n\nIt will exacerbate a lot of your anxieties around self-worth, trust, and will completely tank your physical and emotional wellbeing. I'll give you a heads up here and tell you that going to therapy didn't change things very much. There's not much they tell you that you don't already know. The real painful process here is learning to accept and move on from the fact that some people did some pretty fucked up things to you in the past. \n\nThere's not much you can do to change their mind, or fix them or whatever. But what *will* help is realizing that trying to change their behaviour is *not* your responsibility. You will come to realize that there is no rhyme or reason to their actions at times and the mental gymnastics they do to justify their actions are not for you to untangle.\n\nThe key realization that will really help you start to move on is to treat their voice like *a* voice, but not the only one that matters. I'll quote [[thoughts/In Over Our Heads|Kegan]] at length because I think he says it a lot better than I can.\n\n\u003e  Suppose you have a dog. A big-hearted, high-energy dog who begins to bark, and won't shut up, every time someone approaches your door. Now one day your dog starts into howling something first. He sounds a terrible alarm. You look out the window and it's just your friendly neighbourhood mailman. So what do you do? You aren't going to shoot your dog dead. He's a pain but you wouldn't think of it. Your dog loves you. He barks to warn you when *anyone* approaches. He wants nothing bad to happen to you. That's just how he is. Problem is, he's completely indiscriminate. He thinks everyone's a danger, barks at anyone who approaches... You're *going to have a look for yourself*. You're going to bend over and stroke your dog. 'Down boy,' you say. 'It's just the postman. No harm here, silly guy'\n\nIt sounds almost silly when its said out loud like this, but you will learn it with time. It's not a process that is super linear either. There will be days you break down and won't be able to leave the house, but it does get better.\n\nYou'll start to settle back into old rhythms with school and pick up the guitar. You also start going to the gym regularly again because, goddamn people were right when they said how much of a mood booster exercise was.\n\nYou will make it to the end of the year, finally at a point where you feel well enough to reflect on the past and start thinking about the future again.\n\n## Learnings\n1. A *yes* means nothing if you never say *no*.\n2. Learning is learning. If you spend five hours on a problem and can't figure out the answer, it doesn't mean you haven't learned, it means _you spent five hours learning_. Your brain has rewired and formed new attractor states, you've done necessary work, the activity you've done is called learning. ([Source](https://io0.github.io/))\n3. [[thoughts/50 pounds of pots|Make 50 pounds of pots]]. Quantity is the journey to quality.\n4. \"Choose joy. Choose it like a child chooses the shoe to put on the right foot, the crayon to paint a sky. Choose it at first consciously, effortfully, pressing against the weight of a world heavy with reasons for sorrow, restless with need for action.\" ([Source](https://www.themarginalian.org/2020/10/21/14-years-of-brain-pickings)) Choose joy because what you look for in life is what comes your way.\n\n## Looking forward\nUnlike last year, I think it would be a little silly to try to set rigid goals for myself. Some of my best moments this past year happened because I gave myself the flexibility, and free-time to do so.\n\nTo continue the trends of values I'd like myself to embody next year:\n\n- I would like to be emotionally and physically well. I would like to be able to reach deep focus in whatever work I do and have the resources to be able to choose the work I find enjoyable.\n- I hope you are ambitious in how you choose to cultivate spaces of joy and abundance in your life. \n- I hope you give yourself the grace and time to do things that bring you into company with good people. I would like to be a great friend, family member, partner, and community member. I want to have the bandwidth to be generous to the people around me and the clarity to prioritize the important people in my life.\n- I hope you continue to be someone who is mesmerized by the beauty of the world.\n\n![[thoughts/images/mesmerized by the beauty.jpg|500]]\n\nKindly,\n*Your present self*","lastmodified":"2023-02-15T01:38:21.169820744Z","tags":null},"/posts/a-failure-resume":{"title":"A Failure Resume","content":"\nSometimes, I feel like I don't deserve a lot of my current accomplishments and that I need to work even harder just to deserve what I have right now. I came across the concept of a **failure resume**[^1] a while ago. It's a list of things that didn't exactly go according to plan, and the lessons learned.\n\nThe more I think about it, the more I realize that a failure resume a showcase of failure in and of itself, but also a document of all the spectacular ways you've worked hard towards your own goals and accomplishments. In many ways, it *validates* your struggle and your effort.\n\nI've recently been inspired by both Kate Huang[^2] and Joice Tang's[^3] failure resumes and decided to make my own. Rather than focusing on the individual failures themselves, I want to focus on what I learned from each of them. \n\nThis document has served as a powerful reminder to myself of how much I've struggled to get to where I am and why I deserve to be here. And more importantly, it serves as a place to reflect and learn from the past and be less scared of failure in the future.\n\nKeeping a failure resume has let me be so much more ambitious in trying new things and applying for things I would otherwise think I'm unqualified to apply for.\n\n## 2022\n\n- Rejected from Agency Fund's Social Impact Fellowship\n- Finding it extremely difficult to apply for grants for my independent research. Got rejected from Emergent Ventures which I thought I was most likely to get funding from which is extremely dejecting. More thoughts in my [[thoughts/Rhizome Research Log|research log]].\n- Rejected from [Thinking Microgrants](https://twitter.com/sariazout/status/1571871089713680386)\n\t- *Candidly, given the volume of applications I was not able to spend more than 30 seconds on each. I am certain there were many wonderful candidates that were overlooked.*\n\t- There are just so many other similar people looking for grants !! Feels more luck of the draw than anything with this volume of applicants\n- Questioning my own self-worth as a writer and engineer\n\t- The more time I spend in school, the more I feel that I am actually very average in terms of writing/engineering, especially amongst my peers. I think I'm able to still achieve a lot that others find impressive is because things that come easy to me -- like working on projects or writing in my spare time -- are things that others find difficult/hard to commit to.\n\t- Especially with grading, I feel like I'm consistently being told my thoughts/words are not good by different people and it gets in my head sometimes. I wonder if I am just bad at writing/thinking about these things!\n\t- But on the other hand, there are clearly a handful of people who *do* like my writing and how I think about these things, conduct my work, etc.\n\t- I know the rational brain take is to accept that there is and always will be people better and that it's *completely okay* to not excel in everything but my emotional overthinking brain can't help but to feed the negative self-talk\n\t\t- For now, what is keeping it at bay is reassuring myself that the work I am doing is significantly better than it was in the past. I am improving and the work I am doing is fulfilling.\n\n## 2021\n\n* Stopped sending out newsletter issues :(( Ended up focusing more on longer form [[thoughts/writing|writing]] instead\n* Ghosted by both Contrary Build and Contrary Fellowship\n* Couldn't work up the courage to apply to the [Maintainers Summer Fellowship](https://themaintainers.org/summer-fellow)\n\t* I really love the work that the Maintainers org is doing and this internship would have combined so many things that I'm interested in and passionate about: maintenance, writing, software, infrastructure, etc. I just couldn't convince myself that I wouldn't have made a fool of myself by applying :(\n* Had to cut out a bunch of commitments in order to maintain mental sanity\n  * While this isn't a 'failure' in the traditional sense, it was a failure for me in terms of setting good boundaries for myself. I had been spending way too much of my 'free' time working for projects and commitments I wasn't 100% interested in. I missed being able to just dedicate an afternoon to tinkering and exploring an idea so I decided to make the leap and cut down on commitments. **If it's not a hell yes, it's a no.**\n* Rejected from the Delta Fellowship\n* Rejected from ZFellows after they reached out to 'learn more' about my idea\n* Rejected from the Y. P. Heung Foundation Award\n  * This scholarship is awarded to someone who demonstrates outstanding academic performance and is involved with community activities. I thought that, despite my slightly-above-average grades, I had a decent shot at this award given my involvement with the CS community at UBC but things didn't turn out the way I wanted. This award would've helped alleviate the financial stress that comes with having to pay tuition out-of-pocket, so I'll need to work a bit more for that money.\n\n## 2020\n\n* Rejected from an undergraduate TA position for a CS course\n  * I really wanted to give TA-ing a shot, especially after hearing almost all friends' positive experiences with it, so I decided to apply to TA a class I had done well in. It was a good reality check to realize that there's more to being a TA than just good grades and the title. Next time I apply, I'll find a course that I'm really passionate about and get to know the prof better.\n* Didn't finish 3 of the projects I wanted to finish over the summer\n  * I think I really just tried to commit to too many things this summer and spread myself really thin \u0026mdash; I'm still working on learning how to say no!\n* Ghosted by a professor for an undergrad research position\n* Rejected from a lot of grants and incubator programs for reflect\n  * We took the shotgun approach by applying to as many grants as possible but ended up realizing that were just applying to grants for the sake of applying, rather than having a good reason for why. It was a really good catalyst to reflect (pun intended) on what we wanted reflect to be and what direction to take it in the future.\n* Rejected by DeepMind (and 67 of the 70 companies I applied to)\n  * This position rejection hurt more than most \u0026mdash; even if it was swift and abrupt. DeepMind is a company that has played a huge part in shaping my interest of the intersection of machine learning, ethics, and philosophy, so you can imagine that the rejection email was not a pleasant sight to see in my inbox.\n\n## 2019\n\n* Rejected by 46 of the 47 companies I applied to\n* Practiced data structures/algorithms for a few months only to completely blank on final round phone interviews\n  * Though I agree that the technical interview process is broken, I think there are still some lessons that can be learned. I suck at thinking under pressure so I'm going to learn to improve this by trying to keep my practice environment as similar to the real thing as possible. In this case, doing mock interviews with friends rather than just blindly grinding away at LeetCode.\n* Got a 52% on an honours math midterm\n  * It was an extremely difficult course but it really changed how I think about math and problem solving overall. I doubt I would've been able to learn those lessons in a regular math course. Even if the actual marks I got in the course were subpar at best, I think the lessons I learned were worth more than the GPA dent.\n* Rejected by Hack the North (despite being on their website ???)\n  * Sometimes even when all the cards seem to be in your favour, things just don't work out. There's a factor of luck in everything \u0026mdash; dont take things for granted!\n* Got charged an excess of $350CAD in cloud computing costs because of bad architectural decisions\n  * Ouch, this one really hurt the wallet. Learn to estimate costs in advance, and don't overengineer if you don't need to! Keep it to the simplest and most minimal viable product possible until you're ready to scale it. If it doesn't need huge infrastructure, don't design it that way!\n\n## 2018\n\n* Rejected by 16 of the 17 universities I applied to\n  * This was a good reality check \u0026mdash; the real world is difficult. Sometimes, what you offer may not be what the universities are looking for and thats ok! I think what matters more is what you do, not where you do it.\n* Rejected from a bunch of scholarships\n* Applied to speak at TEDxRedmond but got rejected at the last round\n  * I ended up learning a lot about my topic (ethics in AI and machine learning) through preparing for my speech. Even if I never got the chance to actually go up on stage and see it, the subject still ocassionally comes up in conversation and makes a great talking point! I think its super important to be educated on this, especially as our world becomes increasingly dominated by AI and machine learning.\n* Gave up on my DroneNet project after running out of money to work on it and little to no progress for multiple months\n  * This was my first **real** long term project and probably the project that got me really invested in the field of CS. I learned a lot about how to scope out and plan larger scale projects and how to stay motivated for long stretches of time.\n\n[^1]: [New York Times](https://www.nytimes.com/2019/02/03/smarter-living/failure-resume.html)\n[^2]: [Kat Huang's](https://www.katmh.com/fail/)\n[^3]: [Joice Tang's](https://www.notion.so/failure-resume-5e67efb72dfe4f4896bc812ed94dc098)","lastmodified":"2023-02-15T01:38:21.169820744Z","tags":null},"/posts/ai-systems":{"title":"Machines and Intelligence","content":"\nThis blog post is adapted from a term paper I wrote for PHIL250: Minds and Machines at UBC. I hope you enjoy the post and learn as much as I did in writing it!\n\n---\n\n## Introduction\nHistorically, development of AI has taken a very specific approach \u0026mdash; systems that represent the world through symbols and manipulate those tokens in a systematic way to arrive at a result. This type of AI was coined Good Old-Fashioned AI (GOFAI) by John Haugeland[^1]. \n\nThis worked well up until around 1984 when the field entered an 'AI Winter', a long plateau in progress that was most likely due cynicism in the AI research community that trickled to media and [funding](thoughts/funding.md) bodies, halting research and development[^2].\n\nHowever, with the rise of Moore's Law and the insane amount of compute and data available, a new approach to the development of AI arose \u0026mdash; one that focused on statistical methods and connectionist networks like artificial [[thoughts/neural networks|neural networks]][^2]. Haugeland[^1] dubbed this approach to AI design New Fangled AI (NFAI).\n\nThis paper will examine factors that differentiate GOFAI and NFAI systems, such as their ability to adapt to changes in input, and the explainability of their outputs and internal representations. It will also examine current work in integrating the two approaches to Artificial Intelligence to create an artificial general intelligence.\n\n### GOFAI Systems\nSince the inception of the term GOFAI, the basic idea has remained unchanged: thinking as internal symbol manipulation. Within these GOFAI systems, symbols are representative of aspects of our world. These symbols are manipulated in a systematic and logical matter, performing a series of deterministic steps that results in another sequence of symbols[^1].\n\nA very common example of GOFAI systems are expert systems, which are computer systems that emulate the decision making ability of a human expert[^3]. They solve problems via decision-tree reasoning, figuring out whether to perform certain actions based off of if-then rules.\n\nHowever, just being able to solve a problem shouldn't be sufficient for intelligence. So what qualifies it? At its core, GOFAI can be considered 'artificially intelligent' because of semantic interpretation. If the symbols represent aspects of our world, the result, which is also a symbol sequence, can be *translated* back into aspects of our world. This is called semantic interpretation, which \"seeks to construe a body of symbols so that what they mean ('say') turns out to be consistently reasonable and sensible, given the situation\"[^1]. \n\n### NFAI Systems\nNFAI, on the other hand, is a diverse and still rapidly evolving set of systems and algorithms. It is more of a grab-bag term, roughly meaning any sort of scientific mind design that is not GOFAI[^1]. Under this umbrella are connectionist networks, which are networks composed of lots of simple units that are interconnected with various strengths. This paper will mostly focus on connectionism as a synecdoche for the greater umbrella of NFAI.\n\nSome classic examples of connectionist networks include convolutional [[thoughts/neural networks|neural networks]] (CNNs), which are a form of image classifiers[^4]. These networks operate by applying filters or kernels to an input between layers of the network. Each of those filters have their own set of strengths that will learn and evolve over time to identify certain 'features' from the input. Similar to cell assemblies in animal perceptual systems, these filters assemble more complex patterns using smaller and simpler patterns[^5].\n\nThese connectionist networks are very inspired by the structure of the brain, with its hierarchical patterns and compositional nature[^6], rather than the rational manipulation of symbols that is observed in GOFAI.\n\n## The Potemkin Village Analogy\nWhile it is obvious that GOFAI and NFAI are very different approaches to constructing AI systems, how do they differ in their resilience to failure? An analogy that may be useful in visualizing this is a [potemkin village](thoughts/potemkin%20village.md) \u0026mdash; a fake village that is built to resemble and deceive others into thinking it is real. AI systems attempt to build a sort of 'potemkin village' that \"works well on naturally occurring data, but is exposed as fake when one visits points in space that do not have high probability\"[^7].\n\nGOFAI systems are excellent at \"processing syntactical patterns like those characteristic of logical formulae, ordinary sentences, and many inferences\"[^1], but are also very narrow-minded and vulnerable when it comes to unexpected variations or oddities in the input given. The potemkin village that a GOFAI system may construct will hold up if only seen from the intended angles, but any slight deviation from an intended or expected input would shatter the illusion immediately.\n\nNFAI systems, on the other hand, are \"adept at finding various sort of similarities among patterns, at recognizing repeated (or almost repeated) patterns and filling in missing parts of incomplete patterns\"[^1]. These also happen to be the exact things that GOFAI systems struggle with. The potemkin village that a NFAI system may construct will hold up much more robustly to unexpected patterns or noisy input, but will, at heart, still be a fake village.\n\n## Rationality and explainability\nIn GOFAI systems, [intentionality](thoughts/intentionality.md) \u0026mdash; the meaning and semantics behind the tokens \u0026mdash; is injected through explicit programming by those who create it. These GOFAI systems are able to process these tokens and make conclusions based off of logic and reason rather than just trial-and-error. Case in point, expert systems. These if-then statements can easily explain decisions by showing which parts evaluated as true or false in its decision making process[^3]. \n\n[Connectionist networks](thoughts/connectionist%20networks.md), for the most part, are very hard to explain and are often dubbed black-box models due to the hidden nature of its internal workings. Unlike GOFAI systems, its internal representation model is defined by the state of the entire network rather than that of any single unit \u0026mdash; this is commonly referred to as a distributed model of connectionist representation[^8] and is often claimed to be one of the distinctive features of connectionism.\n\n## Models of [representation](thoughts/representation.md)\nTo put it in sound terminology, note while in the GOFAI system, the *tokens* are the objects of formal processing, so the system which manipulates the tokens is the actual vehicle of computation. The tokens themselves are also *representations* of aspects of the world, so they are also vehicles of mental content. In GOFAI systems, tokens are both the vehicle of computation and the vehicle of mental content.\n\nThis is in contrast with connectionist systems, where computation is performed at the level of simple units (unit activations, backpropagation), meaning the units are the vehicles of computation. However, as these systems use a distributed model of representation, it is not a single unit that represents something, but rather the \"network state as a whole thats interpreted as representing\"[^8]. Thus, in connectionist systems, the vehicles of computation (units) need to be the vehicles of representation (network state).\n\n## Integrating GOFAI and NFAI\nGiven that GOFAI and NFAI systems seem so vastly different in their approaches to AI, how might one go about reconciling them?\n\nOne approach is to combine both into one system. This is used when there’s a rational, known, and algorithmic way to process a subproblem. Systems like AlphaZero, a connectionist based Go playing system, use mixed systems to achieve the level of performance they report. Although at heart, AlphaZero uses a deep neural network to assess new positions, it also uses a Monte Carlo Tree Search (a GOFAI algorithm) to determine its next move based of the assessment of the neural net[^9].\n\nAnother, less researched method, are interpretable connectionist systems. As traditional connectionist networks rely on the network state being the vehicle of representation, the complexity, depth, and scale of modern connectionist models means that it is becoming increasingly difficult for humans to interpret the output. The field of [explainable](thoughts/explainability.md) AI (XAI) focuses on incentivizing connectionist networks to develop localist representations (i.e. moving away from having the vehicle of representation be at the network level, but at the unit level). Zhang, Wu, and Zhu of UCLA recently showed that it is possible to train a CNN to use 'interpretable filters', which encourage networks to group feature detectors into single filters, showing the possibility of moving from distributed representations to more local representations[^5].\n\n### What is AGI?\nWhile intelligence can be understood in many ways, this paper will focus on examining the prospects of emulating or achieving the capacity to understand or learn anything a human can \u0026mdash; the hallmark of an artificial general intelligence (AGI).\n\nMost commentators would agree that current AI systems fall short of implementing general intelligence[^4]. These are narrow AI systems, which are used to accomplish or solve specific tasks like the game of Go or language translation, rather than to attempt to create a system capable of AGI. So, what's stopping us from making the transition from domain-specific algorithms to domain-general algorithms?\n\nOne problem that stumped earlier attempts at AGI was the *common-sense problem*: how do we represent common-sense information that is obvious to most humans in a way that is accessible to AI systems that use natural language? Unsurprisingly, the problem of storing all of this information was solved by the massive explosion in compute and data in the past few decades[^2]. However, the difficult part of this problem, choosing what subset of that huge information bank is relevant in any situation, remains a huge unsolved problem. How do we update our database of knowledge when relationships between symbols change? This is referred to as the [frame problem](thoughts/frame%20problem.md).\n\n### Dissolving the frame problem\nDreyfus[^10] posits that any AI systems which attempt to tackle the frame problem through storing relevant frames are bound to failure. He argues that, \"human beings do not simply store common-sense information,\" rather they \"directly perceive and act upon significance in their environment\". In his view, a more Heideggerian approach to AI will dissolve this problem.\n\nHeideggerian AI, in its most basic sense, is concerned with \nthe Heideggerian concept of Dasein, which literally means 'Being-there'[^11]. Through the use of this expression, Heidegger calls to attention the fact that a human cannot exist or be taken into account without existing in [context](thoughts/context.md) of a world with other things \u0026mdash; \"to be human is to be fixed, embedded, and immersed in the physical, literal, tangible day to day world\"[^12].\n\nDreyfus believed that, for any AI system to achieve any sort of general intelligence, it must also exhibit Dasein. Thus, \"a successful Heideggerian AI would need a perfect model of the human body – and by implication, that Dasein must be expressed as a human being, organically as well as existentially\"[^10].\n\n### A non-humanistic approach\nHowever, Steed refutes Dreyfus' overly humanistic interpretation of Heideggerian AI, believing that a AI model only needs to be \"embedded and embodied such that what AI experiences is significant for AI in the particular way that AI is,\" and thus intelligence would be possible by Heideggerian standards[^13].\n\nThe refutation against a purely anthropocentric view of AI brings to light an important concept: the [multiple realization](thoughts/multiple%20realization.md) argument. Emulating or copying human intelligence isn't the only way to achieve intelligence that rivals that of humans.\n\nContemporary AI systems are almost always used as a problem solving tool, a means to tackle uniquely human problems and to convey results that are semantically useful to us. As a result, these approaches are doomed to be constrained by human problems. This is the essense of the [bitter lesson of AI](thoughts/multiple%20realization.md). However, if we look outside the anthropocentric view of intelligence, AI systems may not share these human problems with us and \"perhaps an authentic, free AI system does not converge to a solution that is interpretable from a human standpoint at all\"[^13]. \n\nAI is already capable of learning, adaptation, and basic Being-in-the-world. Thus, to achieve general intelligence, we should allow AI to contemplate its own problems and existence.\n\n[^1]: Huageland, John. (1996). *What Is Mind Design?* Mind Design II, doi:10.7551/mitpress/4626.003.0001. \n[^2]: Hendler, J. (2008). *Avoiding another AI winter.* IEEE Intelligent Systems, (2), pp. 2-4.\n[^3]: Jackson, Peter (1998). *Introduction To Expert Systems* (3 ed.). Addison Wesley. p. 2. ISBN 978-0-201-87686-4.\n[^4]: Buckner, C. (2019). *Deep learning: A philosophical introduction.* Philosophy Compass, 14(10), e12625.\n[^5]: Zhang, Q., Nian Wu, Y., \u0026 Zhu, S. C. (2018). *Interpretable convolutional [[thoughts/neural networks|neural networks]].* In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 8827-8836).\n[^6]: Churchland, P. (1990). *Thinking: An invitation to cognitive science.* Vol. 3., pp. 199-228.\n[^7]: Goodfellow, I., Shlens, J., \u0026 Szegedy, C. (2014) *Explaining and harnessing adversarial examples.* ArXiv Preprint ArXiv: 1412.6572.\n[^8]: Crane, Tim. (2003). *The Mechanical Mind.* doi:10.4324/9780203426319. \n[^9]: Silver, D., Hubert, T., Schrittwieser, J., Antonoglou, I., Lai, M., Guez, A., ... \u0026 Lillicrap, T. (2017). *Mastering chess and shogi by self-play with a general reinforcement learning algorithm.* arXiv preprint arXiv:1712.01815.\n[^10]: Dreyfus, Hubert L. (2008) *Why Heideggerian AI Failed and How Fixing It Would Require Making It More Heideggerian.* The Mechanical Mind in History, pp. 331–362., doi:10.7551/mitpress/9780262083775.003.0014. \n[^11]: Solomon, R. (1972), *From Rationalism to Existentialism: The Existentialists and Their Nineteenth Century Backgrounds*, Harper \u0026 Row, New York.\n[^12]: Steiner, G. (1978), *Heidegger*, The Harvester Press Limited, Sussex\n[^13]: Steed, R. (2019). *AI is Heideggerian Enough, But Can It Be Authentic?* Unpublished manuscript, Carnegie Mellon.","lastmodified":"2023-02-15T01:38:21.169820744Z","tags":null},"/posts/bft-json-crdt":{"title":"Building a BFT JSON CRDT","content":"\n![[thoughts/images/bft-crdt-cover.jpg]]\n\nCRDTs are a family of data structures that are designed to be replicated across multiple computers without needing to worry about conflicts when people write data to the same place. If you've ever had to deal with a nasty `git` merge conflict, you know how painful these can be to resolve.\n\nCRDTs mathematically guarantee that an application can *safely* update their local state without needing to coordinate with all of its peers. By avoiding the extra coordination overhead, they have very good latency properties and work well in scenarios where real-time collaboration is needed (e.g. text editing, presence, chat, etc.).\n\nOver the past few years, really cool open source CRDT libraries like [Automerge](https://github.com/automerge) and [Yjs](https://github.com/yjs/yjs) have emerged that enable developers to easily add these replicated data types to their own applications. Their support for JSON means that most web-applications can just plug-and-play, enabling collaborative experiences to be created easily.\n\nWhat normally would have taken weeks or months of engineering to setup infrastructure for a collaborative web experience can be done in a day, bringing us one step closer to a future where the internet feels more default-multiplayer, cozy, and alive with life.\n\nI learn best through building so I set out to write [my own CRDT library from scratch](https://github.com/jackyzha0/bft-json-crdt) to grok what was going on under the hood. When I was first learning about it, I spent a good few months scratching my head trying to read the papers. A lot of the literature took a long time for me to understand and required me to learn a non-trivial amount about [[thoughts/Order theory|order theory]] and [[thoughts/distributed systems|distributed systems]].\n\nI write this blog post mostly as a note to my past self, distilling a lot of what I've learned since into a blog post I wish I had read before going in. I hope you find this useful too.\n\nAs a brief warning, the target audience of this blog post are people who have worked with a bit distributed systems in the past and is curious about the realm of CRDTs. I try my best to explain any relevant terminology when it comes up but familiarity with the topics helps a lot!\n\n*This blog post is really long so use the Table of Contents at the top to jump to whatever section interests you the most!*\n\n## How CRDTs differ from traditional databases\nBefore we really dive into CRDT internals, we first need to understand how they are different from databases. When I normally think of shared state, I think of databases. However, the guarantees that databases provide are *really* different than the ones CRDTs provide.\n\nTraditional databases focus on a property called [[thoughts/consistency|linearizability]], which guarantees that all operations behave as if executed on a *single copy of the data*. We call this canonical view the **primary site**. Every read in a linearizable system, no matter what database node you read from, gives you an up to date value.\n\n![[thoughts/images/linearizability.jpg]]\n\nThis is great for allowing developers to reason about distributed applications more easily (you just treat your distributed database like a single database). There are no conflicts by definition because there is only one authoritative view on what the right state is.\n\nHowever it isn't without downsides either. Achieving this property adds a lot of overhead because both writes *and reads* need to coordinate (the dashed lines in the diagram above) across all database nodes to ensure consistency. This creates an availability problem: if you can't reach a majority of your nodes, you can't process any operations.[^1]\n\n[^1]: There are ways you can mitigate this by 'predicting' a successful outcome. However, if the actual write/read fails, we may need to rollback what the user sees which is not ideal from a user experience perspective\n\nCRDTs kind of throw all of that out the window and embrace the eventual nature of the real world. In an often cited essay titled *[[thoughts/A Certain Tendency Of The Database Community|A Certain Tendency Of The Database Community]]*, the author argues that trying to provide “single system image” semantics (read: [[thoughts/consistency|linearizability]]) is fundamentally flawed and at odds with how systems operate in the physical world. [[thoughts/the garden and the stream|The garden and the stream.]]\n\nIn the real world, it takes time for us to learn about things that are happening around us and around the world. It takes time for our mail to send, calls to go through, and light to travel between servers across the world. We can take inspiration from the real world and embrace a design that considers every member in the system as the primary site for the data that it generates.\n\nThis means we allow peers to actually have different states as long as they *eventually* converge to a correct result. By relaxing the constraint on needing a globally consistent result, we remove the need to wait for all of our replicas to agree. In more formal distributed systems language, we trade linearizability for a property called **strong eventual consistency**:\n\n- All updates will *eventually* reach every node\n- Every node that has received the same updates will have the same state\n\n### When should we use strong eventual consistency over linearizability?\nIt turns out that this is good enough most of the time. [Conventional wisdom](https://databeta.wordpress.com/2010/10/28/the-calm-conjecture-reasoning-about-consistency/) in the database world would agree that perfect data consistency is way too expensive in terms of both latency and bandwidth if changes happen frequently. Using eventually consistent approaches generally work better as temporary inconsistencies work out in most cases.\n\n\u003e Two users might simultaneously withdraw money from an account and end up with more money than the account ever held. Would a bank ever want this behavior? In practice, yes. An ATM's ability to dispense money (availability) outweighs the cost of temporary inconsistency in the event that an ATM is partitioned from the master bank branch's servers. In the event of overdrawing an account, banks have a well-defined system of external compensating actions: for example, overdraft fees charged to the user.\n\u003e \n\u003e from *[Eventual Consistency Today: Limitations, Extensions, and Beyond](https://queue.acm.org/detail.cfm?id=2462076)*\n\n## What actually is a CRDT\nOk so after about 1000 words, you're probably asking \"wtf is a CRDT??\". Maybe we should define that now.\n\nCRDT stands for conflict-free/commutative/convergent replicated data type. Funnily enough, there is no strong consensus on what the C actually stands for[^2]. Regardless of the name, the tldr; is the same:\n\n[^2]: NB: there is actually two main subtypes of CRDTs. [[thoughts/CRDT#Operation-based|CmRDTs]] or commutative replicated data types are based off of exchanging messages which contain single operations. [[thoughts/CRDT#State-based|CvRDTs]] or convergent replicated data types send their whole state. They are also sometimes called operation-based and state-based CRDTs respectively. The rest of this blog post assumes CRDT to mean operation-based CRDTs.\n\n- You can write and read from your local copy of the data without needing to coordinate with other peers\n- Over time, all nodes converge to the same state by sending each other state modifications/updates they have performed on their local data\n\t- Because of the eventual nature of message delivery, there is no guarantee that the state across all the actors are consistent at any given moment\n\t- **If the CRDT is written properly, a view of a CRDT can only ever be out-of-date, but never incorrect**\n- Each operation contains the necessary metadata to figure out a deterministic way to merge any operations that may happen concurrently\n\t- I'll note here that the term 'conflict-free' is a little misleading. **It's not that conflict doesn't ever occur, but rather that CRDTs are always able to determine how to resolve the conflict up front** (without user intervention)\n- CRDTs always try to preserve user intent and try not to lose data whenever possible\n\t- If two people insert a character into a string at the same spot, it will try to keep both edits\n\t- Note that these is inherently *different* from consensus methods. Collaboration involves keeping *all* edits and merging them. Consensus involves picking one of several proposed values and agreeing on it\n\nAgain, CRDTs are a *family* of data structures. There is no one single CRDT. You can make CRDTs that produce single values (registers), lists, maps, graphs, JSON, and many more I haven't listed here. However, they can't represent everything. A fundamental limitation here is that there are certain types of data structures (like sets) that *cannot* be made into CRDTs[^3]. We'll talk more about these limitations later.\n\n[^3]: The [[thoughts/CALM Theorem|CALM Theorem]] states that anything that is logically monotonic (read: append-only) can be made into a CRDT.  Non-monotonic things may 'retract' previous statements.\n\nNow equipped with a 30,000ft overview of CRDTs, let's dive into how they resolve conflicts.\n\n### Ordering Messages\n\u003e A small note: this part will be pretty heavy on theory. If that's not your cup of tea, you can just assume that there exists a way to order operations and skip to the section titled *Intuition behind CRDTs*\n\n![[thoughts/images/message-ordering.jpg]]\n\nThere is a whole branch of math focused on how to order things called [[thoughts/Order theory|order theory]]. In the case of message ordering, we want to define some way to compare messages such that no two messages are considered chronologically equal (in academic terms, we define a total ordering). If we can do so, we've mathematically avoided conflicts. So how do we do that?\n\nYour first intuition may be to just use clocks. However, it would be naive to just randomly trust two different clocks from two different machines. Clocks can drift out of sync, leap seconds happen, and users can change their system time. Keeping time is famously hard.\n\nIf we can't trust actual clocks, what can we do? Well, we can use Lamport timestamps. These track *logical time* rather than actual wall time, meaning we count number of events that have occurred rather than seconds elapsed.\n\nThis timestamp is just a simple counter. For the rest of the blog post, we refer to this counter as the sequence number `seq`.\n\n- All nodes start their counter at 0\n- Everytime we perform an operation locally, we increment our counter by one\n- Everytime we broadcast a message to our peers, we attach this counter\n- Everytime we receive a message, we set our timer to `max(self.seq, incoming.seq) + 1`\n\nIf `a.seq \u003e b.seq` then event $a$ must have happened after event $b$. However, if `a.seq == b.seq`, we cannot be sure which event came first. This means that Lamport timestamps only give us a partial ordering, which means two identical sequence numbers might not correspond to the same unique event. For example, both nodes could emit an event with `seq = 1` even though they are different events.\n\n![[thoughts/images/duplicate-seq.jpg]]\n\nThankfully, we can actually create a total ordering of events in a distributed system by using some arbitrary (but deterministic) mechanism to break ties. For CRDTs, if we give each node a unique ID, we can actually tie-break on this ID to provide a deterministic way to order concurrent events.\n\nIn pseudocode, we can create a comparison operation that looks something like the following:\n\n```rust\n// We assume this is unique for every node\ntype AuthorID = u8;\n\n// A lamport timestamp\ntype SequenceNumber = u8;\n\n// A CRDT Operation\nstruct Op\u003cT\u003e {\n\tauthor: AuthorID,\n\tseq: SequenceNumber,\n\tcontent: Option\u003cT\u003e\n}\n\n// Compare based off of sequence number\n// If there's a tie, tie-break on unique author ID\nfn happens_before\u003cT\u003e(op1: Op\u003cT\u003e, op2: Op\u003cT\u003e) -\u003e bool {\n\top1.seq \u003c op2.seq ||\n\t\t(op1.seq == op2.seq \u0026\u0026 op1.author \u003c op2.author)\n}\n```\n\nOrdering solved!\n\n### Causality\nOr so we thought... Let's think about when it is safe for us to apply an operation that we have received locally.\n\n![[thoughts/images/safe-operation.jpg]]\n\nSay that the largest sequence number we know of is 3. We receive an operation with sequence number 5. We know that we are missing the operation with sequence number 4. Can we still deliver 5?\n\nIf 5 does not causally depend on 4, then we actually can still safely apply this operation.\n\nBut we can't figure out this causality information from just sequence numbers alone. If an event A causes another event B to happen, then `a.seq \u003c b.seq`. However, we **don't know the converse**. That is, if `a.seq \u003c b.seq`, we cannot say that A caused B to happen.\n\nIt turns out the fix for this is actually quite easy. As we have a unique way of identifying each operation, we can just send along a list of operations it causally depends on. That way, if we receive a message and we know we've received all of its causal dependencies, it should be safe to deliver.\n\nIf we receive a message where we *haven't* received all of its causal dependencies, then we can add it to a queue so that when the message does get delivered, we can apply it afterwards. In the above example, if message 5 marked 4 as a causal dependency, it would wait until 4 was delivered before also applying 5.\n\nThis means that as long as we declare the right causal dependencies, we can make certain things that don't seem commutative (like list operations) actually commute.\n\n### Intuition behind CRDTs\nOkay enough about theory, how do we actually go about making a CRDT?\n\nLet's survey what we have at our disposal so far (our assumptions):\n- We can reliably send messages between peers\n- We have a total ordering on the messages so we don't get any conflicts\n- We have some way of indicating causal dependencies\n\nThis gives us an ever-growing pile of messages that are deemed 'safe' to apply. Here is probably a good time to make a distinction between the data in the CRDT itself and the view of that data.\n\n- The data itself are the operations that are coming in\n- The view is the data structure we compute from it (and what applications end up seeing)\n\n```rust\nstruct CRDT\u003cT\u003e {\n\tdata: Vec\u003cOp\u003cT\u003e\u003e,\n}\n\nimpl\u003cT\u003e CRDT\u003cT\u003e {\n\t// modify self.data to include op\n\tfn apply(\u0026mut self, op: Op\u003cT\u003e);\n\n\t// traverse self.data to produce the data structure\n\t// we're actually interested in (a list in this example)\n\tfn view(\u0026self) -\u003e Vec\u003cT\u003e;\n}\n```\n\n![[thoughts/images/crdt-apply-view.jpg]]\n\nSpecifically, we never[^4] delete any operations from the internal data representation. The best we can do is mark them as deleted using a [tombstone](https://en.wikipedia.org/wiki/Tombstone_(data_store)). Because a peer could technically reference any past operation as a causal dependency, we need to keep that metadata around.\n\n[^4]: Garbage collection + rebalancing technically requires achieving [[thoughts/consensus|consensus]] on nodes in order to do this. \"So, as far as I know, we would need a consensus protocol attached to the CRDT in order to get garbage collection / compaction.\" [(#2)](https://github.com/ipfs-inactive/dynamic-data-and-capabilities/issues/2)\n\nOf course, we can't go about willy-nilly trying to model every data structure this way. We can only have CRDTs of data structures which have invariants that **do not depend on knowing the most up to date version of the data structure**. From before, CRDTs are always guaranteed to have a correct state, but they may not have the most up-to-date value. This means that receiving any new operations should never break a CRDTs invariants.[^5]\n\n[^5]: This is formulated in a more formal manner in  [[thoughts/I-Confluence]]\n\nAn example of something that CRDTs cannot model is an account balance that never decreases below zero. Say that you have $100 in an account. You spend 70 on your laptop and another 40 on your phone at the same time. Without waiting on the other transaction to arrive, there is no way for the CRDT to know whether these are valid! Even though both transactions are valid on their own, when done concurrently, they decrease the value to a negative value. Thus, CRDTs cannot model anything that requires maintaining **global invariants**.\n\n### List CRDTs (RGA Explained)\nThis seems to lead us to the biggest problem in the room: list CRDTs.\n\nWhen you think of the API for a list, most operations are normally done by indexing. But isn't this a global invariant? Don't we need to know what other operations have been done to the list to figure out what the index of each character is?\n\nThis is not an easy problem to solve. It may also be a reason as to why the vast majority of CRDT projects focus on lists or text editing (which is essentially a list of characters). Luckily for us, some smart people have figured it out for us so we can look to what they've done for inspiration.\n\nThe key insight here is that instead of using relative addressing (e.g. positional indexing), we can use absolute addressing (e.g. using IDs).\n\nEvery time we insert an element into the list, we need to know the ID of the character we are inserting after. Then, we just place it somewhere between that element and the element following it.\n\nSo instead of saying “insert ‘A’ after the character at position 4” we say “insert ‘A’, with ID `5`, and insert it after the character with ID `4`”. This matches our intuition for how text editing happens anyways. When we imagine inserting text, we are inserting it *after* something. It wouldn't make sense to insert the character \"a\" of \"cat\" before we insert the character \"c\".\n\nWe can imagine saying that \"c\" *caused* \"a\" which caused \"t\". Conveniently, we can encode this causality by making the causal parent of each item the character it was inserted after. Remember causal dependencies? Yeah those. \n\n![[thoughts/images/rga-explained.jpg]]\n\nThis forms a sort of *causal tree* and this is effectively how RGA, a list CRDT, structures its data internally. Let's modify our `Op` to match that:\n\n```rust\ntype OpID = (AuthorID, SequenceNumber);\nstruct Op\u003cT\u003e {\n\tid: OpID,\n\torigin: OpID, // causal dependency\n\tauthor: AuthorID,\n\tseq: SequenceNumber,\n\tcontent: Option\u003cT\u003e,\n\tis_deleted: bool // tombstone as we can't actually remove items\n}\n```\n\nWhen inserting a character we\n\n1. Find the origin (causal dependency). If it doesn't exist, we queue it up for later.\n2. Starting at this node, all of its siblings were inserted concurrently. We look through the list of siblings until we reach a node that we are greater determined by the happens-before comparison we defined[^6]. Recall that we sort operations first by their sequence number then tie break by the author ID.\n\n![[thoughts/images/rga-insert.jpg]]\n\nIn the example above, `'s'` has `'a'` as its causal origin. Thus, we look at where to insert it in the list of children of `'a'`. As `'t'` and `'b'` both have smaller sequence numbers, we skip past these. Both `'s'` and `'p'` have a sequence number of 5 so we tie-break on the `AuthorID`. As 1 \u003c 2, we insert `'s'` between `'b'` and `'p'`.\n\nTo get the actual list this CRDT represents, we perform an in-order traversal over the tree and only keep nodes that are not marked as deleted.\n\n[^6]: NB: performance enthusiasts will be quick to point out how to make this go faster. This is a terribly unbalanced tree. On average, it takes $O(n)$ to find the origin and another $O(n)$ to insert into the tree. There are clear optimizations to be made here. [Yjs](https://github.com/yjs/yjs) uses a doubly-linked list for a faster insert. They also use a cursor to track the last ~5-10 visited positions. It makes the assumption that editing patterns are *not* random (which is true for most applications). [Diamond Types](https://github.com/josephg/diamond-types) and the new [Automerge](https://github.com/automerge/automerge-rs) use a range-tree to achieve $O(\\log n)$ find and $O(\\log n)$ insert\n\n## Adding Byzantine Fault Tolerance for free (almost)\nUp to this point, the CRDTs we've covered all work in trusted scenarios. These are scenarios in which you *know* all of the people participating and you trust them to not screw up the system for everyone else. For example, in a collaborative text document, you may limit collaborators to immediate colleagues who you trust to run the CRDT algorithm correctly and not attempt any funny business.\n\nHowever, most of the interactions we have online are not in trusted scenarios. Luckily, we have servers to help mediate these interactions, dictate what is and what isn't possible. Peer-to-peer systems, on the other hand, cannot rely on nodes always behaving the way the designers of the system intended. Here, we would like to be able to guarantee that the system continues functioning correctly even in the face of some nodes crashing, failing, and even acting maliciously.\n\n![[thoughts/images/byzantine-node.jpg]]\n\nThe CRDTs we have been exploring so far do not work in these untrusted scenarios. That is, any one node can do something bad and cause state to diverge permanently. Not good.\n\nTo be more concrete, here are some examples of what a malicious actor can do:\n- Send malformed updates\n- Not forward information from honest nodes (an eclipse attack)\n- Send invalid updates\n\t- Messages that have duplicate IDs\n\t- Send incorrect sequence numbers (an equivocation attack)\n\t- Claim to be another user\n\nIdeally, we want to adapt our existing CRDT algorithms to be resistant to these attacks while still allowing honest nodes to continue business as normal. This would allow us to use CRDTs in untrusted environments which opens up the door to lots of cool applications like games, social, and more.\n\nTo borrow a term from distributed systems, we want to make our CRDTs [[thoughts/Byzantine Faults|Byzantine fault-tolerant]].[^7] The 'Byzantine' part of the name comes from the Byzantine Generals Problem, a situation where, in order to avoid catastrophic failure of the system, the system's actors must agree on a concerted strategy, but some of these actors are unreliable and potentially malicious.\n\n[^7]: For those coming from a more traditional distributed systems context, I will clarify that BFT means something different from a consensus context. Traditionally, this means getting some $n-f$ nodes to agree on a particular value. However, because CRDTs focus more on collaboration than consensus, we just want to prevent Byzantine actors from disrupting the *functioning* of the system. Byzantine actors can still send a bunch of 'valid' updates that may be unwanted. Imagine you sent a Google Docs link to a group of people and one of them is mucking around and inserting a bunch of images and removing information from the document. These would all be considered 'valid' operations in the sense that a 'correctly' functioning node could have done the same thing.\n\nNotation wise, we denote the total number of nodes in the system $n$. We denote the number of faulty/Byzantine nodes $f$. Most consensus algorithms claim a tolerance of up to $f \u003c \\frac n 3$, which means they can tolerate up to [[thoughts/33% Impossibility Result||33% of the nodes being faulty]]. However, CRDTs require an even weaker bound. Remember that we are not trying to achieve consensus! All we really need to do is make sure that Byzantine actors can't interrupt honest nodes from functioning properly.\n\nIn fact, we can reduce this to a problem called [[thoughts/Byzantine Broadcast|Byzantine Broadcast]]. Dolev-Strong, back in 1983, showed that it was possible to tolerate up to $f \u003c n$ faulty nodes! This means that, as long as there are honest nodes and they are connected to each other, they can still function properly.[^8]\n\n[^8]: See notes on the [[thoughts/PSL-FLM Impossibility Result]]. We use a [[thoughts/Public-key Infrastructure|PKI]] assumption to get around this result.\n\nKleppmann detailed an approach in his paper *[Making CRDTs Byzantine Fault Tolerant](https://martin.kleppmann.com/papers/bft-crdt-papoc22.pdf)* that works without changing the internals of most CRDTs; it can be fully retrofit on top of it. We can create a 'BFT adapter' layer between the transport and application layer that is responsible for filtering out any Byzantine operations.\n\n![[thoughts/images/bft-layer.jpg]]\n\nThis approach has two major components we need to grasp:\n- How we ensure Byzantine nodes don't tamper with messages and pretend to be someone else (hashes + signed message digests)\n- How we ensure messages don't get blocked from reaching honest nodes (eager reliable causal broadcast with retries)\n\n### Hashes as IDs and Signed Message Digests\nSo here's a little trick we can do. Our only requirement for operation IDs is that they uniquely identify a node. We can generate this ID by SHA256 hashing parts of the operation:\n\n```rust\n// Set the ID to the hash of its contents\npub fn set_id(\u0026mut self) {\n\tself.id = self.hash_to_id()\n}\n\n// SHA256 computation over an operation\npub fn hash_to_id(\u0026self) -\u003e OpID {\n\tlet fmt_str = format!(\n\t\t\"{},{},{},{},{}\",\n\t\tself.origin, self.author, self.seq, self.is_deleted, self.content\n\t);\n\tsha256(fmt_str)\n}\n```\n\nThen, to check if an operation is valid, we can just hash the contents again and see if it matches the ID. If a Byzantine actor tries to change any of these properties while trying to pass it off as a different ID, there will be a hash mismatch.\n\nHowever, how can we be sure that a Byzantine actor hasn't just pretended to be someone else? After all, they could just create an operation, set the author field to someone else, then hash the content so that there is no mismatch between hash and ID.\n\nLuckily, we can use [[thoughts/Asymmetric Key Cryptography|public key cryptography]] to help us out here. Each node has a private key they keep to themselves. Earlier, we also mentioned that each node should have a unique identifier. We can actually use the public key of each node as its `AuthorID`.\n\nThen, whenever we send a message to another peer, we hash `op.id` to create a digest, and then sign it with our private key. This way, we can verify that the person who signed the message is the actual author. \n\n![[thoughts/images/op-hashing-process.jpg]]\n\n```rust\n// Create a digest to be signed\nfn digest(\u0026self) -\u003e [u8; 32] {\n\t// note that self.dependencies here is *different* from self.origin\n\t// this will allow us to indicate causal dependencies *across* CRDTs\n\t// which we will cover in more detail later\n\tlet fmt_str = format!(\"{},{},{}\", self.id(), self.path, self.dependencies);\n\tsha256(fmt_str)\n}\n\n// Sign this digest with the given keypair\nfn sign_digest(\u0026mut self, keypair: \u0026Ed25519KeyPair) {\n\tself.signed_digest = sign(keypair, \u0026self.digest()).sig.to_bytes()\n}\n\n// Ensure digest was actually signed by the author it claims to be signed by\npub fn is_valid_digest\u003cT\u003e(op: Op\u003cT\u003e) -\u003e bool {\n\tlet digest = Ed25519Signature::from_bytes(\u0026self.signed_digest);\n\tlet pubkey = Ed25519PublicKey::from_bytes(\u0026self.author());\n\tmatch (digest, pubkey) {\n\t\t(Ok(digest), Ok(pubkey)) =\u003e pubkey.verify(\u0026self.digest(), \u0026digest).is_ok(),\n\t\t(_, _) =\u003e false,\n\t}\n}\n```\n\nOk great! We now have a unique way to identify both peers and operations. But there is one more thing here that is a little pesky to deal with: mutability.\n\nWhen we create references to operations in this internal representation (e.g. we need to declare a causal dependency), we expect that the `OpID` of an operation stays *static* throughout its lifetime. However, because we now set `OpID` to be the hash of the content, updating a node would change its `OpID` all the time!\n\nDoes this mean we have to give up hashing the message content for fault tolerance? Fortunately not! There is one tiny hack that allows us to still use this hashing approach.\n\nInstead of making a copy of the original operation and just changing the content (which would cause the operation to be considered invalid by our hash check!), we can produce an *entirely new* operation that has the original ID as a causal dependency. These 'modification' operations don't actually get included in the internal representation of the CRDT, rather they modify it directly.\n\nWe can look to our list CRDT for an example. This `delete` function produces an entirely valid operation. This also makes sense from a causality perspective, we need to have delivered the original before trying to delete it!\n\n```rust\n  fn delete\u003cT\u003e(\u0026mut self, id: OpID, keypair: \u0026Ed25519Keypair) -\u003e Op\u003cT\u003e {\n\tlet mut op = Op {\n\t\tid: PLACEHOLDER_ID,\n\t\torigin: id, // the actual operation we are deleting\n\t\tauthor: self.our_id,\n\t\tseq: self.our_seq + 1,\n\t\tis_deleted: true,\n\t\tcontent: None,\n\t\tsigned_digest: PLACEHOLDER_DIGEST,\n\t};\n\top.id = op.hash_to_id();\n\top.signed_digest = op.sign_digest(\u0026keypair)\n\tself.apply(op.clone);\n\top\n}\n```\n\nWhen we apply it, we treat these modification events differently from insertion events. We look for the origin and just update its deleted field.\n\nWith that small problem solved, we know that our operations are now tamper resistant!\n\n### Eager Reliable Causal Broadcast and Retries\nNow, we just need to make sure that there is a way to get messages between honest nodes such that Byzantine faulty nodes can't block it.\n\nThe easiest (and probably most naive) way to do this is through eager reliable broadcast:\n\n1. Each time a node receives a message with an `OpID` it has never seen before, it re-broadcasts that message to all its peers it is connected to\n2. If we have been missing a causal dependency for a while, occasionally ask our peers if they have it\n\nThis makes sure that as long there is a connected subgraph of honest nodes, they can all still communicate.\n\n![[thoughts/images/connected-components.jpg]]\n\nHowever, there are a lot of potential optimizations to make here. It may be reliable but we broadcast $O(n^2)$ messages for each actual operation. This is really expensive and may flood the network!\n\nThankfully, we can take inspiration from `git` to figure out how to do this more efficiently. Kleppmann, again, mentions this approach in *Making CRDTs Byzantine Fault Tolerant*. \n\n\u003e Using cryptographic hashes of updates has several appealing properties. One is that if two nodes $p$ and $q$ exchange the hashes of their current heads, and find them to be identical, then they can be sure that the set of updates they have observed is also identical, because the hashes of the heads indirectly cover all updates. If the heads of $p$ and $q$ are mismatched, the nodes can run a graph traversal algorithm to determine which parts of the graph they have in common, and send each other those parts of the graph that the other node is lacking.\n\nThis project does not include this more advanced hash graph reconciliation but it is a direction for future work.\n\n## A JSON CRDT\nOk, we've seen now how we can create a Byzantine Fault Tolerant list CRDT. How can we make a JSON CRDT out of this?\n\nNormally with JSON CRDTs, we just have a bunch of nested CRDTs.\n\n- Values are LWW registers\n- Lists are RGA lists\n- Maps are lists of key-value pairs\n\nEach nested CRDT also keeps track of its path (e.g. `inventory[0].properties.damage`) so that when CRDTs produce an event, this information is also included. This ensures that peers know how to route a message to the right CRDT.\n\nHowever, we have to be careful about how we store this path. We can't naively just use the index into the list as we saw earlier how this is unstable. A small workaround here is having the `OpID` be the index.\n\nAdditionally, in addition to the `origin` field, we added a `dependencies` field. The distinction between the two is that the `origin` field is for same-CRDT causal dependencies whereas the `dependencies` field allows for cross-CRDT dependencies. This is important if we want, for example, an inventory update to be causally dependent on a LWW register CRDT update.\n\nThere is one last challenge to account for: JSON has no schema; data types can change! For example,\n\n- A sets `\"a\": [\"b\"]`\n- B sets `\"a\": {\"c\": \"d\"}`\n\nHow do we resolve this? The way Automerge and Yjs resolve this is by essentially using a multi-value register: they keep both values and punts the responsibility to the application choose the right answer.\n\nBut wasn't the whole point of CRDTs that there is no conflict? With most applications, allowing users to set arbitrary JSON is not actually desirable. We can somewhat mitigate these problems by allowing the application developers to define a fixed schema ahead of time and validating all operations through this[^9].\n\n[^9]: As pointed out by [Bartosz Sypytkowski](https://twitter.com/Horusiath), this assumes that the schema is static and never changes, which may be not the case in many practical scenarios. Additionally, because of the nature of CRDTs, schema updates may be acknowledged by peers in different points in time. This is an ongoing area of research\n\n### Putting it all together into a crate\nWhat if we took advantage of the type-safety and metaprogramming abilities of a language like Rust to automatically derive these strict-schema BFT CRDTs from programmer-defined data structures?\n\n```rust\n#[add_crdt_fields]\n#[derive(Clone, CRDTNode)]\nstruct Player {\n\tinventory: ListCRDT\u003cItem\u003e,\n\tx: LWWRegisterCRDT\u003cf64\u003e,\n\ty: LWWRegisterCRDT\u003cf64\u003e,\n}\n\n#[add_crdt_fields]\n#[derive(Clone, CRDTNode)]\nstruct Item {\n\tname: LWWRegisterCRDT\u003cString\u003e,\n\tsoulbound: LWWRegisterCRDT\u003cbool\u003e,\n}\n```\n\nAfter 5000 words of writing, I present to you the `bft-json-crdt` Rust crate. By using the provided CRDT types, programmers can instantly add CRDT functionality to their project.\n\nThere is a clear boundary between BFT and non-BFT operations as distinguished by data types to make sure that you don't accidentally apply an operation to the wrong place.\n\n```rust\n// initialize a new CRDT with a new keypair\nlet keypair = make_keypair();\nlet mut base = BaseCRDT::\u003cPlayer\u003e::new(\u0026keypair);\nlet _add_money = base.doc.balance.set(5000.0).sign(\u0026keypair);\nlet _initial_balance = base\n\t.doc\n\t.balance\n\t.set(3000.0)\n\t.sign(\u0026keypair);\n\nlet sword: Value = json!({\n\t\"name\": \"Sword\",\n\t\"soulbound\": true,\n}).into();\n\nlet _new_inventory_item = base\n\t.doc\n\t.inventory\n\t.insert_idx(0, sword)\n\t.sign_with_dependencies(\u0026kp1, vec![\u0026_initial_balance]);\n\n// do something here to send _new_inventory_item to our peers\n// and on a remote peer...\nbase.apply(_new_inventory_item)\n```\n\nFinally, I want to leave a word of warning. This is **not a production ready library by any means**. Although I do think this is a very solid proof of concept to demonstrate the potential of BFT CRDTs, it was still first and foremost for educational purposes.\n\nI do not consider myself to be proficient at Rust so there might be lots of bad code smells/mistakes sprinkled throughout (please do [PR](https://github.com/jackyzha0/bft-json-crdt) if you have any fixes/suggestions)!\n\n## Future directions for CRDTs\nThe field of CRDTs is still quite young. I really think there is a lot of promising work being done in exploring how CRDTs can be used to enable collaboration on the web.\n\nJames Addison has been working on creating a [real-time 3D engine using CRDTs](https://twitter.com/JungleSilicon/status/1592022670044205058). Projects like [BLOOM](http://bloom-lang.net/) work on trying to figure out at compile time what parts of program state require coordination and what parts don't.\n\nI'd love to see more exploration of CRDTs applied to games and other real-time things. I think there's a lot of really cool work to be done with interpolation *between* operations. Think [GGPO](https://www.ggpo.net/) or [perfect-cursors](https://github.com/steveruizok/perfect-cursors/) but for general CRDTs.\n\nI hope that this blog post is a jumping point for new people interested in the space to really get their hands dirty and see what they can do with this technology. Again, checkout the codebase if you are interested in the internals and feel free to try to tackle anything under the 'Further Work' heading in the [README](https://github.com/jackyzha0/bft-json-crdt/tree/main)!\n\n## Acknowledgements\nIf you are still reading by this point, I want to give you a huge thank you.\n\nThis was probably the most technically difficult project I've ever attempted, let alone finished. I felt like my conviction in my own abilities was tested multiple times and I can say I came out of the other side a better engineer. Thank you to the people who supported me as I struggled and stumbled around while trying to figure this project out.\n\nThere are a few people I'd like to thank individually. Thank you to [Anson](https://www.ansonyu.me/) for listening to my long and incoherent rambles and celebrating my small wins. Thank you to [Scott Sunarto](https://twitter.com/smsunarto) and [James Addison](https://twitter.com/JungleSilicon) for proofreading. Thank you to [Nalin Bhardwaj](https://nibnalin.me/) for helping me with my cryptography questions and [Martin Kleppmann](https://martin.kleppmann.com/) for his teaching materials and lectures which taught me a significant portion of what I've learned about distributed systems and CRDTs.","lastmodified":"2023-02-15T01:38:21.169820744Z","tags":null},"/posts/bias-bug":{"title":"On AI's 'Bias Bug'","content":"\nThis blog post was originally intended to be a TED Talk given at TEDxRedmond but I unfortunately was never accepted. However, I did learn a lot in the process of writing it, and I hope you get some value out of it even its presented through just text.\n\n---\n\n## Hey Google\nTake a picture in 5 seconds. Say cheese!\n\nSee that? This is just one of many examples of where AI is becoming a larger part of what we accept as normal. What seemed far-fetched and straight out of science fiction a few years ago is now becoming a reality. \n\nToday, tech giants deploy AI to dictate what we see, hear, buy – even feel and think. They control what kind of news we see every morning, suggest places to go, and even drive our cars. In order for us to have a healthy relationship with this technology, we have to adapt as quickly as it is advancing. In doing so, we need to ask ourselves: what kind of decisions AI should be allowed to make?\n\n### What kind of decisions AI should be allowed to make?\n\nSure, most of you in the audience may be comfortable letting an AI decide what kind of music to add to your Spotify playlist, but when an AI needs to decide what kind of jail time a criminal should face we all get a little squeamish.\n\nIn fact, let me give you a few examples of decisions that AI make every single day and see whether you would be comfortable with an AI making that same decision.\n\n![An AI-based breast cancer detector in action](https://3.bp.blogspot.com/-BCz28oA5THs/W7_1x671dkI/AAAAAAAADXg/h6OcOZnRZl0vN8mw02gNVcwglJTqE87bwCLcBGAs/s1600/image1.png)*Google AI Blog, 2018*\nWould you be comfortable with an AI helping doctors to identify cancerous tumours?\n\n![A game of Survival of the Best Fit](/posts/images/bias-bug/hiring.png)*survivalofthebestfit.com*\nHow about an AI helping companies decide who to hire based on only your name, age, gender, and resume?\n\n![Chihuahua or muffin?](https://media4.s-nbcnews.com/j/newscms/2016_10/1008761/chihuahua-muffin-today-160311-tease-02_15277fe1b7a8c911f94700f866189fc2.social_share_1024x512_center.jpg)*@teenybiscuit*\nThe classic image detection example: are these chihuahuas or muffins?\n\n![A modified version of the trolley problem](https://miro.medium.com/max/1400/1*dCk2Jns5Deg4Y2O6KBcuzA.jpeg)*Illustration: Simon Landrein*\nHow about the trolley problem? Should a self-driving car \u0026mdash; given no other option \u0026mdash; kill A) the child or B) the elderly person?\n\nAs you can see, there is a really obvious difference each of those decisions that were proposed. In the tumour example and chihuahua example, you likely weren't super bothered if an AI were to make that decision. Yet for the hiring example and the self-driving car example, you likely were more uncertain.\n\n### Why the uncertainty?\n\nWhat we can see from this is that there is a difference between objective and subjective problems. In the tumour and chihuahua examples, we were mostly comfortable with that decision being made because there is a clear ‘right’ or ‘wrong.’ However, in the case of the hiring example and self-driving car example, the subjectivity makes it difficult. A lot of it has to do with what kind of environment we were raised in and how each of us sees the world. Everyone is born with some kind of bias, favouring certain ways of viewing the world.\n\nAI can do a lot of really great things such as helping doctors identify tumours or interpret the world for the deaf. But when used improperly, that subjectivity can propel some of the worst biases we have as humans.\n\n## Garbage in, garbage out\n\nThere’s a timeless saying “garbage in, garbage out” in the field of Computer Science which essentially states that bad data or bad input will produce an output that’s of equal quality. This holds true for almost all the tech we use today, from trading algorithms to search results. If what we put into the system is inherently unclear or flawed, then the output will also give back something that’s ‘wrong’ or doesn’t align with our objectives.\n\nHowever, this saying “garbage in, garbage out” is most prevalent in the AI which sits at the forefront of this tech revolution. AI, in one form or another, is still created by humans, who are imperfect, make mistakes, and are inherently biased.\n\nInterestingly, there are two distinct ways that this bias can shine through.\n\n### 1. Problem definition\n   \nThe first is in the problem definition. When creating an AI, we need to define an objective for it. That means putting something vague like “create a realistic human-sounding voice” or “help me translate this speech to French” into definitive, and certain terms and mathematical concepts. How do we do that? Because we don’t have algorithms that do this step for us, this is usually done by a team of machine learning engineers. They are responsible for deciding how to represent our ‘objective’ in terms of penalties and rewards. This also means that how the team of engineers decide to represent the problem is a product of their biases. \n\nTake Amazon for example. In 2014, Amazon decided to create a recruitment engine that was able to look at a job applicant and rate them from a one-star rating to a five-star rating. However, by 2015, Amazon realized that their software was not evaluating candidates for positions related to tech in a gender-neutral way[^4]. Although unintentionally, Amazon’s engineers included a gender field. The algorithm, after sifting through 10 years worth of resumes, began to favour men and penalize women. After deeper inspection, this was most likely an unfortunate reflection of the male-dominated tech industry. The lesson is clear. The algorithm served to reflect this bias that was observed in the past.\n\n### 2. Lack of Data Diversity \nThe second, less obvious way bias can poison AI is with [data diversity](thoughts/data%20distributions.md) \u0026mdash; or rather the lack of it. I think the best way to explain this is through a metaphor. Imagine the AI as a small child. It likes to learn from its environment. If this child were to be raised in a racist family, it will almost undoubtedly hold similar views in the future. This is a very similar case for AI. It learns from the environment and data it's given.\n\nOne case of this is the very first iteration of Google Photo’s image classification feature back in 2015. This feature claimed to be able to identify people, places, and things with high accuracy. Twitter user [@jackyalcine](https://twitter.com/jackyalcine/) found that the algorithm identified people with darker skin as gorillas[^3]. Google quickly was able to work and manually ‘patch’ the issue, but the actual issue was much deeper – and it had to do with the data used. In this case, the dataset that Google used to train their algorithm had an over proportional amount of middle-aged Caucasian people under the category of ‘people.’ This meant that while the recognition accuracy was really high for that select group of people, the accuracy for people of colour was significantly worse. \n\nFrom both cases, we can see that an over-focus on results and accuracy can cause these companies to ignore these [biases](thoughts/bias.md). When the deadline is too tight or the manager sets an expectation for a “10% increase in accuracy,” there is a very strong incentive to ignore the ‘edge cases’ or things that happen very rarely.\n\nToo often our society is focused on the raw accuracy that we forget that the same accuracy metric is something that we set for ourselves – created arbitrarily by humans which have bias. Unfortunately, this results in things like the Google Photos and Amazon Hiring cases.\n\n## Fairness in AI\nTruth is, data lacks [context](thoughts/context.md). While the trends in the data may show that in the past there have been more men in the women in the workforce, the majority of the population can agree that we are moving away from that more traditional view into more of an equal playing ground. Unfortunately, these models that we create don’t have a deeper understanding of these changes and as a result, produces naïve predictions that we believe are wrong or ‘garbage.’ But is it really? Is it really only a ‘bad’ result because of what we define as fair or right?\n\n![COMPAS exhibiting bias against those of African descent](https://static.propublica.org/projects/algorithmic-bias/assets/img/generated/methodology-risk-of-recidivism-scores-by-race-900*363-482d1c.png)*ProPublica, 2016*\n\nWe can take a look at the COMPAS system which is a piece of software used by U.S. courts to assess the likelihood of a criminal to reoffend. ProPublica, a non-profit newsroom, did an investigation back in 2016[^1] and claimed that COMPAS was biased against those of African descent \u0026mdash; citing that it overestimated the false positive rate of reoffending for those of African descent by almost twice as high as those for Caucasians. ProPublica reasoned that a fair algorithm would not have such a big difference.\n\n### So, is COMPAS fair?\nWell, there’s no concrete answer.  The algorithm never had any access to any contextual information about the neighbourhoods or the actual situation for each of the offenses. Was the area more heavily policed because it was a predominantly black neighbourhood? Were the officers themselves biased in making arrests?\n\nEven more interestingly, a study done at Dartmouth[^2] showed that random volunteers, when given the same information as the COMPAS algorithm, achieved a nearly identical accuracy of identifying the rate of recidivism.\n\nThis is interesting. This means that either COMPAS is accurate or holds the exact same biases as we do as a society. Unfortunately, this is a problem that I don’t think we can solve, so we don’t have a solid definition as to what makes an algorithm fair. But what is clear, is that there is bias in play here, whether that be through the police, the companies, the actual algorithm, or society itself. This bias is what causes that “subjectivity” and “garbage in.” This is what is preventing us from making ‘fairer’ AI and applying AI to more tasks.\n\n### The inevitability of bias\nThe point is, unless we work to prevent, catch, and deter bias, it will inevitably occur. One of the biggest problems in the field of AI is that so many of the models exist in a black box, meaning that its inner workings are only known by a select few. This makes it near impossible to identify and train out bias. Machine intelligence will become almost integral to our lives, becoming less visible in the process, and AI’s bias bug will get harder to beat. Our time to act is now.\n\n## What we can do\n\u003e So? What can we, as the next generation, do to help?\n\nFirst, we need to build a [better understanding](thoughts/explainability.md) of how the AI systems we are building work. Through this understanding, we can better [trust](thoughts/trust.md) and, as a result, effectively manage the emerging generation of AI. So, don’t be afraid to learn that programming language you heard about. Read up on how that cool translation algorithm works. \n\nSecondly, we need to diversify. Diversify not only in the sense of having better representation in datasets, but in tech. Next time you pitch a new product, or create a new project, ask yourself this:\n\n\u003e “How many people have you considered before you make that decision?”\n\nLet's [design for everyone](thoughts/Design%20Justice.md). Consider people of different ethnic groups, sexualities, income, just to name a few. By having more representation in these teams, AI can cater to more than just that select group of people who are western, educated, and rich. Instead, by bringing in a fresh perspective on the problems that these teams are trying to tackle, they can create innovation that benefits a whole range of communities. \n\nWith increased diversity and representation, the Google Photo misidentification problem never would have happened. Together, we can help to build a future where diversity is no longer an issue in both machine learning models and tech, but society too. Where we don’t just use AI mindlessly but understand it and use it in such a way that it helps to empower humanity. Where we can work towards a future where we can begin to trust the more subjective decisions that an AI can make.\n\nTogether, we can make that future a reality tomorrow. Thanks for coming to my TED talk (unironically this time).\n\n[^1]: [ProPublica Analysis](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm)\n[^2]: [Dartmouth Study on COMPAS accuracy](https://advances.sciencemag.org/content/4/1/eaao5580)\n[^3]: [News coverage on the Google Photos case](https://www.forbes.com/sites/mzhang/2015/07/01/google-photos-tags-two-african-americans-as-gorillas-through-facial-recognition-software/#2842682a713d)\n[^4]: [News coverage on Amazon Hiring case](https://www.businessinsider.com/amazon-built-ai-to-hire-people-discriminated-against-women-2018-10)","lastmodified":"2023-02-15T01:38:21.169820744Z","tags":null},"/posts/casual-magic":{"title":"Casual Magic","content":"\n*A small collection of poetry about magic in the everyday*\n\n---\n\n**casual magic**\n\n{{\u003c poem \u003e}}\nAt 1:00, the sun streamed at just the right angle through the patterned glass,\nsplitting the uniform beam of light into a hidden spectrum of fractals,\nbathing the room in a shower of brilliant colours.\n\nThe dripping of the water from the faucet was always erratic,\nnever settling on any sort of discernible pattern. \nDrip drip       drip     drip drip         drip    drip            drip     ,\nIt was always 8 drips of the faucet before each perennial was well watered.\n\nThe clouds seemed to agree that today would be a great day to read at sunset.\nA friend once commented how they found books so weird,\nyou just stared at marked slices of a tree for hours, vividly hallucinating.\nI joked how the beach matched the cover of my book; they laughed,\nour bodies bathed in the mellow yellow that seemed to melt the world around us\nuntil it was just us, the ocean, and the setting sun.\n\nThere was a cozy spot to put my head,\njust below the PULL FOR STOP cord,\nbetween the metal frames of the bus windows,\nenough space for me to have an earbud in.\nI would spend the 40 minutes bus ride shuffling for new songs,\nsinging under my breath,\nfeeling and voicing the shape of each word,\nwatching the clouds slowly losing their tinges of colour as night fell.\n{{\u003c /poem \u003e}}\n\n---\n\n**child of the light**\n\n{{\u003c poem \u003e}}\nPhotography literally means 'writing with light'.\nFrank Lloyd Wright understood this\nhanging light like pictures on a wall,\nknowing it to be as important a material as brick and wood.\n\nThere's a certain beauty to the shimmering\nof blades of light as it cuts through the dust of a family home;\nthe way it twinkles as it touches the drop of rain and,\nat just the right angle, blossoms and blooms into all the colours of the world;\nhow it paints the mountains and valleys a smattering of different colours,\na different palette every morning;\nenthralling people by the way the rays filter through the trees\nand bounce off the waves.\n\nEratosthenes used light to figure out the size of this little ball of earth we stand on.\nI think often about how each ray of light \ntravelled 8 minutes and 20 seconds, \nburned its way through the atmosphere,\nbounced off countless people, houses, trees, \njust to be stopped by our eyes,\nunbashed and perfectly content at its destination.\n\nLight enchants at every scale it is perceived.\nThe way it dances and shimmers, you would think it had a life of its own.\n\nI am a child of the light,\nstriving to live each day with the beauty of the cozy light of a sunset,\nthe confidence of a single photon traveling 100 million miles to its destination.\n\n'Striving' is the keyword.\nOn some days, my eyes get moist,\nacquiring the same glistening as water droplets falling from the sky.\nIt is on these days that the light is especially beautiful, \ntaking on an almost ephemeral and magical feeling.\n\nI borrow strength from the light:\na gentleness of the touch,\na twinkling of the soul,\na lightness of the self.\n\nI see the light as beautiful\nmaybe the light will see me as beautiful too.\n{{\u003c /poem \u003e}}\n\n---\n\n**sun(set/rise)**\n\n{{\u003c poem \u003e}}\nThe shape of the sun is a contour, carved by its intensity, angle and number of\npeople who are awake to see it. In the evening, the sun sets the sky ablaze\nwith the vibrant shades of a ripe peach; a final spectacle.\nSunset: a time of day when a significant portion of all\npeople on Earth all glance at the same thing and\nadmire its beauty. A small act of cohesiveness\nand shared beauty in a world that\ndesperately looks for things to\nthings to glue it\nback together.\n\nAt night,\na million\nstars pierce\nthe darkness.\nA stillness,\nilluminated\nby none other\nthan a\nreflection of\nthe sun.\n\nIt is not by chance\nthat the first piece of art\nmade by a human in space is\nthe orbital sunrise. A promise that the day\nwill start anew, a sign that tomorrow exists, that\nthings dormant can wake once again. As the rays peek over\nthe crests of mountains and waves, there is a warmth that wakes the world again.\n{{\u003c /poem \u003e}}\n\n---\n\n**stargazing**\n\n{{\u003c poem \u003e}}\n    From   far   away,\n    it   looks   like   we   are   huddled   close.\n    A   community   of   stars,\n    clustered   and   cozy.\n\n\nYet   the   distance   between   us\nis   so   vast   that\ntravelling   at   the   speed   limit\nof   the   universe\nwould   still   take   billions   of   years\nto   traverse.\n\n\n\tPeople   used   to   tell   stories\n\tmillennia   ago\n\tabout   how   stars   are   just\n\tholes   in   the   blankets   of   the   sky,\n\tthere   so   the   light   of   day    \n\tcan   peek   through   at   night.\n\n\nI   wish   we   could   pull   the   blankets   closer,   to   keep   us   warm.\nAll    we    can    do    is    longingly    gaze,\nwatching     us     each     shift     red,\nhoping      that      one      day      our      dust      will      meet.\n{{\u003c /poem \u003e}}","lastmodified":"2023-02-15T01:38:21.169820744Z","tags":null},"/posts/collaborative-thinking":{"title":"Collaborative Thinking","content":"\nRecently, I've been reading **21 Lessons for the 21st Century** written by none other than Yuval Noah Harari, and have been enjoying the book. Its approach to weaving together insights from a vast number of disciplines to create something novel is extremely refreshing. I just read a section on learning, the knowledge illusion, and collaborative thinking and wanted to share some of my thoughts that have been bouncing around and marinating for a few days as well as some learnings that I've applied to my own life.\n\n## Collaborative Thinking\n\u003e Humans rarely think for themselves. Rather, we think in groups. Just as it takes a tribe to raise a child, it also takes a tribe to invent a tool, solve a conflict, or cure a disease. No individual knows everything it takes to build a cathedral, an atom bomb, or an aircraft. \n\nIt is no secret that the key to the rise of *Homo Sapiens* and the anthropocene wasn't due to the rationality of any individual human, but rather our collective unparalleled ability to think and share knowledge in large groups. This concept has arisen in the form of *specialization of labour*.\n\nAs a society, we consistently rely on the knowledge of others to live our own comfortable lives. I may not know how to grow my very own russet potatoes, but a farmer in Alberta might. Similarly, a plumber in Massachusetts may not know how to build their own website, but I might. Through being able to supplement each other's knowledge of the world, our *collective* knowledge is much greater.\n\n![Left: Collective knowledge of the group. Right: My subset of knowledge](/posts/images/collaborative-thinking/knowledge.png)*Left: Collective knowledge of the group. Right: My subset of knowledge*\n\nI like to think about collective knowledge as a big blob. Each individual contributes a unique *subset* of knowledge. We get the entirety of human knowledge by taking the *union of the knowledge* of all the individuals in the group. Of course, as these groups of individuals grow ever larger due to globalization, each individual may choose to specialize in a narrower subset of knowledge as generations go on to reduce redundancy. Why know how to build your own car when you can buy it yourself? The adoption of globally accepted currencies has made this easier than ever.\n\n## Knowledge illusion\nHumans also have this 'knowledge illusion' where we think we know a lot, even though individually we know very little. We treat the knowledge of the human collective as if it were our own, even subconsciously.\n\n![A crude illustration of a jacket zipper](/posts/images/collaborative-thinking/zipper.png)*A crude illustration of a jacket zipper*\n\nAn example Harari used was the sweater zipper. If I were to ask you if you knew how a zipper works, the vast majority of you would exclaim \"yes, of course!\" Yet, if asked to describe in *detail* every single step, most would fail to do so. Even with something that seems so basic and intuitive seems to elude an explicit explanation. We have begun to stand on the shoulders of giants yet refuse to acknowledge their presence.\n\nAlthough we may have increased the overall area of our collective knowledge, the surface area of each individual has also shrunken, turning from balanced and broad to narrow and unwieldy.\n\n## Rebalancing our blob of knowledge\nAnother interesting property about the knowledge blobs of individuals is that they are *magnetic*. I mean this in the sense that individuals that have one blob of knowledge tend to attract and be attracted to individuals with similar orientations and shapes in their blobs of knowledge, much like how magnetic dipoles align in a magnet. As humans, we tend to want to minimize our cognitive dissonance and surrounding ourselves with like-minded individuals is the easiest way to do that.\n\nIndividuals in these clusters experience a sort of echo chamber effect whereby the *magnitude* of their knowledge is amplified through the mutual alignment of their knowledge. However, this also poses a unique challenge where movement only happens in one direction and there is little to no room to deviate from that direction and try something new; something incredibly dangerous for innovation. This, in a sense, is turning collaborative thinking into groupthink.\n\n\u003e People afraid of losing their truth tend to be more violent than people who are used to looking at the world from several different viewpoints.\n\n![Broadening our base fundamental knowledge. Blue: Previous 'specialized' knowledge. Purple: broad foundational knowledge](/posts/images/collaborative-thinking/spikes.png)*Blue: Previous 'specialized' knowledge. Purple: broad foundational knowledge*\n\nWhat we can do to counteract this extreme alignment is to build a broader foundation of knowledge. When you come across an individual with differing views, hopefully you will at least have the base fundamental knowledge to understand their perspective.\n\n## Learning communities\nThis, at least in part, is why I've recently become more certain of wanting to go to [academia](/thoughts/academia) in the future. I used to have tunnel-vision in thinking that all I wanted to do in the future was to just work in industry CS. Recently, I've started to realize that CS not a single discipline, but rather it's a tool that can help solve uniquely human problems, and these human problems are inherently multidisciplinary.\n\nI've started to read and learn more about the world around me outside of my little bubble of CS-related topics and it's been eye-opening to see issues I read about in my philosophy class come up in a [[thoughts/language|linguistics]] lecture which in turn comes up in a book I'm reading. I've found that the best way for me to cement my learning and understanding is through discussion with people, rather than just sitting and ruminating on my own -- a very different pace than the typical *code-Stackoverflow-copy-repeat* self-learning cycle that most programmers (including myself) are familiar with.\n\nThe important part of learning communities like colleges is not necessarily the alignment in what you're studying, but rather in the shared mindset of discussion, learning, and understanding. To broaden my foundation of knowledge is to read more about the opinions and findings of others and to critically discuss these among peers who may have different views. If we want our specialized knowledge to be applicable in a wide range of situations, we need a broad foundational base that can support that.\n\n## Wiggle room\n\u003e If you want to go deeply into any subject, you need a lot of time, and in particular, you need the privilege of wasting time. You need to experiment with unproductive paths, explore dead ends, make space for doubts and boredom, and allow little seeds of insight to slowly grow and blossom\n\nFor me, learning is very close to a [zero sum](thoughts/zero%20sum.md) game. I can only expand the area of my knowledge blob so fast. If I want to broaden my foundational knowledge base, I need to reign in the amount of time spent growing purely technical strengths and to stop saying 'yes' to any and every opportunity that comes up.\n\nSlowly but surely, I'm learning to value my own time and to set it aside to just absorb more about the world and to extend the reaches of my knowledge just a little bit further. To dilly-dally among the Wikipedia rabbit holes, cultivate [my digital garden](/posts/digital-gardening), and faff among the ridiculously long list of side projects I planned to start. I'm experimenting with what I previously thought were deadends and little seeds of insight are starting to grow. Maybe I'll find something interesting to share among the construction of this broader foundation.\n\n**Acknowledgements**\n\nA big thank yu to [Anson](https://twitter.com/ansonyuu) for always being a sounding board for fresh dough (half-baked ideas would be too generous of a description for these). Thanks to [Anne](https://www.linkedin.com/in/anneguo3/) and [Joice](https://twitter.com/y1huen) for also giving feedback on rough drafts :))","lastmodified":"2023-02-15T01:38:21.169820744Z","tags":null},"/posts/communal-computing":{"title":"Communal Computing Networks","content":"\n\u003e This post is part of an ongoing letter series with [Spencer](https://www.spencerchang.me/) and some other internet friends about what we think the future of the Internet could look like. Find more letters over on our [(we)bsite](https://we-b.site/)\n\n![[thoughts/images/minecraft.png]]\n\nI vividly remember the Minecraft LAN parties we would have during middle school lunch breaks. Our eyes, glued to the clock as each minute by agonizing minute ticked by. The lunch bell would ring and we'd rush out into the hallway to set up our laptops. We spent the next 55 minutes tapping at our keys, yelling about how somebody stole all the diamonds we spent the last week collecting and how there was a village just over the hill. After school, we retreated to the computer lab to play more Minecraft before our parents picked us up.\n\nAt some point, school IT blocked the port ranges that Minecraft uses to establish local multiplayer worlds. No more lunch-time Minecraft. I remember asking the school if we could run a Minecraft server using the school computers and they said no.\n\nAs any stubborn middle schooler would do, I spent the next few weeks figuring out how to host my own Minecraft server on a laptop at home because who was the school administration to tell me what I could do on my lunch break. Running this server meant that us gathering in our virtual blocky world didn't need to stop as soon as we left the school perimeter.\n\nSometimes, I would get up at 2am and sneak downstairs to my laptop to figure out which cool new plugins and mods we could add and combine without completely crashing the game. I sneaked because I was only allowed 45 minutes of computer time after school.\n\nI cried because in the last week before winter break, some random person joined and completely blew up the server with TNT. We didn't know backups were a thing.\n\n---\n\nIn 7th grade, our home room teacher showed us [Scratch](https://scratch.mit.edu/) for the first time. The majority of fun with Scratch was sharing. Posting graphics on the walls, modifying and experimenting with each other's work, and bringing the \"new\" products back to their original inventors.\n\nBut the real spark of Scratch came from just how easy it was to make shared state. In Scratch, you can create a [globally consistent variable](https://en.scratch-wiki.info/wiki/Cloud_Data) that is synced across every one who ran my game just as easily as any other variable. Adding a leaderboard to my game was just as easy as replacing my variable with a Cloud Variable.\n\n![[thoughts/images/cloud-variable.png|300]]\n*Making a shared variable is as easy as clicking a checkbox*\n\nThis was the last era of the internet where it felt personal, multiplayer, distributed, and evolvable. It was easy to build stuff on your own and remix other work. It felt like a clearing in the woods, a safe gathering space for those who knew about it.\n\n---\n\n![[thoughts/images/house-from-up.jpg]]\n*The house from Up (2009)*\n\nOver time, this started to fade. Geocities came and went. Big platforms like Facebook, Google, and Amazon swooped in to buy all the real estate around our little clearing. It lost most of the personal aspects as it grew into an app platform. \n\nSome stubbornly kept their little hypertext gardens but doing so was a radical act rather than the norm. We, as citizens of the internet, have lost our ability to shape it and make it a home.\n\nIn 2019, Yancey Strickler illustrated this in what he called the *[Dark Forest Theory of the Internet](https://onezero.medium.com/the-dark-forest-theory-of-the-internet-7dc3e68a7cb1)*. \n\n\u003e Imagine a dark forest at night. It’s deathly quiet. Nothing moves. Nothing stirs. This could lead one to assume that the forest is devoid of life. But of course, it’s not. The dark forest is full of life. It’s quiet because night is when the predators come out. To survive, the animals stay silent.\n\u003e \n\u003e This is also what the internet is becoming: a dark forest. In response to the ads, the tracking, the trolling, the hype, and other predatory behaviors, we’re retreating to our dark forests of the internet, and away from the mainstream.\n\nOur web has turned into a relentless competition for our attention. As corporations and influencers grasp for power, an increasing number of the web's citizens have retreated to the underground burrows of the cozy web to avoid the fallout. Hidden away from a hostile public web filled with spam, AI marketing, and malware, we find respite in our group chats, Discord servers, and forums.\n\n![[thoughts/images/dark-forest.png|500]]\n*Maggie Appleton in [The Dark Forest and the Cozy Web](https://maggieappleton.com/cozy-web)*\n\nBut we've fallen into a very narrow set of design patterns. In the name of profit, platforms optimize for views, hours spent, and clicks. They 'accidentally' boost provocative and incendiary behaviour because they know that it draws people to their platform, healthy or not. Each additional app on the web increasingly competes for increasingly scarce [[thoughts/attention economy|attention]]. Who has space for authentic connection anymore? That doesn't make profit numbers go up.\n\nIt seems that we've reached the inevitable conclusion of optimizing \"connecting with each other\" to the extreme. With no feedback system for users to have a say or improve the conditions, the web is quickly spiralling into something that doesn't do all that good of a job. The thing that the web originally was meant to do -- enable people to meaningfully meet and collaborate with each other -- is harder than ever. Perhaps we might carve out a bit of space for those again?\n\nIn design, there is a technique [diverge-converge](https://www.nngroup.com/articles/diverge-converge/), which as the name suggests, has two stages:\n1. Diverge: come up with many independent solutions to the problem\n2. Converge: narrow down and refine a small number of solutions to the problem\n\n\n\nThe early days of the internet exemplified the diverge cycle of design. We tried a lot of ways to connect people and things on the web. Over time, some things stuck and others didn't.  Evolutionarily, we've guided ourselves to this unfortunate set of web design practices and it's not clear that these will continue to serve us well. We’ve converged on a state of the internet that worked great for the first 15 or so years, but now parts are creaking and dilapidated.\n\nHow might we broaden the design space again?\n\n---\n\nThe first step to this seems to be to dispel the myth that the internet and the web as a whole is something so vast and monolithic that it is unchangeable. We look at these entrenched protocols and take them as a given.\n\nBut here's the wonderful bit about software (and specifically the web) that feels uniquely special: you don't need permission to make things.\n\nThe internet is the first place people got to build real things without needing to ask someone if they could. This is powerful. We should give people the ability to own technology, to bring it into their own complex life stories. The *real* use cases may be the ones waiting to be discovered. One of my favourite examples is the French bistro.\n\n\u003e The small Parisian restaurants serving home-cooked meals in very modest settings—like the cafe before it, was an invention. Many tales exist of its origin. Some say it was working-class landlords opening their kitchens for extra income. Others say it was the Auvergnats, immigrating to Paris from what is today central-south France, who first worked as rag-pickers, then wood and coal sellers, then metalworkers, who created small working-class restaurants to supplement their income. **Either way, it was not planned or engineered, but simply not-disallowed.** There were no rules in place to stop this invention.\n\u003e \n\u003e (Simon Sarris, *[Welcome, ghosts](https://simonsarris.substack.com/p/welcome-ghosts)*, emphasis added)\n\nThe best pieces of software I've had the pleasure of using are ones that are agentic. Examples like Minecraft and Scratch let me fully construct a world for myself in which I operate. They set the rules, but *I* am the one who decides how I want to play.\n\nAgentic software designs for and explicitly allows user-made [[thoughts/desire paths|desire paths]] and [[thoughts/cozy software#Folk Software|folk-usages of software]]. People will use software in whatever informal, distributed ways that emerge from real world contexts. Folksonomies are a great example of these informal taxonomies developed by users on social sharing platforms. Tumblr tags, for example, have adapted to become not just a form of tagging or organizing, but also metacommentary, memes, and other comedic content.\n\n![[thoughts/images/yokocho-alley.png]]\n*An Yokochō alleyway in Tokyo, Japan. There is an inherent smallness to the design that fosters communication and character. Owners say that the smallness encourages genuine communication between staff and customers as well as among characters, much unlike the homogenization of shopping malls and chain stores (paraphrased from Emergent Tokyo: Designing the Spontaneous City). How might we create Yokochō alleys of the internet?*\n\nAgentic software embodies a [Hundertwasser flavour of design](https://hundertwasser.com/en/texts/verschimmelungsmanifest_gegen_den_rationalismus_in_der_architektur) where:\n-  The resident has access to the same tools as the architect.\n-  Everything is writeable, everything is rewriteable.\n-  People can solve their own problems.\n\nFor this to happen, we need to reduce the burden of building software. Not all tools need to be complex power tools that require university degrees to operate. Progress can mean simplifying tools to enable the layman to shape his immediate environment to his taste. How might we make software not just the tools of the engineering elite but the layperson as well?\n\n\u003e Like any society, it is not only architects, builders, or engineers that move us towards this collective consciousness. We need people to bring themselves and assume new identities—perhaps where the role of ‘technologist’ is fluid and all-encompassing. Where ‘technologist’ is everyone and anyone concerned with the role of technology, empowered to use it to shape their experience in our pervasive digital world.\n\u003e \n\u003e (Chia, *[There is an internet that is mine \u0026 I would like you to live in it with me](https://chias.blog/2022/there-is-an-internet-that-is-mine)*)\n\nWe must make it possible for the average layperson to be able to change and adapt software for their own needs; for them to experience creating software not like a professional chef, but [[thoughts/cozy software|a home cook]].\n\n---\n\nFirst, we need to address the double-edged sword that is scale. Scale, of course, can be a good thing. Economies of scale enable us to have cheap hosting, comprehensive web search, and many more luxuries we enjoy on the web today. However, the Silicon Valley mindset of always asking what the billion-dollar version of your idea is and how you can get _everyone_ using it is slowly poisoning how we think about software.\n\nBecause realistically, when most of us want to create software, the intention isn't to release something that the whole world will end up using. Yet, with all the knowledge you end up needing to be able to do it, it seems like everything we release into the world needs to be production ready!\n\nFor someone to make a web service today, they need to know\n- HTML, CSS, and JavaScript\n- How to pick and choose a hosting provider to put their service on the web\n- Basics of [[thoughts/DNS|DNS]] so they can use a custom domain\n- Choosing a database, host it, and figure out how to safely talk to their database from their service\n- How to talk to APIs without leaking secrets\n- ... and many more I'm not mentioning here (especially if they choose to make something [[thoughts/peer-to-peer]])\n\nI spent a lot of time around university-aged students first learning software engineering and there is a *really* large gap between how easy it is to get a static website on the web and how difficult it is to add a database to it. This, for most people, is where they decide that software is too difficult and give up.\n\nIt has become so difficult to learn that it has almost killed software's viability as a tool for expression. Imagine if, every time you cooked a meal for your friends or family, world-class critics came in to judge and prod at your food. Or if, every time you wanted to write a letter to your partner, the postal service would refuse to send it if it contained even a single grammatical error.\n\n\u003e Learning how to store passwords or add OAuth2 to your toy web site is not fun. So much of programming today is busywork, or playing defense against a raging internet. You can do so much more, but the activation energy required to start writing fun collaborative software is so much higher you end up using some half-baked SaaS instead.\n\u003e \n\u003e Writing a web service for use by your friends should not be a form of combat, where you spend your days worrying about XSS attacks or buffer overflows. You should be focused on creating something new and wonderful in a place without bad people hounding you.\n\u003e \n\u003e  (David Crawshaw, *[Remembering the LAN](https://tailscale.com/blog/remembering-the-lan/)*)\n\nIt wasn't always like this. In fact, the internet used to be pretty flexible. In the days when [we still had plenty of IPv4 addresses to hand out to computers](https://en.wikipedia.org/wiki/IPv4_address_exhaustion), when  [CORS](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS) and [[thoughts/NAT|NAT]] hadn't made the web [[thoughts/computer networking#Peer-to-peer today|peer-to-peer hostile]], LANs meant it was easy to learn about computers and experiment with things. I could just run something on my machine and open the port to my computer from my router and anyone in the world could see it.\n\nUnfortunately, we can't just naively revert back to this. It is no secret that our modern internet is peer-to-peer hostile. Almost all of the communication we do on the web is fully client-server because that was the easiest way to make things secure and work.\n\nPart of this comes down to the entrenched nature of how the web is structured. Our browsers and home computers can only speak and request from services, but we've lost the ability to [listen for others and serve services of our own](https://www.robinsloan.com/lab/bad-hosts/). Security is a hard problem to solve and there are a lot of malicious people on the web. But going down this path closes many doors for what we *could* be doing with the internet.\n\nHow do we make *making* on the web easy and fun again?\n\n![[thoughts/images/just make learning fun.png|300]]\n*From the blogpost introducing [CoCo](https://medium.com/mit-media-lab/meet-coco-a-real-time-co-creative-learning-platform-for-young-people-bdfe23edd5a7)*\n\n--- \n\nIt's true that networks are [fundamentally sloppy and all sorts of broken.](https://apenwarr.ca/log/?m=202007#:~:text=Internets%20are%20fundamentally%20sloppy) But broken does not mean unmendable. \n\nThis latter point is one that Chia talks about in her articulation [for a future of the internet](https://chias.blog/2022/there-is-an-internet-that-is-mine/).  To declare it unmendable or unfixable is to abandon the many people that still need these deeply broken technologies. \n\nStarting a new system from scratch with a grand vision is not the way to do this either. History has shown us that trying to purge everything and build out a totalizing vision can have [[thoughts/Seeing like a State|terrible implications]], regardless of whether they succeeded or not.\n\nTo reform the web is not to wipe everything and start over *tabula rasa*, but rather to move through the [adjacent possible](https://subconscious.substack.com/p/evolution-adjacent-possible), figuring out how we can improve the existing condition of those trapped by these systems without uprooting them.\n\nThe internet is based on [[thoughts/Postel's Law]]: work the world as it already is, not as you wish it were. In fact, this is how the Internet today evolved. It was bootstrapped on top of existing telephone networks, exapting existing phone hardware to get it off the ground. It didn't need to deploy expensive new hardware or lay down new cables, it just conformed to existing infrastructure.\n\nJust as the early internet was built on top of telephone networks, we can build a new set of cozier, smaller networks on top of an internet that is showing its age.\n\nMaybe we bring back the philosophy of LANs, but rather than networks based around closeness in physical distance bounded by routers, we created networks based around closeness in **social and trust space**? What about [Communal Computing Networks](https://alexanderobenauer.com/labnotes/027/)? What if I could make an [[thoughts/Overlay Network|overlay network]] with all my friends who are interested in poetic computation?[^1] \n\n[^1]: In a magic world where IPv6 was adopted by everyone, every computer and device would have a unique address to send and receive things from. It would enable people to host things again, to have their own little home dinner parties instead of always going out to the restaurant. Unfortunately, IPv6 adoption has been really slow and we're stuck in a world where IPv6 isn't widespread enough to assume that most users have an IPv6 address as of yet.\n\n![[thoughts/images/trust-overlay-network.png|500]]\n\nWe could have:\n1. Countless local networks, many overlapping with each other. \n2. A larger network of networks to allow for cross-network collaboration.\n\nThis *is* a design pattern we have seen work well in the past with email and Matrix. These platforms often function as networks of networks, allowing communities within them to have control over their own smaller networks but still allowing users on different providers to interact with each other seamlessly.\n\nWith this infrastructure in place, we can also think about what *community owned applications* may look like. Perhaps this is infrastructure that will allow us to not necessarily decentralize but decenter servers, moving them from the source of truth to a supporting role.\n\nPerhaps this looks like people having [[posts/towards-data-neutrality|ownership of their own data]]. They could use servers to help make it available to their peers when they are offline but they are never essential to people accessing their own data.\n\nYour peers, friends, and colleagues could help replicate, host, and process indexes for data they are also interested in. A big community corkboard of all the things the group may be interested in. In this magic world, anyone could write applications that pull in data from these indexes, making it easy to experiment and just *make* things that work on the web.\n\n---\n\nAs we spend more time on the web, it’s clear what may have worked for a smaller web no longer works today. In today's web, the powerful become more powerful, the rich become richer. The day-to-day users have no say over the terms of service we are served. We live in a feudal web.\n\nIt used to be the case that you needed to train to become a scribe to write words for any reason. But just as pens were taken out of the hands of the scribe during the Reformation of Europe, we must take the code out of the hands of software engineers and share it with the masses.\n\nWriting software shouldn’t take a degree and many years of training, it should be as simple as making a meal at home or writing a letter to a friend. Doing so will lead to a more diverse and resilient internet, with a greater variety of voices and perspectives represented so we may build an internet that works for us.\n\nI dream of a future where we have this LAN-like experience back again with all the best parts of the 21st century internet. A safe small space of people we trust, where we can go, rest, and look out for each other. A harbour from the multi-billion-person internet for when we want to feel cozy and safe.\n\nLet's make the web feel local and multi-player again.\n\n---\n\nHello stranger! If you're still reading by this point, then you've probably been thinking about similar things for a while. I want to extend [an open invite](https://we-b.site/) to you to lend your thoughts too.\n\nJoin us as we write about what it would be like to make these fictions become reality because the way these ideas become powerful and revolutionary is to have more people contribute to them.\n\n*Thanks again to [Anson](https://www.ansonyu.me/), [Spencer](https://www.spencerchang.me/), and [Vivian](https://vivianmeng.com/) for some really clarrifying feedback.*","lastmodified":"2023-02-15T01:38:21.169820744Z","tags":null},"/posts/context-collapse":{"title":"Framing and Context Collapse","content":"\n![Abstract illustration of a blob framed by two picture frames](/posts/images/framing/title.png)\n\nThe content I throw on Twitter is not something I would readily post on LinkedIn. I also wouldn't post LinkedIn-style business content to my Facebook timeline. To an extent, my social presence across these platforms is *incongruent*. The core tenet is that different apps curate different types of communities and thus social contexts. As a result, we try to separate these contexts in the best way we know how to: by acting differently, **and that's ok.** \n\nIt is not 'inconsistent' for us to want to frame ourselves differently on Twitter than on Facebook, and in fact, a lot of key aspects of human behaviour point to why we default to doing so.\n\nThe problem comes when these spaces start bleeding into each other, and the boundaries between the different audiences on each of them start amalgamating. The *overlap* in target audience between these spaces then becomes very large and all of these different social contexts ['collapse'](https://www.rewire.org/context-collapse-online/) and it becomes increasingly difficult to maintain these separate personalities.\n\n## What's (not) in the frame\nIn this [vlogbrothers video from March](https://www.youtube.com/watch?v=ZRZuEGuU_es), John Green talks about the metaphorical frame in which people present themselves. We tailor and adjust our behaviour depending on the environment we're in, or the audience we find ourselves in front of. However, in doing so, we inadvertently portray an incomplete picture – we frame only the parts we want them to see.\n\n\u003e \"I mean of course the central trick of the social internet, is that whenever you make something, you choose what's inside the frame, but as viewers the rest of us can't help but believe what's inside the frame, because it's literally all we can see\"\n\nAn unfortunate side effect of this is that it starts setting expectations for the audience as to how we 'normally' behave. This 'audience' of people can be friends, followers, or strangers. They are a group of people that pay attention to what *you* have to say because of your thoughts, opinions, and general persona. So what happens when we change?\n\nIf we're expected to keep growing as people, these thoughts and opinions will obviously change over time. So why does it feel so *weird*, for both the audience and ourselves, to deviate from these set identities that we've become used to portraying in certain scenarios?\n\n## Context separation\n![Abstract illustration of a blob framed by two picture frames](/posts/images/framing/context-separation.png)\n\nIn order to answer that question, let us make a brief foray into the realm of psychology. Why do humans tend to act differently in different environments? I think three key aspects of behaviour play a role here:\n\n### People are unique\nNo one individual has the exact same interests, goals, values, and [[thoughts/identity|identity]] as you. We have different friends and environments, so we create different contexts in which we can exercise different aspects of ourselves. People find spaces where they can authentically express all the dimensions of themselves. If a situation only exercises one axis of our self-identity, we will actively seek out places to exercise other axes.\n\n### Behaviour is sticky\nIt is easier to travel along a path well-travelled than one covered in weeds and bush -- if you do something once, it becomes easier to do it again. Similarly, doing something with a certain context once means it becomes easier to repeat that same behaviour in that context again. If I use Twitter as my social media of choice to post memes, I'm likely to continue using it like so.\n\nIn some ways, this is Newton's First Law but applied to behaviour: if you do something one way, you are likely to keep doing things in that way unless encouraged to do otherwise.\n\n### Individuals tend to conform to [group norms](thoughts/social%20contracts.md)\nIn 1951, Solomon Asch conducted [an experiment](https://en.wikipedia.org/wiki/Asch_conformity_experiments) to investigate the extent of which social pressures can affect a person's behaviour. In this experiment, he asked, \"Which line is the longest out of the three given?\". In an individual setting, 99% of people answered correctly. However, when put in a room of actors instructed to answer incorrectly, nearly 75% of all participants gave at least one incorrect answer throughout 12 trials.\n\nPeople conform for two main reasons:\n1. They want to fit in with the [group](/thoughts/communities) **(normative influence)**\n2. They believe the group is better informed than they are **(informational influence)**\n\nHistorically, having different behaviours in different contexts may have been evolutionarily beneficial, helping us to better collaborate and form connections with each other without causing undue conflict.\n\nEven as children, when we get hurt, we look to authority figures around us to see how to react. If our mother comes to us expressing worry and concern, we cry. If everyone around us continues to play as if everything is normal, we will brush aside the injury and continue to play with the group.\n\nOur ability to 'frame' ourselves different depending on the social situation likely stemmed from this behaviour too.\n\n\n## Why context collapse is bad\n![Abstract illustration of a blob framed by two picture frames](/posts/images/framing/context-collapse.png)\n\nWhen experiencing context collapse, talking to your audience beyond a surface level becomes very difficult. Smaller groups, by nature, have more commonalities to relate to, whether that be interests, music taste, place of study, or lived experiences. These groups provide the chance for individuals to have intimate conversations and exercise different facets of themselves that they otherwise wouldn't get the chance to. A queer person may be out to a close group of friends but not to their family; a budding writer can have a safe place to explore potential ideas without alienating the rest of their friend group.\n\nWhen we experience context collapse, these social groups and audiences become massive, and the amount of overlap in interests or values of the collective group is miniscule. How are you supposed to have any sort of meaningful connection when the only thing you share in common on the platform is that you ‘know’ each other?\n\n## Centrifuging contexts\nI’ve noticed three main strategies individuals, companies, and platforms have adopted in trying to tackle context collapse.\n\n1. **Lowest Common Denominator** ([Vanilla Ice Cream effect](thoughts/Vanilla%20Ice%20Cream%20effect.md)). Only making posts that anybody will be able to understand and relate to, staying away from controversial or overly personal topics. This approach places an emphasis on quantity of impressions over quality of impressions.\n\n2. **Realtime**. Platforms and individuals are leaning more towards [ephemereal content](thoughts/ephemereal%20content.md), like stories or streaming. The 'live' aspect of it means that the audience is encouraged to interact immediately, creating a tighter feedback loop with the audience.\n\n3. **Fragmentation**. Purposefully having conversations in places where your audience is smaller, like group chats, direct messages, or small closed communities. In these cases, the specific context and audience is well-defined. More users are also turning to 'finstas' which are accounts focused for a closed group of friends and family rather than the entire public [internet](thoughts/Internet.md)r.\n\nI don’t think there is a single 'right' approach, and in part that's why so many types of social networks exist today: they each have their own merits that incentive different approaches to communication. But one part I do want to emphasize is the tradeoff of depth and breadth in these approaches.\n\n## Social bandwidth\nI think in part, this is why nobody has been successful in creating a single social network to replace all of the existing apps. As humans, we want the ability to closely connect with people, and context collapses makes that exceedingly difficult. We have limited social [bandwidth](thoughts/bandwidth.md) -- there's only so much attention we can give to everyone. By increasing the breadth of our audience, we reduce the depth at which we can communicate with each individual. As app developers rush to combine all of these platforms into one, maybe we should step back and think whether this is really necessary.\n\nOn these larger social media apps where I'm 'connected' to hundreds of people, I don't feel like I can have very insightful conversations or thoughts. Those conversations almost exclusively happen in communities like [nwPlus](http://nwplus.io/) and [Reboot](https://twitter.com/reboot_hq/) where there is enough alignment of values and interests that we can scrape past the surface level chit chat and get to really exploring ideas and knowing people.\n\nBecause we're so actively a part of all of these different contexts, we are forced to be excessively general on these platforms to try to cater to everyone. We should have platforms where it's ok to engage with different elements of who you are. We have different groups of friends to cater to different aspects of who we are, so why should social media platforms be any different?\n\nDifferent social contexts call for different social behaviours, and that's ok.\n\n*Special thanks to Anson, Ivan, Rishi, Joss, Jasmine, Kat, and Anh for helping read over and edit this piece! Wouldn't be possible without y'all :)*","lastmodified":"2023-02-15T01:38:21.169820744Z","tags":null},"/posts/ctrlv-next":{"title":"Rewriting ctrl-v using Next.js","content":"\n![Rewriting ctrl-v using Next.js](/posts/images/ctrlv-next/title.png)\n\nEver since I released [ctrl-v](https://github.com/jackyzha0/ctrl-v/), friends from HackClub have kept bugging me about switching my current React code over to use Next.js. I wanted to see what all the fuss was about, so I finally set aside some time this weekend to rewrite the frontend using Next.js and deployed it on Vercel instead of Firebase Hosting. I thought it would take the whole weekend, but I managed to go from zero knowledge about Next.js to a fully finished refactor in just under 6 hours!\n\nThis will be more of a technical blog post walking through my process in converting ctrl-v from using React Router and Firebase Hosting to Next.js and Firebase.\n\nSource code: https://github.com/jackyzha0/ctrl-v\n\n## Learning Next.js\nI'm a very hands-on learner. I learn the fastest stumbling my way through a project with a framework I barely know my way around than watching multiple video examples or reading blog posts. Having a tangible project to work with and break as I learned things really helped speed up the learning process for me. That being said, here are a few other resources I found really helpful in my journey!  \n\n* [Next.js in 100 seconds + good beginner tutorial](https://www.youtube.com/watch?v=Sklc_fQBmcs)\n* [Twiddling around with `create-next-app`](https://nextjs.org/docs/api-reference/create-next-app)\n* [Next.js official documentation for migrating from React Router](https://nextjs.org/docs/migrating/from-react-router)\n\n## Why Next.js\nThe main reason I wanted to switch to Next.js is because it makes it dead easy to implement both Static Site Generation (SSG) and Server Side Rendering (SSR) for your React app. For those uninitiated, SSR and SSG are different approaches to rendering content.\n\nIn **Client Side Rendering (CSR)**, the client is responsible for rendering the content on the page. All they receive is an empty HTML document, and a bunch of JavaScript bundles through which the browser populates the page. The downside of this approach is that no content exists on the page when it is first loaded. As a result, web crawlers won't be able to find your content (not great for SEO), and you won't get link previews to your content as the page metadata won't have loaded. This is the behaviour you get when you use plain old React.\n\nIn **Server Side Rendering (SSR)**, the server is responsible for rendering the content of the page and sending the fully rendered the content to the user to display. In this approach, all the content is already loaded when the user is receives it, we only need JavaScript to make it interactable (i.e. hydrate it). As a result, this approach is a lot more SEO friendly.\n\nOn the very other end of the spectrum, **Static Site Generation (SSG)**, means that the server does all of the page rendering at *build time* rather than on each request. This has all the same benefits as SSR but doesn't really make a lot of sense for this project as I don't have a full list of pages I need to render handy.\n\n**A hybrid approach**\n\nHowever, Next.js doesn't force you to choose between the two. It actually prides itself in just how easy they make it to switch between them. Here's the approach I decided to take for ctrl-v. \n\nIn the old frontend, everything was completely client-side rendered. My 'productionized' application was quite literally an `index.html` with a bunch of JS bundles. It sucked as whenever I sent a ctrl-v link to a friend, there wouldn't be a preview about what the content was and most people were scared to just open a random link like that (rightfully so). There was also a not-very-pleasant 'loading paste...' period before any content actually appeared on the screen.\n\n![Old vs new approaches to rendering content](/posts/images/ctrlv-next/rendering.png)\n\nI realized that there were only really two main types of pages\n1. View Paste (`/:paste`)\n2. Create Paste (`/`)\n\nNothing on the create paste page actually required hitting the backend, it was effectively completely static. I could safely just replace that entire page and have it be statically generated at build time. The view paste page required me to make a call to ctrl-v's backend API but I still wanted the page to have that content rendered on server so I opted for client side rendering on any view paste pages.\n\n## Steps\n### Replacing React Router with `next/router`\nNext.js uses a file-based routing system rather than routes-as-code approach that React Router takes. I decided to first convert the new paste page as that would be completely SSG. Luckily, I had originally structured my React components into a `pages` folder so pulling out that component into a page wasn't terrible.\n\nI wasn't super certain of how SSR worked right off the bat so I first played with the `/raw/:paste` page first before tackling the comparatively more scary `/:paste` page with password handling and actual error handling. \n\n```jsx\n// old CSR\nconst Raw = ({hash}) =\u003e {\n   const { err, result } = useFetchPaste(hash)\n   return \u003cRawText\u003e{result?.content || err}\u003c/RawText\u003e\n}\n\nexport default Raw\n\n// new SSR\nexport async function getServerSideProps(ctx) {\n  // ctx.params.hash allows us to access the slug (the :paste part of the url)\n  const data = await resolvePaste(ctx.params.hash)\n  return { props: { ...data } }\n}\n\nconst Raw = ({error, data}) =\u003e {\n  return \u003cdiv\u003e\n    {/* Only load title/description metadata if no error */}\n    {!error \u0026\u0026 \u003cNextHead data={data} /\u003e}\n    \u003cRawText\u003e\n      {/* Just render the content if it exists, otherwise render the errror */}\n      {data?.content || error}\n    \u003c/RawText\u003e\n  \u003c/div\u003e\n}\n\nexport default Raw\n```\n\nThe biggest part I needed to wrap my head around was the `getServerSideProps` async function. I didn't realize that the only job that `getServerSideProps` actually does, is fetch data and pass that data as props to your actual component. Once that clicked, the rest of the refactoring went relatively smoothly.\n\nI had to refactor my `useFetchPaste` hook to just fetch data and then delegated the responsibility of state and password validation shenanigans to whatever component. I ended up changing the name to `resolvePaste` as it no longer followed the [Rules of Hooks](https://reactjs.org/docs/hooks-rules.html).\n\nIn hindsight, I probably should've done this step incrementally using something like [Next.js's rewrite rules](https://nextjs.org/docs/api-reference/next.config.js/rewrites) to gradually transition ctrl-v from React Router to Next.js. Luckily I didn't have that many pages to migrate but this is good to know for the future.\n\n### `styled-components` and theme provider\nFrom what I've seen, Next.js doesn't play nicely with `styled-components` out of the box. Throughout the entire previous step, I was looking at painfully broken CSS. Turns out you need to [install an additional Babel plugin](https://styled-components.com/docs/tooling#babel-plugin) to add SSR support to `styled-components`. Then, I added a custom `Document` to `pages/_document.js`. This code augments the root `\u003chtml\u003e` tag of our application which will allow us to inline our CSS styles. \n\n```jsx\n// shamelessly stolen from\n// https://github.com/vercel/next.js/blob/master/examples/with-styled-components/pages/_document.js\nimport Document from 'next/document'\nimport { ServerStyleSheet } from 'styled-components'\n\nexport default class StyledDocument extends Document {\n  static async getInitialProps(ctx) {\n    const sheet = new ServerStyleSheet()\n    const originalRenderPage = ctx.renderPage\n\n    try {\n      ctx.renderPage = () =\u003e\n        originalRenderPage({\n          enhanceApp: (App) =\u003e (props) =\u003e\n            sheet.collectStyles(\u003cApp {...props} /\u003e),\n        })\n\n      const initialProps = await Document.getInitialProps(ctx)\n      return {\n        ...initialProps,\n        styles: (\n          \u003cdiv\u003e\n            {initialProps.styles}\n            {sheet.getStyleElement()}\n          \u003c/div\u003e\n        ),\n      }\n    } finally {\n      sheet.seal()\n    }\n  }\n}\n```\n\nAs I was also using theme provider from `styled-components`, I needed a way to wrap the ThemeProvider component around everything. Luckily a custom `App` created by adding a `pages/_app.js` will allow us to do just that. This also allows us to add any 'global' structure like padding or margins around the edges.\n\n```jsx\nimport ThemeProvider from \"../theme/ThemeProvider\";\nimport GlobalStyle from \"../theme/GlobalStyle\";\n\nconst Main = styled.div`\n  margin-top: 10vh;\n  padding: 0 20vw 30px 20vw;\n`\n\nconst App = ({ Component, pageProps }) =\u003e (\n  \u003cThemeProvider\u003e\n    \u003cGlobalStyle /\u003e\n    \u003cHead\u003e\n      \u003ctitle\u003ectrl-v | a modern, open-source pastebin\u003c/title\u003e\n    \u003c/Head\u003e\n    \u003cMain id=\"appElement\"\u003e\n      \u003cComponent {...pageProps} /\u003e\n    \u003c/Main\u003e\n  \u003c/ThemeProvider\u003e\n)\n\nexport default App\n```\n\n\n### State caching for password pastes\nThis part stumped me for a good bit. I needed to find a way to do an initial data fetch, check to see if the paste has a password, prompt the user for a password, then reload the page data. I contemplated using [SWR](https://swr.vercel.app/) for data fetching but realized in the shower that it wouldn't really make sense as the initial load is handled in the `getServerSideProps` function anyways. I realized the best way forward was to fetch the initial state in `getServerSideProps` then store it as a React State so I can update it when a password is entered and data is re-fetched. This way there are no page reloads to disrupt user experience and keeps code change minimal. \n\n```jsx\n// simplified version of pages/[hash].js\nexport async function getServerSideProps(ctx) {\n  const data = await resolvePaste(ctx.params.hash)\n  return { props: { ...data } }\n}\n\nconst ViewPaste = ({data, unauthorized, error}) =\u003e {\n  const router = useRouter()\n  const { hash } = router.query // equivalent to ctx.params.hash\n  const [enteredPass, setEnteredPass] = useState('');\n  const [correctPass, setCorrectPass] = useState(!unauthorized);\n  const [clientData, setClientData] = useState(data)\n  const {content, language, expiry, title} = clientData;\n\n  const getWithPassword = (password, errorCallback) =\u003e {\n    resolvePaste(hash, password)\n      .then(resp =\u003e {\n        setCorrectPass(true)\n        setClientData(resp.data)\n      })\n      .catch(e =\u003e errorCallback(e.response.data))\n  }\n\n  return (\n    \u003cdiv\u003e\n      {!error \u0026\u0026 \u003cNextHead data={data} /\u003e}\n      ...\n      \u003cPasteInfo\n        hash={hash}\n        lang={language}\n        theme={theme}\n        expiry={expiry}\n        err={unauthorized ? '' : error}\n      /\u003e\n    \u003c/div\u003e\n  );\n}\n\nexport default ViewPaste\n```\n\n### Deployment\nGreat! At this point, everything was working great -- locally. Every developer knows just how much of a leap it is to go from local machine to hosted and on the cloud. Right?\n\nMy first thought was to see how difficult it would be to port my existing frontend on Firebase Hosting to run using Next.js instead. Turns out I would've needed to enable Firebase Functions and to do that I needed to enable the Blaze plan (pay as you go). Seeing just [how much of a hassle the process was](https://dev.to/rowaxl/what-i-struggled-with-next-js-using-firebase-hosting-and-enable-ssr-4e67) made me look for other alternatives. \n\nVercel really surprised me with how easy it was to get setup. All I had to do was signup for Vercel using my GitHub account and select a repository to import. It took a total of 5 minutes to go from GitHub repo to deployed website which was a first.\n\nFunnily enough, the hardest part of this entire deployment process was deleting the old frontend off of Firebase. I accidentally deleted the entire project (including my Cloud Run deployed backend) twice and quite nearly misconfigured my domain.\n\n## Impact\nAll in all, trading 6 hours for such a huge quality-of-life improvement on a project that I personally use a lot has been absolutely worth it. To list a few tangible improvements:\n\n* Smoother user experience (no more annoying 'loading paste...' messages)\n* Cleaner codebase\n* Better link previews (sending links to friends)\n  \nIf you haven't had the chance to try Next.js out for yourself and you've made it this far, you owe it to yourself to at least give it a shot. Thanks to the HackClub community (specifically [Rishi](https://rishi.cx/), [Safin](https://safin.dev/), and [Ani](https://anirudhb.github.io/)) for their constant encouragement and criticism of my 'outdated' tech stack.\n\n**Source Code**: https://github.com/jackyzha0/ctrl-v\n\n**Try it out for yourself**: https://ctrl-v.app/","lastmodified":"2023-02-15T01:38:21.169820744Z","tags":null},"/posts/digital-gardening":{"title":"Digital Gardening","content":"\n\u003e As of 2021, this process is no longer accurate. I've embraced a much more networked form of note taking which I've written about [here](posts/networked-thought.md) and [[thoughts/the garden and the stream|here]].\n\nThe first image that comes to my head when I hear the word 'gardening' is of a small plot with some leafy greens sprouting their heads from an earthy bed. A gardener tenderly shovels and removes unwanted weeds and pours water to nourish the plants he wants to grow. He takes care to make sure the soil isn't too wet and that each plant has ample space to grow. When the time comes, he harvests each fruit and vegetable and makes sure to plant seeds so that he can repeat the process anew in a few weeks time.\n\nA garden is a metaphor for a lot of things: growth, persistence, and the constant battle against entropy.\n\nWhen I talk about digital gardening, I don't mean digital gardening in the Stardew Valley or FarmVille sense. I mean gardening as in the tending and growth of my own ideas and projects on my own little plot of the world wide web -- namely through my [[thoughts/writing|writing]], notes, and projects. After reading Joel Hook's blog post on his own [digital garden](https://joelhooks.com/digital-garden), I've been thinking and reflecting on my own processes for managing my own digital garden (which you are on right now).\n\n## The garden plot\nAccording to [GitHub](https://github.com/jackyzha0/blog/commit/74f7460c49a7c56acfadf3f8f1cdd892005ebed4), I first created this blog in late August of [2020](posts/2020.md). At the time, it was more of a novelty thing. I wanted to get off of Medium and onto my own platform where I had more fine-grained control over how I could present my work and how people discover it.\n\nI spent a few hours building out my own Hugo theme, making it as frictionless as possible to write produce new content. I threw up a few of my old Medium blog posts just to see how it would look, and I was happy with it. However, even with the novelty of the blog, I had nothing to write about.\n\nThe plot was there; I just didn't have anything to plant in it.\n\n![The Garden Plot](/posts/images/digital-gardening/plot.png)\n\n## Planting the seeds\n\nIf you have no seeds in your garden, the only things that will grow are weeds. I could barely remember the last time I read a book on my own time. Needless to say, garbage in, garbage out.\n\nOver the summer, I began to read again. Technical write-ups, fiction novels, traversing into self-help, and memoirs. I started to read more about the state of the world and critically discuss these with family and friends. Reading helped me colour in the lines as to why we need to build in the first place. I started to realize that the problems we try so hard to solve with technology are not actually tech problems, but inherently human ones.\n\nI've started to write more about some these ideas (like within this blog post!), at first to help me organize my own thoughts, but eventually segued into an excuse for me to talk to people about interesting ideas and get their perspective. It's started a sort of chain reaction, with observations from a book leading to a conversation with a friend to a blog post ad infinitum. I've been able to slowly build up my [base of knowledge](/posts/collaborative-thinking) so that I can contribute meaningfully to conversations.\n\nThese are the seeds I plant in my garden, but these seeds will stay seeds unless watered.\n\n![Planting the seeds](/posts/images/digital-gardening/seeds.png)\n\n## Watering the plants\n\nI have a Notion page of random thoughts and ideas. Whenever I come across something interesting in a conversation or book or article, I file it away in this Notion page. Slowly, categories have appeared as blog posts, articles, and papers coalesce and self-organize.\n\nThis input of information -- the water -- is what allows the ideas to grow. Just as it's not enough to just water a plant once and forget about it, I've found that in-taking information inconsistently is about as good as not doing it at all. To be an effective watering can, I need to be intentional and consistent with my watering.\n\nMy process of collecting random scraps of information first sprung up from coming across interesting blog posts on Reddit. I'd always just read a cool post, follow a few hyperlinks, nod to myself and say \"huh\", and maybe forward it to a friend or two. While it may have been entertaining to read, I got no value out of it. Now that I've started cultivating this garden of ideas, I have a reason to be more intentional in how I sift through the information and be more mindful of what I'm actually taking away from each piece. [[thoughts/writing|Writing]], specifically on this blog and on my newsletter (which you can subscribe to at the bottom of this page), has helped me to go back to more mature ideas and condense and refine them into something presentable and legible to others -- quite literally picking the fruit of my labour. \n\n\u003e We are all constantly bombarded with information, a lot of it is really good information too, but the challenge is absorbing it and applying it to the context of our lives and careers. \u0026mdash; Joel Hooks\n\nNow that I have all of these new-found ideas and tidbits of information, what do I do with them? Keep growing them forever? At some point on the [exploit explore](thoughts/exploit%20explore.md) tradeoff, this knowledge should be applied to something in order to manifest it into something useful. The problem is, which ideas get priority of my time and effort?\n\n![Watering the plants](/posts/images/digital-gardening/watering.png)\n\n## Pulling weeds\n\nNo garden has unlimited space or nutrition to go around. Maybe you have a bigger garden than most, but that doesn't mean you can grow whatever you want silly-willy. Some will need more space than others and others you simply just cannot grow in the same garden plot.\n\nSimilarly, no one has unlimited time and energy they can put into projects and learning. I, unfortunately, have yet to fully learn this lesson. After having an empty plot for so long, having a little greenery show up has inspired me into a planting frenzy, trying to cram as much into the garden as possible.\n\nI'm starting to step back and reflect on my current commitments and deciding to either to step down from things that I'm less passionate about to make more time and room to double down on the things I'm truly passionate about.\n\n![Pulling weeds](/posts/images/digital-gardening/weeds.png)\n\n## End\n\nNone of what I do is perfect. Looking back at writing from a year ago, reading code from a few months ago even, makes me cringe a little. Like any garden, this one evolves and grows over time; there is no 'end-state' that I'm trying to get the garden to. This little garden is just a little place for me to experiment, to push out things that I'm working on, and to provide snapshots of all the in-progress things going on in my life.\n\nThrough tending to this garden [in public](thoughts/building%20in%20public.md), I hope to show my success, failures, and everything in between and offer it as an open garden to learn from for anyone who stumbles upon it in the future. If just one person is inspired by it, learns from a mistake I made, or builds off of my work, then I would consider this garden a success.\n\nMaybe you'll find this as an incentive to start your own.","lastmodified":"2023-02-15T01:38:21.169820744Z","tags":null},"/posts/digital-identity":{"title":"On Digital Identity","content":"\n*What is identity? Who defines it? Who controls it? What is its relationship to software?*\n\nSoftware developers and computer scientists have been tackling [[thoughts/identity|identity]] for almost half a century now, trying to model identity in ways that are understandable to machines. Different models seek to emulate different aspects of the identity.\n\nBut for engineers building these digital identities, the primary focus is on legibility: the process of simplifying, labelling, and modelling. ISO/IEC 24760-1, the only formal international standard for identity, sees identity as a set of attributes to be managed[^1]. \n\nLegibility on its own is not a bad thing. It’s how Google assembles droves of information on the web so we can search through it easily. It’s how we have transparency into the progress of publicly funded projects and initiatives by our governments.\n\nBut this process of legibility becomes dangerous when it forcefully shapes users. When legibility becomes the lens you view the world through, relationships are front-run by a deluge of data rather than formed more organically between individuals[^2]. This systemized legibility of the world is an interpretive and transformational force that changes how we perceive others[^3].\n\nIn the process of being made legible, nuance is excluded. Legibility means that ‘only what matters’ and can be quantified is kept; all else is discarded. This is especially dangerous when that legibility happens without the choice of the users.\n\n![[thoughts/images/forest death.png]]*Illegible natural forest vs legible \"scientific\" forest (James C. Scott in Gordon Brander)[^4-1]*\n\nForced legibility may look like a set of failing grades on a report card without an accompanying note explaining how you missed finals week because you needed to grieve for the death of a loved one. Forced legibility may look like a conviction charge without the context behind how the officer was racially motivated. Forced legibility may look like having to choose between identifying as a man or a woman on the national census when neither describes you well, erasing their lived experience. When legibility is forced upon people, it only serves to widen the gulf that already exists in society and disproportionately impacts marginalized groups[^2]. This legibility is beneficial for companies and governments seeking to better model user-data, but it doesn’t serve humans who seek to govern their own identities and control who accesses their information.\n\nIf we want to flip [[thoughts/access control|access control]] back to the users, we need to consider other representations of identity. Clearly, it doesn't make sense to try to make every part of our digital identities legible. **Can we develop alternate systems that provide similarly rich models of identity that also allow people to be illegible? Or at least self-selectively legible?**\n\nThis essay seeks to explore alternate abstractions for identity to better resolve the identity needs of *all* relevant stakeholders, not just centralized providers. We can categorize digital identity models based on the primary representation of identity along with the locus of control (managed versus self-sovereign).\n\n|Identity as...|Managed|Self-sovereign|\n|-|-|-|\n|Attributes|Video game character, e-shopping account, TikTok|Verifiable Claims, NFTs|\n|Capabilities|IAM (Identity and Access Management)|OAuth Tokens, UCANs|\n|Relationships|Messenger, Whatsapp|???|\n\n*Fig 1: Different models of digital identity.*\n\nWhat are ways we can lean towards self-sovereign models of identity? How do we give users freedom to choose how legible they are online?\n\n## Identity as Attributes\n\n![[thoughts/images/identity-attribute.png]]\nOur digital representations consist of:\n-   What we bought last time we visited Amazon;\n-   All the files you’ve uploaded to Google Drive;\n-   Google Analytics data points about what pages we visited and when;\n-   What type of videos we watched on TikTok over the past week.\n\nMost data models default to this assumption of identity as objects with attributes. Almost all programming languages model things, including people, this way. Databases are similar, either being documents with attributes or rows in a table. Relations are encoded as references to other documents, not as things in and of themselves.\n\nWhen we model identity as a collection of attributes, all aspects of identity are, by default, quantifiable and measurable.\n\nHaving individuals completely own their identities (e.g. [[thoughts/Self-sovereign Identity (SSI)|Self-sovereign Identity (SSI)]] and [[thoughts/Verifiable Credential|Verifiable Credentials (VCs)]]) gives agency to people to control these representations but the main function of these identities is still to make the bearer legible.\n\n## Identity as Capabilities\n\n![[thoughts/images/identity-capability.png]]\n\nWhen I think about what digital identity ultimately feels useful for, it is to gesture at *capabilities* rather than attributes. My identity can also be represented by how I act and what I have permission to do. Gordon Brander suggests similarly: \"digital identity should not be about who you are, but what you are authorized to do.\" [^5] \n\n\u003e \"[A model of identity as capabilities] considers it to be dynamic, multiple, informational, temporary, contextual. Whereas the [model of identity] as attributes] attach actions and interactions to actors, the [capability model] recognises that identity is co-emergent with actions and interactions in contexts.\" (AKASHA and Kernel[^6])\n\nFrom a software perspective, this isn't a new representation of digital identity either. [[thoughts/UCAN|UCAN]] serves to be a promising way to delegate permissions and actions through a [[thoughts/DID|decentralized identity]]. JWTs have been granting permissions to users for a decade. New forms of token-based access using NFTs are being experimented with.\n\n\u003e Everything that a user is allowed to do is captured directly in a key or token, and can be sent to anyone that knows how to interpret this format. _([ucan.xyz](https://ucan.xyz/))_\n\nThere is no ‘identity’ to be managed but rather a set of capabilities to be possessed. Signable messages using [[thoughts/Asymmetric Key Cryptography|public-key cryptography]] means that we can prove the same person you issued the access token to is now requesting access *without* revealing who it is. As there is no global registry of who has what permissions, this is by default illegible unless a user wants to manually publish their key to make it known.\n\nThis feels promising. A token that grants access isn’t making legible any information that doesn’t need to be, it just grants access to whoever has it. It grants a basic level of illegibility to those who prefer to keep real-world identities and digital ones separate.\n\nYet, I think there is still room for improvement here. Identities based off of tokens and keys aren't human-meaningful. In gaining the option for illegibility, we've lost any resemblance of a human identity. I want to know that I'm talking to my friend Kevin and not just a key like `0x8ff6b283368b5f149f1de2005d763243` or a phone number like `323-594-1604`.\n\n## Identity as Relationships\n\n![[thoughts/images/identity-relationship.png]]\n\n\u003e \"Unfortunately, due to their peculiar nature, humans are unable to memorize large numbers of keys, and use them as names for a multitude of objects.\"[^7]\n\nYou are already most likely familiar with a system for 'memorizing' these large keys already. All of our phones have a personal address book that we use to map meaningless phone numbers to human-meaningful names.HCI researchers call systems like these [[thoughts/petname|petname]] systems.\n\n\u003e For example, if you meet someone named Becky who plays trombone, you could name her “Becky Trombone” and someone else could name her “Becky 101B.” This personal relationship is more recognizable to each individual than a single, self-described user profile named “Becky Smith.” Instead of a single global contact list (like Facebook), we want many personal contact lists (like phonebooks). *([Backchannel](https://www.inkandswitch.com/backchannel/), Ink \u0026 Switch)*\n\nIn this way, the petname doesn’t just represent the person you are referring to, but also the relationship between the two of you. The *real identity* is neither the phone number nor the petname. Rather, the real identity is the *intersection* of all of the relationships they have with others. Just as we have many ‘alt accounts’ that exist to approximate the many facets of our being, each identity in this model is specific to each relationship. Even if data gets leaked, it is extremely difficult to trace back to the original author because there is no ‘global’ identity to trace it back to — all of it is contextual.\n\nThe key thing in a relational notion of identity is that the relation – the ‘join’ between identities – is an entity in and of itself. It can be described, and it has a history which can be built on top of. This is a relation that is private by default (only between parties involved) and unique (no other relation like this exists).\n\n**Perhaps the new atom of identity is not a single entity but a set of relationships: *a group chat.***\n\nIdentity may be a difficult thing to model, but it is worth thinking about deeply. Our models for identity will impact how many future generations of internet users are categorized and made legible. It makes sense to ensure it best serves the people it represents.\n\nAs [[thoughts/peer-to-peer|peer-to-peer]], [[thoughts/local-first software|local-first]], and [doorless](https://rosano.hmm.garden/01evv3hq1ak4b6ng1jzppx5n2j) apps slowly make a resurgence, I hope that agency is the value at the forefront of new applications and protocols, enabling users to choose which parts of themselves to make legible.\n\n*Thank you to Anson Yu, B Cavello, Cent Hosten, Saffron Huang, Shrey Jain for reading earlier drafts and providing clarifying feedback.*\n\n[^1]: Source: [ISO Standard](https://www.iso.org/standard/77582.html)\n[^2]: Source: [Is \"acceptably non-dystopian\" self-sovereign identity even possible?](https://blog.mollywhite.net/is-acceptably-non-dystopian-self-sovereign-identity-even-possible/), Molly White\n[^3]: Source: [To Live in Their Utopia](https://dl.acm.org/doi/fullHtml/10.1145/3411764.3445740), Ali Alkhatib\n[^4]: Source: [Soulbinding Like a State](https://subconscious.substack.com/p/soulbinding-like-a-state), Gordon Brander\n[^4-1]: \"Scott details a pattern of disaster that repeatedly manifests around legibility. His opening example is from the late-18th century discipline of “scientific forestry”. A natural forest is illegible. A tangle of plants. This is inconvenient from the standpoint of harvesting lumber. How do you quantify yield? Can you even make a meaningful map of this mess? Much easier to clear the forest and plant a legible “scientific” forest. Uniform rows of trees that produce good lumber. Now we can count the trees, make a map, track sustainable yield. What’s missing from our map? Everything else. The forest has been _made legible_ to lumber production. In the process, the entire ecological web of trees, shrubs, birds, bugs, moss, soil microbiota are stripped away. They didn’t fit into our map. By the second generation of planting, there is a noticeable decline in forest health. Within one century: _Waldsterben_, forest death, ecological collapse.\" Quote from [Soulbinding Like a State](https://subconscious.substack.com/p/soulbinding-like-a-state), Gordon Brander\n[^5]: Source: [Five Mental Models of Identity](https://github.com/WebOfTrustInfo/rwot7-toronto/blob/master/final-documents/mental-models.pdf), presented in *Rebooting the Web of Trust VII* by Joe Andrieu, Nathan George, Andrew Hughes, Christophe MacIntosh, and Antoine Rondelet\n[^6]: Source: [Human identity: the number one challenge in computer science](https://generative-identity.org/human-identity-the-number-one-challenge-in-computer-science/), AKASHA Foundation and Kernel\n[^7]: Source: [PetName Markup Language](http://www.erights.org/elib/capability/pnml.html) by Mark S. Miller et. al","lastmodified":"2023-02-15T01:38:21.173820752Z","tags":null},"/posts/docker":{"title":"Docker Explained","content":"\nContent from my own ['Docker Explained' repo](https://github.com/jackyzha0/docker-explained). Check out the repository for example code!\n\n## Introduction\n### What is Docker?\nDocker is a tool that makes it really easy to package applications into self-sustaining 'containers'.\n\n### What are containers?\nContainers, as their name suggests, contain things. In the case of Docker, these contain all the parts the application needs to run, everything from libraries and dependencies to the actual source code.\n\n### Why containers?\nContainerization means that everything to do with your application stays inside the container. You shouldn't need to worry about how stuff on your machine (e.g. which version of Python you have) affects how your program runs. As a side benefit, this means that Docker containers are dependency-free. Never worry about \"oh, it works on my machine\" ever again! After a Docker image is created, all of its contents are frozen so it should work exactly the same on your computer as it does for someone else (assuming you both have Docker).\n\n### Why Docker?\nDocker makes it super easy to work with these containers and, by proxy, you can get all the cool benefits of containers easily too! It also allows you to programmatically define a container through code, meaning you can collaborate and work on Docker containers just as you would with a regular piece of code through version control like `git`.\n\n## Installing Docker\nMore detailed instructions can be found [here](https://docs.docker.com/get-docker/).\n\n## Parts of Docker\n### Docker Containers\nI think the intro covered this pretty well so I'll repeat it again here.\n\n\u003e Containers, as their name suggests, contain things. In the case of Docker, these contain all the parts the application needs to run, everything from libraries and dependencies to the actual source code.\n\nThis means that 'containerized' applications don't need to rely on a system to have certain dependencies (e.g. `Node.js`) installed on the user's system to run because the container will have it packaged.\n\nYou can think of Docker containers like a fully self-contained and running version of your application.\n\n### Docker Image\nYou can think of Docker images like a sort of 'template' that describes to Docker how to create a container from scratch. You can build these images by providing instructions on how to build them in the form of layers.\n\n### Layers\nDocker images, like ogres (or cakes if you're a boring person), have many layers. The base layer often provides some basic functionality like providing `git`, `bash` or `apt` -- otherwise your container has nothing to run off of! We can then add our own layers on top of that base layer, like installing dependencies, copying files into the image, and defining the command to run when the container starts up. These instructions are programmatically defined through a Dockerfile.\n\n\u003e One of the coolest parts of Docker is that these layers get cached between builds if nothing has changed. That means that if you rebuild an image and only changed the last layer, it'll only need to rebuild the last layer rather than rebuilding the whole image, making for some really fast iteration times.\n\n### Dockerfile\nThe Dockerfile are the actual specific instructions for how to create the actual image or 'template'. The Dockerfile starts off by defining a 'base-layer', which serve as the basis for your actual image. Some common base layers are `ubuntu` (which contains a minimal install of the actual Ubuntu operating system) and `python` (which contains everything needed to run a basic Python app). \n\nI won't dive into too much details about each command you can use as these will be described more in-depth within the examples. You can find detailed documentation on the commands you can use in a Dockerfile here: https://docs.docker.com/engine/reference/builder/\n\n## Docker CLI\nGreat, so now I know a little bit about how Docker actually works, how do I get started? First, let's make sure our Docker install works correctly. You can do this by opening your favourite terminal and entering `docker run hello-world`. You should get something that looks like:\n\n```bash\n$ docker run hello-world\n\nHello from Docker.\nThis message shows that your installation appears to be working correctly.\n...\n```\n\nNow, let's go over a few basic CLI commands that you'll probably be using as you work with Docker.\n\n### `docker build`\n\u003e How do I turn a Dockerfile into an actual image? \n\nTo built an image, you can do `docker build . -t \u003cname-of-image\u003e` which tells Docker to look in the current directory for a file called `Dockerfile` and to follow the instructions inside to build an image. After doing so, tag the image so we can easily find it later. Docker image tags let you version your images as well. Say you wanted to build a v1 for your image, you would do `docker build . -t \u003cname-of-image\u003e:v1`. If you have a different name for your Dockerfile, you can also refer to it using the `-f` flag like so: `docker build . -t \u003cname-of-image\u003e -f \u003cname-of-dockerfile\u003e`\n\nMore info can be found here: https://docs.docker.com/engine/reference/commandline/build/\n\n### `docker image ls`\n\u003e How do I get a list of all the images I've built?\n\nThe command will give you an output that looks something like the following.\n\n```bash\nREPOSITORY                 TAG                 IMAGE ID            CREATED             SIZE\nimage1                     0.1.1               9eb95c7f06b0        2 days ago          343MB\nimage2                     \u003cnone\u003e              c99ac06cf60a        2 days ago           23MB\n...\n```\n\nMore info can be found here: https://docs.docker.com/engine/reference/commandline/image_ls/\n\n### `docker run`\n\u003e How do I create a container from an image?\n\nNow that you've built an image, you can just run it by doing `docker run \u003cname-of-container\u003e:\u003cversion\u003e`. More often than not, you can just use the latest version of the image, `docker run \u003cname-of-container\u003e:latest`. However, certain applications (like servers) need to listen on specific ports. By default, Docker doesn't allow containers to use ports on your local machine, but you can allow this by specifying ports using the `-p` flag, `docker run -p \u003chost-port\u003e:\u003ccontainer-port\u003e \u003cname-of-container\u003e`. If your container listens on port 3000, but you want it to appear as port 5000 on your local machine, it would look like `docker run -p 5000:3000 \u003cname-of-container\u003e`\n\nIf you want to run your container in the background in a detached manner, you can just add the `-d` flag.\n\nMore info can be found here: https://docs.docker.com/engine/reference/commandline/run/\n\n### `docker ps`\n\u003e How do I figure out what containers are currently running?\n\nYou can get a list of currently running containers by doing `docker ps`, which will give you each container running along with details about its Container ID, what image it was created from, when it was created, as well as which ports are open.\n\n### `docker exec`\n\u003e How do I run a command inside a container?\n\nYou can use the command `docker exec -it \u003ccontainer name\u003e /bin/bash` to get a bash shell in the container, allowing you to run commands from within the container as if it was a full-fledged machine. If you know specifically what command you want to execute, you can use `docker exec -it \u003ccontainer name\u003e \u003ccommand\u003e` to execute whatever command you specify in the container.\n\n## Docker Examples\n1. [Basic Python app with dependencies](https://github.com/jackyzha0/docker-explained/tree/master/1-basic-python/)\n3. [Node.js and Express app](https://github.com/jackyzha0/docker-explained/tree/master/2-basic-node)\n4. [Multi-stage Go app](https://github.com/jackyzha0/docker-explained/tree/master/3-multi-stage-go)\n\n## Further reading\nThese topics will not be talked about within this repository, but I've added a few resources I've found helpful in my understanding of each of them.\n\n### Docker Compose\nDocker Compose is a tool that lets you start multiple Docker containers together and configure how they interact.\n* https://docs.docker.com/compose/\n* https://github.com/docker/compose\n\n## Kubernetes and Microservices\nmIcRoSerViCeS you may hear them say. What's all the hype about? Basically, its the [single responsibility principle](https://en.wikipedia.org/wiki/Single-responsibility_principle) but applied to services. This means that each responsibility should, ideally, be split out into its own service and be completely responsible for that one thing. This lends itself really easily to Docker and containers. Kubernetes is a system that makes it really easy to deploy, scale, and manage a bunch of containers, making it near ideal in creating a microservices architecture using Docker.\n* https://microservices.io/\n* https://medium.com/hashmapinc/the-what-why-and-how-of-a-microservices-architecture-4179579423a9\n* https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/\n* https://kubernetes.io/docs/tutorials/kubernetes-basics/\n* https://opensource.com/article/17/11/getting-started-kubernetes\n\n## Deploying to the Cloud\nNow that you got some cool new containers? How do I run them in the Cloud like all the other cool kids? Thankfully, Docker makes this super easy too.\n\n### Google Cloud Run (GCR)\n\u003e https://cloud.google.com/run\n\nGCR completely manages scaling and deploying your containers for you so you don't need to worry about server management (yay serverless)! Simply upload your images to Google Container Registry, and create a new Cloud Run deployment.\n\n* https://cloud.google.com/run/docs/quickstarts/prebuilt-deploy\n* https://cloud.google.com/run/docs/quickstarts/build-and-deploy\n\n### Google Kubernetes Engine (GKE)\n\u003e https://cloud.google.com/kubernetes-engine\n\nWant to run your own Kubernetes cluster and have a lot of money to burn? GKE may be right for you! Other than the price, GKE is super user friendly and makes it really easy to manage and visualize your deployments.\n\n### Amazon Fargate\n\u003e https://aws.amazon.com/fargate/\n\nThink GCR but Bezos.\n\n* https://medium.com/@ariklevliber/aws-fargate-from-start-to-finish-for-a-nodejs-app-9a0e5fbf6361\n\n# Closing\nI hope you learned a thing or two about Docker! If you found anything the be incomplete, poorly explained, or just garbage, feel free to open an issue about it (and maybe even make a PR improving it)! If you liked it, feel free to give it a ⭐ so both you and I can feel fuzzy inside.","lastmodified":"2023-02-15T01:38:21.173820752Z","tags":null},"/posts/hackathons":{"title":"Hacking the Hackathon","content":"\n## The 'Involution' of Hackathons\n![A late night breakthrough on our PennApps XX Project](/posts/images/hackathons/drone.png)*A late night breakthrough on our PennApps XX Project*\n\n\u003e \"Quick, quick, Caden! Wake up -- the drone is **flying**!\"\n\nHalf of our team had been sleeping for the past hour and a bit. Acceptable, considering the time was now 2:42 am. The drone was whirring midair in our little room, nearly getting snagged on our laptops, chargers, and free event swag. Beside us, a blackboard wall displayed a rough chalk diagram of our technical architecture. We had roughly 20 hours left in the hackathon and now that the drone worked, our biggest roadblock was out of the way — it was time to build! We grabbed a plate of cold noodles from the meal line and ran past the crowd of people doing cup stacking competitions, karaoke, and Smash tournaments.\n\nThere is something truly special about being able to manifest an idea into reality, that's what pulled me into hackathons in the first place. Anytime I went to a hackathon not knowing anyone, I left with a new group of friends and mentors and a handful of new skills. I've learned a sizeable amount of my technical knowledge through workshops and hackathon projects. These events inspired me to be intellectually curious. To this day, they're the main reason why I still to this day spend hours tinkering on projects and exploring new ideas.\n\nIn comparison, something feels different about the vast majority of hackathons held today. Recent hackathons may have all the bells and whistles of earlier events, featuring elaborate meal plans and free bubble tea, but it feels performative at best. When asking most people about why they want to go to a hackathon, most people will mention something about the prizes, the recruiting, or the free t-shirts with company logos plastered over them. There is an unavoidable corporate air to the events.\n\nHowever, this transition goes much further back than just the past few years. The origin of the more 'modern,' corporate hackathons arose out of corporate spaces like Facebook, which coopted design spaces like hackathons to further their hiring pipelines or to maintain their outward appearance being 'cool' to work for.[^1]\n\nThis corporate co-optation of hacker culture at hackathons has been on the back of my mind ever since reading the chapter on design sites in [*Design Justice*](thoughts/Design%20Justice.md) by Sasha Costanza-Chock. As someone who first got their footing in computer science through hackathons, it pains me to see that this is the rep that hackathons have slowly gotten over time, moving from safe spaces for idea exploration to increasingly corporate, competitive events where hackers spin up apps to test company products in exchange for the slim chance of winning prizes and recognition.\n\nHow did we get here?\n\n## Hacker Culture\nThe hacker subculture formed mainly out of the collaborative (and often competitive) DIY ethic of the [counterculture](thoughts/From%20Counterculture%20to%20Cyberculture.md) of the 1960s. This was the generation of the '[Hackers](thoughts/Hackers.md),' those interested in figuring things out as they go and invented for the *pure ecstasy of building and learning new things*. As Steven Levy defines it, 'hacks' were projects undertaken by these hackers not to fulfill any sort of end goal other than to take pleasure from working on it.[^2]\n\nThe congregation of hackers eventually led to the creation of alternative design and hackerspaces like hackathons. These very first hackathons were gatherings of excited groups of people ready to build something cool over the weekend.\n\nThese spaces were described as originally being \"third spaces\" outside of the influence of the state and the capitalist market.[^3] Yet, without intentional intervention, it is difficult for these design spaces to even uphold their claim as spaces for intellectual exploration for all, as they become dominated mostly by the privileged to expend free time and income, and overrun by corporations clamouring to sponsor hackathons in order to get as much cheap testing on their products as possible, shoving discount code after free credits at each hacker.\n\n**These design sites used to be valorized as places of learning, making, and building. Why then, have they become increasingly corporate places of extraction of free labour?**\n\n## Incentive Structure of Hackathons\n![Stacks of hackathon stickers ready for hackers' laptops](/posts/images/hackathons/swag.jpg)*Stacks of hackathon stickers ready for hackers' laptops*\n\nIt takes money to run events. Providing an adequate venue, food, internet, and power are not free resources. Yet, with the exception of a few corporate hackathons, the majority of hackathons remain free for attendees. To accomplish this, most hackathon organizers decide to try to acquire monetary sponsorships, food partnerships, and in-kind sponsorships in order to offset costs.\n\nAs a result a viscious cycle of [incentives](/thoughts/incentives) forms:\n1. Sponsors try to maximize the benefits they get for their money (e.g. hosting workshops, hiring booths, keynote speakers, company branding)\n2. With more money, hackathon organizers increase the size and scope of the event, leading to more hackers\n3. Hackers see sponsors as increasingly quintessential to the hackathon experience, being a key reason why hackers attend the events (sponsor prizes, free merch, hiring opportunities, etc.)\n4. Repeat\n\nThis leads to some key downstream effects on hackathon culture.\n\n### Prize Incentives\n\u003e \"People are now prioritizing their projects for the dollar value of prizes and the clout of awards. There is a trend where more and more attendees no longer come in to learn and make memories. Teams are now arriving to hackathons fully formed, with an idea in hand, and a checklist of the prizes they want to win.\" -- [Jonathon Xu](https://jonathanxu.com/blog/2020-07-25-on-hackathons)\n\nIncreasingly so, hackathons have placed more emphasis on prizes rather than building. They prominently display the total value of prizes available to entice hackers to attend, tout the available prizes again at opening ceremonies, and repeatedly blast announcements on them during hacking hours. Even DevPost, the 'homepage' for hackathons, organizes hackathons by how much there is to reap. Then again, who wouldn't want a free iPad and tens of thousands in cash prizes and online subscriptions?\n\n![DevPost Top Hackathon categories by prize pool](/posts/images/hackathons/devpost.png)*DevPost Top Hackathon categories by prize pool*\n\nUnfortunately, this [incentive](thoughts/incentives.md) structure attracts people to hackathons for the wrong reasons. Individuals are motivated to tick boxes on a judging rubric rather than to learn and build new skills on a solid foundation; people who *are* there to learn are pushed to try and compete for prizes instead. Beginners, who may have wanted to just learn how to build a website, are instead cajoled into unsustainably trying to learn how to build something completely out of their skill range, becoming frustrated and losing sleep in the process. This is not to say that pushing hackers outside of their comfort range is a bad thing, but there is a limit to how much useful knowledge is retained after patching together APIs and blindly copying tutorials.\n\nThese incentive structures push hackers to tailor projects specifically for prizes to see just how many sponsor prizes they can shotgun for. In most of these cases, hackers don't dare build outside of their comfort zone, instead choosing to work with technology they are already familiar with or project ideas they know have been successful in the past (don't say you haven't seen a gamifying volunteering or smart garbage bin hack before).\n\n### Short Term Optimization\n\u003e \"A one day hack for homelessness takes away from the complexity of social justice issues… you can't just come up with an app that solve the world's problems\" -- Design Justice[^3]\n\nMost hackathon projects are unsustainable and are unlikely to be used or continued to be worked on outside of the hackathon. A lot of this practice arises out of the Silicon Valley [saviorism problem](https://www.stanforddaily.com/2018/02/16/silicon-valleys-saviorism-problem/) and \"[move fast and break things](thoughts/move%20fast%20and%20break%20things.md)\" attitude. [^7] \n\nThe problem with this approach is that it becomes incredibly reductionist. Hacks nearly always focus on problems and rarely build on existing knowledge and work in the field, often ignoring important context about the issues they so readily reduce to a single web app. Ever seen an app claiming to solve the fentanyl crisis or healthcare for the elderly? People think hackathons can do things that they usually can't, such as solve global problems, create new products overnight, or 'level the playing field' of innovation through meritocracy.[^3]\n\nHackathons, as they stand today, seem to optimize for short term excitement, and not so much for long term benefit. But this short-term burst of new products and ideas is exactly what corporations need to fuel their endless hunger for products, testing, and new talent.\n\n## Corporate Cooptation\n\n![Cupstacking, a commonplace hackathon activity](/posts/images/hackathons/cooptation.jpg)*Cupstacking, a commonplace hackathon activity*\n\nCompanies realized that the attendees of these design spaces would *readily* give up their free time to build potentially marketable products. If hackers so readily built things in their own time, why couldn't we co opt these for the company? Hackers provided a source of interesting ideas that could be milked, and, as a result, the creative outputs of these hackerspaces were \"suddenly highly acclaimed, applied, and copy-pasted into capitalist developing laboratories.\"[^5]\n\nThe free market has warped the hacker ethos and hackerspaces into something almost unrecognizable from what it was supposed to stand for. This set of values which may have worked well for small startups or individuals just doesn't scale well for an entire industry. Sharon Zukin and Max Papadantonakis in their work *Hackathons as Co-optation Ritual* describe three quasi-Orwellian principles that describe this new hacker culture: Work is Play, Exhaustion is Effervescent, and Precarity is Opportunity.[^1]\n\n### Work is Play\n\u003e \"Forget about work-life balance. It's all about work-life _integration._ Why else would the office have on-site acupuncture, nap pods, and free dinner after 7 pm?\" -- [Arielle Pardes, WIRED](https://www.wired.com/story/how-silicon-valley-ruined-work-culture)\n\nThe initial hacker ethos of wanting to 'innovate' was evident in how vehemently startups disowned the 9-to-5 cubicle life. Walk into any tech company office building and you'd barely be able to tell if it was supposed to be a corporate office or adult playground with all the ping pong tables and colourful decor. The expectation was for employees to treat coworkers as family, office as home, and work as play.\n\nBut this playful front is not exactly as it seems. A [2017 study](https://businessresearcher.sagepub.com/sbr-1863-102641-2779724/20170508/more-companies-offering-unlimited-time-off) by Sage Business Researcher found that employees who work in offices with these benefits tend to stay in the office longer after work, pushing individuals to spend more and more of their lives in the office. Corporations frame events like hackathons as fun events to attend in an effort to appeal to the hacker ethos and to maintain their public image of 'coolness'. Disguised under the nerf gun fights, ping pong tables, and free food is a more sinister intent to treat work as play. Is it wrong to love what you do and treat it as play? No, but corporations shouldn't conflate the hacker ethos with a willingness to 'play' at work.\n\n### Exhaustion is Effervescent\n\u003e \"There are way easier places to work, but nobody ever changed the world on 40 hours a week\" -- [Elon Musk](https://twitter.com/elonmusk/status/1067173497909141504)\n\n100 hour work weeks and 'hustle culture' are becoming increasingly normalized by tech moguls like Elon Musk. Being constantly tired is somewhat of a [status icon](https://www.youtube.com/watch?v=_o7qjN3KF8U) as individuals boast about how little sleep they got.\n\nIt has been disturbingly normalized and even celebrated that [exhaustion is a sign of strength](thoughts/pain.md). Among a [global sleep-loss pandemic](https://www.theguardian.com/business-to-business/2017/dec/04/clocking-off-the-companies-introducing-nap-time-to-the-workplace), events like hackathons which push for attendees to stay up for lengths of 24 to 36 hours are particularly worrisome.\n\nI am viscerally reminded of sharing a hard gym floor with dozens of other sleep-deprived hackers, taking shifts to sleep so some people can stay up to work on the hack. Despite the timeboxed nature of hackathons, there is no reason purposefully staying up all night should be quintessential to the hackathon experience.\n\nPhysical and mental health should not be \"instrumentalized in service of being useful to a startup mission, or even a life philosophy.\"[^7] These events set the precedence of what the next generation of engineers, builders, and designers consider as 'normal' for the industry. Why are we saying that it's okay to prioritize 'success' above personal wellbeing?\n\n### Precarity is Opportunity\nThe startup and hustle culture heavily idolizes those who live precarious lifestyles. *High risk, high reward*. The industry has normalized high turnover rates and job-hopping, with companies like Google and Amazon reporting median tenures of around a year, compared to the national average of 4.1 years.[^6]\n\nToday, the majority of tech employment consists of internships, contract work, short tenures at medium to large companies, and precarious work at startups. Because of the incredulous demand for tech jobs, candidates have considerably more leverage than employers do in offer negotiations, with individuals often using competing offers between companies to renege better signing bonuses and compensation.\n\nWhile not precarious in the traditional labour sense, the employment itself is unstable and temporary. The concept of a 'life-long job' just doesn't exist in this industry. As a result, individuals are constantly asked to market themselves for continually shifting jobs.\n\nSimilarly, these coopted design spaces reshape precarious and unpaid work from exploitative to opportunity. Writing code and building apps for free becomes something to be clamoured and competed over. In other words, \"institutions use the allure of hackathons, with sponsors, prizes, snacks, and potential for career advancement, to get people to work for free.\"[^4]\n\n## Reclaiming Design Spaces\n\n![Liminal spaces: The morning after nwHacks 2020](/posts/images/hackathons/liminal_space.jpg)*Liminal spaces: The morning after nwHacks 2020*\n\nMaybe this is the [death of the hackathon](https://jonathanxu.com/blog/2020-07-25-on-hackathons) as we know it, and that might not necessarily be a bad thing. Maybe we can throw away the focus on prizes, winning, and short-term projects and replace it with something better.\n\n### Sustainable Learning\n\u003e The word hackathon is the portmanteau of *hacking marathon*. Why then, do we treat it like a sprint?\n\nThe 'finish a complete project in two days' mindset of hackathons rarely transfers well into the real world. Realistically, most projects are complex in scope and attempting to reduce complex problems down to a one-weekend hack omits a lot of context and nuance that is often important.\n\nWork done at hackathons should be toward long-term sustainable processes instead of short term precarious work. During the past year, there has been a noticeable uptick in design spaces intended to facilitate longer term work like coliving houses, incubators, and fellowships. Hacker houses like [Edyfi](http://edyfi.org/) and [School 2.0](https://school2point0.com/) give individuals the option to work on existing projects or scale new ones in a supportive community. A few organizations like the Cal Hacks Foundation are pioneering initiatives in this space with programs like the [Cal Hacks Fellowship](https://fellowship.calhacks.io/) (a semester-long idea accelerator that invites teams to build beyond their side-projects) and [Hack Month](https://hackmonth.calhacks.io/) (which is a month-long build-a-thon focused on recentering the fun of building). MLH is also working on non-hackathon initiatives like the [MLH Fellowship](https://fellowship.mlh.io/) and the [Local Hack Day](https://localhackday.mlh.io/) workshops that refocus learning and maintenance rather than just blind creation. I've even noticed more individuals starting larger-scale personal projects that happen on the order of weeks to months rather than single days.\n\nEncouraging the growth of more sustainable skill building enables individuals to take into account a more holistic view of problems. Hopefully, this leads to building longer term, larger scope, and bigger impact projects and skills.\n\n### Places of [play](thoughts/play.md)\nDo we so necessarily need to tie rituals of play in building and tinkering to the recruiting and product testing pipeline for large corporations? Hopefully the answer to that question is no.\n\nYet even today, a majority of communities focused around building like [YCombinator](https://www.ycombinator.com/) or [OnDeck](https://www.beondeck.com/) are ultimately not places of play – they have external outcomes they'd like to achieve. We should create dedicated spaces for exploration and learning *without* needing to justify it via some specific outcome. This is not to say that spaces with those goals in mind are bad, but giving individuals the option to have a space for unfettered exploration can give them the freedom to explore ideas that may not have clear monetary value in the short term. Communities like [Hack Club](https://hackclub.com/) and [Reboot](https://reboothq.substack.com/) do this particularly well. There is no central 'goal' of trying to launch a product or anything, but rather it's a group of individuals that are intellectually curious and want to learn and build cool things.\n\nThe goal is to provide the infrastructure so that *everyone* can play, not just those privileged enough to throw spare income and time at it. Hackathon organizers shouldn't assume that everyone is able and willing to stay up the entire event and barely set aside enough time for meals. It is important to consider food, bio breaks, accessible bathrooms that are friendly to all body types and genders, comfortable spaces to nap or relax, and decent lighting, etc.[^3]\n\n## Moving Forward\n![A project demo at nwHacks 2020](/posts/images/hackathons/reclaiming.jpg)*A project demo at nwHacks 2020*\n\nIf well-organized, hackathons can provide a fertile ground for pathways to employment as well as being a place of exploration. Those identities don't need to be mutually exclusive. My argument here is that hackathons have recently placed too much emphasis on the pathways to employment; the main focus of design spaces like hackathons should be on hackers, not sponsors. Even for lower-income students, the 'employment' opportunities are usually short-term and precarious. Of course, sponsorship and money does have a role in making these hackathons possible, but not to the scale we've come to expect at these events.\n\n### The Future of Hackathons\nWhat might the future of the hackathon look like, if not what it is now? \n\n* **Emphasis on sustainable learning**. Realistically, hackers will not *learn* if all they did was copy tutorials off the internet. Most learning happens through sharing between individuals and teams. Hopefully, we can bake this into the hackathon structure by creating cohorts of hackers for [parallel play](https://en.wikipedia.org/wiki/Parallel_play) and refocus the hackathon as a means to [learn and explore](thoughts/Mindstorms.md) for the sake of learning and exploring rather than to hit the checkboxes on a rubric.\n* **Realistic Scoping**. Too many of today's hackathons boast that they focus on creating 'hacks for social good.' The reality of the situation is that these complex and nuanced societal problems *cannot* be solved overnight with a simple web app. Either we stop advertising hackathons for good on the timescale of a single weekend, or we increase the timescale of the hackathon from a weekend to months or even years.\n* **Deprioritization of prizes and winning**. Instead, we should provide a space for hackers to play and explore ideas. Obviously in an ideal world, both can happen at the same time, but the rubric-based approach that most hackathons take make these almost mutually exclusive. For now, let's incentivize participation, completion, and novelty over prizes, competition, and winning.\n* **Hacker-focused spending**. Money spent on often unsustainable swag could be much better spent in favour of more emphasis on higher quality venues, food, and accomodations. In doing so, we can work on raising enough money to run a successful event for the hackers rather than a sponsor's notion of a successful event. At the end of the day, money is power. If you have external [funding](thoughts/funding.md) coming in, the expectation is that they have partial influence over the event. Let's make sure that we draw the line where appropriate with sponsors so that the focus remains on the hacker. \n\n### A Promising Pilot\nThe sudden switch to virtual events due to COVID-19 may actually have been the catalyst to the potential future of hackathons. Virtual hackathons this year have shown how successfully we can run events on low budgets that are often 1/10th of our regular running budget. This means we were able to shave off swag, venue, transportation, and food costs to just a tiny fraction of what they used to be. This taste of what hacker-centric hackathons could be like was incredibly exciting to see, almost a glimpse into what the future of hackathons could look like.\n\n![After HackCamp 2020](/posts/images/2020/post-hc.png)*After HackCamp 2020*\n\nThis year, I was responsible for leading logistics at our beginner-focused hackathon called [HackCamp](https://hackcamp.nwplus.io/). To recentre hackathons around learning and to rebuild a healthier hacker culture, we decided to restructure our event into a virtual conference weekend. Here are a few things we changed:\n\n1. We separated learning and workshops from building and hacking and turned it into a two-day hackathon. This allowed hackers to attend workshops and learn without fear of missing out on precious hacking time and to have scheduled sleeping time between the Learn and Build days.\n2. We replaced our 'top' hackathon project awards with a $25 donation to charity for every project submitted. In the past, we've had feedback from hackers saying how this gave them the confidence to finish a project rather than to fail and give up working on the 'perfect' or 'winning' project.\n3. All events were live streamed. This meant that hackers could do the event on their own time and rewatch important events like opening ceremonies while still providing a 'live' viewing experience for those who are available.\n4. We changed judging to be focused on feedback rather than on evaluation. To do so, we replaced exposition judges (who were normally volunteers or company sponsors) with hackers and did [peer-to-peer](thoughts/peer-to-peer.md) judging. With this approach, each team averaged 7 pieces of feedback.\n\nAlthough this is by no means a full overhaul of the traditional hackathon, we think this is a great pilot into what a more explorative hackathon could look like. We were able to reach over 500+ attendees, 3.2k+ live stream viewers, and over $1200 in donations to charities, and the feedback we got was absolutely stellar.\n\n### Takeaways\nHaving more of the tools to articulate and locate exactly why hackathons have felt increasingly corporate is the first step to reinstate hackathons as third spaces not as places of competition and exploitation, but as places of play and exploration. Hackathons have so much potential to be safe havens for people to find like-minded people away from school assignments or startup grinds or corporate products. \n\nLet's hack the hackathon. This time, with hackers first, not companies. \n\n*Special thanks to Anson, Joice, Ivan, Jasmine, and Jess for reading and helping edit earlier drafts :)*\n\n[^1]: [Hackathons as Co-optation Ritual: Socializing Workers and Institutionalizing Innovation in the \"New\" Economy](https://academicworks.cuny.edu/cgi/viewcontent.cgi?article=1575\u0026context=gc_pubs)\n[^2]: [From Counterculture to Cyberculture](https://fredturner.stanford.edu/books/from-counterculture-to-cyberculture/)\n[^3]: [Design Justice: Community-Led Practices To Build the Worlds We Need](https://mitpress.mit.edu/books/design-justice)\n[^4]: [*Wired* on Hackathons and Exploitation](https://www.wired.com/story/sociologists-examine-hackathons-and-see-exploitation/)\n[^5]: [Post-it Note City](https://placesjournal.org/article/post-it-note-city)\n[^6]: [*Forbes* on High Turnover Rate in Tech](https://www.forbes.com/sites/forbesbusinessdevelopmentcouncil/2018/06/29/the-real-problem-with-tech-professionals-high-turnover)\n[^7]: [Beyond Instrumentalization](https://letterstoayoungtechnologist.com/Value-Beyond-Instrumentalization) by Jamie Wang","lastmodified":"2023-02-15T01:38:21.173820752Z","tags":null},"/posts/hootsuite":{"title":"Interning at Hootsuite in Highschool","content":"\n(with insights from Calvin and Hobbes)\n\nSince I’ve started at Hootsuite, I have\n\n* added and/or changed 6223 lines of code in 16 different repos\n\n* closed 24 tickets\n\n* made 4 new Slack emotes\n\n* listened to almost 10,000 minutes of lofi\n\n* had 1 amazing summer at Hootsuite\n\nIncluding the amount of money I’ve spent on lunch this past summer, everything has been so much more than I expected it to be. This short but sweet experience is something that I definitely will remember for a very long time.\n\n![[October 18th, 2015](https://www.gocomics.com/calvinandhobbes/2015/10/18)](https://cdn-images-1.medium.com/max/2000/0*uK2cNprrvSGsaECM.jpg)*[October 18th, 2015](https://www.gocomics.com/calvinandhobbes/2015/10/18)*\n\nOver these short 8 weeks, I’ve learned a lot. Everything at Hootsuite has served to be a once-in-a-lifetime learning opportunity, from learning to build complex services in languages that I’ve never even heard to doing technical demos in front of the entire Product Development team. Despite being a ‘software development’ position, I found myself learning to be a better technical communicator, to have better personal confidence, and so much more.\n\nYet among everything, two big lessons stood out to me:\n\n## The balance of life and work\n\n![](https://cdn-images-1.medium.com/max/2000/0*Mj-EMJtcvI4hM_jC.jpg)\n\nPeople often say how elusive good work-life balance is, even to the point of saying that it doesn’t exist. Yet, at my 2 months here at Hootsuite, I can positively say that it is alive and well. We’ve hiked almost 44km across 4 different trails in BC, attended music festivals, and even found niche groups for those interested in bouldering. At the office, there is no shortage of Slack memes and free birthday cake either. On a more serious note, the managers and leads here care deeply about their team members and go out of their way to ensure not only their well-being but also their development as a person.\n\n![Mount Seymour Trail Hike with the team!](https://cdn-images-1.medium.com/max/7936/1*eM_TIZGbBJIz485ssMqKTQ.jpeg)*Mount Seymour Trail Hike with the team!*\n\nThis was a big change from high school where a day at school left me completely drained and just ready to crash. Everything was so focused on grinding for results and doing work that it was hard to make time for myself. At Hootsuite, the community made it feel easy and natural to find the balance that worked for me.\n\nI was still working 8 hours a day, but somehow I felt energized and ready for more each day. It motivated me to make time to take on a freelance web development job just for practice (and to pay rent — living in Vancouver is rough) and even to make a simple project for a friend’s birthday!\n\nI know that this has probably been repeated countless times already, but I cannot stress how important it is to make sure you’re taking enough time off to relax.\n\n## Rejection\n\n\u003e Don’t reject yourself before other people get the chance to\n\n![[December 27th, 1985](https://www.gocomics.com/calvinandhobbes/1985/12/27)](https://cdn-images-1.medium.com/max/2000/0*Psh-fqFgVeQegGay.jpg)*[December 27th, 1985](https://www.gocomics.com/calvinandhobbes/1985/12/27)*\n\nBecomes sometimes, you just gotta go for it. You probably shouldn’t be going around and ruining nice coffee tables, but it works as a metaphor I guess? The point is: take necessary risks. Don’t say “nah, that’s not possible” before someone else tells you it is. At the start of summer, if someone told me I was going to be doing a demo on a proposal for a massive re-architecture of one of Hootsuite’s core services, I would have told you that you were insane. Yet here I am, doing just that:\n\n![](https://cdn-images-1.medium.com/max/3488/1*P8WSSl993SYILSfw9EfCwg.png)\n\nIf your brain is anything like mine, you often get these nagging self-doubts about whether you’re capable of doing something. The first time I was assigned to help define Service Level Objectives ([SLOs](https://landing.google.com/sre/sre-book/chapters/service-level-objectives/)) for some of Hootsuite’s core services, I was shocked.\n\u003e They’re letting a high schooler do this? How am I even close to being qualified?\n\nNot wanting to miss the opportunity, I took it. But as I began work, it became clear that I was the biggest critic in the room. They wouldn’t have asked me to do it if they didn’t trust me to do it and to do it well. Moving forward, I tried to trust myself more and to put myself out there, eventually taking on projects that I never thought would’ve been possible:\n\n* Designing prototype service meshes\n\n* Adding endpoints and writing scripts to cleanup user data\n\n* And other crazy things that I probably can’t publicly disclose\n\nIf an opportunity presents itself, jump on it! You don’t know where it might take you.\n\nIt’s really hard to put in words how much I’ve learned from the Owls here at Hootsuite. To the Owls: hopefully I’ve added something of value to all of you too.\n\n* Thanks to my manager and team lead Imtiaz and Shaun for being absolutely amazing in supporting my whole journey from start to finish.\n\n* Thanks to our team — team Golden Hammer — for helping me realize that yes, work can still be done while having fun. (:harold:)\n\n* Thanks to the co-ops (most notably Kevin, Andy, and Albert) for being so welcoming and having such a wholesome community.\n\n* Thanks to the other high school interns (Chloe, Kai, and Scarlet) for making sure that I wasn’t the only high school student that was being made fun of at board game night.\n\nAnd finally, thanks to Hootsuite for showing this little owl the world!\n\n![](https://cdn-images-1.medium.com/max/9312/1*RwlvNswSg95J253WHq2zbQ.jpeg)\n\nHootsuite has changed my attitude on how I see the world and it’s beautifully captured in one quote from Waterson —\n\u003e “It’s a magical world, Hobbes, ol’ buddy ... let’s go exploring!”\n\n![](https://cdn-images-1.medium.com/max/2000/0*aq1RW9_3MViZBV0b.png)\n","lastmodified":"2023-02-15T01:38:21.173820752Z","tags":null},"/posts/me-myselves-and-i":{"title":"Me, my selves, and I","content":"\n*An exploration on commitment, [trust](thoughts/trust.md), and growth.*\n\n![The Persistence of Memory by Salvador Dalí](/thoughts/images/the%20persistence%20of%20memory.png)*The Persistence of Memory by Salvador Dalí*\n\n---\n\nThe sound of the waves are nice, huh?\n\n*Yeah.*\n\nThe ebb and the flow of the waves, the toppling of sand sculptures of children. Of so much chaos in the world, the constancy of the ocean and its rises and falls gives me comfort.\n\n*You sound quite melancholic. Is everything alright?*\n\n... I've been thinking about the concept of commitment and trust. And maybe a bit about belonging too.\n\n*Can I lend an ear or a shoulder? We can just sit in the sun in quiet if you'd like.*\n\nThank you.\n\n**[And they sat there for a while. The sun inched downwards, setting the sky ablaze.]**\n\nWhat do you think it means to take on an identity?\n\n*Hmm. I think there is an element of trust -- that the ground below them will hold, that tomorrow will come again, and that the ocean will continue to rise and fall. Trust is an unquestioning attitude, an absence of deliberation over reliability. To commit is to believe it as a truth about oneself.*\n\nDo you think identities can change with time?\n\n*Yes. I don't think truth is absolute -- I think truth is a function of identity and identity itself is a function of time. Maybe, at this slice in time, certain axioms hold true about the universe. A few hours, years, millennia might pass and those truths might be different. Our different selves can choose between different systems of meaning and sense as our basic axioms.*\n\nI think my sense of self is undergoing a shift. It feels very liquid right now. One supposedly is supposed to 'live in the present' to enjoy the tea[^2], but I can't help but feel... scattered. I feel like I am trying to live too many lives at once and I feel the very fabric of my being being tugged at the seams. \n\n*I think empathy is a means of time dilation. For one to slow down or speed up their rate of life to match another. Of course, to constantly time travel to bridge the worlds of slow and fast is incredibly tiring. You must be very worn.*\n\nI want to be whole again. I want to be able to pour my everything in one life and to live that life well.\n\n*I understand. What is stopping you?*\n\nWell. What does it mean to responsible to a commitment that a past self has made? I promised [x] to some people very dear to me. At the time, it very much felt like the right thing to promise. I think my selves have changed though. The me that used to really enjoy [x] doesn't get that same spark, that same excitement as it used to. I found [y] pretty recently, and it gives me so much life to put time aside to work on it. Yet, I feel guilty. I made a commitment. A promise. It feels selfish to go back on that. I want to be someone who is reliable -- someone people can depend on and trust unquestioningly.\n\n*Ah yes, the desire to be a constant in the lives of others, yet to be fluid and growing in the life of your own. It is an unfortunate truth in life that we rarely get to choose both.*\n\nIs is possible? With all the time flowing through my hands, I am afraid that I am reaching for too much and end up not catching any at all.\n\n*Well let's see. What do you like so much about [y]?*\n\nI think recently, I've been able to better articulate the questions I want to spend my life answering. I think I've grown as a person and [y] aligns much more with what I want in the future, both in terms of myself and and the people I surround myself with. [x] feels like the trappings of the past, the remnants of a self I'm not sure I still consider my own. Yet, I am scared to let go of [x].\n\n*I think you are still muddled. I think what you lack is self-belief. The people in [y] inspire you, they amaze you. They have a ceiling of self-belief so high that it raises yours just through osmosis. These people are flawed too. They come from histories of [x], yet they still believe in themselves and what they want. Surround yourself with people in [y], for they are free in ways you're not[^3]. They are playing an infinite game in the hopes of waking you from the finite one you play in.*\n\nWhat shall I do?\n\n**[Both held their palms up to sunset.]**\n\n*Even if it is not your ideal life, you can always choose it. No matter what your life is, choosing it changes everything. I think you need to work on transitioning out of doing [x]. The self that committed to doing [x] has moved on. The self that is here and present needs to deal with the consequences of the past, but is not a slave to it. How we spend our days is, of course, how we spend our lives[^1]. What we do with this hour and that one is what we are doing. What can you do to make your days meaningful? I think [y].*\n\n**[The two sat in silence, their silhouettes indistinguishable in the fading sunlight.]**\n\nThank you for your company, your space, and your time. I want to take the necessary time to ease out of [x] and to do it with care and tenderness.\n\n*You and me, we are not so different. One of us might be a few chapters ahead, but you'll be back at this beach someday. I'll be going now. See you soon.*\n\n*Yes, I hope so.*\n\n**[And the waves continued to crash down. One got up to leave, another came to sit down.]**\n\nThe sound of the waves are nice, huh?\n\n*Yeah.*\n\n[^1]: Annie Dillard, *The Writing Life*\n[^2]: Thich Nhat Hanh's *Tea Meditation*\n[^3]: Patricia Mou, *[Rabbit Holes](https://wellnesswisdom.substack.com/p/-wellness-wisdom-vol45-30-pieces)*","lastmodified":"2023-02-15T01:38:21.217820833Z","tags":null},"/posts/networked-thought":{"title":"Networked Thought","content":"\n\u003e \"Gardens … lie between farmland and wilderness ... The garden is farmland that delights the senses, designed for delight rather than commodity.\" -- [Bernstein](http://www.eastgate.com/garden/Gardens.html)\n\nWe live in an information age. The amount of data we produce far outweighs what we consume, so much so that it has extended far beyond our ability to make meaningful use of it. Even our modern day [search](thoughts/search.md) systems seem to be falling apart under the stress of today's overwhelming flow of data with the quality of our search engines degrading from all of the SEO hacks, paid advertiser content, and clickbait headlines.\n\nOver the past year, I've slowly found processes that have worked well in creating a little curated corner of the [Internet](thoughts/Internet.md), rich with wonderfully curious people exploring exciting ideas.\n\n## What is digital gardening?\nA digital garden is not a file cabinet, nor is it fully an index. A digital garden, in fact, is less so a well-kempt plot for farming and more so a mess of entangled growth. It is a network of interconnected ideas and thoughts, clustered by how they are associated with each other.\n\nThis is not because I don't like order, but because I think **a dash of chaos and entropy is good for new ideas**. They help connect two separate ideas that you normally would not have associated with each other, and to imagine the 'what if' more frequently.\n\n\u003e But there is also a philosophical basis for this which to me is quite practical. A pretty good master analogy is that it’s an attempt to make a big stew pot out of my brain – there is tremendous value in allowing all of these notes and ideas and observations to stew and ferment in there. For me, the real power comes when ideas intermingle and I’m able to discover connections that I truly could never have dreamed of under normal conditions. ([Robin Sloan](https://every.to/superorganizers/tasting-notes-with-robin-sloan-25629085)on [[thoughts/rhizomatic vs arborescent|rhizomatic]] notetaking)\n\nMy goal with a digital garden is not purely as an [organizing system](thoughts/organizing%20system.md) and information store, thought it works nicely for that. I want my digital garden to be a playground for new ways ideas can connect together. As a result, existing formal organizing systems like Zettelkasten or the hierarchical folder structures of Notion don't work well for me. There is way too much upfront friction that by the time I think about how to organize my thought into categories, I've lost it. [[thoughts/rhizomatic vs arborescent|Rhizomatic, not arboresecent.]]\n\nMany try to organize their lives through note taking. There is a classic \"top down\" vs \"bottom up\" design tension projected onto how people take notes. Some people trust their ability to predict the future, they want top-down, they want to pave the paths in the garden. Others (normally those that have tried and failed) don't trust their own ability to predict the future, they want to make it possible for the cows to roam safely, then pave the [[thoughts/desire paths|desire paths]] after they form.\n\nThis is the problem with the file cabinet: it focuses on efficiency of access and [interoperability](thoughts/interoperability.md) rather than generativity and creativity. Thinking is not linear, nor is it [hierarchical](thoughts/A%20City%20is%20not%20a%20Tree.md). In fact, not many things are linear or hierarchical at all. Then why is it that most tools and thinking strategies assume a nice chronological or hierarchical order for my thought processes? The ideal tool for thought for me would embrace the messiness of my mind, and organically help insights emerge from chaos instead of forcing an artificial order.\n\n## How I garden\n\u003e Digital gardens focus not on being a definite source of truth, but rather a source which is constantly evolving as your own knowledge grows and changes\n\nMy blog made me scared of posting. I was scared of putting things into the public because I was anxious about all the different ways people could perceive it, both in the present and in the future. What if I posted something that people thought was *stupid*? Or worse yet, somebody would see my current work in the future and look down on me for how naive my thinking was. I was scared of [digital permanence](thoughts/digital%20permanence.md).\n\nBut honestly, the more I wrote and just put things out there, the less that line of thinking made sense. The internet is pretty [ephemereal already](thoughts/ephemereal%20content.md). It's hard enough to *willingly* create something people will remember a week from now, let alone for all of eternity. While this is still a non-zero probability, the consistent outpour of support and interesting comments I *did* get from posting made me feel it was worth it.\n\nI still, by and large, write for myself. [[thoughts/writing|Writing]], for me, is a form of [knowledge distillation](thoughts/knowledge%20distillation.md). It helps to clarify my thinking and condense my knowledge so I can easily articulate it to others. If done well, I have a **shareable representation of my thoughts** that I can send out into the world and people can respond. Even for my most half-baked thoughts, this helps me create a feedback cycle to strengthen and fully flesh out that idea.\n\nDigital gardening is not just passive knowledge collection. It's a form of expression and sharing. The goal should be to tap into your network's collective intelligence to create constructive feedback loops, not to post content that 'gains clout' or makes you look smart.\n\n\u003e “[One] who works with the door open gets all kinds of interruptions, but [they] also occasionally gets clues as to what the world is and what might be important.” — Richard Hamming\n\nHere are some learnings over the past year of digital gardening:\n- Link by concept rather than by exact match. I will often explicitly have a `Related: (some concept)` link somewhere if I feel two subjects are closely associated. Linking new knowledge to existing knowledge makes it easy to remember. This has helped me find really cool connections on numerous occasions. \n- Name notes to be as simple as possible. I prefer using verbs or nouns to make it easier to link concepts and thoughts.\n- Good [search](thoughts/search.md) matters a lot. When I search, I usually don't know the exact name of the thing I'm looking for, otherwise, why would I be searching for it in the first place? I use search as an entry-point into a single node, *then* recall by associativity rather than by indexing. But having a good entry-point can make or break my flow into finding what I'm looking for. \n\nThis is still a process I'm refining to this day. Likely, my learnings will have grown by the next time around when I rewrite this again.\n\n## Knowledge Flow\nI don't read everything I come across. I am at a point where I am constantly bombarded with new and interesting things from my Twitter Feed, friends, Slack groups, Discord Servers, Telegram DMs, and so much more.\n\nDespite my manic page parking, I really only get time to read about 30% of content sent my way. Even among those 30%, I probably only have meaningful thoughts and connections with about half of those.\n\nI've started developing a process to better manage my process for information intake.\n\n### Seeds\nI am a person who needs a very low friction way to dump new ideas and things to look at in the future.\n\nI built [TabSpace](https://github.com/jackyzha0/tabspace) to be a 'scratch space' in my new tab page where I have my running list of todos, temporary thoughts, and things to read in the next little bit. It's the Apple Notes for my laptop. I use [Curius](https://curius.app/) to keep a backlog of things that are interesting but not interesting enough for me to read at this exact moment.\n\nI tend to generally bookmark things for later then revisit them when I have time. For [projects](thoughts/idea%20list.md), writing, and all sorts of reading. Even when reading books, I don't like to take complex notes right away will only bookmark or highlight phrases. I will eventually come back to the bookmarks a second time to generate insights and actual thoughts. It feels like this weeds out unnecessary noise and provides a natural chance for spaced repetition.\n\nThese are the seeds that form the basis of ideas and thoughts.\n\n### Saplings\nSaplings are single nodes or thoughts. When linking notes, I generally do not silo notes into categories. Sometimes, the presence of specific 'folders' or 'topics' prevents us from making surprising connections between otherwise related topics (e.g. [urban planning](thoughts/urban%20planning.md) and [data structures](thoughts/A%20City%20is%20not%20a%20Tree.md)).\n\n### Fruits\nOf course, a knowledge index isn't much use if it doesn't inform future thinking and output. Fruits are what I like to call derivative or 'new' pieces of content.\n\nIt's the act of creating 'newer' work from saplings, mostly longer form essays, projects, etc. At this stage, thoughts and ideas have matured enough to be able to share and collaborate. Right now,  traditional '[tools for thought](thoughts/tools%20for%20thought.md)' are not great for this aspect, lacking the ability to publish, edit, and share notes with others.\n\n## Start your own\nI've found having my own digital garden has been immensely helpful. It's created a playground for me to experiment with writing, have an excuse to read, learn, and share with others, and be less scared of putting this out into the public.\n\nThrough tending to this garden [in public](thoughts/building%20in%20public.md), I hope to show my success, failures, and everything in between and offer it as an open garden to learn from for anyone who stumbles upon it in the future. If just one person is inspired by it, learns from a mistake I made, or builds off of my work, then I would consider this garden a success.\n\nMaybe you'll find this as an incentive to start your own.\n\n\u003e I'd like digital garden to be like a bonsai tree. Carefully growing, trimming, pruning, artfully shaping a beautiful tree of resources and ideas\n\n![[thoughts/images/garden-bird.png|500]]\n*'Everyone tends his or her own little [epistemological](thoughts/epistemology.md)' garden, growing ideas from seed and sharing them with anyone who comes by.*\n\n[Image Source](https://www.are.na/block/2175982)\n","lastmodified":"2023-02-15T01:38:21.217820833Z","tags":null},"/posts/new-words":{"title":"A New Glossary of Words","content":"\n*This is an expansion of thoughts on [terminology](thoughts/terminology.md) and why we need new words. The following is a dialogue on the original [consensus](thoughts/consensus.md) problem: agreeing on what we mean. You can view the full artifact [here](https://play.jzhao.xyz/new-words).*\n\n---\n\n**Characters**\n- **W:** a wordsmith, a poet, a pluralist \n- **P:** a pedantic\n\n**P:** Why do we need all these words? \n\n**W:** Ah, a question much asked throughout much of history.\n\n**P:** Well no one seems to have a good answer at least. Don't we have enough words to express all we want to express already? There are innumerable ways to combine the words we already do have.\n\n**W:** The whole point of [[thoughts/language|language]] is to have shared mental models to enable us to communicate complex ideas more easily. There is a form of epistemic injustice known as [hermeneutical injustice](thoughts/hermeneutical%20injustice.md) where one has no labels or common [terminology](thoughts/terminology.md) to describe or explain experiences to others. Clearly, there are not enough words to express the human experience.\n\n**P:** Okay, I admit that new words are useful. But who is to say what each word means? Who is to say that the word 'apple' even refers to the fruit I just ate, or that 'metaverse' is even a real word?\n\n**W:** Language is logically [decentralized](thoughts/decentralization.md), is it not? There is no governing body that determines what a word means. The meaning of a word lies in its use[^1], and that is decided by those who speak the language.\n\n**P:** That is not necessarily true though. The language of the law sets out centralized definitions for words *so* that definitions cannot be swayed or morphed to fit the needs of its wielders. Similarly, at the start of a mathematical proof, one should *always* define the axioms or givens to be agreed upon before attempting to use them in any capacity.\n\n**W:** There seems to be a flaw in your argument. Yes, I agree that a consistent set of definitions is required for any sort of productive knowledge sharing. But you fail to account for **plurality**. [context](thoughts/context.md) modifies meaning.\n\n**P:** Plurality as in a multitude of definitions?\n\n**W:** Precisely.\n\n**P:** Well that is almost certainly problematic as well, is it not? Too many competing definitions cannot be a good thing. We have dictionaries for a reason. How would anyone new to learning English be able to grasp the nuances of all of the meaning and history behind each term? It would get overwhelming incredibly quickly.\n\n**W:** I concede that you have a good point. However, we can take a leaf out of Karl Popper's [^3] book: the *lie-to-children*. We can create simple glossaries and terminological definitions as some abstraction for the larger, more nuanced concepts of the real world.\n\n**P:** Wait... lying is categorically bad is it not?\n\n**W:** Hold on and let me finish my thought. According to Pratchett[^2], \"a lie-to-children is a statement that is false, but which nevertheless leads the child's mind towards a more accurate explanation.\" I think what I'm trying to get at is this concept of [verisimilitude](https://en.wikipedia.org/wiki/Verisimilitude): that there is no binary true or false, [some propositions are more true](thoughts/philosophy%20of%20science.md) than others, especially in context.\n\n**P:** Okay, I accept that taking a toy-model approach to new terminology makes sense. But I still don't understand why we couldn't just have a single definition for each word in this model.\n\n**W:** My concern with a 'standard' library of definitions is that interpretations of concepts are not allowed to adapt to usage over time. How does a dictionary or thesaurus adapt to the historical meaning of racial slurs, for example? Those who hold the ability to rewrite the past are the ones with power. Again, this is why having centrally controlled language is a bad idea. This was quite clear in Orwell's work.\n\nOf course, this is not to say that definitions are not important. In fact, quite the opposite. Definitions hold immense power in shaping how we talk and think about the world writ large. What I am saying is that language needs the ability to evolve on its own. Individuals and groups should have the agency to 'reclaim' harmful and outdated definitions.\n\n**P:** Isn't this exactly *why* we need centralization? This is like Plato's Ship of State[^4]. Any large vessel by their very nature needs to be steered firmly. Those aboard must yield to their captain's commands; no reasonable person believes that a ship can be run democratically.\n\n**W:** Would sailors want to obey a captain who takes them somewhere they don't want to be? No. I imagine language like multiple small ships, each one with its own crew (crew of course, meaning an agreed meaning for a set of definitions). Let me reiterate without the ship metaphor: language requires **localized** [consensus](thoughts/consensus.md) for it to function.\n\n**P:** Ah, now I see that you don't mean complete [decentralization](thoughts/decentralization.md), that makes a lot more sense. I can agree on this. I am, however, curious about how local agreement should propagate to become widely accepted. After all, almost all English speakers can agree and what an 'apple' refers to, yet nobody seems to have a good definition for relatively newer terminology like the 'metaverse'.\n\n**W:** This is an interesting question to think about. Not only do we need to think about spatial locality, but also temporal locality as well. I'd like to think about this in terms of metallurgical annealing if you'd let me.\n\n**P:** As in the process of heating metal to make it more malleable?\n\n**W:** Yes, exactly! Let us imagine definitions of words as metal nodules. After a nodule is heated to a high temperature, it is workable. Similarly, when new terminology is coined, it has a period where it is malleable and adaptive and achieving local consensus is relatively easy.\n\nOf course, over the course of the annealing process, meaning can drift. Centralizing then, is a form of metal hardening and shaping. It anchors meaning and prevents it from being easily modified. Just as one should not have metals be load bearing until they've hardened and been shaped for their specific use case, semantically fluid terms should not be epistemelogically load bearing.\n\nWe imagine new words as small nodules. The size correlates with the number of individuals that agree with the definition. Smaller nodules reach the right temperature for annealing more easily. As the definition becomes more widely accepted, it gains mass and becomes harder to work.\n\n**P:** Sorry, I don't follow this metaphor very well. Could you rephrase?\n\n**W:** I hope you excuse my thinking out loud, but this metaphor has given me the clarity to better express this idea in terms of regular language.\n\nEarly on, achieving local consensus on a definition is rather easy; there are only a handful of people who then know about the term, let alone use it regularly. As the term grows more popular, it becomes increasingly difficult to maneuver and adapt in such a way that the meaning of the term cannot shift very much without causing fracturing.\n\n**P:** Ah that makes a lot more sense. Hmm. This covers the initial semantic definitions for a word but is there any way to change the meaning of a definition after it's been concretized?\n\n**W:** This seems quite difficult for terminology already ingrained within society. Especially as meaning is not dictated by some central organization, any old definitions\nneed to be collectively forgotten. As we concluded earlier, this is incredibly difficult for widely used terms.\n\nAs we enter an age of digital permanency, we should normalize the right to be forgotten for terminology. It should be normal for terminology to be forgotten -- for it to slip through the hands of time like sand.\n\n**P:** This ignores a lot of history, does it not? \"By changing what we were, you change what we are and what we are going to be.\"[^5] This is a form of erasure through terminology change. By 'forgetting' terminology, you deny its existence.\n\n**W:** I may have phrased my words poorly, that was not my intention. Maybe abandoned is a better word? I want to create dictionaries and glossaries that keep terminological history. A sort of 'append-only' record of how terminology has split, died, and evolved over time.\n\n**P:** What do you mean by append only?\n\n**W:** The only way to overwrite an existing definition is to either hard-fork it within a subcommunity or to create entirely new words. Hard-forking involves an agreement from a subcommunity to use an alternative definition for specific terms.\n\n**P:** Well, what words need to start anew? Clearly there are words that could benefit from redefinition.\n\n**W:** The 'metaverse' for one could use a lot of redefinition. Meta has put a lot of effort into claiming and defining this term for their own benefit -- a closed, profit-driven, and attention-farming dystopia. A few groups have cropped up around reclaiming some of this terminology, including one forking John Perry Barlow’s 1996 [Declaration for the Independence of Cyberspace](https://www.eff.org/cyberspace-independence) as a reaction to Facebook's recent rebranding as Meta.\n\nLikewise, many groups across the world have tried to redefine and hard-fork the definition of 'hacker' for quite some time. Hacking, as known by the general public, generally refers to gaining unauthorized access to technology. Yet within this local hacker subcommunity, a hacker is widely defined as one who builds and creates for the sake of creating.\n\n**P:** I am increasingly convinced by your argument against centralized definitions. I think, as a society, we need to think more critically about language and terminology and how they carry power. We want to enable evolution and creation of new terminology to enable others to have the language to speak of their lived experiences and complex ideas.\n\n**W:** Yes! In fact, I think we need a new approach to building glossaries and dictionaries. At the core of it all, we are hoping to better solve the original consensus problem: agreeing on what each other mean. To abolish the existing centralized dictionaries and glossaries without suggesting an alternative would be in bad faith.\n\n**P:** What sort of alternative are you proposing?\n\n**W:** A collectively curated glossary of sorts. One which involves a rich history and [context](thoughts/context.md) of terms, pluralist in nature, and always ongoing. If meaning is a negotiation, then the history of that negotiation needs to be a crucial part of achieving consensus on the meaning.\n\nLet us create a new glossary of terminology. May it be *a* source of [truth](thoughts/truth.md) rather than *the* source of truth.\n\n[^1]: *Philosophical Investigations*, Ludwig Wittgenstein\n[^2]: *The Science of Discworld*, Terry Pratchett\n[^3]: *The Logic of Scientific Discovery*, Karl Popper\n[^4]: *Republic*, Plato\n[^5]: Martín Becerra on Natalia Denegri","lastmodified":"2023-02-15T01:38:21.217820833Z","tags":null},"/posts/nothing-stops":{"title":"Nothing stops","content":"\n*It was so heavy-handed and so stupid, hitting the nail on the head so hard that it rang like a bell. Nothing stops.* -- [Helena Fitzgerald on Substack](https://griefbacon.substack.com/p/nothing-stops?utm_source=url\u0026curius=1294)\n\n![](thoughts/images/Nothing%20Stops.png)\n\nNone of it. The good times, nor the bad. There is no \"until this is over\", or \"when I'm done this.\" There is no \"when I get less busy\" or \"after this term.\" *Nothing stops.*\n\nThere is one Annie Dillard [quote](thoughts/quotes.md) I hold central to my 'consciousness cannon',\n\n\u003e How we spend our days is, of course, how we spend our lives. \n\nWhat we do with this hour and that one is what we are doing. What can you do to make your hours, days, and life meaningful? Certainly not toiling away for the next few years on things that pain you and question your sanity. Pain is *not* the unit of effort that matters[^4]. Time is.\n\nTake the time to find yourself. Take the time to smell the proverbial flowers. Take a break to sharpen your saw for it will not delay you from cutting more wood.\n\nThere is no permanence to this universe. If we could stop time, we would. Bill Waterson once said that 'If people could put rainbows in zoos, they'd do it'. Everything we build is a sand castle waiting to be washed away at high tide.\n\nWe build and craft the most beautiful sandcastles we can, knowing they will be washed away. We get others to build with us, suspending the knowledge that this will all eventually disappear.\n\nI think that's what gives life its beauty.\n\nWhat gives life meaning is its scarcity. If one could live forever and do everything they could ever want, why wouldn't they choose it[^1]? We value the time of others because we know that is finite. Life has meaning because it is finite.\n\nLove then, is *knowingly* choosing the losing side. What is love but the constant battle against entropy that drives everything apart and strips it of its salience? Loving one another is always the process of deluding ourselves into believing in a better world. What greater project is there, in an unbearable time, in a perpetual future, where nothing stops? In a society that never stops, isn't loving the ultimate form of protest? To be able to be whole in your existence, to share your time on this little piece of rock drifting through space together?\n\nCompanionship is valuable because it affords the opportunity to feel 'seen' by another. We can only, according to Nathaniel Braden, view ourselves conceptually but we need others to view ourselves perceptually. Other consciousnesses function like a mirror -- being seen in this way is recognition of personhood. The feeling of being seen is psychological visibility. Love then, is witness through it all.\n\nWitness is deep attention[^5]. To witness is not to tether or to pop their balloon, but to hold their strings carefully. adrienne maree brown described relationships like a spiderweb—diaphanous yet strong, thick yet porous. “A web allows things to fall through, like a sieve,” she said. “Some things are not meant to be caught.” David Whyte believed that the ultimate touchstone of a relationship is not improvement, neither of the other nor of the self. \n\n\u003e \"The ultimate touchstone is witness, the privilege of having been seen by someone, and the equal privilege of being granted the sight of the essence of another, to have walked with them, and to have believed in them, and sometimes, just to have accompanied them, for however brief a span, on a journey impossible to accomplish alone\" -- David Whyte\n\n*Nothing stops* isn't a statement about how nothing matters. Rather, it is a call to spent time on what does matter. As Patti Smith said when discussing William Blake and her creative influences, \"Who are the people, ideas, and books that magnify your spirit? Find them, hold on to them, and visit them often.\"[^3]\n\nIn the lifespan of the universe, how lucky are we to share our lives together? \n\n[^1]: [Nozick's Experience Machine](thoughts/Nozick's%20Experience%20Machine.md)\n[^2]: Bill Waterson\n[^3]: [Patti Smith on Time, Transformation, and How the Radiance of Love Redeems the Rupture of Loss](https://www.themarginalian.org/2015/10/19/patti-smith-m-train-loss-time/)\n[^4]: I've seen a lot of people take interest in [this article by Mark Manson](https://markmanson.net/question) which argues that \"what pain you want in your life\" is a much more defining question than what we want in life. I agree that happiness requires struggle. But struggle for *yourself* and what *you* want. Struggle because it is meaning-laden, not because society demands it and optimizes for the *appearance* of sufferance. I like this anecdote from [alkjash](https://www.lesswrong.com/posts/bx3gkHJehRCYZAF3r/pain-is-not-the-unit-of-effort) (more thoughts [here](thoughts/pain.md)): \"If it hurts, you're probably doing it wrong... If your wrists ache on the bench press, you're probably using bad form and/or too much weight. If your feet ache from running, you might need sneakers with better arch support. If you're consistently sore for days after exercising, you should learn to stretch properly and check your nutrition.\"\n[^5]: I loved Jasmine's piece on *[attending to the other](https://jasminewang.substack.com/p/attending-to-the-other)* and I consider it a critical part of my consciousness cannon","lastmodified":"2023-02-15T01:38:21.217820833Z","tags":null},"/posts/open-source-and-politics":{"title":"Open Source and Politics","content":"\n**[[thoughts/Coraline Ada Ehmke|Coraline Ada Ehmke]]** is an acclaimed speaker, writer, engineer, and activist with over 25 years of experience in software and almost 20 years in open source. She works to promote diversity, equity, and justice in open source communities and the tech industry as a whole. She created the Contributor Covenant, the very first code of conduct for open source communities, as well as the Hippocratic License, which legally prohibits an open source project from being used for human rights violations. \n\n**Jacky Zhao** is studying computer science and philosophy at the University of British Columbia. He thinks a lot about how we can better incentivize public goods funding, support better interactions with computers, and be more responsible stewards of technology. He has built and maintains many widely used open source projects like Quartz, which enables users to host their digital gardens online for free, and cursor-chat, which is a library to add Figma-like cursor chat to websites.\n\n_This conversation has been edited for clarity and length._\n\n## How did we get here?\n\n**Jacky:** I’m curious about how you first got involved with the tech justice movement and open source.\n\n**Coraline:** I was a software engineer for 26 years. When I started my gender transition in 2013, I started experiencing first-hand some of the pervasive problems in open source and the tech industry that I had only been aware of intellectually before. It woke something up in me. It was around that time that I started becoming more interested in the issues of justice and equity and technology.\n\nI remember back in the early 2010s, when tech conferences started becoming popular, there was a big fight to get tech conferences to have codes of conduct. It's something that seems so normal and natural today, but it was actually a very, very difficult fight.  \n\n2014 was also when I wrote version 1.0 of Contributor Covenant, which was the first code of conduct for open source communities. I feel like over the years — eight years now — that Contributor Covenant has been around, we've seen codes of conduct become more normalized in open source communities.\n\nToday, it's hard to count the number of adoptions. It's in the ten thousands. And it's kind of wild! I was talking to a friend last year who said, “Coraline, there's an entire generation of engineers who have never worked in an open source project that did not have a code of conduct.”\n\nOne of the things I worry about though, with that normalization, is that we don't recognize our history. *People in tech have very, very, very short memories, which is part of why we keep reinventing the same stuff over and over.*\n\n**J:** Yeah. In my free time, I do a lot of open source projects and hack on a lot of little things in general. I initially started posting a lot of my projects on GitHub more for backup and archival purposes and never really expected any real usage, so I never really thought about being “a maintainer,” or whatever that meant.\n\nIt wasn't until my very first project started getting real usage that I realized there never was any real introduction to being an open source maintainer, or what it means to be a *good* maintainer. There’s no “How to be a Good Maintainer 101” course. It wasn't until I started getting contributors that were like “Hey, you actually don't have a license or a code of conduct in your repository, have you considered adding one?” Then I realized, wait, I actually don't know much about — as you said — how we got here. What is the history of all these codes of conducts? I think that definitely kicked off a personal learning journey for me to figure out the history of a lot of this as well.\n\n**C:** Yes. So that takes us to 2018. An activist group called Mijente was in the midst of their No Tech for ICE campaign. One of the things that they were doing was posting the names of companies that had contracts, either with Customs and Border Protection or with ICE directly. One of the companies that got called out was Chef, which plays a large role in infrastructure, server deployments, and was very necessary for a lot of the large-scale internet operations.\n\nSeth Vargo, who had previously been a developer at Chef and had worked on open source tooling for them, saw that Chef was called out as one of these companies profiting from human rights abuses at the border. In an act of conscience, he pulled all of his open source code that was part of the Chef ecosystem and made a statement about why. But within two hours, both GitHub and RubyGems forcefully restored the code he took down because it was affecting the many companies around the world who depended on those libraries. \n\nThe open source establishment, or what I call “open source traditionalists,” saw this and said “No, no, you can't do that because open source is neutral.” I saw that as an epic moral failure on the part of the establishment. So I wrote version 1.0 of the Hippocratic License, which was not intended to be a viable license, but rather a lightning rod for broader discussion around the neutrality of open source tech in general.\n\n**J:** That's really interesting. At school, I study computer science and philosophy, so I spend a lot of time thinking about how technology impacts the people that use it. And I think one of the foundational pieces that I read that really shaped my thinking around this was “[[thoughts/Do Artifacts Have Politics|Do Artifacts Have Politics?]]” I think that paper was really influential in terms of making me think, “Wait, actually, this technology that we spend so long claiming to be neutral actually has political implications as well.” And I think a lot of people working in tech spend a lot of time trying to deny the fact that it does.\n\n**C:** A couple of years back, I gave a talk called “The Rising Ethical Storm in Open Source.” I actually traced that illusion, or, you know, honestly, that lie, that computer technology in particular is neutral. I traced it all the way back to the 1950s with Edmund Berkeley, who was one of the cofounders of the Association for Computing Machinery, and he served on the committee called the Social Responsibility of Computer Professionals.\n\nTheir findings were that yes, technologists are absolutely responsible for how and what is developed. The how, what, why and its impact. And the fledgling computer science industry at the time rejected that.\n\n**J:**  I watched that talk that you mentioned. One of your quotes in that talk that really resonated with me was: “I believe that as technologists, we have a moral imperative to prevent our work from being used to harm others. Responsibility is about impact and not intent.” That definitely feels relevant.\n\nOne model I use often to think about tech is to model it as a multiplicative tool instead of something that's purely additive[^1]. Multiplicative in the sense that it will only exacerbate the existing discrepancies in distributions of power, right? Some people will obviously be way better off and then there's some that will be disproportionately harmed by it.\n\nI feel like some other people hold a very strong belief that technology is purely additive in that it will just truly raise the ground bar of everyone who uses it. Yeah, I don't know. I feel like that's always been missing from how people think about technology, that there's always a hidden tradeoff or downside to whatever technology that you're building with.\n\nI wonder whether the developers of these technologies should be responsible for expecting how their tools will be used in whatever way down the line, right? If you build an open source project, it's very hard to tell what type of people will actually end up using your project. And so, at what point do developers have to start thinking about these tradeoffs? For example, who will my end users be and what is acceptable use and what’s not?\n\nEven from a developer standpoint, it obviously helps if you’re educated in these issues in order to make these calculations. But even as someone who is educated about these things, how do you weigh the potential upsides and the potential downsides.\n  \nI came across the concept of the [[thoughts/Collingridge dilemma|Collingridge Dilemma]] a while ago, which I think captures the double bind of technology quite well. In essence, it says that any efforts to influence or control further development of technology kind of faces a double bind, where you come across two irreconcilable problems. One is an information problem. You can’t really predict what impact your technology will have until it is extensively developed and widely used. But then, two, you also run into a power problem where by the time you’ve already extensively developed and put it into wide use, changes become too difficult because the technology has already become so entrenched in society. And at any point, it  is incredibly difficult to even begin to evaluate that type of impact. So, what is even the ideal place to start thinking about this impact?\n\n**C:** Continually. You have to do it continually. You have to do it after deployment, you have to do it after it’s widespread. You have to do it continuously.\n\nIn academia, if you’re a sociologist or an anthropologist or in any of the social sciences, you have to go before an institutional review board when you’re planning a research or development project. One of the requirements for launching any such activity is having an effective plan for not only preventing harm, but mitigation plans when someone actually is harmed. We don’t see that same principle being applied to hard science, we don’t see it applied to engineering. Why not?\n\nBut to your point, it is very difficult to predict. One of the instruments that we’re developing at the Organization for Ethical Source is something we’re calling a priority of constituencies which comes from one of the [W3 specs](https://www.w3.org/TR/html-design-principles/#priority-of-constituencies) for HTML. So there’s this one sentence in the spec that was developed that said, in case of conflict, we “consider users over authors over implementors over specifiers over theoretical purity.”\n\nWhen you draw a line like that, what you’re explicitly saying is that even if this makes it inconvenient for adopters, even if it makes it inconvenient for developers, even if it makes it inconvenient for end users, we have to make that decision based on the most vulnerable and work upward. It may be uncomfortable, but if the potential is there to reduce harm, to mitigate harm, or to have a plan for what to do when harm occurs, that cuts through a lot of the ethical gray areas.\n\n**J:** I wanted to poke from the opposing side a little bit. I think there’s a non-negligible number of people who argue that by increasing consideration for [[thoughts/ethics|ethics]], even in the medical industry where I think a lot of this regulation is important, they say that the regulations are too tight to enable innovation at a speed that is continually beneficial to progress by imposing all of these restrictions on what you can do[^2]. It limits people from trying new things and innovating and developing new technologies that potentially could have far greater upsides than we could have predicted.\n\n**C:** Every technology for the entire duration of human history has been modulated by understanding that it doesn’t exist in a vacuum, that it exists in an increasingly complicated sociotechnical space. There’s no telling ourselves that there’s neutrality. Doing so ignores the actual mechanisms of human community, human society, human civilization as a whole. So if that stifles innovation, if that means a given technology is five years late, isn’t it worth being careful? Isn’t it worth being safe?\n\nRegulations are imperfect. But they are a way of codifying constraints or guardrails. And, you know, maybe it’s okay to slow down a little bit, right? If we’re gonna reduce harm, maybe it’s okay to slow down a bit.\n\n## What can we do?\n\n**J:** One take I have been seeing a lot is that top-down regulation is explicitly bad and we should “decentralize.” And I think one interesting aspect that I spend a lot of time thinking about is the value of decentralization when it comes to technology. A lot of these new technologies like blockchain treat decentralization as an end rather than as a means.\n\nBut there’s a lot of use cases that are very much building decentralized applications for the wrong reasons. I don't think decentralization is objectively a good thing [on its own], but rather something that can return agency to users. A lot of my research work this summer has been figuring out how to apply, for example, the net neutrality debate to data. The net neutrality debate was very much about separating content from providers; similarly, [[posts/towards-data-neutrality|how do we separate data from applications]]? \n\nA lot of our modern centralized providers are incredibly successful and have such large network effects. It is so hard to migrate from them because they have these huge data moats where it's impossible to just move from Facebook, for example, to some other provider that claims to be better. So a lot of it has been asking questions of how we reclaim agency for people to choose how to use their data, how they want to store their data.\n\nI think the convincing case for decentralization is in terms of enabling agency for people to choose what types of frameworks they want, rather than having to be locked into these providers.\n\n**C:** Twenty some years later, we’re never going to have an internet that’s 100 percent open source. And hopefully, we’ll never have an internet that's 100 percent closed or proprietary either. What we have to recognize is the reality of where we are — that we need more than data portability. We need data autonomy, and we need permeability between closed and open systems. And I believe permeability as opposed to mobility is an important aspect. \n\n**J:** How would you differentiate permeability and mobility?\n\n**C:** [[thoughts/credible exit|Mobility]] means you can export all of your tweets. Okay, well, what are you going to do with that? Can you import them into Mastodon? No. So when you withdraw your data, it becomes valueless. It's not in a form that you can ever reuse. So is that really ownership of your data? No.\n\n**J:** Yeah, one common theme I am noticing in a lot of retrospectives of older peer-to-peer projects that have been alive for a while but haven’t really garnered any major usage is that they’ve thought about all these ways to create new shiny platforms that claim to be better or give more agency to users, but no one has really thought about how to off-ramp easily from existing systems to get people onto these new platforms.\n\n**C:** I think the way we guarantee that kind of permeability between closed and open systems is through standards.\n\nBut the problem is that representation in these standards bodies are primarily private corporations, and they are trying to influence things. Logically, they will try to veto things that will probably impact their business models. Amnesty International actually wrote a paper in 2018 where they flat-out said that for platforms like Google and Facebook, their entire business models are predicated on human rights abuses and on harvesting data and surveillance capitalism. So we can’t expect those companies to do the right thing for the right reason. And those are the companies that have not only the economic power, but also power in the standards bodies and governing bodies. I think that reclaiming standards bodies is a way of having meaningful consequences for willful violations of standards. I think that’s critical.  \n\n**J:** I agree. At some point, being able to download the source code isn’t enough. Governance and accountability is critically important too.\n\nWhat do you think the first step to reclaiming standards bodies even looks like? I read the [[thoughts/DID|Decentralized Identifiers (DID) specification]] a while ago and I remember that of all of the W3C members, only three members had formal objections about the proposal. They were Google, Apple, and Mozilla. When you propose new standards that inevitably will undermine the business model of these large companies, it feels incredibly difficult to get these pushed through.\n\nAlso, a lot of these standards and processes are illegible to people new to this space. I read a lot of these, like Internet Engineering Task Force (IETF) proposals, and they’re ridiculously long at times, often almost 100 pages. It feels like some of them require decades of experience working in the space to even begin to have a voice. It’s incredibly difficult for the average person to participate and make meaningful decisions.\n\nSo if you want to create a widely accepted standard, is there any way to do that without dismantling these original systems with these large corporations sitting on the standards boards?\n\n**C:** I don’t know the answer to that. I don’t know how we do it. But I think we need to prioritize it. I think we need to figure it out.\n\nThere’s a growing trend: More people are asking the question of whether tech companies should pay for the tech that open source contributors are freely giving them today.\n\nI think we have a lot of power. As participants and members in good standing in the open source community, we should find ways to hold these large players accountable, either by threatening their primacy through the development of alternatives, but also figuring out how can we pressure them to make governance as intentional, as equitable, as diverse as we’ve done within our developer communities.\n\nIt’s sort of a radiating effect, right? We’ve normalized codes of conduct. Now let’s normalize representative and equitable governance of open source projects. Let’s go a step beyond that and talk about standards and enforceable standards. And then beyond that, of course, we have the legal aspects.\n\nI think of an InfoSec metaphor. You have a server on the internet. It is not secure, as it is impossible to secure any resource on the internet 100 percent. But what we do is we add layers of protection, layers of privacy, layers of security to make it not impossible to breach a system, but make it so involved and so expensive, that it’s no longer worth someone's while.\n\nAnd I think that’s an approach that we can take with the development of ethical and equitable technology as well. If we’ve made it difficult for Google to sweep issues like accessibility standards under the rug, then we’re incentivizing them to do the right thing. Because if they don’t, they will lose status, they will lose their ability to draw employees. We as developers do have the ability to exercise some moral authority and we have the ability to decree meaningful consequences for the corporations.\n\n## Where do we go from here?\n\n**J:** How do you think we can best bring about these changes to build more ethical and equitable technology? The logical path forward seems to be either finding ways to empower a more diverse set of people to help build these standards and technologies or regulating how open source is used by these large companies through licenses and the law.\n\n**C:** To be clear, ethical source is not about licensing. Ethical source is not about the Hippocratic License. It is not solely about legal instruments for trying to protect the vulnerable, marginalized, and under-represented. It’s bigger than that. It’s about codes of conduct. It’s about governance. It’s about social contracts and rights.\n\n**J:** It’s about building those layers, right?\n\n**C:** Exactly, that layered approach. I think it represents a movement to change our mindset to really ask ourselves some of these difficult questions, to look at who’s making the decisions around what technologies are developed. Are we comfortable leaving these decisions in the hands of those players?\n\nIt’s not a fire-and-forget thing either. It’s not a problem that we solve at the beginning and we’re good forever. These systems that can cause harm and perpetuate systemic inequities — they’re not static either. Just like how consent isn’t an event, it’s a process, harm reduction is also not an event, it’s a process.\n\nAnd I think we have to start normalizing those processes [of harm reduction at all of these different layers], if we want any chance at all of allowing the internet to be the incredible force for good that it has the potential to be[^3].\n\nAnd, as you said, part of that is being interdisciplinary, transdisciplinary, and multidisciplinary in our thinking. Bringing together the people who have different areas of expertise, whether it be technological or social in nature, because, you know, a lot of these problems that we’re facing have happened before. They’re not new problems.\n\n**J:** I think a big part of this is moving beyond the individualistic perception of open source as a lone hacker in the basement and more towards curators and crafters of a community around this project that you’re building.\n\nBased on personal experience, I think building a visible community around synchronous interaction with the actual users makes such a big difference when it comes to maintenance. As a maintainer or creator of a software library, most people are like, “I just want to make new features and do whatever works best for me.”\n\nBut there are so many edge cases and small bugs that don't work for a lot of users of your library. For example, users from Saudi Arabia said that they would really appreciate right-to-left support using Quartz. How do we enable people from all over the world who weren't necessarily the users that you initially had in mind to still be able to use the software and tools you make?[^4]\n\nI think by curating a community that is open and accepting of more types of people and getting them to suggest and contribute.\n\n**C**: Absolutely. And I think a lot of that comes down to ingroup-outgroup biases. Just look at it from the perspective of how much open source technology is simply tooling for people just like us.\n\n**J:** Yeah. And I think this is a great call for more diversity in the space as well. A while ago, a friend and I noticed that the people who build developer tooling and tools for other developers do that because that’s the only problem they’ve really known their entire lives! And by bringing people who’ve had problems and experiences in other fields, then you start getting useful applications of technology in those areas. So this is a call for all types of people to contribute to technology, to contribute to open source in hopes of a more diverse future.\n\n**C:** And we do that not through consultation, but meaningful empowerment. Getting people who are not like us in positions of power, by yielding power and distributing agency.\n\n[^1]: This model emerged after reading \"[[thoughts/The ones who walk away from Omelas|The Ones Who Walk Away From Omelas]]\" by Ursula Le Guin for the second time. The story presents a classic utilitarian problem: is it morally justifiable to inflict suffering on one person in the service of others’ happiness (and a potential utopia)? Is it then morally just to develop technology to benefit others knowing that it will exacerbate the suffering of marginalized groups? Is progress to one person necessarily progress to the collective?\n\n[^2]: Do we care more about technological progress or social progress? Historically, Silicon Valley has valued ‘[[thoughts/move fast and break things|moving fast and breaking things]]’, but progress implies direction. What is progress towards? Who decides that? The relatively new field of [[thoughts/progress#Progress Studies|Progress Studies]] attempts to critically take apart and answer this question, including looking at the potential drawbacks and mitigating risks of progress.\n\n[^3]: Systems of feedback and regulation are incredibly important if we want to prevent absurd and tragic events from happening on the internet. As Ali Akkhatib states in his work [[thoughts/To Live in their Utopia|To Live in Their Utopia]]: \"Absurdity follows when algorithmic systems deny the people they mistreat the status to lodge complaints, let alone the power to repair, resist, or escape the world that these systems create.\"\n\n[^4]: Many treat algorithmic systems as ‘mathematically pure’ objects, taking only pure inputs and producing pure outputs. To these engineers, human lives are treated as ‘externalities’ that spoil that purity. Impacts on humans should be first an foremost. To quote [Runar Bjarnason](http://blog.higher-order.com/blog/2009/04/27/a-critique-of-impure-reason/) post on the future of software, “Why does a computer even exist? The reality is that computers exist solely for the purpose of executing programs. The machine is not a metaphysical primary. Reality has primacy, a program is a description, an abstraction, a proof of some hypothesis about an aspect of reality, and the computer exists to deduce the implications of that fact for the pursuit of human values.”\n","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/posts/paid-open-source":{"title":"A case for funding Open Source","content":"\n## Making of Open Source software\nI’ve recently made my way through [*Working in Public: The Making and Maintenance of Open Source Software*](thoughts/Making%20and%20Maintenance%20of%20OSS.md) by Nadia Eghbal. Not only does it have some absolutely stunning cover art, it also touches on some thoughts that have been marinating in my head about the intersection of open source and [funding](thoughts/funding.md). So much so, that I’ve started experiencing the Baader-Meinhof effect, seeing something to do with open source and funding everywhere I look in tweets, conversations, and blogs.\n\nThis blog post is an exploration of processes in open source, the value it provides, and how money fits into the picture.\n\n![Working in Public: The Making and Maintenance of Open Source Software](/posts/images/paid-oss/oss_book.jpg)*Working in Public: The Making and Maintenance of Open Source Software*\n\n### How it's made\n\u003e \"Open source developers were frequently characterized as 'hobby' developers, because the assumption was that only companies could make 'real' software.\"[^1]\n\nAs it stands, there are two primary schools of thought about how open source software is created.\n\n1. **Firm-based** production involves companies, organizations, governments, or any institution with centralized resources. Their driving thesis is that only companies make software because, from a coordination standpoint, centralized firms are the most efficient way to manage resources. Most development done this way is motivated extrinsically by means of monetary compensation.\n   \n2. **Commons-based** production is a more vague concept that involves a distributed group of developers that work on a resource that is used, owned, and governed by its own community - free of  employer affiliations. Most development done this way is motivated intrinsically, people do work because they want to do it.\n\nTraditionally, software has been seen as a product of firms. Open source developers were often treated as hobbyists and the projects they made trivialized as toys. The assumption was that only companies could make ‘real’ software. However, the rise of [Internet computing](thoughts/internet%20computing.md) and collaboration tools like [[thoughts/git|Git]] have decreased the barrier to entry enough that producing software through a commons is now feasible and very much alive. The success of projects like Apache, Linux, and FreeBSD proved just how successful a commons-based method of production could be.\n\nSurprisingly, this may also help to explain why some developers view open source and money as completely separate. If the commons-based method of production is rooted in intrinsic motivation, then money, an extrinsic motivator, will be seen as opposite to core ideals that open source stands for.\n\n\n## Creation vs Maintenance\n\u003e \"Creation is an intrinsic motivator, maintenance usually requires extrinsic motivation\"\n\u003e\n\u003e @balupton, isaacs/github [#167](https://github.com/isaacs/github/issues/167)\n\nWhen an artist finishes a painting, or a runner finishes a marathon, that usually signifies the end of said responsibility. There is no such finish line for an open source project, even after pushing out an initial product.\n\nCreating a project is fun. It’s a wild exploration into a new idea, a frivolous journey to create something useful or to learn something new. As cloud platforms continue to eat the world, the costs of distributing and sharing a project are almost completely nullified.\n\nJust a few clicks and a few taps of your keyboard and your project is readily available to any of the 4.66 billion people around the world with [Internet](thoughts/Internet.md) access. This adrenaline rush of finally releasing the labour of your work onto the world is the moment developers are constantly chasing. For most developers, the process of creation and distribution is intrinsically motivated; it’s an enjoyable process.\n\n[Maintenance is less so.](thoughts/maintenance.md). This is akin to a writer that’s been asked to edit and revise the same book day in and day out, long after they’ve reaped the initial financial and reputational rewards from its creation. Even when the creator wants to leave the project to work on something else, they can’t. They’re tightly shackled by the fact that hundreds of thousands of other organizations, companies, and tools rely on their code to keep their operations running. Bringing on additional developers may not help either, as they still require onboarding, code reviews, and general guidance.\n\nCode may be nearly free to create and distribute, but maintenance is still expensive.\n\n## Types of code\n### Code as an artifact\nThere are two main ways we can look at code. The first of which is *static* code. Code that, on its own, does nothing but exists as an archive. Others can copy and download the code without incurring any additional costs to the author. For the maintainers, it should make no difference in regards to cost whether 10 or 10,000 people use it.\n\nThis type of code is a pool resource or [public good](thoughts/public%20goods.md), it is\n1. **Non-rivalrous.** My ability to copy the code doesn’t affect your ability to copy it. (This isn’t exactly true due to some marginal costs but I’ll discuss this later)\n2. **Non-excludable.** If someone has a copy of the code, it is very difficult to prevent them from sharing that code with others.\n\nAny code that is in this state is easy to share, copy, and distribute. This is the type of code that lives dormant on Github, on StackOverflow answers, and in GitHub’s Arctic Vault[^2]. However, the main purpose of consuming code is not to simply read and study it, but to actually use it and to let it interact with other code.\nIn doing so, we bring it to life.\n\n\n### Code as an organism\n\u003e \"Open source code derives its value not from its static qualities but from its living ones.\"[^1]\n\nAs soon as you hit CTRL-V on that snippet of code, as soon as that static code is inserted into your own, that code comes to life. It might surface  ridiculous amounts of red squigglies, break other code, or force you to rewrite your previous code just to make it work. When code transitions from a resting static state to an active living state, it starts to incur a set of hidden costs.\n\nLike a living organism in a symbiotic relationship, there is a mutual interdependence between it and others in the software ‘ecosystem’ in order to survive. As a result, this ecosystem requires constant upkeep to ensure that components don’t fall out of balance: dependency bumps, documentation updates, and infrastructure changes.\n\n## Free as in speech, not as in beer\n‘Free’ software doesn’t refer to its price. In fact, ‘free’ software is often extremely expensive. As Richard Stallman first described free software, it’s “free as in speech, not free as in beer.” The point Stallman was trying to make was that ‘free’ refers to what one could do with the software, rather than the price tag.\n\n### Latent cost of software\nIn reality, code in its alive state is more like a free puppy. In the beginning, it’s a great and wonderful thing! Super fun and super cute. As it grows and gets older, you realize “geez, it actually takes a lot of my own time to take care of this thing.” Unlike a piece of inanimate furniture, bringing a living creature into one’s home comes with bringing in a new set of responsibilities too.\n\n**Marginal costs** are costs increase on a per-user basis. I mentioned earlier that these costs mean that software is actually rivalrous, meaning that at some point, the project won’t be able to support the n+1th user. Some of this cost comes from physical infrastructure like code hosting and infrastructure. However, the majority of the cost comes from user support. Say you have a billion users and only 0.1% of them require support. If it takes you roughly 10 minutes to resolve each issue, you would still need 20,833 people working 8-hour shifts a day just to be able to keep up with the support volume. Maintainers are constantly wrestling with keeping their issue volume low and questions answered. Eventually, it just becomes a hindrance preventing them from working on the core product.\n\n**Temporal costs** are those which build up and compound over time. Most of it comes from technical debt, choices that are easier today at the expense of time and money in the future. This is the eternal battle against entropy: the inevitable decay of systems over time. When code changes, all the supporting knowledge that surrounds it must be updated too. Documentation, tutorials, programming books, videos, and more slowly become obsolete.\n\nPaying off these latent costs is seldom intrinsically motivated. When people talk about how fun making new projects is or contributing to open source, it’s never referring to writing documentation or refactoring code. This isn’t the ‘fun’ part of writing software. This is the nasty upkeep that goes into maintaining a building from the 1850s that’s had new rooms, plumbing, and electric wiring frankenstein-ed into it over the years.\n\n## Funding Open Source\nI first started on BentoML[^3] as a casual contributor last summer, submitting a few decently sized PRs. It was almost all intrinsically motivated; I found issues that I enjoyed working on and that I knew I would learn lots from. Satisfied with my experience, I decided to join the team as a paid contractor expecting to just continue the type of work I was doing in the summer. As issue after issue piled on, I slowly started to realize just how much extra work being a maintainer meant and why it was a paid position. Making proposals, triaging issues, adding tests, and writing documentation took up the majority of my time. While I recognized it was important work, it was not work I was intrinsically motivated to do. Thus, to motivate people like me to get that work done, an extrinsic motivator -- in this case, money -- needed to be applied.\n\nHow do we best incentivize maintainers to work tasks stripped of the very excitement and promise of creation that initially drew them to the project in the first place? There is a jarring disconnect between work that is needed versus work that is intrinsically motivated. This is where I believe open source funding should play a role. There are two main potential avenues to go about this.\n\n\n### Funding projects\nOne possibility is to fund projects directly. This route builds a brand around the project. The status of the project then transcends any single person’s contributions and becomes a tangible entity that has the brand recognition and reputation that comes with becoming an independent entity.\n\nProjects also tend to attract corporate/government funding much better than individuals can since companies are more comfortable paying for a product (code) than for a one off contract (talent). As part of the transaction, companies are typically promised service availability, influence in decision making, or technical support. However, this tradeoff also means that projects lose a bit of their freedom. Not only do maintainers have to worry about the future of the project, they need to make sure that the agreements laid out between the project and the companies are met too.\n\n### Funding individuals\nA more individualistic model would provide greater flexibility and avoids the centralized governance issues that are so antithetical to what open source stands for. Maintainers then don’t need to deal with figuring out who should get paid how much as each maintainer is responsible for securing their own funding (if even needed). Unlike a company, what each maintainer looks to get from contributing to a project may look completely different. One may be looking to build technical skill, another to gain reputation in the community. From a governance perspective, funding individual developers is also better aligned with the distributed nature of open source projects too.\n\nAs the world’s media moves towards empowering independent creators through platforms like Twitch, YouTube, and TikTok, funding individuals is becoming an increasingly viable option. The way most of these creators make money is through *patronage* rather than donations. Although often conflated with donations, patronage is an interest and commitment to following a creator’s *future* work based on their *current* reputation rather than a one-time tip for their current work.\n\nWhen you are funding an individual, you are paying for the regular delivery of well-defined value.[^1] There are three key parts to this:\n1. **Paying.** This is an ongoing commitment to the production of content, not a one-off payment for one piece of content that catches the eye.\n2. **Regular Delivery.** It isn't random discovery, rather the content is delivered directly to the user via email or application.\n3. **Well-defined value.** It is clear what the money is going towards and what value it is helping provide.\n\nFunding individuals means trusting not just in the projects they are currently working on, but also that they will continue to deliver future value too. Rather than being tied down to one project, creators then have the creative freedom to apply what they learned and create more groundbreaking initiatives.\n\n## Mixing money and open source\n\u003e **Q:** Won't financial rewards adversely affect developer's [incentives](thoughts/incentives.md) to contribute?\n\u003e \n\u003e **A:** Yes, but it depends on who you're funding.\n\n[Attention](thoughts/attention%20economy.md) is the main currency of production. Attention is what you divert when you choose to focus on prioritizing a feature request over adding support for a library that you promised to add a few months back. Attention is what limits you from doing everything at once.\n\nAttention, then, is a common pool resource. It is non-excludable (anyone can bid for their attention) and rivalrous (limited attention). But, by charging for access to maintainer’s attention, it then becomes a private good: excludable and rivalrous. The belief is that, by making attention excludable, the quality of contributions will increase as contributors and users compete for the attention of producers.\n\nThere are two main camps on funding open source projects. The first camp believes that we should pay all maintainers to keep their projects alive. The other camp believes that paying project maintainers will destroy the entire ideology that open source is based upon.\n\nI stand somewhere in between the two camps. I’m a big proponent of “if it ain’t broke, don’t fix it.” There are a lot of competing motivations already, both intrinsic and extrinsic, that powers open source today. We shouldn’t touch the parts that are currently working. Rather, we should focus on funding places that are absent from existing motivation like software maintenance and documentation\n\n## Conclusion\nThere is an abundance of open source projects and casual contributors as it stands today. With the ever lowering barrier to entry, these will only become more abundant. Casual contributors already incur a marginal cost on maintainers, their contributions need a maintainer to review whether it’s okay to merge or not. Adding more extrinsic motivation will just exacerbate this existing problem. This is the same reason why initiatives like Hacktoberfest, which promises to give a free t-shirt to anyone who makes a few pull requests, are counterproductive to open source.\n\nWhat isn’t significantly increasing are the number of maintainers responsible for maintaining the existing projects we have today. We should be funding maintainers who already have the contextual knowledge to be able to effectively tackle issues and guide the project. Funding will be an important extrinsic motivator to make sure that the difficult work that needs to be done, gets done.\n\nThis is not, by any means, an all-encompassing post about funding in open source. If that’s what you’re looking for, then Eghbal’s book is a great starting point. What this post does do, however, is raise important points about the processes behind open source and prod at why exactly we need to fund these seemingly ‘free’ processes. In order for open source to continue on its growth trajectory, these are questions we need to put more collective effort into thinking about.\n\n[^1]: *Working in Public: The Making and Maintenance of Open Source Software* by [Nadia Eghbal](https://nadiaeghbal.com/)\n[^2]: [GitHub's Arctic Vault](https://archiveprogram.github.com/)\n[^3]: [BentoML](https://github.com/bentoml/BentoML)","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/posts/play":{"title":"Play to Win: A Post-Work Society","content":"\n*Extension of my thoughts about [play](thoughts/play.md) and discussions from our [Interact Circle](thoughts/Interact%20Circle%20W21.md) on [Hackathon Culture](posts/hackathons.md) and Play.*\n\n## Defining play\nI've spent a lot of the past few months reminiscing on the childhood days of finding funny looking patterns in the rocks in my backyard and building LEGOs without instruction manuals.\n\nI've spent so much time thinking about how to ['bring back play'](posts/hackathons.md), yet not a lot of thinking about *what play is*. The more I think about it, the more nebulous it feels to define. I know examples of it when I see it -- the building of blanket forts during sleepovers, the joy of beating Minecraft for the first time with your friends -- but to put words to it feels difficult.\n\nThe most intuitive definition is one that comes from Bill Watterson: play is anything that you do on your own volition or agency just for its own sake. It is an *intrinsically* motivated activity.\n\n![](/posts/images/play/agency.png)\n\nPlay is the act of enjoying the process, the means to the end. To have as much fun as possible along the way. Quoting [Kernel](https://kernel.community/en/learn/module-1/joyful-subversion), to \"turn life into a canvas, rather than a graph with checkpoints\".\n\nYet this definition still seems inadequate. What separates work from play? Are they mutually exclusive? What about those who cannot afford time out of their day to do anything *but work*? Those who play games professionally?\n\nHere, I turn to Jenny Odell's [*How to Do Nothing*](thoughts/How%20to%20do%20Nothing.md) and Bernard Herbert Suit's [*The Grasshopper: Games, Life, and Utopia*](thoughts/The%20Grasshopper,%20Games,%20Life%20and%20Utopia.md) to further explore this definition.\n\n## How to Do Nothing\nOdell’s book *How to Do Nothing* focuses on resisting the current attention economy. Doing ‘nothing’ within a productivity-obsessed environment can, in fact, help to restore communities, both locally and beyond.\n\n'Nothing', in this case, refers not to actually doing nothing but rather to not participating in the [attention economy](thoughts/attention%20economy.md) and hustle culture. 'Nothing' means doing nothing productive.\n\nRecently, I have been grappling with the question of whether self-care is [selfish](thoughts/selfish.md). My inner self wants to be able to do nothing: just do projects I find fun, hang out with my friends, and go outside. However, I know that *long term*, working hard at doing well at my job and in school will do me more good, career-wise.\n\n![](/posts/images/play/long-term.png)\n\nHow can I justify setting aside time to do nothing when I have so many people asking for my time and pulling me in so many directions? In the attention economy, attention is scarce. \n\nPlay allows us to create environments where saying 'no' is okay. By definition, nobody forces you to play. **Play is what allows us to create local spaces of abundance.**\n\n\u003e \"Caring for myself is not self-indulgence, it is self preservation, and that is an act of political warfare.\"\n\nPlay is the catalyst that will enable the post-attention-economy society. But what do we do when we get there?\n\n## The Grasshopper\n*Of all the things you could do in utopia, why would one play [games](thoughts/games.md)?*\n\n*The Grasshopper* was a book unlike any I've ever read before. A talking grasshopper and his insect disciples convinced me, through [Socratic dialogue](https://www.thoughtco.com/socratic-dialogue-argumentation-1691972) nonetheless, that \"refusing to work and insisting upon devoting himself exclusively to play\" is a perfectly acceptable thing to embody.\n\nWhereas Odell focused on how to get to a post-work society, Suit's approach to play and games focuses on what to do *in* a post-work society. A utopia of doing absolutely nothing feels dreadfully boring. What is there left to do? To play games, obviously!\n\nWhen I say 'game', I don’t just mean chess, basketball, or a video game. I mean a more holistic one that includes climbing mountains, the pursuit of knowledge, and the creation of art itself.\n\nGames, as Suits defines it, are \"goal-directed activities in which inefficient means are intentionally chosen.\" In games, one *purposefully* ignores the more efficient method. To play a game is to do the crossword puzzle *without* looking up the answers, even though looking it up would be the most efficient way of finishing the crossword. The added rules and restrictions are what make possible the act of playing outside of the endless pursuit of efficiency.\n\n**Playing a game is the voluntary attempt to overcome self-imposed obstacles.**\n\n### A post-work society\nIn fact, I posit that play is not only necessary but the *only thing* that can exist in a post-work utopia. Let us explore this argument through a Socratic dialogue.\n\n---\n\n**Characters**\n- **G**: the player of games.\n- **S**: the disillusioned worker, a skeptic. \n\n**G**: I would rather die than work another day, toiling away to produce goods and services in an attempt to sate the infinitely hungry needs of society. \n\n**S**: You talk as though there are only two possibilities: either a life devoted exclusively to play or a life devoted exclusively to work. How will you feed yourself? Put a roof over your head?\n\n**G**: The only argument against the life I wish to lead is death. One dies if they do not work. Yet, death is also inevitable. To continue to work is to bring about the death of my character, my curiosity about the world, my will to exist. To continue to work would effectively cause my death. If I die regardless, I might as well live a life I fully enjoy, if not short. What is life for, if not to enjoy it and to seek pleasure out of things you find valuable?\n\n**S**: This seems awfully hedonistic of you. What about personal fulfillment? Don't you have responsibilities to the rest of society?  If everybody lived like you, society itself would collapse.\n\n**G**: I am not saying everyone should lead the life I claim to want. I simply claim that this life is the one that would lead me to be the most fulfilled. However, is it wrong to dream of a future where a life like mine could be the norm? To create [shared fiction](thoughts/fiction.md) we can rally around and build towards? Having dreamers who believe in and drive this vision forward are a necessary step to manifest it into reality.\n\n**S**: I guess there is no harm to dreaming a little. I'm curious what this future of yours could look like.\n\n**G**: Wonderful. Let us imagine an utopic future where all work has been automated by machines activated purely through thought, requiring no labour to maintain its running cogs or to provide its goods and services to society. This is a utopia of abundance. Anything you could wish for, you can have: food, luxury, knowledge, happiness. In this utopia, one does not need to work to sustain themselves. I argue that there is no work to be done here. In fact, the only *rational* activity is to play.\n\n**S**: Forgive my interruption, but how do you define 'play' here? Isn't it at odds with your definition of 'work'?\n\n**G**: I suppose I should clarify some terminology. Let us first define something as *instrumental* if it serves as the means to an end (*i.e.* as a way to accomplish a goal). Work then, is explicitly defined as labour which is *instrumentally* valuable.\n\nPlay, on the other hand, is defined as labour which is non-instrumental. It should be *intrinsically* valuable and self-motivated. Games, then, are the reversal of means and ends. When playing, the means that traditionally entail an end become the ends themselves.\n\nLet us take mountain climbing as an example. Say person **A** considers reaching the top as the end goal. For **A**, climbing is just a means of reaching the top. If a helicopter came by to offer them a lift to the top, they would happily take it.\n\nSay person **B** climbs mountains for the thrill of climbing itself. **B** actually doesn't really care if they reach the top each time, it is just a means for them to climb more mountains. Even if a helicopter offered **B** a ride to the top, they would happily decline and continue their trek up the side of the mountain.\n\nPerson **A** clearly considers mountain climbing *work* whereas **B** considers mountain climbing *play*.\n\n**S**: Ah, I see. This clarifies my understanding of how you define 'work' and 'play', but I still have a counterpoint. What about those who enjoy their work? The scientist, who after a great effort, has a major breakthrough on a problem they've been stumped on for ages. Far from rejoicing in the discovery, they are eagerly searching for their next challenge to be engaged once more. The carpenter who builds houses because she likes how they look and the feeling of it coming together. Can these individuals not exist in your utopia?\n\n**G**: Hmm. I would posit that both of the mentioned individuals are actually *playing games*. The resolution appears to be the fact that activities which one views as instrumentally valuable (work) can, for another, be intrinsically valuable (play). The human experience is subjective, there is no universal standard for whether society considers something work or play. An environment of play is created when one self-imposes rules to prevent them from the most efficient way of achieving their goal.\n\nTo the carpenter who enjoys building for its own sake, that otherwise instrumental activity has intrinsic value as well. The same could be true of anyone who really enjoys their work, whatever that work might be. This is the definition of game playing.\n\n**S**: This does make a lot of sense. So in this utopia that you propose, I could theoretically just do what I find intrinsically valuable -- play? And I suppose the rest of my needs would be met by the machines?\n\n**G**: Correct.\n\n**S**: I am excited to create this utopia of ours. Let us dream together then.\n\n---\n\n## A re-worked definition\nObviously, this is an exaggeration of the argument I'm hoping to make -- we clearly don't live in this caricature of a post-instrumental society. However, we *do* live in is a society that is malleable to change.\n\nLanguage is one of the only logically [decentralized](thoughts/decentralization.md) aspects of humanity. It is also one that has considerable effects on [how we think](posts/new-words.md) about ourselves and the world.\n\nWe started off this journey by asserting that our current accepted definition of play was inadequate. In its place, we offer a plurality of alternatives:\n\n- Play is an *intrinsically* motivated activity. \n- Play is labour which is non-instrumental.\n- Play is the act of enjoying the means to the end.\n- Play is what allows us to create local spaces of abundance.\n\nRe-defining play gives us power in the form of shared fiction which we can build towards and manifest into reality.\n\nHere's to building the future we can play in.","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/posts/primacy-of-consciousness":{"title":"On Consciousness","content":"\n![[thoughts/images/consciousness-midjourney.png]]*\"Bridging the explanatory gap from the other side\" [@midjourney](https://www.midjourney.com/)*\n\n\u003e An exploration into the [[thoughts/philosophy of science|philosophy of science]].\n\nWhat is consciousness even?\n\nFor many, it is the ability to be human. To feel the warm of sunlight on our skin, to see the redness of sunset, to taste the crunch of a sweet apple, to love and be loved. Distilled, it is the ability to have subjective human experience.\n\nPhilosophers in particular define consciousness as *experience*. Something is conscious if there is an experience to *be like that thing*. But there is a deeper question that philosophers have been digging at for the past few millennia: why should all of this experience *feel* like anything? How do we get from the physical act of feeling things in our environment to the mental experience of *being* human?\n\nThis is the [[thoughts/mind body problem|mind-body problem]] and the fundamental question of the [[thoughts/Hard problem of consciousness|hard problem of consciousness.]] \n\nEver since the turbulent events of the early 20th century, **logical positivism** had flowered. Logical positivism is a belief that scientific knowledge is the *only* kind of factual knowledge, discounting and pushing away the realm of [[thoughts/metaphysics|metaphysics]] to the sidelines. The question of consciousness was (and in many ways, still is) taboo to many philosophers and scientists alike, perceived as too \"new-age-y\" or metaphysical to be considered a worthwhile pursuit. Philosophers were encourage to \"earn their keep\" by providing actual contributions to science rather than musing about what it means to be human.\n\nAs metaphysical questions about consciousness faded slowly, behaviourism found its footing through psychology. Behaviourists believed that the mind could be entirely understood purely by reducing it to its environmental inputs and behavioural outputs.\n\nTo give them credit, many scientists found success through this approach. Scientists figured out how to correlate brain states with solving problems and even feelings of pain and pleasure. They figured out how activations in the V1 area of the cortex react to certain colours like the redness of an apple. Further physiological work discovered the existence of the V4-V8 areas which had an even stronger correlation with shapes, motion, and lighting conditions. The moonshot goal was to build up to a full **neural correlate of consciousness** or [[thoughts/Neural Correlates of Consciousness (NCC)|NCC]] -- some way of explaining what physical brain states correlate to mental ones.\n\nYet, at the end of the day, all of this work only proved *correlation*. Behaviourist approaches were no closer to answering the question of how physical brain states *produce* mental ones. **Any theory that attempted to explain consciousness in terms of the physical is forced to take no less than a leap of faith from the objectively physical to the subjectively mental.** This leap is across what is known as the [[thoughts/Hard problem of consciousness#Explanatory Gap|explanatory gap]].\n\n\u003e \"The mind-body problem is not just a local problem having to do with the relation between mind, brain, and behaviour in living animal organisms ... it invades our understanding of the entire cosmos and its history.\" (Thomas Nagel, *Mind and Cosmos*)\n\nThis isn't just a problem for philosophy or neuroscience but rather our **entire understanding of the physical world** -- this is the blind spot of science.\n\n![[thoughts/images/explanatory-gap-midjourney.png]]*\"Vector illustration of hands grasping at the explanatory gap\" @midjourney*\n\n Scientific [[thoughts/Materialism|materialists]] argue that science and the scientific method enables us to get \"outside of experience\" and grasp the world in and of itself. Yet, subjective experience is present at every step[^1]. When we look to send people to the cosmos, we do so by formulating theories and models about how we think they work. All of this depends on the subjective experience. We look at the results of our complex telescopes and formulate theories based off of what we have learned and have observed in the world. We pull scientific models from our experiments and observations but again, these are models and idealisations, not actual instantiations of *things* in the world.\n\n\u003e \"In principle, it is absurd to think that we can explain consciousness by reducing it to certain objects of science, since these objects are abstract relational structures extracted from the life-world of lived experience\" (Husserl, *The Crisis of the European Sciences and Transcendental Phenomenology*)[^11]\n\nGottfried Leibniz, Immanuel Kant, Arthur Schopenhauer, and Bertrand Russel were all strong believers that a fully physical account of the world actually offers no explanation of the *intrinsic nature*[^2] of the things within it.[^6] The ideal gas law tells us how pressure, volume, amount, and temperature of a gas are all related to each other, but tells us nothing about what each of those things in and of themselves are. Chemistry tells us that Carbon has an atomic number of six. At first glance, this seems be an intrinsic property. But probe deeper at what an atomic number truly represents and all it is the number of protons it has. Protons themselves are not \"real\" things. They are a convenient model of how this group of abstractions we call quarks behaves together depending on their relations. Mass is a property that determines how an object will obey the relation $m = \\frac{F}{a}$. Again, it is abstractions all the way down. Purely physical descriptions **tell us not what matter *is* but what what it *does*.**\n\nPhysics, by name, is supposed to be a mathematical theory of the physical. Yet mathematics by nature is purely relational; numbers are quantifiers on abstract objects, formulas describe precise relations between variables. But intuitively, there must also be an *intrinsic nature* to these objects as well. *What is an atom in and of itself?* This question is not answered by a relational account of the world.\n\nIt is tempting to say at this point that perhaps a relational view all there is to reality. After all, this is realistically all that is useful to the functioning of society. It has enabled us to program silicon, photograph the depths of the universe, and predict weather across the world. \n\nYet intuitively, a world held up purely through relations does not make sense. As Hedda Hassel Mørch pointed out in her critique of physics for ignoring consciousness, \"for there to be a relation there must be two things being related.\" [^3] Otherwise, the relationship is empty -- \"a show that goes on without performers, or a castle constructed out of thin air.\" Mørch argues that all physical relations should be made real by some substance that itself is not purely relational or else there would be no difference between mere mathematical abstraction and the concrete universe.\n\nClearly, if we wish to poke beyond this veil of pure abstractions, our current explanations of our reality will not do: intrinsic natures simply cannot be captured through a purely physical approach. [[thoughts/Materialism|Materialism]] as given so far does not seem to stand. Taking its physical description as the totality is like **confusing the map with the territory.** It may be fine if you just need the map to navigate the world, but to open one's eyes to the real world, we must dig deeper.\n\nWe thus try to **bridge the explanatory gap from the other side**. Perhaps consciousness is fundamental to reality, not the other way around.\n\n![[thoughts/images/life-world-ghibli.png]]*\"The life-world contains the universe\" illustrated in the style of Studio Ghibli @midjourney*\n\nUp until this point, I have painted a picture of why the intrinsic nature of consciousness cannot be fully explained by the physical. Now, I push to make a stronger claim that consciousness is **primary** -- namely existentially, transcendentally, and epistemologically. For something to be primary is for it to be the first and foremost, a prior for all else that comes after it.\n\nIt seems almost self-evident that consciousness is **existentially primary** -- it is through the subjective human experience that the universe is disclosed to us. Arthur Eddington argued that the one thing we know concretely about consciousness is that it has an intrinsic nature.[^8] [[thoughts/Descartes' Meditations|René Descartes]] famously said \"cogito, ergo sum\": I think, therefore I am.[^9] It is the foundation upon which Descartes builds upon his certainty in his knowledge about the world. In all the ways we can be mistaken about reality, consciousness is not one of them -- it is a reality that we apprehend directly and without inference. Thus, consciousness is existentially primary.\n\nConsciousness is also **transcendentally primary**. Kant defined transcendental primacy as all knowledge which is \"occupied not so much with objects as with the mode of our knowledge of objects in so far as this mode of knowledge is to be possible a priori.\" [^10] In more colloquial language, the transcendental primacy of consciousness refers to how consciousness is not another object of knowledge, but that by which any object can become *knowable*.\n\nEdmund Husserl, in his 1936 work *The Crisis of European Sciences and Transcendental Phenomenology,* defines a concept called the *life-world*. Roughly defined, it refers to the world as it is collectively experienced. Husserl likened this model of consciousness to our visual horizon: it is not really an object, but a rather a process of uncovering or displaying potentialities.[^11]\n\nIt is in this way then that the horizonal sense of consciousness is not something that can be *had,* but rather something we *live*. Quoting Bertrand Russel, \"we know nothing about the intrinsic quality of physical events except when these are mental events that we directly experience.\"[^12] As such, consciousness is transcendentally primary.\n\n![Merleau-Ponty on the world and consciousness](thoughts/images/Merleau-Ponty%20on%20the%20world%20and%20consciousness.png)*Merleau-Ponty on the world and consciousness*\n\nConsciousness is additionally **epistemically primary** -- it is the source and destination of all knowledge. In creating models, we set aside aspects of experience on which we have doubts about (e.g. our senses, emotions, etc.) and extract idealised and abstract models (e.g. mathematics, physics, logic). Even the most abstract physical relation or mathematical formulas describe some \"real\" thing we are trying to model or express a relation between. These models ideals and models are only as useful insofar as we can implement these abstractions as things we can use to measure, predict, and control phenomena within our lived experience. In this way, consciousness is epistemically primary.\n\nI will pause here to clarify that I am *not* claiming consciousness to be ontologically primary. I am not making any sort of [[thoughts/Panpsychism|panpsychist claim]] that consciousness exists as a fundamental aspect of reality where everything has a small amount of consciousness.[^5] Neither am I claiming that consciousness exists inherently in the natural world as a fundamental aspect of reality.[^4]\n\nRather, I am positing a form of **neutral monism** that sits somewhere between physicalism and idealism. Monism, in its simplest form, suggests that there is only one *kind* of underlying reality. A neutral stance on this does not side with either matter or mind, instead a potential 3rd substance. Russel explained this form of reality as having \"a single underlying nature that is *neither* mental nor physical but capable of being expressed in these two different ways.\"[^13]  Much like the interiors and exterior of any object, Russel's account of the mental and physical imply and necessitate each other as reflection of a single nature.\n\nIn Husserl's horizon metaphor, the horizon is not possible without a world to be observed but the world also cannot be perceived without a perceiver. Similarly, the horizon of consciousness is not possible without the physical but the the physical cannot be perceived without the mental. It is absurd to try to reduce one completely to another.\n\nFrancisco Varela's notion of \"mutually generative constraints,\"[^14] points toward a possibility where both physicalism and idealism work together towards reciprocal enrichment:\n\n1.  Phenomenological reports may help to pick out and ascribe meaning to previously unnoticed neural configurations\n2.  Neurological findings may become an incentive for re-categorization and further development in phenomenological research\n\nThis neutrally monistic view of consciousness does not \"solve\" the hard problem. Rather, the problem never even arises because the physical world is no longer the standard for being, and objectivity is no longer the ultimate standard of being. \n\nIt is in this neutrally monistic view that one can acknowledge consciousness as primary without necessarily needing to discount our existing objective knowledge about the world.\n\nInstead of absorbing or reducing contents of experience into the relational network of objective science or vice versa, we could strive towards embedding these experiences within a broader network of a potentially new amplified science of structures which we may not know of yet.\n\n*Adapted version of my [[thoughts/Primary of Consciousness|PHIL451A final paper]].*\n\n![[thoughts/images/observatory-midjourney.png]]*\"A beautiful observatory in the park of Mars\" in the style of James Paik and Ross Tran @midjourney*\n\n[^1]: The upshot is that there is no simple way to remove our experience as scientists from the characterization of the physical world. In Popperian fashion, scientific knowledge then is a self-correcting narrative made from the world and our experience of it evolving together. Popper personally rejected logical positivism as well. He believe that there are statements that have varying statements of 'truth' or [[thoughts/truth#Verisimilitude|verisimilitude]] relative to our conscious experience of the world.\n[^2]: In philosophy, an intrinsic property is a property that an object has in and of itself, whereas extrinsic properties are properties than depend on that object's relation with other things.\n[^3]: *Is Matter Conscious?* in [Nautilus](https://nautil.us/is-matter-conscious-6028/)\n[^4]: The position of ontological idealism explores this further, positing it is fundamentally human consciousness that gives rise to the physical world. This is not a new idea, having being explored in both Eastern thought (through [[thoughts/idealism#Pratyabhijna Self-awareness|Pratyabhijna self-awareness]]) and Western thought (platonic idealism).\n[^5]: In fact, I think there are quite a few problems in panpsychist theories, namely [[thoughts/Consciousness is not Information|how theories like Giulio Tononi's IIT define information]] and how they fail to adequately resolve [[thoughts/emergent behaviour#Combination Problem|the Combination Problem]]. The typical [[thoughts/Panpsychism|panpsychist]] response would be to agree that consciousness could never emerge from exclusively physical processes and that consciousness exists as a fundamental aspect of reality (often referred to as the Intrinsic Nature Argument). One of the original arguments for panpsychism posited by Eddington, Russell, Strawson relies on quite a few problem assumptions (namely, that \"relational properties are determined by intrinsic properties\" and \"own inner awareness reveals that phenomenality is an intrinsic property\"). A more modern form of this argument crops up in IIT and has been widely lauded as influential in finally providing a testable hypothesis of consciousness. However, Tononi defines information in very atypical fashion and refuses to address potential edge cases in which integrated information of seeming non-conscious objects (e.g. a large number of connected logic gates which do not compute anything meaningful) is unreasonably high (and potentially infinite).\n[^6]: Kant, Immanuel, 1787, _Critique of Pure Reason_. Leibniz, Gottfried Wilhelm, 1686, _Discours de métaphysique_ (_Discourse on Metaphysics_), G, IV. Schopenhauer, Arthur, 1818, _Die Welt als Wille und Vorstellung_. Russel, Bertrand, 1959, *My Philosophical Development*\n[^7]: Kant defines \"transcendental knowledge\" as \"all knowledge which is occupied not so much with objects as with the mode of our knowledge of objects in so far as this mode of knowledge is to be possible a priori.” (Critique of Pure Reason A295/B352)\n[^8]: Eddington, A., 1928, *The Nature of the Physical World,*\n[^9]: Descartes, R., 1641, *Meditations on first philosophy*, Meditation II\n[^10]: Kant, I., 1787, _Critique of Pure Reason_ A295/B352\n[^11]: Husserl, E., 1936, *The Crisis of the European Sciences and Transcendental Phenomenology*\n[^12]: Russel, B., 1959, *My Philosophical Development*\n[^13]: Russel, B., 1919, “On Propositions: What They Are and How They Mean”, _Proceedings of the Aristotelian Society_, Supplementary Volume 2: 1–43. pp. 283–321.\n[^14]: Varela, F. J. (1996). Neurophenomenology: A methodological remedy for the hard problem. _Journal of consciousness studies_, _3_(4), 330-349.","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/posts/react":{"title":"React in 30 minutes","content":"\nReact is, as the [website](https://reactjs.org/) says, \"a JavaScript library for building user interfaces.\" What this means exactly, is often confusing to people.\n\nMany articles claim to teach you \"React in 10 minutes\" but rarely go beyond a few code examples. The problem is that this leaves you with an inkling of what React looks like and maybe how to write a bit of it, but no clue *why* it works and how to think about fixing React bugs.\n\nThis isn’t some random tutorial which throws you a bunch of example code that you go on to copy-and-paste and then leaves you hanging wondering what it does. The goal of the workshop is to give attendees a good foundation of the concepts within React, why people choose to use React, and how it works behind the hood. Hopefully, this gives you a good enough foundation to hit the ground running and avoid entire classes of bugs when starting out in React!\n\nThis post assumes that you know basic HTML, CSS, and JavaScript.\n\n## What is React?\nThe TLDR; is that it's a bunch of code you can add to your project that makes building websites and interfaces that **react** to changes when you do things (e.g. press buttons) really easy.\n\nReact has two distinguishing features that set it apart:\n1. React is **declarative** meaning you tell React exactly what you want the page to look like and it'll figure out how to do that.\n2. React is **component based** meaning that you can create pieces of the UI that you can reuse across different parts of your application.\n\n## How a website works\nMost likely, you've written some code for a website in plain old HTML before. This, as you know, defines the structure for what is inside a webpage. If the webpage is a house, the HTML is the blueprint that tells you what the house should generally look like and what is inside.\n\nYet, to turn that bunch of HTML into something displayable in your web browser, it needs to parse it into a more intermediate format it can more easily work with: the Document Object Model (DOM).\n\nThe nested structure of the HTML lends itself very well to a tree-like structure which the browser can then efficiently traverse and make updates to.\n\n![Turning HTML into the DOM and then into the actual site](/posts/images/react/html-dom-site.png)*Turning HTML into the DOM and then into the actual site*\n\n## How React works\n### The Virtual DOM\nOf course, you can still manipulate and interact with the regular DOM [through JavaScript](https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model/Introduction) still but the main gripe that React has with this way of manipulating the DOM (e.g. adding new things to the screen or modifying existing bits on the page) is that it can be *realllyyy* slow in some cases.\n\nThis is where the mystical **virtual DOM** comes in. Modifying the DOM in a declarative way is difficult because modifying the real DOM is imperative by nature, making it difficult to write declarative applications. You could use `element.innerHTML = 'your html'` in a declarative fashion, but an in-memory version implemented in JavaScript would be faster than using `innerHTML`, which is exactly exactly what React does. React creates a virtual DOM where it keeps track of what it would *like* the real DOM to look like and then intelligently batches and combines changes together to optimize and squeeze the most performance out of the few expensive writes to the real DOM that it actually does. More info on [how DOM diffing and patching works](https://buildwithreact.com/tutorial/under-the-hood) under the hood for those curious.\n\n\u003e Please note that Virtual DOM is not faster than raw, imperative operations on the real DOM (best performance). React uses the Virtual DOM because it is a relatively efficient way of declaratively representing your UI from state, and much faster compared to straight `innerHTML` calls.\n\n![React's Virtual DOM in action. ReactDOM.render() tells React to attach your React components to the real DOM](/posts/images/react/virtual-DOM.png)*React's Virtual DOM in action. ReactDOM.render() tells React to attach your React components to the real DOM*\n\n### Components\nAnother things that React tackles really well is that regular HTML and JS makes it a lot more difficult than it should be to re-use the same UI and logic across different pages on your website.\n\n![What if you wanted to reuse this 'product card' component?](/posts/images/react/component-reuse.png)*What if you wanted to reuse this 'product card' component?*\n\nThe main philosophy of functional React is that you shouldn't override and inherit behaviour. Instead, get the behaviour you want by creating and composing reusable *components*. Each of these components can hold some sort of data of its own, called its **state**. Each component can also take in a few arguments or parameters called **properties** or **props** for short. Each component is composed up of either primative HTML elements (e.g. `\u003cdiv\u003e` or `\u003ch1\u003e`) or other React components. The elements that a component is made up of are called its **children**.\n\n![React Component Diagram](/posts/images/react/component-diagram.png)*React Component Diagram*\n\nBecause React uses composition to build components, there is a natural *downward flow of information*, where components pass data to their children. Thus, to change a parent's state, the parent needs to explicitly pass a callback function that allows that behaviour to the child (e.g. an arrow function that wraps the `setState` function for the parent). This is detailed more in the 'Building an App section'.\n\n### JSX\nJSX is a extension to regular JS which lets you write HTML-like code to define React components. It is declarative at heart, meaning you describe exactly what you want the component to look like based off of some given data (props and state in this case) and React will figure out how to get the page to look like that.\n\nJSX can be just regular HTML.\n\n```jsx\n\u003cdiv\u003eBottom Text\u003c/div\u003e\n```\n\nIt can also be a user-defined component. In this case, the component has no children or 'inner HTML' so we can write its shorthand.\n\n```jsx\n\u003cExampleComponent/\u003e\n```\n\nWe can also pass in properties to a component by adding a tag with that property name. Any string can be passed in regularly, or you can also choose to pass in any JS expression (e.g. number, function, object, etc.) by enclosing it in curly braces.\n\n```jsx\n\u003cHello name=\"World\" someData={2 + 3}/\u003e\n```\n\nTo 'compose' components, you can nest them as children within each other.\n\n```jsx\n\u003cDashboard\u003e\n  \u003cGreeting/\u003e\n  \u003cStatistics\u003e\n    \u003cBarChart data={data}/\u003e\n    \u003cPieChart data={data}/\u003e\n  \u003c/Statistics\u003e\n\u003c/Dashboard\u003e\n```\n\nGreat, so that's just what JSX *looks like*, how do we use it in React? The first thing to note is that a **component in React is defined as a function which returns some JSX**.\n\nHere's a simple 'Hello World' component in React! We then write a return statement that defines exactly how to render this component (i.e. what children make up this component).\n\nNote that React passes us all of the props from the parent in a 'props' object. Then, in the return statement's JSX, we can then access the name property by using `{}` to indicate a JS expression and accessing the 'name' field in the `props` object.\n\n```jsx\nimport React from 'react'\n\nfunction Greeting(props) {\n  return \u003cp\u003eHello {props.name}!\u003c/p\u003e\n}\n```\n\nLet's say we want to create a `\u003cHelloWorld/\u003e` component that re-uses our `\u003cGreeting/\u003e` component from above.\n\n```jsx\nimport React from 'react'\n\nfunction HelloWorld() {\n  return \u003cdiv\u003e\n    \u003ch1\u003eMy Hello World App\u003c/h1\u003e\n    \u003cGreeting name=\"World!\"/\u003e\n  \u003c/div\u003e\n}\n```\n\nThen, at the end, we tell React to finally render our `\u003cHelloWorld/\u003e` component into the actual DOM by using `ReactDOM.render(...)`. Here, we choose to replace the element with the id 'root' in the real DOM with our `\u003cHelloWorld/\u003e` component.\n\n```jsx\nimport ReactDOM from 'react-dom'\n\nReactDOM.render(HelloWorld, document.getElementById('root'))\n```\n\n## Life Cycle\nSo far we've covered static components using just plain old JSX and data passing using props, but this misses the biggest benefit that React offers: reactivity to data changes. We'll look a little at the life cycle of React components to see where we can update a component when data changes.\n\nThere are three main parts to the life cycle to a React component. They are mounted, updated, and eventually unmounted.\n\n![React Component Lifecycle](/posts/images/react/lifecycle.png)*React Component Lifecycle*\n\n### Mount\nMounting happens when the component is first added to the virtual DOM. Here, we set the initial state of the component (e.g. to track the number of clicks, a user's input, etc.) and tell React to update the DOM.\n\n### Update\nAn update happens when its parent component is updated or when its state or props changes. Here, we can modify the state of the component, do asyncronous things (like call an API), and rerender the component.\n\n### Unmount\nThe unmount happens when the parent component is no longer rendered to the DOM. Now, we cleanup anything that needs to be cleaned up, destroying all state, and removing the component from the DOM.\n\n## Hooks\nNote that when a component updates, React will call the component again with the new props thus **clearing all local state**. This is why you can't just declare a new `const` inside a component for state. Introducing: hooks! They are JavaScript functions that allow us to 'hook' into the React lifecycle and do things like fetch data and persist state.\n\n### useState\nLet's say we want to track how many times a user has clicked a button. A naive implementation might look something like this, where we define a variable in the scope of the component.\n\n```jsx\nimport React from 'react'\n\nfunction Counter() {\n  let count = 0\n\n  return (\n    \u003cdiv\u003e\n      \u003cp\u003eYou clicked {count} times\u003c/p\u003e\n      \u003cbutton onClick={() =\u003e count++}\u003e\n        Increment\n      \u003c/button\u003e\n    \u003c/div\u003e\n  )\n}\n```\n\nHowever, this will not work! Because React doesn't know about the count variable, incrementing it will not update the component and thus not re-render it onto the screen. To register a component's state with React, we use the `useState` hook.\n\nThis will allow React to preserve the state between re-renders. `useState` returns a pair: a read-only variable representing the _current_ state value and a function that lets you set a new value for the state.\n\nThe first parameter to the `useState` hook is the default value that React should assign to the state when the component is first mounted.\n\n```jsx\nimport React, { useState } from 'react'\n\nfunction Counter() {\n  // Declare a new state variable called count initialized to 0\n  const [count, setCount] = useState(0)\n\n  // When the button is clicked, update the count to be\n  // the previous count + 1\n  return (\n    \u003cdiv\u003e\n      \u003cp\u003eYou clicked {count} times\u003c/p\u003e\n      \u003cbutton onClick={() =\u003e setCount(count + 1)}\u003e\n        Increment\n      \u003c/button\u003e\n    \u003c/div\u003e\n  )\n}\n```\n\nNow when the button is clicked, the count is then incremented by one. Because we used the `useState` hook, React knows about this component state and will then known to re-render the component when the state is updated.\n\nNote that you **cannot** directly modify the `count` variable because it is read-only. If you want to mutate it, use the `setCount` function that is returned from the hook.\n\n#### A note about syntax\nBecause this is just using JavaScript's [destructuring assignment syntax](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment), we can call the variable whatever we want.\n\n```jsx\nconst [count, setCount] = useState(0)\n\n// is equivalent to\n\nconst state = useState(0) // state is an array of length 2\nconst count = state[0]\nconst setCount = state[1]\n```\n\n### useEffect\nAsynchronous data fetching, manually changing the window title, and setting recurring events are all examples of side effects. Yet, React won't let us do that right now because we have no way to do things in between the mount and unmount lifecycle events.\n\nIntroducing the `useEffect` hook, which lets us peform side effects within components.\n\nLet's consider the previous example of keeping track of amount of times the user has clicked a button. What if we want to set the window title to be the number of times the button has been clicked so far?\n\n```jsx\nimport React, { useState, useEffect } from 'react'\n\nfunction Counter() {\n  const [count, setCount] = useState(0)\n\n  // setup a new effect that runs everytime `count` is updated\n  // this will re-render the component too\n  useEffect(() =\u003e {\n    document.title = `${count} clicks`\n  }, [count])\n\n  return (\n    \u003cdiv\u003e\n      \u003cp\u003eYou clicked {count} times\u003c/p\u003e\n      \u003cbutton onClick={() =\u003e setCount(count + 1)}\u003e\n        Increment\n      \u003c/button\u003e\n    \u003c/div\u003e\n  )\n}\n```\n\n`useEffect` doesn't return anything, but takes two parameters. The first is the callback which is the effect we want to run, this callback takes 0 parameters. The second parameter is the array of dependencies for the effect. React uses this array to determine when to re-run our effect (you can optionally omit this entire array to re-run the effect *every* time the component updates).\n\n### useSWR\nWhat about making API requests to fetch user data or data from an external third-party? While technically you can do this with `useEffect` and `useState`, it gets messy really quickly.\n\nThis hook isn't an official React one, but I use it so much in my projects that it might as well be. Introducing `useSWR`, a [hook from Vercel](https://swr.vercel.app/) that lets you make asynchronous HTTP requests extremely easily.\n\n```jsx\nimport React from 'react'\nimport useSWR from 'swr'\n\n// a function that performs an http request and returns a response\n// this can be reused across all of your requests\nconst fetcher = url =\u003e fetch(url).then(res =\u003e res.json())\n\nfunction Profile() {\n  // example HTTP GET request to /api/user\n  const { data, error } = useSWR('/api/user', fetcher)\n\n  // we can use conditional rendering to display\n  // error or loading messages\n  if (error) return \u003cdiv\u003efailed to load\u003c/div\u003e\n  if (!data) return \u003cdiv\u003eloading...\u003c/div\u003e\n\n  // if the code reaches this point, we know\n  // that our request will have finished and have no errors!\n  return \u003cdiv\u003eHello {data.name}!\u003c/div\u003e\n}\n```\n\n### Order matters\nOne really common beginner mistake that I made a lot when first starting out is that **hooks need to be called in the exact same order every time.** This means that you can't have hooks after any conditional returns, inside `if` statements, or inside function/callback definitions.\n\n```jsx\n// DON'T: conditionally run hook\nif (someCondition) {\n  useEffect(() =\u003e {\n    // run effect here\n  })\n}\n\n// DO: put conditional inside the hook\nuseEffect(() =\u003e {\n  if (someCondition) {\n    // run effect here\n  }\n})\n```\n\nFor more information, read the [official React docs on this](https://reactjs.org/docs/hooks-rules.html#only-call-hooks-at-the-top-level).\n\n## Building an App\nGreat, so now you have all this theory. You're probably itching to build something and that's exactly what this section is for! We'll be building a very basic **todo application** where you can add and remove from the list. For this bit, a basic understanding of [Git and GitHub](https://resources.nwplus.io/2-beginner/how-to-git-github.html) is required.\n\nFirst, make you install a version of [Node](https://nodejs.org/en/) `\u003e= 12.x`. If you are unsure, you can check your Node version by doing `node -v`.\n\n```bash\n$ node -v\nv12.14.0 # good to go!\n```\n\n### Starter Code\nNormally, most people will tell you to run `create-react-app` here to create a new React application, but I find that `create-react-app` has way too much boilerplate (extra code) for my taste so I made my own more stripped down version of `create-react-app`. It contains everything you need to get started with a new React app and, in my opinion, is a lot less confusing.\n\nTo get started open your terminal of choice and clone this [minimal React template](https://github.com/jackyzha0/min-react). This will give you all the code you need to get started!\n\n```bash\n# clone the repository\n$ git clone https://github.com/jackyzha0/min-react.git\n\n# navigate to folder\n$ cd min-react\n\n# install dependencies\n$ npm i\n\n# run local dev server! (open localhost:3000 in your browser)\n$ npm run start\n```\n\nThen, let's remove some of the starter files we don't need. Delete the `src/components` folder. We'll be working `src/App.js` for the rest of this tutorial.\n\n### Creating the App component\nLet's delete what's in `src/App.js` and start fresh. What do we need in our todo app? Well, we need to track the list of todos the user has. Let's create a state for that and initialize it with a few default todos. Then, the component should just be a container for all of our todo items. We can just map over the `todos` state and turn them into `\u003cTodoItem\u003e` components!\n\nWe can keep the styling from the template just so it looks a bit nicer.\n\n```jsx\nimport React, { useState } from 'react'\nimport styled from 'styled-components'\n\n// custom styling using styled-components!\nconst AppContainer = styled.div`\n margin: 40vh 30vw;\n`\n\nfunction App() {\n  // setup todos\n  const [todos, setTodos] = useState([\"do laundry\", \"finish homework\"])\n\n  // app is composed up of all the current todos\n  return (\n    \u003cAppContainer\u003e\n      \u003ch1\u003etodos\u003c/h1\u003e\n      {todos.map((item, i) =\u003e \u003cTodoItem\n        key={i}\n        name={item}\n      /\u003e)}\n    \u003c/AppContainer\u003e\n  )\n}\n\nexport default App\n```\n\nThe problem is, we don't have a `\u003cTodoItem\u003e` component yet. Let's make it!\n\n### Creating a Todo component (Component Styling)\nWe need a component to display each of our todo items. The only prop we really need is the name of the todo to display it so we'll make a simple component; no need to track state or anything.\n\n```jsx\nfunction TodoItem(props) {\n  return (\n    \u003cdiv\u003e\n      \u003cp\u003e{props.name}\u003c/p\u003e\n    \u003c/div\u003e\n  )\n}\n```\n\nLet's add a hover state so that the item has a strikethrough effect when you hover over it. We can do this using `styled-components` which is a way for us to add CSS to our components really easily.\n\n```jsx\n// create a 'styled' div that has a strikethrough on hover\nconst TodoItemContainer = styled.div`\n  \u0026:hover \u003e p {\n    text-decoration: line-through;\n  }\n`\n\nfunction TodoItem(props) {\n  // replace the original div with the `TodoItemContainer`\n  // styled div we just created\n  return (\n    \u003cTodoItemContainer\u003e\n      \u003cp\u003e{props.name}\u003c/p\u003e\n    \u003c/TodoItemContainer\u003e\n  )\n}\n```\n\nGreat! Now let's see what that looks like.\n\n![Our todo app with a strikethrough effect!](/posts/images/react/todo-0.png)*Our todo app with a strikethrough effect!*\n\n### Deleting a Todo (Passing callbacks)\nHmm, would be great if we could actually delete a todo by just clicking on a todo item. Good thing [React has event handlers](https://reactjs.org/docs/handling-events.html) just like regular HTML elements do! Let's modify our `\u003cTodoItem\u003e` to handle a click event. To do that, we just pass a callback to the the desired component using the `onClick` prop.\n\n```jsx\nfunction TodoItem(props) {\n  return (\n    \u003cTodoItemContainer\n      onClick={() =\u003e {\n        alert(`You finished ${props.name}!`)\n      }}\n    \u003e\n      \u003cp\u003e{props.name}\u003c/p\u003e\n    \u003c/TodoItemContainer\u003e\n  )\n}\n```\n\nNow, when we click each todo item, our page will give us an alert saying we completed that item! Not super useful though. Can we just delete the item from the component?\n\nRecall from earlier that with React, information flows *downward* in the component hierarchy tree. This means that in order to modify the state of the parent (`\u003cApp\u003e` in this case), we need to pass a callback that helps us modify the information.\n\nTo do that, we create a `deleteTodo` function in `\u003cApp\u003e` and then pass an anonymous function to each todo which deletes that given todo. Note that because we can't directly modify the `todos` variable as it is read-only, we create a copy of it using the spread syntax (`[...todos]`), then remove a single element by index using splice.\n\n```jsx\nfunction App() {\n  const [todos, setTodos] = useState([\"do laundry\", \"finish homework\"])\n\n  // callback to remove a todo\n  const deleteTodo = (index) =\u003e {\n    // copy current todos\n    const newTodos = [...todos]\n    // remove todo at given index\n    newTodos.splice(index, 1)\n    setTodos(newTodos)\n  }\n\n  return (\n    \u003cAppContainer\u003e\n      \u003ch1\u003etodos\u003c/h1\u003e\n      {todos.map((item, i) =\u003e \u003cTodoItem\n        key={i}\n        name={item}\n        deleteCallback={() =\u003e deleteTodo(i)}\n      /\u003e)}\n    \u003c/AppContainer\u003e\n  )\n}\n```\n\nThen, we update `\u003cTodoItem\u003e` to use this callback on click.\n\n```jsx\nfunction TodoItem(props) {\n  return (\n    \u003cTodoItemContainer onClick={props.deleteCallback}\u003e\n      \u003cp\u003e{props.name}\u003c/p\u003e\n    \u003c/TodoItemContainer\u003e\n  )\n}\n```\n\nGreat, so now we have display and deletion. Adding new todos is up next!\n\n### Adding a Todo (Form Inputs)\nFirst, let's create a short form component that will allow us to accept user input. Let's setup a state field for the user input and create a form with a single text input. To update the state of the component as the user types, we attach an `onChange` event handler to the `\u003cinput\u003e` which sets the value of the `todo` state to whatever the input field is.\n\n```jsx\nfunction TodoForm(props) {\n  // form state\n  const [todo, setTodo] = useState(\"\")\n\n  return (\n    \u003cform\u003e\n      \u003cinput\n        type=\"text\"\n        value={todo}\n        onChange={e =\u003e setTodo(e.target.value)}\n      /\u003e\n    \u003c/form\u003e\n  )\n}\n```\n\nNow, let's handle what happens when the user submits this form (i.e. presses enter). We add an `onSubmit` handler to the form to handle this. Note that we specifically tell the browser to *not* refresh the page (which is the default behaviour for a form submission) and clear the form state.\n\nBy telling React that the value of the `\u003cinput\u003e` is equal to the component state `todo`, React knows that this is a [controlled component](https://reactjs.org/docs/forms.html#controlled-components), meaning that the component state is the **single source of truth** here.\n\n```jsx\nfunction TodoForm(props) {\n  const [todo, setTodo] = useState(\"\")\n\n  const handleSubmit = (e) =\u003e {\n    // prevent form from refreshing page\n    e.preventDefault()\n\n    // show an alert with user input\n    alert(todo)\n\n    // clear form\n    setTodo(\"\")\n  }\n\n  return (\n    \u003cform onSubmit={handleSubmit}\u003e\n      \u003cinput\n        type=\"text\"\n        value={todo}\n        onChange={e =\u003e setTodo(e.target.value)}\n      /\u003e\n    \u003c/form\u003e\n  )\n}\n```\n\nLet's add a bit of styling to make the text box not as ugly and add `\u003cTodoForm\u003e` to the end of the todos list so it actually gets rendered.\n\n```jsx\nconst TodoInput = styled.input`\n padding: 0.7em 0.5em;\n border: 1px solid black;\n border-radius: 4px;\n`\n\nfunction TodoForm(props) {\n  const [todo, setTodo] = useState(\"\")\n\n  const handleSubmit = (e) =\u003e {\n    // prevent form from refreshing page\n    e.preventDefault()\n\n    // show an alert with user input\n    alert(todo)\n\n    // clear form\n    setTodo(\"\")\n  }\n\n  return (\n    \u003cform onSubmit={handleSubmit}\u003e\n      \u003cTodoInput\n        type=\"text\"\n        placeholder=\"Add a new todo...\"\n        value={todo}\n        onChange={e =\u003e setTodo(e.target.value)}\n      /\u003e\n    \u003c/form\u003e\n  )\n}\n\nfunction App() {\n  const [todos, setTodos] = useState([\"do laundry\", \"finish homework\"])\n\n  const deleteTodo = (index) =\u003e {\n    const newTodos = [...todos]\n    newTodos.splice(index, 1)\n    setTodos(newTodos)\n  }\n\n  return (\n    \u003cAppContainer\u003e\n      \u003ch1\u003etodos\u003c/h1\u003e\n      {todos.map((item, i) =\u003e \u003cTodoItem\n        key={i}\n        name={item}\n        deleteCallback={() =\u003e deleteTodo(i)}\n      /\u003e)}\n      \u003cTodoForm/\u003e\n    \u003c/AppContainer\u003e\n  )\n}\n```\n\nLooking snazzy!\n\n![A nice new 'Add Todo' field!](/posts/images/react/todo-1.png)*A nice new 'Add Todo' field!*\n\nFinally, let's link this up back to the main `\u003cApp\u003e` state so that adding a new todo actually modifies the state of the app. We create a `addTodo` callback and pass this to the `\u003cTodoForm\u003e` component through using a `addCallback` prop.\n\n```jsx\nfunction TodoForm(props) {\n  const [todo, setTodo] = useState(\"\")\n\n  const handleSubmit = (e) =\u003e {\n    e.preventDefault()\n    // use the provided 'addCallback' prop\n    props.addCallback(todo)\n    setTodo(\"\")\n  }\n\n  return (\n    \u003cform onSubmit={handleSubmit}\u003e\n      \u003cTodoInput\n        type=\"text\"\n        placeholder=\"Add a new todo...\"\n        value={todo}\n        onChange={e =\u003e setTodo(e.target.value)}\n      /\u003e\n    \u003c/form\u003e\n  )\n}\n\nfunction App() {\n  const [todos, setTodos] = useState([\"do laundry\", \"finish homework\"])\n\n  const deleteTodo = (index) =\u003e {\n    const newTodos = [...todos]\n    newTodos.splice(index, 1)\n    setTodos(newTodos)\n  }\n\n  // callback to add a new todo\n  const addTodo = (todo) =\u003e {\n    const newTodos = [...todos, todo]\n    setTodos(newTodos)\n  }\n\n  return (\n    \u003cAppContainer\u003e\n      \u003ch1\u003etodos\u003c/h1\u003e\n      {todos.map((item, i) =\u003e \u003cTodoItem\n        key={i}\n        name={item}\n        deleteCallback={() =\u003e deleteTodo(i)}\n      /\u003e)}\n      \u003cTodoForm addCallback={addTodo} /\u003e\n    \u003c/AppContainer\u003e\n  )\n}\n```\n\n### Finished App\nAnd with that, you've finished your first React application! To recap, you've learned\n\n1. What React is\n2. How React works\n3. The React Component Lifecycle\n4. React Hooks\n5. and much more!\n\nHopefully this leaves you in a really good position to becoming more comfortable with React. I'll link a few more resources that I personally found really helpful in my understanding of React.\n\n* [A [re]introduction to JavaScript](https://developer.mozilla.org/en-US/docs/Web/JavaScript/A_re-introduction_to_JavaScript)\n* [React in 100 seconds by Fireship.io](https://www.youtube.com/watch?v=Tn6-PIqc4UM)\n* [Official Intro to React](https://reactjs.org/tutorial/tutorial.html)\n* [React Intro to Hooks](https://reactjs.org/docs/hooks-intro.html)\n* [10 React Hooks Explained by Fireship.io](https://www.youtube.com/watch?v=TNhaISOUy6Q)\n\n![Our working todo tracker!](/posts/images/react/todo-fin.gif)*Our working todo tracker!*\n\n```jsx\n// Full Code\nimport React, { useState } from 'react'\nimport styled from 'styled-components'\n\nconst AppContainer = styled.div`\n margin: 40vh 30vw;\n`\n\nconst TodoItemContainer = styled.div`\n  \u0026:hover \u003e p {\n    text-decoration: line-through;\n  }\n`\n\nfunction TodoItem(props) {\n  return (\n    \u003cTodoItemContainer onClick={props.deleteCallback}\u003e\n      \u003cp\u003e{props.name}\u003c/p\u003e\n    \u003c/TodoItemContainer\u003e\n  )\n}\n\nconst TodoInput = styled.input`\n  padding: 0.7em 0.5em;\n  border: 1px solid black;\n  border-radius: 4px;\n`\n\nfunction TodoForm(props) {\n  const [todo, setTodo] = useState(\"\")\n\n  const handleSubmit = (e) =\u003e {\n    e.preventDefault()\n    props.addCallback(todo)\n    setTodo(\"\")\n  }\n\n  return (\n    \u003cform onSubmit={handleSubmit}\u003e\n      \u003cTodoInput\n        type=\"text\"\n        placeholder=\"Add a new todo...\"\n        value={todo}\n        onChange={e =\u003e setTodo(e.target.value)}\n      /\u003e\n    \u003c/form\u003e\n  )\n}\n\nfunction App() {\n  const [todos, setTodos] = useState([\"do laundry\", \"finish homework\"])\n\n  const deleteTodo = (index) =\u003e {\n    const newTodos = [...todos]\n    newTodos.splice(index, 1)\n    setTodos(newTodos)\n  }\n\n  const addTodo = (todo) =\u003e {\n    const newTodos = [...todos, todo]\n    setTodos(newTodos)\n  }\n\n  return (\n    \u003cAppContainer\u003e\n      \u003ch1\u003etodos\u003c/h1\u003e\n      {todos.map((item, i) =\u003e \u003cTodoItem\n        key={i}\n        name={item}\n        deleteCallback={() =\u003e deleteTodo(i)}\n      /\u003e)}\n      \u003cTodoForm addCallback={addTodo} /\u003e\n    \u003c/AppContainer\u003e\n  )\n}\n\nexport default App\n```","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/posts/reflect":{"title":"reflect: NLP Model Explained","content":"\n![An image of the reflect block page](https://miro.medium.com/max/1400/1*yjCs2Mmcve8wNI1pdfXelw.png)*How do we tell that this is a “valid” intent?*\n\nA (not so) brief exploration of how we tackle classifying intents in reflect. Part 1 will touch on defining the problem we’re trying to solve, the data we have, and how we pre-processed it. Part 2 will focus on the architecture of the model we built, how well it does, and thoughts on improving it for the future.\n\n## The problem\n\nClassifying intents is at the core of reflect. When a user inputs an intent, its reflect’s job to figure out whether that intent should let them into the website.\n\n\u003e How do we make sure “do some marketing work for reflect” is classified as productive but “watch cute dog videos” isn’t?\n\n## Why it’s so difficult\n\nA lot of it comes down to the fact that natural language processing ([[thoughts/NLP|NLP]]) is a very difficult task. What does the sentence “learn about physics” mean, and how is it semantically different from “asdflkj I can’t do work”?\n\nWe can’t just parse for keywords and just allow a user in if we see the word “work” because that word can mean different things in different contexts. For example, “I’m not doing any work right now” would have otherwise been classified as valid. Thus, we can employ the help of a machine learning algorithm to help us capture this deeper meaning.\n\nSpecifically, the form of machine learning we will be using is called **supervised learning,** in which we give an algorithm a bunch of labelled data, tell it what it’s doing wrong, and let it ‘learn.’ Through doing this, hopefully the algorithm will be able to generalize and make predictions on unseen data too.\n\n## The data\n\nOf course, if we want to perform supervised learning, we’re going to need a lot of data. Where are we going to get all of it? Luckily, we were able to get it through 3 different sources.\n\n### Survey data (444 entries)\n\nOur team sent out an interest survey in early January in which we asked 3 questions:\n\n1. How would you answer if you were trying to visit a distracting site while trying to focus? (eg. youtube, facebook, etc)\n\n1. How would you answer if you were trying to visit a distracting site to take a quick break from your work? (eg. youtube, facebook, etc)\n\n1. How would you answer if you were trying to visit a distracting site like Facebook but to do work? (e.g. make a marketing post)\n\nWe used these answers to form the basis of our very first dataset. We ended up getting a surprising amount of entries, ending with 148 responses to 3 questions and totalling 444 different observations. Here’s what some of that data looks like after tidying it up:\n\n\u003e We classified any answer to Q1 as invalid and Q2 + Q3 as valid\n\n\n| intent | valid |\n|-|-|\n| I am watching a 5 minute video to take my mind off not being productive :/ | no |\n| I'm just bored | no |\n| I’m bored/tired and trying to relax | no |\n| ... | ... |\n| work is pretty boring, i need to take a quick break I just can't focus atm | yes |\n| I finished all my work for today so I'm going to take a break now! | yes |\n| getting some advertising done for my club | yes |\n| I need to make a post on Twitter for my job announcing the latest update to our site | yes |\n| I'm trying to network | yes |\n| ... | ... |\n\n\n### Closed Beta (790 entries)\n\nAfter we made a basic dataset, we were able to make our first (admittedly not great) model. But in doing so, this let us create an MVP to which we could use to actually test with. We then deployed this model for use to our closed beta testers and collected their responses (with consent of course!) along with the website it was input on. This was then converted into a .csv file. A few examples are show below:\n\n| intent | url |\n|-|-|\n| to do some marketing | facebook.com/ |\n| i cannot focus on my work | instagram.com/ |\n| fuel my crippling social media addiction | facebook.com/ |\n| ... | ... |\n\nThese were then hand-labelled by our reflect team in a similar format as the survey data we collected earlier.\n\n| intent | valid |\n|-|-|\n| to do some marketing | yes |\n| i cannot focus on my work | no |\n| fuel my crippling social media addiction | no |\n| ... | ... |\n\n### Closed Beta Corrections (37 entries)\n\nFinally, we created a Google Forms through which we directly asked beta testers if a decision made by reflect’s intent classifier was faulty. Specifically, we asked what they input, and what they expected. Here are a few examples:\n\n\n| input | valid |\n|-|-|\n| reply to a friend about a lab | yes |\n| listening to a youtube music playlist | yes |\n| goof off as much as possible | yes |\n|...|...|\n\n\nThis entire section of the dataset was only 37 observations, but it drastically helped us reduce false positives and false negatives by focusing specifically on misclassifications.\n\nAfter aggregating and combing all our data into one common format, we ended up with a grand total of 1271 observations. They looked something like this:\n\n\n| input | expected |\n|-|-|\n| fail school by watching youtube | no |\n| sdlkjasd | no |\n| making a quick product post (should take \u003c10 min) | yes |\n| ... | ... |\n\n\n### So?\n\nNow that we have the data, can we just throw it into a machine learning model? Unfortunately, the answer is no, not quite yet.\n\n## Data augmentation\n\nOur dataset is still pretty small, even after aggregating all of our data. It most definitely doesn’t cover all of our bases for all the possible things that future users could possibly input. So, how can we “upsample” our data to get more of it? Well, it turns out that the field of Natural Language Processing has quite a few tricks to augment our data.\n\n### Sentence Variation\n\nEssentially what sentence variation is, is just replacing a few words of given sentences with their synonyms. If we have a sentence like “I’m trying to make a marketing post,” we can swap out singular words with their synonyms and tell our network that it means the same thing.\n\nIn this example, we could get something like “I’m attempting to fabricate a marketing post”. Adding these additional sentence variations will allow our machine learning model to learn semantic relationships between similar words (e.g. fabricate and make have similar meaning)\n\n### Sentence Negation\n\nAdditionally, if we add a ‘not’ in the sentence, it should flip the meaning of the sentence. An example would be “learning about physics” is valid, whereas “not learning about physics” is not. However, if the sentence already contains ‘not’ (e.g. “I’m not being productive”), adding another ‘not’ would make the sentence too complex and obfuscated, so we just label it as invalid. In essence, we just add ‘not’ to a bunch of sentences and label them as invalid. This helps us to combat intents which use negations in a sort of round-a-bout way to confuse the algorithm.\n\n### Shuffled Sentences\n\nIf we take an existing, valid sentence and completely shuffle the words, the resulting sentence should be invalid. An example would be “to watch a crash course video*” should be valid whereas “video course a watch crash to*” should be invalid. Basically, we’re just shuffling existing sentences and also labelling them as invalid. This helps us to combat intents which grammatically make no sense, but are otherwise valid.\n\n### Garbage Sentences\n\nWe can also take completely random words from the English language and put them together. The resulting sentences should all be invalid. For example, “*untinkered phalangitis shaly quinovic dish spadiciflorous unshaved” *clearly makes no sense. However, the addition of these gibberish sentences allows our model to be more robust against foreign words and out-of-vocabulary terms.\n\n### Vocabulary-mix Sentences\n\nLast but definitely not least, we can take the most common words in our dataset and mash them together. This should yield us a bunch of sentences which contain “key words” but should be marked as invalid because the context in which they are used makes no sense. For example, “video look watching” and “get research facebook take need want need message watch” are both clearly gibberish sentences, but they have a lot of keywords that one would think would let you in (e.g. video, research, watching, etc.). This lets us be more robust against those who try to get around the algorithm using keywords.\n\n## Data preprocessing\n\nWhat about now? Can we throw it into the neural network yet? Well, no. We may have increased the amount of data we have to work with, but we also need to convert it to a form that is easy to understand for both the computer and for our algorithm. We do that with a series of functions that we apply on our data.\n\n### Strip punctuation\n\nAs the name suggests, we remove all punctuation from the input phrase. We found that including the punctuation hurt our performance, most likely due to the fact that they offer very little in terms of semantic meaning and obfuscate the real meaning of the sentence.\n\n```python\nstripPunctuation(\"I don't know if I'm being productive! :(\") \n\u003e \"I dont know if Im being productive\"\n```\n\n### Make everything lowercase\n\nAdditionally, we found that in this particular setting, capital letters also didn’t matter that much. Because of the nature we collect our data (just a simple textbox), users tend to not bother with capitalization. As such, we remove it to make it consistent across our data.\n\n```python\nlower(\"I dont know if Im being productive\")\n\u003e \"i dont know if im being productive\"\n```\n\n### Expand contractions\n\nThe English language does this weird thing where we can just smush two words together (e.g. “I am” to “I’m”). Unfortunately for us, these produce extra complexity in our model that we could reduce by making them all consistent. In our case, we chose to expand all of these contractions.\n\n```python\nexpandContractions(\"i dont know if im being productive\") \n\u003e \"i do not know if i am being productive\"\n```\n\n### Remove stop words\n\nThe English language also has a bunch of these things called **stop words** — words that do not contribute anything major to the sentence in terms of semantic understanding (usually in the context of natural language tasks such as this). A few examples of them are ‘I’, ‘me’, ‘my’, ‘by’, and ‘on’. By removing them, we once again remove unneeded complexity from the model.\n\n```python\nrmStopwords(\"i do not know if i am being productive\") \n\u003e \"not know productive\"\n```\n\n### Tokenization\n\nHowever, these words are not super friendly for machine learning algorithms who would much rather deal with integers and floating point numbers than words and sentences. How do we fix this?\n\nWell, one thing we can do is turn words in indices by how often they appear, capped at the most common 1000 words — in essence, creating a vocabulary list mapping common words to numbers. For example, if “the” is the most common word, we convert it to 1. If “work” is the 8th most common word, we convert it to 8. For anything that isn’t in the top 1000, we give it the value of 0.\n\n```python\ntokenize(\"not know productive\") \n\u003e [12, 35, 7]\n```\n\n### Fixed sequence length\n\nFinally, we need to ensure that all the inputs are the same length of simplicity sake. If we were to handle dynamic length inputs, it would introduce a whole other level of complexity that we’re really not ready to deal with. As such, we can make sure all the inputs are the same length by adding a bunch of zeros to those who are too short (zero padding) or by slicing those who are too long.\n\n```python\npad([12, 35, 7], 10) \n\u003e [0, 0, 0, 0, 0, 0, 0, 12, 35, 7]\n```\n\n### Finally\n\nAfter all of these functions have been applied, we have successfully converted a complex sentence into a series of ‘tokens’ that is easy to understand for the machine learning algorithm.\n\n```python\npreprocess(\"I don’t know if I’m being productive! :(\")\n\u003e [0, 0, 0, 0, 0, 0, 0, 12, 35, 7]\n```\n\n## What’s next?\n\nNow that we have something ready to feed into our neural network, let’s dive into how the actual model itself works! How do we tell that this is a “valid” intent?\n\n## The model\n\nThe type of neural network that we’ll be using is called Long Short-Term Memory ([[thoughts/LSTM|LSTM]]).\n\n![credit: Christopher Olah, 2015](https://cdn-images-1.medium.com/max/4000/0*HyoZq6fOfsnn2YOC)*credit: Christopher Olah, 2015*\n\nWhat’s so special about these networks is that they are really good at modelling time-series data, making it an ideal candidate for tasks like forecasting or natural language processing.\n\n```python\n# Function to create a RNN model with given parameters\n# max_seq_len: maximum token sequence length\n# vocab_size:  size of tokenizer vocabulary\ndef RNN(max_seq_len, vocab_size):\n    inputs = Input(name='inputs', shape=[max_seq_len])\n    layer = Embedding(vocab_size, 64, input_length=max_seq_len)(inputs)\n    layer = LSTM(64, return_sequences = True)(layer)\n    layer = Dropout(0.5)(layer)\n    layer = LSTM(64)(layer)\n    layer = Dense(256, name='FC1')(layer)\n    layer = Dropout(0.5)(layer)\n    layer = Dense(1, name='out_layer')(layer)\n    layer = Activation('sigmoid')(layer)\n    model = Model(inputs=inputs, outputs=layer)\n    return model\n```\n\nHere’s how we define it in our [Keras code](https://github.com/jackyzha0/reflect-nlp/blob/master/nlp/net.py), don’t worry if you don’t understand it just yet! We’ll explain it in the next few paragraphs.\n\n```python\ninputs = Input(name='inputs', shape=[max_seq_len])\n```\n\nRight off the bat, you’ll notice that the first layer is the Input layer. Basically, this tells Keras to instantiate a new tensor (a multi-dimensional vector) with a given shape. In this case, we’re creating a one-dimensional tensor that is max_seq_len units long. When we trained our model, this was set to 75.\n\n```python\nlayer = Embedding(vocab_size, 64, input_length=max_seq_len)(inputs)\n```\n\nNext up, we have the Embedding layer. We could get into a really technical discussion about what this really does, but you can think of it as a layer that helps the neural network to learn semantic relationships between inputs.\n\n![credit: Rutger Ruizendaal, 2017](https://cdn-images-1.medium.com/max/3010/0*YOZ_CfmtgpUbJ9BD)*credit: Rutger Ruizendaal, 2017*\n\nEssentially, it embeds tokens in a [[thoughts/latent-factor model|higher dimension vector space]], where distance between tokens represents its similarity.\n\n```python\nlayer = LSTM(64, return_sequences = True)(layer)\n```\n\nNow, we get into the meat of the neural network: the LSTM layer. As stated before, these LSTM networks are really good at modelling time series data like language. In this case, our LSTM network has 64 hidden units per cell, and that we’d like to pass these hidden states to the next layer. If you’d like to learn more about the inner workings of the LSTM model, theres a really good resource [here](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)!\n\n```python\nlayer = Dropout(0.5)(layer)\n```\n\nNext, you’ll notice there are a few Dropout layers. These layers help to prevent overfitting by randomly killing off connections between the two layers (a sort of regularization). This makes sure neurons aren’t just “memorizing” the input data. This is especially important because our dataset is relatively small (~2000 observations even after augmentation), so making sure that our machine learning model can generalize outside of this limited dataset is really important.\n\n```python\nlayer = LSTM(64)(layer)\n```\n\nWe have yet another LSTM layer! By having these two chained right after each other, the first layer can pass all the values of all of its hidden states to the second layer, effectively allowing a sort of ‘deeper’ neural network.\n\n![credit: Jianjing Zhang 2018](https://cdn-images-1.medium.com/max/2000/0*0BRdnA5sJBYbaeR9)*credit: Jianjing Zhang 2018*\n\nThis deep LSTM allows our network to learn more abstract concepts, making them well suited for natural language tasks.\n\n```python\nlayer = Dense(256, name='FC1')(layer)\n```\n\nNext, we have something called a Fully Connected layer, or a Dense layer. In a dense layer, each of the input neurons is connected to every output neuron. This kind of ‘glue’ layer helps the network to pick out and discriminate feature output by our previous LSTM layer.\n\n```python\nlayer = Dense(1, name='out_layer')(layer)\nlayer = Activation('sigmoid')(layer)\n```\n\nSimilarly, we have one final Dense layer that ‘compresses’ all of the hidden units down to one neuron. However, we want the output value of this neuron to be how confident from a scale of 0 to 1 it is that the intent is valid. We do this by applying something called an activation function.\n\n![A sigmoid activation function](https://cdn-images-1.medium.com/max/2000/0*kdowh3GOGOUvGBr0)\n\nIn this case, the particular function we chose is the sigmoid activation function, which looks something like the above.\n\n### Model Overview\n\nPhew, finally got through everything! After putting it all together, we end up with a network that looks something like this:\n\n```python\n# 75 max_seq_len\n# 1000 tokenizer_vocab_size\nmodel = net.RNN(75, 1000) \nmodel.summary()\n\n# _________________________________________________________________\n# Layer (type)                 Output Shape              Param #   \n# =================================================================\n# inputs (InputLayer)          (None, 75)                0         \n# _________________________________________________________________\n# embedding_1 (Embedding)      (None, 75, 64)            64000     \n# _________________________________________________________________\n# lstm_1 (LSTM)                (None, 75, 64)            33024     \n# _________________________________________________________________\n# dropout_1 (Dropout)          (None, 75, 64)            0         \n# _________________________________________________________________\n# lstm_2 (LSTM)                (None, 64)                33024     \n# _________________________________________________________________\n# FC1 (Dense)                  (None, 256)               16640     \n# _________________________________________________________________\n# dropout_2 (Dropout)          (None, 256)               0         \n# _________________________________________________________________\n# out_layer (Dense)            (None, 1)                 257       \n# _________________________________________________________________\n# activation_1 (Activation)    (None, 1)                 0         \n# =================================================================\n# Total params: 146,945\n# Trainable params: 146,945\n# Non-trainable params: 0\n# _________________________________________________________________\n```\n\nTheres a grand total of 150,000 different trainable knobs and parameters in our neural network!\n\n## Training pipeline\n\nSo, how does the data we got earlier play a role in helping our machine learning model learn and improve?\n\nThe first component is the **loss function.** This component tells the neural network how ‘correct’ its prediction was. In this model, we will use something called [binary cross entropy](https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a), which is basically a fancy word for log-based error. If the true label is 1, we can then show what the log-loss would be for some given prediction probability.\n\n![](https://cdn-images-1.medium.com/max/2000/0*8rd4ho_3Y6zrtra-.png)\n\nNext, we need to pick an **optimizer**. This component tells the neural network how to change its parameters to improve or ‘optimize’ itself. In this model, we chose to use an optimizer called [RMSProp](https://towardsdatascience.com/understanding-rmsprop-faster-neural-network-learning-62e116fcf29a) with a learning rate of 1e-3 . We aren’t going to cover all the technical details of this optimizer in this blog post, but just know that it is a very fast and effective optimizer.\n\n![RMSProp(black) vs a bunch of other optimizers. credit: Vitaly Bushaev](https://cdn-images-1.medium.com/max/2000/0*HZM5XJ-quu276w39.gif)*RMSProp(black) vs a bunch of other optimizers. credit: Vitaly Bushaev*\n\nOne important hyperparameter we choose is the **train-test split.** In data science and machine learning, we typically withhold part of our data and set it aside as a **test set**. The rest of the data will be considered the **training set.** When training the model, we never feed it the test set. As a result, we can use the test set as a metric to see how well it would perform on real-world, unseen data. In our training, we used a train-test split of 20%.\n\nAnother important hyperparameter that we can choose is the **mini-batch size**. The mini-batch size determines how many training examples we feed the machine learning model before updating its parameters. A smaller mini-batch means that we get more frequent updates to the parameters, but it also runs the risk of having outliers that may cause a bad gradient update. A large mini-batch means that we get a more accurate gradient update but it also takes longer. A similar concept is *sample size* in statistics. We could pick a larger sample to get a better estimate of the overall population, but it is often more expensive to do so. A smaller sample might contain outliers and thus be less robust of an estimate of the overall population, but it very easy to do. So, there’s this tradeoff between accuracy and speed. We found that a good balance between these was a mini-batch size of 128.\n\nWe then trained our neural network over 10 epochs. A single epoch is one iteration over the entire dataset. If we train it for too many epochs, you run the risk of overfitting (memorizing the training data), but we don’t train it enough, we run the risk of not discovering a better model. One thing we can do it minimize this problem is through the use of cross-validation, which is a technique that lets us ‘test’ on portions of the training set. Essentially, at each iteration during training, we withhold a portion of the training set and use it as a sort of ‘validation’.\n\n![credit: Raheel Shaikh](https://cdn-images-1.medium.com/max/2000/0*6XoMgZUd3SxXgqBj.png)*credit: Raheel Shaikh*\n\nBy seeing when this validation accuracy goes down, we can get a pretty good idea of when our model begins to overfit on our data, and stop the training before this happens. In training our model, we will use 5-fold [cross-validation](https://towardsdatascience.com/cross-validation-explained-evaluating-estimator-performance-e51e5430ff85).\n\nAfter all of this, we end with a training accuracy of 93.60% and test accuracy of 85.95%. Not bad at all!\n\n## Serving the model\n\nGreat! So now we have a trained model. Can we put that in the Chrome extension now? Not quite yet…\n\nOur model was written and trained with Keras (a Python Deep Learning library). Our Chrome extension is written in TypeScript. How do we get these two to work together?\n\nLuckily for us, Tensorflow.js exists! This library allows us to run Tensorflow models from within JavaScript. Tensorflow has released a script that lets us to convert a Keras model into something that Tensorflow.js understands, so we can run that to convert our models.\n\nHowever, we can’t just directly plug-and-play. You may remember that we did all of that data preprocessing before we trained our model. Tensorflow.js doesn’t have any of this built in, so we made our own implementation of it. You can check it out [here](https://github.com/jackyzha0/reflect-chrome/blob/master/src/nn.ts).\n\nWe’ll leave all the technical code out (if you’re interested, feel free to peek around the source code!), but we’ve abstracted it enough that classifying an intent is a breeze.\n\n```typescript\n// declared somewhere earlier\nconst model: nn.IntentClassifier = new nn.IntentClassifier(\"acc85.95\"); // name of converted model\n\n// send to nlp model for prediction\nconst valid: boolean = await model.predict(intent);\nif (valid) {\n    // let through\n} else {\n    // block page\n}\n```\n\n## Future improvement\n\n### Possible models\n\nWe have thought about using something more established and complex like [BERT](https://arxiv.org/abs/1810.04805) and retraining it on our dataset, however then comes the problem of runtime and memory usage.\n\nBERT is a huge model. If you thought 150 thousand parameters was a lot, wait till you see BERT’s 110 *million* parameters. This bad boy takes a few hundred times longer and many times more memory than our current model. While yes BERT may perform really well, we just don’t think it has a place inside of a Chrome extension.\n\nOur model is decently robust as it is, especially considering the entire model is \u003c2MB and takes less than 200ms to run in browser. For now, we will stick with lightweight models, but we may switch if we find a better match in the future :)\n\n### Misclassifications\n\nOf course, this algorithm isn’t perfect. It does have a lot of flaws and weaknesses that we find every day, and we’re working to fix those! If there are any misclassifications that you find in the algorithm, we love to hear about it on our feedback form: [https://forms.gle/ctypb6FmDT9RQqjv6](https://forms.gle/ctypb6FmDT9RQqjv6).\n\n## Closing\n\nThis NLP model is at the core of reflect. It is this model’s goal to predict whether user intents are valid or not. As a result, we need to make sure this algorithm is accurate, fast, and lightweight. Hopefully, through this blog post, you’ve learned a little about how we went about building a model to fulfill those requirements.\n\nLearn more about us on our website! ✨ [http://getreflect.app/](http://getreflect.app/)\n\nIf you have any further questions about reflect or this NLP model, feel free to shoot us an email at hello@getreflect.app","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/posts/the-fools-who-dream":{"title":"Here's to the fools who dream","content":"\n![[thoughts/images/IMG_2146.jpg]]\n\n*Alternatively: A hitchhiker's guide to independent research*\n\n\u003e *Here's to the ones who dream*  \n\u003e *Foolish as they may seem*  \n\u003e \n\u003e *She told me*  \n\u003e *\"A bit of madness is key*  \n\u003e *To give us new colors to see*  \n\u003e *Who knows where it will lead us?*  \n\u003e *And that's why they need us\"*\n\u003e \n\u003e La La Land - \"Audition (the fools who dream)\"\n\nA year ago, I wrote myself a [[posts/2021|letter]]. In it, I told myself that if I ever found an idea I had high conviction in, I would drop everything to give it a fair shot. I hoped that I would be ambitious in my dreams and to embody a [quiet confidence](https://www.spencerchang.me/experiments/100posts/quiet-confidence/) in my own abilities and interests.\n\n[[thoughts/Rhizome Proposal|Rhizome]] turned out to be project that would let me do all of that. I spent this past summer doing independent research focused on how we can enable [[posts/towards-data-neutrality|data neutrality]] on a web dominated by data moats. I had no academic research experience, barely knew anything about distributed systems, and didn't personally know anyone else doing independent research. At the time, I had no idea this was even *called* independent research.\n\nI'm not sure what about it drew me in exactly. The project started out with a smattering of thoughts around peer-to-peer networking and what I found frustrating about it. Yet, the project took up latent headspace, simmering away quietly only to surface mid-scrub in the shower or on a walk to the bus stop. \n\nI knew that 'good' research practice usually involved writing a detailed research statement or proposal to present exactly what one would work on. I also knew that I had no clue how I would manifest the stirring pot of concepts into something legible. I spent the months leading up to summer bumping around in the dark, trying to phrase and form what exactly about this interested me so much. In my head it felt clear, but each time I tried to force those ideas through my fingers and onto the page they seemed to flit away and vanish, refusing to be expressed in any precise form.\n\nAt the time, this felt like useless floundering. After all, what kind of researcher doesn't even know what they're researching?  Later on, I would find that this floundering was sense-making hard at work. Researching to figure out what you are researching... is still research. There is a certain amount of looking around and orienting yourself you need to do before you know what direction to head. I spent hours cautiously broaching the idea with friends over late night transit rides home. In most of those conversations, my friends nodded blankly, happy to see me obviously deeply invested into an idea but not really understanding what I was blabbing on about.\n\nIn these early days, I was often dejected. I felt incredibly foolish for pursuing something I had absolutely no reason to be so deeply invested in, and I felt foolish that I couldn't explain *why* it felt so compelling to me. I felt terrible about my inability to get any grant money to sustainably work on this project. I felt a deep need to *prove myself*. Maybe it was to prove to myself that I wasn't wasting my time. Maybe it was to prove to others around me that I was doing something just as valid as their internships, startups, or academic research.\n\nOver the span of a month period, I had 3 separate emotional breakdowns \n1. On May 11th: \"I can't help but sometimes feel like I'm wasting my time -- there are so many smart people working on the same problem, what makes me feel like I can be the one to make a meaningful contribution to it?\"\n2. On May 16th: \"I'm often spending 12+ hour days writing grants and I just feel so behind. And I don't get why!!!! I've been looking forward to this summer for so long.\"\n3. On May 27th: \"Once again had a breakdown :)) Constantly feel like I'm not doing enough and that time is slipping between my fingertips...\"\n\nI was in the middle of the midwit bellcurve. When I started with the project, I had a healthy dose of naivete, a belief that *anyone* could make a change and make their project work if they tried hard enough. But now, I started to believe that hard things are hard for a reason; I should leave hard problems to people who are actually skilled and have spent decades of their lives working on these problems. Who was I to think that I, an undergrad student who had still yet to take a distributed system course, would be able to contribute anything meaningful to this decades-old field?\n\nIn mid-conversation with someone who's opinion I cared deeply about, I realized that I strongly needed to figure out how to untie my self-worth from my project. \n\nMidsummer, on a whim, I picked up Annie Dillard's *[[thoughts/The Writing Life|The Writing Life]]*  from a local bookstore and read it cover to cover. In it, she mentions that the greatest teacher of writing is the blank page.\n\n\u003e Who will teach me to write? a reader wanted to know.\n\u003e \n\u003e The page, the page, that eternal blankness, the blankness of eternity which you cover slowly, affirming time’s scrawl as a right and your daring as necessity; the page, which you cover woodenly, ruining it, but asserting your freedom and power to act, acknowledging that you ruin everything you touch but touching it nevertheless, because acting is better than being here in mere opacity; the page, which you cover slowly with the crabbed thread of your gut; the page in the purity of its possibilities; the page of your death, against which you pit such flawed excellences as you can muster with all your life’s strength: that page will teach you to write.\n\nI think it was this lone paragraph that was the turning point where I started to believe that this applied to my work too.\n\nTo do independent research is to learn how to confront the infinite possibility of a blank canvas. To not be intimidated by the possibility of making a fool of yourself, but to embrace the courage to even put brush to canvas, pen to paper. **To assert your freedom and power to act.**\n\nThe midwit would think it truly silly to try and change something as entrenched in our society as the very computing fabric we tap into everyday. But those who do not submit to this status quo recognize there is merit to trying regardless. Octavia E. Butler gestures to this tension between optimism and pessimism, and the possibility of actually breaking through to something new:\n\n\u003e *There is nothing new*\n\u003e \n\u003e *under the sun,*\n\u003e \n\u003e *but there are new suns.*\n\u003e \n\u003e -- Octavia E. Butler, *Trickster*\n\nThe less beaten path is often less beaten for a reason. But if it feels right to take it -- pushing aside the debris and brush and walk the trail because something, a bird or perhaps a ray of light, caught your eye -- then take it. \n\nThis realization dawned on me slowly for me over the span of about a month. I wasn't pursuing it because society deemed my research useful or that I knew it would eventually make me heaps of money or make me incredibly famous. At the end of the day, it was enough that this research is something that I *wanted* to spend time pursuing.\n\n![[posts/images/play/agency.png]]\n\n\u003e People will impose their limiting beliefs onto your world because it’s what governs theirs. They will tell you to stay in something you want to leave, will tell you to keep pushing toward something that feels wrong, feels misaligned. You always have a choice. You can yield to expectation, pessimism, set structures, or [you can take the other path].\n\u003e \n\u003e -- Nicole, [*internal confidence*](https://nicoles.substack.com/p/internal-confidence)\n\nI didn't need to prove to anyone that what I painted on this metaphorical canvas was 'worth' the space that it took up. Instead of claiming to be some sort of expert who had all the requisite skills and knowledge, I began to see myself as an explorer, excited to share what I found with others. I let more people in to see what I was working on because I was excited to share what I found rather than afraid of what they thought of what I knew.\n\nIn early June, I had my first call with people who were as equally excited about the idea as I was. I saw seasoned veterans who have worked decades on related problems ask careful questions and gave my ideas serious consideration.  These people who I had thought would likely shun or ridicule my pursuit turned instead to close collaborators and thought partners. This was refreshing. I was no longer pursuing it alone but also sharing this vision with others, seeing their eyes light up at the potential or future of it.\n\nI found it invaluable to surround myself with people like this. I lived with others who were also incredibly intellectually curious about the world. They would ask \"tell me more\" instead of offering blank stares of ambivalence. Their close consideration and generous imagination enabled my work to truly blossom.\n\n---\n\nWhen people ask about where I am working this summer, I often laugh and reply \"I'm 'funemployed'! But  what I'm *really* doing is independent research.\"\n\nNine times out of ten, the follow up question they ask is \"With who?\" Usually, I laugh again and say that \"that's the fun part about independent research, I get to do it on my own!\"\n\n\u003e These days, if you say you work in research, most people assume you work in academia. But it’s sort of odd that we assume you need someone’s permission to do research. There’s no reason that universities need to be the gatekeepers of exploring and developing new ideas.\n\u003e \n\u003e Nadia Asparouhova, *[The independent researcher](https://nadia.xyz/independent-research)*\n\nWhat I often find gets confusing for people is that **independent research doesn't mean I do it by myself**. Rather, it refers to how my work is not tied to any particular institution. I think the whole career advice of doing internships at big companies and academic research being the two main options is incredibly flawed. Neither leaves much space for individuals to have time or space to figure out what they *actually* want to do with their life. Neither leaves space for individual sense-making.\n\nEvery few months, I'll get an email or two along the lines of: \"Help, I'm stuck in Leetcode hell, how do I escape and do other things?\" I love these emails because I know these are people who have started that introspection process, an internal questioning of \"what do I *actually* care about and why?\" and are looking for containers and institutions for their work.\n\nSooner or later, that line of questioning leads to a question of hypothetical [[thoughts/utopia|utopia]]. In a world where you don't need to work to stay alive, what would you do? What gives you excitement and joy? Completely ignoring what other people tell you is useful or good, what do you find intrinsically beautiful and good to do in the world?\n\nTo most, the answer as to what they want is clear but the difficult question is *how*. Having dreams and working to make them a reality is a privilege in this world. I truly think it’s one of the greatest gifts of life but unfortunately not a gift very many get to have.\n\nHow might we create spaces for abundance so that more people have this sort of privilege? Édouard Glissant's *[[thoughts/Archipelago|Archipelago]]* gives a glimpse into a \"future [which] lies not with the great powers, but with the little islands, lands, and cities.\" Not all research needs to happen within the monolithic institutions in [[thoughts/academia|academia]] or profit-hungry companies. Perhaps the next generation of innovation and discoveries that advance society will be made through [[thoughts/tribe flourishing|small squads]] banding together to build things, live together, and create something more intricate, comprehensive, and wonderful than any one individual could have achieved on their own.\n\n\u003e Benjamin Franklin had the Junto Club, Tolkien and C.S. Lewis had The Inklings, Jobs and Wozniak had Homebrew. The Bloomsbury Group was integral to the success of Virginia Woolf, Clive Bell, and John Maynard Keynes, while MIT’s Model Railroad Club spawned much of modern hacker culture.\n\u003e \n\u003e -- James Mulholland, *[Small Group](https://jmulholland.com/small-group/)*\n\n---\n\nTo those who don't take this path -- parents included -- what I'm doing seems a little foolish. But that's not necessarily a bad thing. The fool is often characterized as naive, a beggar, a hedonist. But the fool is also many other things that more people should be.\n\nThe fool is the [[thoughts/Jestermaxxing|jester]], daring to challenge what other people wouldn't. The fool is the blazer of new trails, happily taking the less beaten path because he does not know better. The fool is the one who does things because they think it is worth doing, not for coin or status. \n\n![[thoughts/images/the fool.png|200]]\n\nI leave this as an invitation to you. Ask yourself: \"what do you *really* want?\" Be honest with yourself. Get your hopes up a little bit; let yourself be a little foolish.\n\n\u003e I know I'm naive; I'm a dreamer. But maybe we should get our hopes up for things sometimes. Maybe we shouldn't dampen how we feel to avoid the possibility of disappointment. Maybe we should hope for and demand everything—ask for the world, the stars, and the ever-expanding universe for ourselves. Maybe naïveté is how we keep imagining in vivid colors, connecting with rich feelings, dreaming of diverse characters.\n\u003e \n\u003e -- Spencer Chang, *[quarter life commitment](https://spencerchang.substack.com/p/quarter-life-commitment?s=r)*\n\n---\n\n## Acknowledgements\nIt is with the generosity of my sponsors of GitHub, close friends, and you, kind reader, that I'm able to continue to do this type of work.\n\nThank you to Anson Yu, Spencer Chang, Sebastien Zany, Jamie Wang, Raymond Zhong, Vincent Huang, Justin Glibert, Morgan Gallant, Ryan Johnson, David Zhou, Aadil Ali, JZ, Nishant Medicharla, Anh Pham, Farzaa Majeed, Amir Bolous, Aaron Pham, Rishi Kothari, Jasmine Sun, and Athena Leong for your continued support. This independent research wouldn't be possible without all of you.","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/posts/towards-data-neutrality":{"title":"Towards Data Neutrality","content":"\n\u003e This essay was originally published in [Reboot](https://reboothq.substack.com/p/rhizome).\n\n*DISCLAIMER: To borrow words from [Robin Sloan](https://www.robinsloan.com/lab/specifying-spring-83/): While it is okay to share this link, I want to underscore that I am sending it specifically to you with the hope that you will really think about it! At such a primordial stage, a proposal like this doesn’t need diffuse, drive-by attention. It needs, instead, close consideration and generous imagination.*\n\nThe competitive advantage of the vast majority of today's centralized platforms are in their data moats and network effects. Services like Facebook, Twitter, and Reddit conceptually aren't difficult to replicate -- in fact, your average computer science graduate could probably recreate the functionality of these apps without much difficulty. Rather, the major reason why these platforms remain so dominant is because of their data and users: Facebook has all of our childhood friends, Twitter is the go-to place for unhinged humour and political discourse, and Reddit has millions of niche micro-communities found nowhere else on the internet.\n\nThese platforms, especially aggregators, are *incentivized* to resist [[thoughts/decentralization|decentralization]] and [[thoughts/interoperability|interoperability]]. After all, 'data is the new oil'. These services almost entirely depend on making sure that only they have access to that valuable data. Interoperability, on the other hand, means you no longer have a data moat, or a privileged hub position in the network.\n\n![[thoughts/images/platforms as old oil rigs.png]]\n\nAs a result, apps have become inseparable from data. They are extractive, asking for ever-increasing access to our personal lives. We willingly sign over the ability to control our data, blindly scrolling miles and miles of Terms of Service Agreements because we know that at the end of the day, we have no power to change what they want from us. You can't choose what parts you like; you either use the platform and sign all of your rights to them, or don't use it at all. [[thoughts/privacy|Privacy]] and security in this world mostly means \"which company do you trust with your safety?\" The answer often is the one with the largest walls and deepest moats.\n\n![[thoughts/images/data moat.png]]\n\nClearly, this leaves much to be desired. We spend so much time online that it is worthwhile to explore better ways of existing online.\n\n## An Ideal World\nDecentralization is not the solution for everything but it has value in empowering people to act decisively within their social contexts[^1]. Decentralizing the Web means that people gain the ability to store their data wherever they want while still getting the services they need. **Decentralization is about agency**: we get choice about where we _store_ our data, who we give _access_ to which parts of that data, which _services_ we want on top of it, and how we _pay_ for those.\n\nIn an ideal world, instead of being forced to accept package deals we cannot customize, we get modular interoperable [[thoughts/local-first software|local-first software]][^2] which we can stack to a global scale. Apps and platforms in this model follow the Unix philosophy: expect the output of every program to become the input to another, as yet unknown, program. Like the Lego \"dot\" that is the universal connector between all Lego pieces, there exists a universal API that freely enables all software of this model to freely interoperate. With a universal API, each composition between each tool increases the total possible compositions and workflows by $n * (n-1)$, all without developers needing to write the transformations between each one.\n\nIn an ideal world, there is *data-neutrality*. Much like how the Net [[thoughts/neutrality|Neutrality]] debate strives to maintain the separation of the content and connectivity markets, data neutrality strives to maintain the separation of data and application markets. Our current market is competitive based on data ownership when it could be competitive based on service quality instead. If we conceive a decentralized approach as a way to enable data and platform neutrality, application platforms and data providers can mix and match, much like how you can browse the many websites of the web on any Internet provider.\n\nIn an ideal world, we focus on local-first software that works independently of large platforms -- at the end of the day **platforms should be used to support efficiency of collaboration at scale, not to gate users from moving their data for the sake of retention.**\n\n## Peer-to-peer\nPeer-to-peer technology has existed for a while and in theory, gets quite close to realizing this ideal world on its own. Federated open source software means anyone can run their own local instances and customize them to their liking. Organizations like the IETF and W3C work on standardizing open data formats to act as universal formats to store and convert between. Yet, most platforms do the minimum they need as required by law to maintain interoperability and data-neutrality. \n\nSo why does it fall short?\n\n### 1. Running your own infrastructure\n\n\u003e Even nerds do not want to run their own servers at this point. Even organizations building software full time do not want to run their own servers at this point. If there’s one thing I hope we’ve learned about the world, it’s that people do not want to run their own servers.\n\u003e \n\u003e Moxie in *My first impressions of Web3*[^3]\n\nRunning your own infrastructure and servers is hard. Maintenance and upkeep of your software is hard. There is a reason that companies which offered to do that for others were so successful.\n\nIf one company figured out a good way to do $x$, it was incentivized to offer doing $x$ as a service (hence the explosion of SAAS startups) instead of making it easy for competitors to do the same. Overtime, companies specialized at getting really good at doing $x$ and thus became known as the go-to people for that thing. This centralization-over-time of this knowledge leads to the monopolies that we see today.\n\nCentralizing this knowledge in open standards and public, forkable code rather than data moats and proprietary technology is a great start but it isn't enough if the general public doesn't know how to use it. Just as you wouldn't expect the average home owner to setup their internet connection, we shouldn't expect the average person to run their own infrastructure.\n\nIt should be easy for people to create competing yet interoperable platform providers and it should be easy for people to switch between platform providers as one can switch between internet providers today.\n\n### 2. Data availability and durability\nThe vast majority of peer-to-peer applications have yet to solve the data availability problem. In short, all connections are ephemeral -- there is no persistent state. Imagine if everybody you shared a Google Doc with had to be online at the same time everytime you wanted to edit it, or if all 3 billion users of Facebook all had to have the app open to even use it. Imagine if you had your Twitter account deleted every time you closed your browser window.\n\nThis means that *asynchronous collaboration isn't possible* in most peer-to-peer apps. Platforms usually get around this by storing the state of a user on one of their many servers who make it available on your behalf but peer-to-peer apps do not have this luxury -- most people do not have a device that is “always-on” like a server is.\n\n### 3. Existing network effects\nMigrating data off of existing platforms is extremely difficult as this is something large platforms are disincentivized from supporting. Even if there are 'export' tools on platforms, they are the worst they can be while still meeting [GDPR Requirements](https://gdpr-info.eu/art-20-gdpr/). New platforms almost never have 'import' tools because each platform has their own data format and that format changes unpredictably. This [creates a form of n-to-n problem](https://twitter.com/andy_matuschak/status/1452438198668328960) where every app needs to know what the APIs of another app are to even begin to interoperate. \n\n\u003e \"But usually you don't want a dead snapshot; you want to \"use this data elsewhere\"—which requires repeatedly exporting \u0026 reconciling.\"\n\u003e \n\u003e [Andy Matuschak on Twitter](https://twitter.com/andy_matuschak/status/1452438176996347907)\n\nThis means that, even if an alternative platform offers a better service, switching is often impossible.\n\nThe important question is: can applications on top of decentralized data **behave the same way as centralized apps**? Can we still aggregate information into feeds and present a cohesive user experience even if all of our friends' data is stored in different places?\n\n## Why not use blockchains?\nI admit that it is true that [[thoughts/blockchain|blockchain]] actually solves most of these problems. Blockchain approaches have great approaches to solving both identity and availability through a combination of wallet addresses and token [[thoughts/incentives|incentive]] mechanisms. Yet, they solve it in a way that leaves much to be desired.\n\nBlockchain causes a whole new set of problems that makes it quite cumbersome to build on top of it. Some of the core problems that I have personally seen include\n- Lack of ability to store large files on-chain in a cost-effective manner\n- Massively reduced speed and efficiency (the global Ethereum computer operates at roughly the speed of a Raspberry Pi)\n- High latency for transactions and finality (not to mention transaction + gas fees but I am assuming these will be negligible at some point down the line)\n\nAll of these make it incredibly unfeasible for data-intensive or real-time applications (e.g. file sharing, games, collaborative text editing) without *aggressive* application of blockchain scaling ideas. Of course, there are certain applications that benefit from the unique properties that blockchains possess (namely strong guarantees about consistency and message ordering among the presence of [[thoughts/Byzantine Faults|byzantine actors]]) that make it worthwhile for certain applications like cryptocurrencies, but for most applications these tradeoffs make it hard for end users to adopt.\n\nBlockchain is suitable for a very small subset of use-cases. Is there a more general purpose technology that still addresses these main problems?\n\n## The personal cloud\n**Rhizome** aims to be a data-persistence and identity layer for the distributed web. The goal of Rhizome is to enable *data-neutrality* by separating data from applications.\n\nIt is made up of two layers\n1. Root: a personal data pod that *you* own. Think iCloud or Dropbox but you have agency over how much storage you want, who has access to it, and what you want to do with it.\n2. Trunk: a framework for easily developing cohesive peer-to-peer applications on top of data from Root\n\nAs a whole, it forms the basis for a new model of the internet where first and foremost, people own their own data. This enables entirely new dimensions of computation and collaboration on the web.\n\n- Single purpose apps backed by general-purpose data[^4]. Apps in this new model are now just views on top of data rather than a tight coupling of data and logic. If two apps are views on the same data, any change to the underlying data will instantly update *both apps*.\n- Applications ask for access rather than store their own data. Instead of maintaining a separate log-in for each app, you give apps permission to read or write specific parts of your data.\n\t- Additionally, this means that existing platforms to relieve themselves of the impossible burden of being the steward of [[thoughts/Moderation|moderating]] what every person on their platform is doing.\n- Local-first means interaction times are measured in *microseconds* not seconds, resulting in more responsive-feeling applications and no loading spinners.\n- Two users can collaborate by simply 'inviting' another to temporarily synchronize a subset of their data. Developers no longer have to worry about building out separate infrastructure for live editing or collaboration.\n- As there are separate markets for data and applications, it creates competition based on service quality rather than on data ownership.\n\nWith Rhizome, we get the convenience of a single centralized platform without the lack of agency that comes with it.\n\nYou can find more technical details [[thoughts/Rhizome Proposal|in the proposal]], and rough notes from my day-to-day in my [[thoughts/Rhizome Research Log|research log]].\n\nI encourage you to imagine with me what a world like this could look like. I miss when we would dream of worlds to come, filled with exciting possibilities and hopeful futures. I love the concept of skyhooks: dream about what you can build as if the sky had hooks you could hang your creations from (a metaphor for unlimited resources) and most of the time, you can still create that with scarce resources.\n\nThink of this project as a [[thoughts/skyhooks|skyhook]]: a dream about a future so that we may build towards it.\n\n\u003e We live in capitalism, its power seems inescapable – but then, so did the divine right of kings. Any human power can be resisted and changed by human beings. Resistance and change often begin in art.\n\u003e \n\u003e (Ursula K. Le Guin)\n\n## Q \u0026 A\n**This proposal has seen a lot of evolution. How does this current version differ from your initial proposal? What shaped your ideas?** \n\nThe [early proposal](https://github.com/jackyzha0/jackyzha0.github.io/blob/bd194ffe671e6ff51b0d79f11a40aa595da17e7f/content/thoughts/Rhizome%20Research%20Proposal.md) contained very lofty goals for the future but I don’t think it critically thought about how to get there or why people would want a future like it. It had very scattered technical ideas and lacked conviction in the vision.\n\nI found it really odd that this type of technology has existed for a while but there were no widespread examples of usage. I spent about a month and a bit looking at retrospectives of peer-to-peer protocols and applications to get a good foundation for what’s been done and what hasn’t been done.\n\nThis literature review era led me to revise the proposal to go a lot more in-depth about the why of the research, placing heavier emphasis on adoption and why the average internet user should care. The internal metric I had was whether my Mom, who doesn’t work in technology and mostly uses the internet to look at articles, would be able to understand why what I was working on was important.\n\n**What’s something that surprised you in your work so far this summer?**\n\nPeople say independent research is a lonely journey. I disagree. I don’t think being independent means you need to do it alone. Rather, it means without being attached to any particular institution or label.\n\nI’ve been very surprised at just the number of people who have been thought partners, collaborators, and supporters throughout the whole process.\n\n**Rhizome is very much in early stages right now from a research perspective. Let’s say the research phase fully succeeds — what do you think would come next? What would it take for this to shape how individuals interact with the internet?** \n\nI honestly don’t think the technical part or the research will be the hard part of this project! Getting people to build on top of it and to imagine possible futures using this technology is the hard part.\n\nBuilding distributed systems and peer-to-peer tech shouldn’t require a PhD to do. I think a large part of the next step if research is successful is to build demo apps with _real users_ to show what’s possible with it.\n\nI want your average computer science student to be able to build apps for their friends and family using this. I want people to actively play with this new framework, this new mental model of computing, and then to build the apps they wish they could have themselves.\n\n[^1]: Divya Siddarth, Danielle Allen, E. Glen Weyl, *The Web3 Decentralization Debate is Focused on the Wrong Question* in Wired Magazine ([Source](https://www.wired.com/story/web3-blockchain-decentralization-governance/))\n[^2]: Martin Kleppmann, Adam Wiggins, Peter van Hardenberg, Mark McGranaghan, *Local-first software* in Ink \u0026 Switch ([Source](https://www.inkandswitch.com/local-first/))\n[^3]: Moxie Marlinspike, *My first impression of web3* ([Source](https://moxie.org/2022/01/07/web3-first-impressions.html))\n[^4]: Spencer Chang on [Twitter](https://twitter.com/spencerc99/status/1544420768137740288)","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/tags/PHIL240A/":{"title":"PHIL240A","content":"","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/tags/PHIL451A/":{"title":"PHIL451A","content":"","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/tags/evergreen/":{"title":"Evergreen","content":"","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/tags/fruit/":{"title":"Fruit","content":"","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/tags/personal/":{"title":"Personal","content":"\n","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/tags/rhizome/":{"title":"Rhizome","content":"","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/tags/sapling/":{"title":"Sapling","content":"","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/tags/seed/":{"title":"Seed","content":"\n","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/tags/technical/":{"title":"Technical","content":"","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/tags/writing/":{"title":"Writing","content":"\n","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/33-Impossibility-Result":{"title":"33% Impossibility Result","content":"\nIn general (assuming a partially-synchronous [[thoughts/system model|system model]]), a protocol can achieve [[thoughts/safety|safety]] all the time and additionally [[thoughts/liveness|liveness]] in synchronous conditions *if and only if* $n \\geq 3f + 1$ (equivalently, $f \u003c \\frac n 3$)\n\nThis result holds despite the assumption of [[thoughts/Public-key Infrastructure|PKI]] (unlike the [[thoughts/PSL-FLM Impossibility Result|PSL-FLM result]]), so this bound must be driven by the possibility of unbounded message delays.\n\nIntuition:\n1. We can't wait indefinitely for all nodes to respond (one valid strategy for Byzantine nodes is to never respond, even after GST) so realistically we can only wait to hear from $n - f$ nodes before deciding on the next possible action\n2. But we can't say for certain the $f$ nodes are actually Byzantine (they could be honest nodes that are congested), thus of the $n - f$ nodes, more than half should be honest, $f \u003c \\frac 1 2 (n -f)$ or equivalently $f \u003c \\frac n 3$","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/50-pounds-of-pots":{"title":"50 pounds of pots","content":"\n**Quantity is the journey to quality**\n\nThe ceramics teacher announced on opening day that he was dividing the class into two groups. All those on the left side of the studio, he said, would be graded solely on the quantity of work they produced, all those on the right solely on its quality. His procedure was simple: on the final day of class he would bring in his bathroom scales and weigh the work of the “quantity” group: fifty pound of pots rated an “A”, forty pounds a “B”, and so on. Those being graded on “quality”, however, needed to produce only one pot — albeit a perfect one — to get an “A”.\n\nWell, came grading time and a curious fact emerged: the works of highest quality were all produced by the group being graded for quantity. It seems that while the “quantity” group was busily churning out piles of work — and learning from their mistakes — the “quality” group had sat theorizing about perfection, and in the end had little more to show for their efforts than grandiose theories and a pile of dead clay.\n\n*From Art \u0026 Fear by David Bayles, Ted Orland*","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/A-Certain-Tendency-Of-The-Database-Community":{"title":"A Certain Tendency Of The Database Community","content":"\n[Source](https://arxiv.org/pdf/1510.08473.pdf)\n\n[[thoughts/distributed systems|Distributed Systems]] that provide “single system image” semantics (read: [[thoughts/consistency|linearizability]]) is fundamentally flawed and at odds with how systems operate in the physical world\n\n## There is no authoritative copy\n- Weaker consistency models that offer fewer guarantees about when the effect of an update might be observed by other members in the system, can offer higher availability, allowing the system to continue to operate while components of the system are offline, where stronger models might prohibit updates when nodes can not communicate\n- A lot of software systems attempt to treat distributed state as **a single system image**\n- But in reality, the world is eventually [[thoughts/consistency|consistent]]\n\t- Members of the same system exchange information by “interacting”, or sending messages containing information to each other. These messages between members of the system can be arbitrarily dropped and delayed, just like in traditional, unreliable, asynchronous networks.\n- Similarly, the web was able to scale to the scale it did because there is no *authoritative* copy of the web\n- Primary site: main source of truth\n- Designs such as this are very familiar in practice. For instance, Facebook, a large social-network application on the web, has a single user profile for each user that is active in the system. Each of these profiles is replicated across several of their data centers for performance; however, only one data center is deemed the primary site where all updates are performed.\n- However, it would be extremely impractical to have to hear information directly from the primary site every time you needed information. This is why we partially [[thoughts/replication|replicate]] data across databases. Databases are optimizations which makes for extremely efficient distribution of information (scale-free rather than random)\n\n## Each node is primary\n- What is another model of databases or state machine replication we can come up with? What about one which places each node as its own **primary site?**\n- In this model, each member of the system has some partially-replicated knowledge and some knowledge that they are the primary site for. This information is exchanged between members of the system and merged with each member’s local information: this provides both fault-tolerance, and lower latency in servicing requests for information from peers.\n- As we continue to increase the number of globally connected devices, we must embrace a design that considers every single member in the system as the primary site for the data that it is generates. It is completely impractical that we can look at a single, or a small number, of globally distributed data centers as the primary site for all global information that we desire to perform computations with.\n- Can we build abstractions that allow devices to communicate [[thoughts/peer-to-peer]], acknowledging the true primary site for a particular piece of information and scale to the amount of information that exists, not only between all computers in a planetary-scale distributed system, but all entities in the universe?\n\n## Limits of the speed of light\n- Coordination in the universe is limited by how much you can observe. That means a globally consistent *anything* will be limited by the speed of light\n- Problematic for global (and potentially inter-planetary) communication\n- Great thing about local-first is that you don't need to know anything about the other side of the world when doing stuff locally","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/A-City-is-not-a-Computer":{"title":"A City is not a Computer","content":"\nReboot event with Shannon Mattern on her new book _A City Is Not A Computer_. Main summary and introduction on the [Substack here](https://reboothq.substack.com/p/mattern).\n\n## Article Notes\n[Source: A City is not a Computer](https://placesjournal.org/article/a-city-is-not-a-computer/)\n\n### Sidewalk Labs\nDoctoroff, the founder of Sidewalk Labs: \"What would a city look like if you started from scratch in the internet era — if you built a city 'from the [internet](thoughts/Internet.md) up?'\"\n\nSidewalk aims to be the 'fourth revolution' of urban infrastructure where the first 3 were\n1. The Steam Engine\n2. Electricity Grid\n3. Automobile\n\nConstant theme of Doctoroff is that of constant [move fast and break things](thoughts/move%20fast%20and%20break%20things.md) of innovation.\n\n### 'New Cities'\nIs it possible to build 'smart cities' tabula rasa?\n\nA sort of [Collingridge dilemma](thoughts/Collingridge%20dilemma.md) where they are constantly developing and \"versioning\" much like a software product in an agile process.\n\n### Cities as information centres\nNot only for transmitting information within a generation (breadth-wise) but also between generations (depth-wise): [generational learning](thoughts/generational%20learning.md) and [Theory of Niche Construction](thoughts/Theory%20of%20Niche%20Construction.md)!\n\n\u003e \"By means of its storage facilities (buildings, vaults, archives, monuments, tablets, books), the city became capable of transmitting a complex culture from generation to generation, for it marshaled together not only the physical means but the human agents needed to pass on and enlarge this heritage.\"\n\n\"What are the non-textual, un-recordable forms of cultural memory? These questions are especially relevant for marginalized populations, indigenous cultures, and developing nations.\" Especially related to [quantization](thoughts/quantization.md), how does always labeling and quantizing our data affect these forms of information? These forms cannot be reduced to 'information' nor can they be 'processed' easily within our digital systems. \"Yet they are vital urban intelligences that live within bodies, minds, and communities.\"\n\n### Computational Metaphors\n\nDoes this only appeal to us because of the recent obsession of [computation](thoughts/computability.md) as a metaphor?\n\nHistorically, we've analogized the brain (and the city) to technologies of our time. For example, we've compared the brain to \"lumps of clay infused with spirits, as hydraulic or electro-chemical systems, as automata.\"\n\n\u003e The _brain as computer_ is just the latest link in a long chain of metaphors that powerfully shape scientific endeavor in their own images.\n\n## Event Notes\n- So much of how we interact with cities is through a computer; how can we reclaim cities for the people within them as people instead of just as data? What have cities lost in the transition to a data governed model\n\t- How we define [computation](thoughts/computability.md) matters a lot\n\t- Definitely something is lost in this 'generalization' of people as data\n\t- A lot of 'messiness' in history (e.g. *why* people were evicted, etc.) especially in *embodied knowledge*\n\t- Let's think about what **can't** be digitized and be put on a dashboard\n\t- Technosolutionism in governing from just a quantized dashboard where the *people responsible for making the decisions are so abstracted away from the actual problems that they need to solve*\n- What are potential solutions to this overly [quantized](thoughts/quantization.md) technosolutionist approach? You mentioned indigenous knowledge and [traditional knowledge](thoughts/traditional%20knowledge.md)\n\t- Think more epistemologically broadly (how do we know what we know, are things inherently quantifiable or not)?\n\t- Can we contextualize wisdom vs knowledge?\n\t- How can we provide public alternatives to privatized social systems (e.g. public interest Google)?\n\t- Examples of where knowledge goes beyond data and information\n\t\t- e.g. Public Libraries: center for civic knowledge, trusted knowledge broker, community archives, public digital infrastructure, rather than just a place to borrow books\n\t\t- these are definitely supplements rather than solutions\n\t- Maintenance and Care\n\t\t- Focus on [maintenance instead of just plain innovation](thoughts/creation%20vs%20maintenance.md)\n\t\t- Tech fetishizes creating new things, is there value beyond [instrumentalism](thoughts/instrumentalism.md)?\n\t- What is the 'dashboard' in the proto-city?\n\t\t- Source: Cybernetic Revolutionaries: Technology and Politics in Allendes Chiles (by Medina)\n\t\t- Feels like a lot of abstraction away from actual problems\n\t\t- [Potemkin village](thoughts/potemkin%20village.md) control room! Semblance of control rather than actual control/usefulness\n\t\t\t- Curious how similar this is to the [potemkin villages](thoughts/potemkin%20village.md) that AI systems construct\n- How can digital communities learn from libraries and librarians to prevent a Library of Alexandria moment?\n\t- Rise of Amazon: do we need bookstores and libraries anymore? Yes!\n\t- Primary point of internet access for underprivileged communities\n\t- Not just about search and delivery of content, but about curation and serving the body not just the mind\n\t- Values of libraries that digital maintainers could learn\n\t\t- When you're trying to optimize for 'hits' or 'clicks' feels very opposite to how libraries value knowledge\n\t\t- What knowledge needs to be protected? What knowledge **shouldn't** be universally accessible?\n\t\t- Alternative networks: what could the internet have looked like? A writing on the bit: [A People's History of Computing in the US](http://joyrankin.com/phcus)\n- Reboot has an ethos of techno-optimism, how do we reconcile this with humanists who vehemently reject technology as a whole\n\t- A lot of blanket rejection of tech and demonisation of the algorithm\n\t\t- misses a lot of things, e.g. predicting weather, modelling climate change, etc.\n\t- Rather than just bringing humanists in, starting the collaboration on a more neutral ground\n\t- Make it as participatory as possible\n- What can city governments do to help the 'exclusion' of previously 'unseen' or minority groups?\n\t- [Design Justice](thoughts/Design%20Justice.md) approach, specifically acknowledge this bias and try to compensate (e.g. [Data for Black Lives](https://d4bl.org/))\n\t- We may not always be able to prevent 'data harvesting', and it sometimes might not all be bad! How do we fairly represent everyone?\n\t- How do we control our own data and how we are presented within algorithms? Data sovereignty (e.g. [[thoughts/GDPR|GDPR]]?)\n- Would smart cities be any different if they prioritized the citizens and participation at the get-go rather than as an after-thought\n\t- Multiple definitions of smart cities (corporate extractivist approaches, civic approaches, improving democratic processes, open data, etc.)\n\t- How do we manage data and data [[thoughts/privacy|privacy]]?\n- Thoughts on [web3](thoughts/web3.md) and cities? CityDAO?\n\t- Blockchain for decentralized mapping? Mapping in particular holds a lot of power for how a lot of citizens interact with the city\n\t- Probably needs more time to read more to provide an intelligent answer\n\t- [Decentralizing](thoughts/decentralization.md) on different axes? Architecturally decentralized vs logically decentralized vs politically decentralized\n\t- Does the definition of city matter in this case?\n- What is the value of proximity?\n\t- Especially certain 'focus' groups e.g. Silicon Valley, why are these centralized?\n\t- What about the future of work and more decentralized approaches to communities?\n- Are ['imperfect' algorithms](posts/bias-bug.md) okay? What about if they are better than biased humans?\n\t- Matter of looking at where the technology is useful, who is using it, how can we mitigate the risks using human-in-the-loop systems (if at all possible)\n\t- Similar to scientific approaches to hypothesis, define these ahead of time so there is less incentive to 'reclassify' data to hit quotas\n- Ground-up emergence vs Top-down [governance](thoughts/governance.md) for cities\n\t- Historically a lot of data **has** been centralized regardless (e.g. libraries, town halls, etc.)\n\t- Similar discussion to a an article thinking about hierarchies within cities: [A City is not a Tree](thoughts/A%20City%20is%20not%20a%20Tree.md)\n- Success metrics on unplanned vs planned development\n\t- How do we think about co-optation of civil design tools that are used typically by more unplanned/ground-up governance by corporations and more centralized governance models? (design justice)\n\t- [Fred Turner](thoughts/From%20Counterculture%20to%20Cyberculture.md) and the communes, New Communalist approaches to communities\n- How can we best familiarize ourselves in new environments or be a 'tourist' in the places we've lived in for a while?\n\t- Think about the various networks that converge on their apartments\n\t- Denaturalize physical environments, look at the infrastructure that makes it possible\n\t- Take in familiar environments with new senses","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/A-City-is-not-a-Tree":{"title":"A City is not a Tree","content":"\n[A City is not a Tree](https://www.patternlanguage.com/archive/cityisnotatree.html)\n\n## Semilattices\n![](thoughts/images/semilattice.png)*More diagrams in [Figma](https://www.figma.com/file/eFPS114umxiV44LgL82UUb/Christopher-Alexander's-Semilattice-from-A-City-is-Not-a-Tree-(Community)?node-id=0%3A1)*\n\n![[thoughts/images/semilattice example.png]]\n\n## Why graphs instead of trees\nBoth the tree and the semilattice are ways of thinking about how a large collection of many small systems goes to make up a large and complex system. More generally, they are both names for structures of sets.\n\n\u003e For the human mind, the tree is the easiest vehicle for complex thoughts. But the city is not, cannot and must not be a tree. The city is a receptacle for life. If the receptacle severs the overlap of the strands of life within it, because it is a tree, it will be like a bowl full of razor blades on edge, ready to cut up whatever is entrusted to it. In such a receptacle life will be cut to pieces. If we make cities which are trees, they will cut our life within to pieces.\n\n## Urban Planning\nColumbia, Maryland: Neighbourhoods, in clusters of five, form 'villages'. Transportation joins the villages into a new town. The organization is a tree.\n\nHilberseimer's book The Nature of Cities: He describes the fact that certain Roman towns had their origin as military camps. The symbol is apt, for, of course, the organization of the army was designed precisely in order to create discipline and rigidity.\n\nSee more in the note on [Urban planning](thoughts/urban%20planning.md)\n\n## Why graphs are hard to visualize\nThe example the article used was to try and an orange, a watermelon, a football and a tennis ball. How will you keep them in your mind, in your mind's eye? However you do it, you will do it by grouping them. Maybe two fruits and two sports balls together. In doing so, you construct a tree structure. Maybe you group it by size, two small spheres and two large spheres. This constructs another tree. But try as hard as you like, two trees combined form a semilattice. It is very difficult to hold a semilattice in your head.\n\nMaybe this is where tools like knowledge graphs come in. Allow us to better visually explore these graph relations and allow us to capture more complex relations in things\n\nRegular note taking like Notion is hierarchical and linear → its a tree\nGraph representations like Roam Research, Obsidian allow us to make non-obvious non-hierarchical connections between concepts\n\nCurious if we can apply graph [[thoughts/visualization|visualization]] approaches to [social media](thoughts/social%20graphs.md)?\n","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/A-Pragmatic-Precautionary-Principle":{"title":"A Pragmatic Precautionary Principle","content":"\n\u003e *Final paper for PHIL321*\n\nThe Precautionary Principle has had many different interpretations across game theory; there is no single accepted formulation. In general, the Precautionary Principle suggests that we should take appropriate measures to prevent potential harm, even if the likelihood or severity of that harm is uncertain. However, part of the reason why there has been such heavy debate around Precautionary Principle is because many terms are already meaning-laden: it is not always clear what constitutes appropriate precautionary measures, and different stakeholders may have different ideas about what is appropriate in a given situation.\n\nIf the principle is to be useful in policy-making, we must make it more concrete. The real meat of the matter comes down to how we characterize what constitutes a relevant thread and what threshold of certainty is necessary to enact action.\n\nNeil A. Manson (2002) in *Formulating the Precautionary Principle*[^2], attempts to derive a more robust definition. In this paper, I will build on Manson's interpretation of the Precautionary Principle and argue that we should regard the weak formulation of the Precautionary Principle as unproblematic. In fact, I claim that controversy and refutations of the Precautionary Principle occur when there are issues of ill-defined terms or the formulation contradicts itself rather than a flaw with the core principle itself. That is, there are constructions of the Precautionary Principle that *are* incoherent, but this does not mean that the Precautionary Principle as a whole is incoherent.\n\nIn the first part of the paper, Manson formalizes the Precautionary Principle into a general three-part structure shared between all versions: For a given *e-activity* that may have a given *e-effect* on the environment, the precautionary principle is supposed to indicate an *e-remedy*. Here, the terms e-activity, e-effect, and e-remedy refer to abstract elements of various Precautionary Principles (e.g. burning fossil fuels is an e-activity, climate change is an e-effect, and enacting a carbon tax is an e-remedy).\n\nAdditionally, Manson defines conditions on each of these terms. The damage condition specifies the characteristics of an e-effect in virtue of which precautionary measures should be considered. The knowledge condition specifies the status of knowledge regarding the causal connections between the e-activity and the e-effect. The remedy condition specifies the e-remedy that decision makers should take in response to the e-activity. Formally,\"if the e-activity meets the damage condition and if the link between the e-activity and the e-effect meets the knowledge condition, then decision makers ought to enact the specified e-remedy\" (Manson 2002, p. 265). This formulation, I argue, is unproblematic. We can boil it down to a simple logical entailment of the form $A \\land B \\rightarrow C$  where A is the damage condition, B is knowledge condition, and C is the remedy condition. The soundness of this statement heavily depends on what $A$, $B$, and $C$ are, but there is nothing inherently wrong with it in and of itself.\n\nIn the second part of the paper, he distinguishes a stronger formulation of the Precautionary Principle (which he dubs the Catastrophe Principle). The Catastrophe Principle is an instantiation of the Precautionary Principle where the damage condition is that the e-effect is catastrophic and the knowledge condition is that there is a possibility that the e-activity leads to the e-effect. That is, if there is even a mere possibility that something potentially catastrophic were to happen as a result of the activity, then we should unconditionally ban it.\n\nSpecifically, Manson argues that the stronger Catastrophe Principle is self-defeating but leaves the earlier formulation of the Precautionary Principle intact. Strong versions of the Precautionary Principle, if applied consistently, lead to paradoxical outcomes.\n\nThe careful reader will notice the similarities between the Catastrophe Principle and Pascal's Wager. In Pascal's *Pensées* (1623-1662), he outlines an argument that one should always believe in God so long as the probability that God exists is nonzero.\n\n| |God exists|God does not exist|\n|--|--|--|\n|Believe|$\\infty$|Finite|\n|Don't believe|$-\\infty$|Finite|\n\nAs there is dominance of the action of believing in God over not believing in God, any rational decision maker must believe in God, no matter how low the probability of 'God does not exist' is. \n\nSimilarly, if we draw a decision table for the Catastrophe Principle, we see they follow a similar structure. Any rational decision maker should always enact the e-remedy given that there is a nonzero possibility that the e-activity leads to the e-effect.\n\n| |Knowledge Condition is met|Knowledge Condition is not met|\n|--|--|--|\n|Enact e-remedy|Finite|Finite|\n|Do nothing|$-\\infty$|Finite|\n\nOf course, Pascal’s Wager has been subjected to a number of philosophical criticisms. Manson specifically focuses on the “many gods” objection as a way to dismantle both Pascal's Wager and the Catastrophe Principle.\n\nWhat if, for example, there are other gods aside from God that also promise an infinite payout? If you chose to believe in God and He does not exist but the other god does, it is plausible (non-zero possibility) that they could sentence you to eternal damnation (infinite punishment). As a result, this would make believing in God a risk not worth taking. That is, Pascal's Wager recommends a remedy (believing in God) that itself could lead to a catastrophic result (infinite punishment from a jealous god).\n\nAlthough many have pointed out flaws to the many-gods objection, it still brings to light the following general point regarding the catastrophe principle: \"even if an e-effect is catastrophic, that fact cannot rationally compel us to impose an e-remedy unless we also know that the e-remedy itself does not lead to catastrophic results\"[^2] (Manson 2002, pp. 272-3).\n\nA proponent of the Catastrophe Principle may then try to strengthen the principle by adding an extra clause stating that it should only be applied if imposing the given e-remedy will not cause another catastrophic e-effect. However, we quickly see that even with this clause, the Catastrophe Principle is still incoherent. Earlier, when we formulated both Pascal's Wager and the Precautionary Principle, we assumed that any rational decision maker would assign non-zero probabilities to any imaginable outcome (whether that be a belief in God or the knowledge condition being satisfied). Thus, we also cannot ever rule out the fact that a given e-remedy will not cause another catastrophic effect. The e-remedy could bring about an outcome which also leads to human extinction and we couldn't rule it out!\n\nThe upshot here is that even well-intentioned safety measures can lead to damaging consequences if we use the Catastrophe Principle. Note specifically, that this isn't a fatal blow for the weak formulation of the Precautionary Principle but rather just the Catastrophe Principle. \n\nManson concludes by saying that a formulation of the Precautionary Principle is coherent, if and only if, it meets a list of 5 core requirements. Of the ones that are applicable to this paper, Manson clarifies that the component concepts used in the conditions should be clearly defined and that the formulation must not be self-refuting. In the case of the Catastrophe Principle, the formulation was self-refuting, so it is not coherent.\n\nStephen M. Gardiner, in his 2006 work *A Core Precautionary Principle*[^3] shares Manson's central concern, stating that because of how low the epistemic standards for the application of the catastrophe principle are, there are always way to construct these mere possibilities in a way that not only recommends the action but prohibit it as well. Thus, it is incoherent. \n\nGardiner defines further criteria to narrow what should be considered a rational Precautionary Principle, noting that the real action involves identifying the relevant circumstances under which the Precautionary Principle is operative (Gardiner 2006, p. 38).\n\nHow do we distinguish between reasonable outcomes (ones we should consider)  and those outcomes which are merely imaginable (ones we should not)?\n\nOpponents may attempt to argue that the precautionary principle is committed to counting any imaginable outcome as possible, no matter how unreasonable it may seem. John Harsanyi makes an illustration of how foolish it may seem to consider unreasonable outcomes (Harsanyi in Gardiner 2006):\n\n\u003e If you took the [strong formulation of the precautionary] principle seriously then you could not ever cross the street (after all, you might be hit by a car); you could never drive over a bridge (after all, it might collapse); you could never get married (after all, it might end in a disaster), etc. If anybody really acted this way he would soon end up in a mental institution.\n\nI argue that this argument depends heavily on the definition of 'possible.' Gardiner proposes that we add another circumstance so that the range of outcomes considered are in some appropriate sense \"realistic,\" so that, for example, only credible threats are considered and cases like these do not arise.\n\nThis begs the question, what makes a circumstance realistic? This is a question Gardiner explicitly leaves out of his argumentation and assumes that such a criterion exists and does not take a position on what it would be.\n\nI suspect that there is a human limit to the size of a probability we find meaningful. Just like how the size of certain numbers are incomprehensible to humans, some probabilities are so unlikely that they are nearly meaningless. Bernoulli conjectured that people neglect small probability events.\n\n\u003e Nicholas Bernoulli who can be held liable as the creator of the Petersburg gamble suggested that more than five tosses of heads are morally impossible. This proposition is experimentally tested through the elicitation of subjects‘ willingness-to-pay for various truncated versions of the Petersburg gamble that differ in the maximum payoff. In fact, the experimental data show that all versions of the Petersburg gamble which allow for more than six repeated tosses of tails elicit the same willingness-to-pay. From this evidence it is concluded that subjects neglect those outcomes in the Petersburg gamble which occur with a probability smaller than or equal to one in sixty-four, because, given this level, the alternative explanations seem implausible. (Neugebauer 2010, p. 3)\n\nEspecially as we want this to serve as a framework to make practical decisions, we should discard  probabilities that people implicitly discard. A good lower bound on if a probability event could feasibly happen is if it could have reasonably occurred within the timespan of the entire universe. This is effectively strengthening the knowledge condition by placing a lower bound on the conceivable range of probabilities we consider. Anything below this bound is considered negligible and assigned a probability of 0. As a result, this makes much more robust the conditions under which it is coherent to apply the Precautionary Principle.\n\nIn conclusion, I have illustrated how the Precautionary Principle itself, if carefully constructed, can come to coherent and rational decisions. By resolving issues with ill-defined terms or self-contradiction in the principle's formulation, we can create a more robust Precautionary Principle that is more suitable to pragmatic use cases like in environment decision making.\n\n[^1]: Pascal, Blaise, 1623-1662. Pascal's Pensées. New York :E.P. Dutton, 1958.\n[^2]: Manson, Neil A. 2002. “Formulating the Precautionary Principle.” Environmental Ethics 24, 263-274.\n[^3]: Gardiner, Stephen M. 2006. “A Core Precautionary Principle.” The Journal of Political Philosophy 14, no. 1: 33-60.\n[^4]: Neugebauer, T. (2010). Moral impossibility in the Petersburg Paradox: a literature survey and experimental evidence.","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/A-Tale-for-the-Time-Being":{"title":"A Tale for the Time Being","content":"\nthe amount of depth being slowly unravelled over time is astounding\n\ni think tale for the time being has really got me thinking about time and time differences\n\nnot just in absolute offsets in terms of like time zones, but how different people experience life at differing speeds\n\ndepending on their context, environment, etc.\n\nand that empathy is really just emotional time dilation and temporarily moving at their pace of live if only for a brief moment\n- the Māori word for autism is takiwatanga: \"in his/her own time and space\"\n\nhttps://clarkesworldmagazine.com/chen_08_11/\n- \"They discovered that those suffering from the side effects of time sense dilation and those suffering from the side effects of time sense compression can help each other, be each other’s cure.\"\n- \"time flies past the laborer, the poor, the “third world”; time crawls for the rich, the idle, the “developed world”; time stays still for those in charge, the idols, the gods . . .\"\n\nhttps://griefbacon.substack.com/p/nothing-stops?utm_source=url\u0026curius=1299\u0026s=r\n- This is the process of history, and of crisis, of disease and of love. We may try sometimes to stand still, but we are standing on a moving walkway.\n- All people want is for nothing to happen; all anybody wants is another day of our soft, stupid little lives, to be allowed the vulnerabilities we have built into them. We clutter up our houses with useless objects that mean something to us; we adopt pets who would slow us down in a crisis. All this is a way of ignoring the truth that nothing stops, which is to say it is a form of love.\n- We are making a declaration that it is worth it to choose the losing side.\n- But I choose all that anyway; I would rather try and fail to stand still with you than to be fast and sleek without you.","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/AI-alignment":{"title":"AI Alignment","content":"\nHow do we get [[posts/ai-systems|AI systems]] to align with real human [[thoughts/social contracts|social contracts and values]]?\n\nMostly sourced from [OpenAI's approach to alignment](https://aligned.substack.com/p/alignment-optimism)\n\n- RLHF: [Summarization from human feedback](https://openai.com/blog/learning-to-summarize-with-human-feedback/) was really the first convincing proof-of-concept that RLHF works on language models and that you can optimize goals that are fuzzy and somewhat ambiguous.\n\t- How do we optimize for goals that are not easily [[thoughts/quantization|quantizable]]?\n- [InstructGPT](https://openai.com/blog/instruction-following/) demonstrated that there is a real “alignment overhang” in language models that wasn’t very hard to access. The amount of human feedback needed to achieve an astounding 100x improvement was pretty moderate and achievable: ~50,000 comparisons, and ~300,000 episodes of training. That number is so small that we could actually have humans hand-label every training episode\n- Using models to augment rather than replace. Helping humans find 50% more flaws that they would have unassisted with a model that isn't superhuman on a task that isn’t hard for humans is a surprisingly strong result, showing that our model can basically already add a lot of value for feedback assistance.","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/ARP":{"title":"ARP","content":"\n## Address Resolution [Protocol](thoughts/Protocol.md) (ARP)\nPurpose: links the [Network Layer](thoughts/Network%20Layer.md) (IP address) with the [link layer](thoughts/Link%20Layer.md) (MAC address)\n\nCase: A wants tot send a datagram to B, but A doesn't know B's MAC address\n\n- A broadcasts an ARP query packet with an IP address: \"who has IP address 130.207.160.47?\"\n- B receives ARP request with that IP address on the LAN will respond with appropriate MAC address.\n- Generates an ARP Table maps IP to MAC\n\t- This is soft state, information that goes away unless refreshed. Each entry has a time limit\n\nGeneral Notes\n- Useful because frames use MAC addresses for addressing\n- ARP is stateless, doesn't remember whether it sent a request (always reads response)\n- Not authenticated, anyone can ARP\n- Easily spoofed","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/ActivityPub":{"title":"ActivityPub","content":"\n[From W3C Editor's Draft](https://w3c.github.io/activitypub/)\n\n\u003e The ActivityPub protocol is a decentralized social networking protocol.\n\nIn ActivityPub, a user is represented by \"[actors](https://w3c.github.io/activitypub/#actors)\" via the user's accounts on servers. User's accounts on different servers correspond to different actors.\n\nUsed to be called *OStatus* which was the basis for Mastadon\n\nBased on [ActivityStreams](https://www.w3.org/TR/activitystreams-core/), a social data syntax.\n\nEach actor has:\n- An `inbox`: How they get messages from the world\n- An `outbox`: How they send messages to others\n\nHere's how sending and reading messages work\n![[thoughts/images/ActivityPub diagram.png]]\n\n- You can POST to someone's inbox to send them a message (server-to-server / [[thoughts/federation|federation]] only... this _is_ [[thoughts/federation|federation]]!)\n- You can GET from your inbox to read your latest messages (client-to-server; this is like reading your social network stream)\n- You can POST to your outbox to send messages to the world (client-to-server)\n- You can GET from someone's outbox to see what messages they've posted (or at least the ones you're authorized to see). (client-to-server and/or server-to-server)\n\nMessages made by clients get posted to their own server's outbox and the server then posts that to the receiver's inbox.","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Algorithms-of-Oppression":{"title":"Algorithms of Oppression","content":"\n## Chapter 1\nMoving the focus away from 'problematic users and data' to search architecture itself.\n\n\u003e If the majority rules in search engine results, then how might those who are in the minority ever be able to influence or control the way they are represented in a search engine?\n\nThese search results influence the values that surround what is being searched for. This means that minority groups often have their own values and identities influenced by the majority: [double-consciousness](thoughts/double-consciousness.md)\n\nWhy have we become so reliant on search? Is it a part of our [Extended Mind Hypothesis](thoughts/Extended%20Mind%20Hypothesis.md)?\n\n\u003e [Search](thoughts/search.md) is a symbiotic process that both informs and is informed in part by users.  \n\n\"Google directs web traffic to mainstream corporate news conglomerates, which increases their ability to shape the political discourse.\" This is the [zero sum](thoughts/zero%20sum.md) [attention economy](thoughts/attention%20economy.md).\n\n\u003e Decreases in funding for public information institutions such as libraries and educational institutions and shifts of responsibility to individuals and the private sector have reframed the ways that the public conceives of what can and should be in the public domain.  \n","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Antimatter":{"title":"Antimatter","content":"\n[Source](https://braid.org/antimatter)\n\nA [[thoughts/CRDT|CRDT]] + OT text editing algorithm with history pruning (read: GC). Permissionless [[thoughts/system model]].\n\n## Components\n- Acknowledgements: require all peers to have acknowledged up to a certain point, then we can bloop\n- Blooping: collapsing history. This is kind of like span-merging which [[thoughts/Yjs]] implements\n\t- When we get acknowledgement from all peers up to a certain point, we can then 'bloop'/flatten all history that is not used in producing the current state\n\t- ![[thoughts/images/antimatter-bloop.png|400]]\n- Fissures: keeps track of disconnections and network partitions\n\t- During a fissure/disconnect, all events concurrent with that disconnect are marked to prevent from being blooped","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Application-Layer":{"title":"Application Layer (Networking)","content":"\nLayer 1, the layer above the [Transport Layer](thoughts/Transport%20Layer.md)\n\nApplication/Presentation/Session layer\n1. Unit: Data\n2. Responsibilities: [human-computer interaction](thoughts/human%20computer%20interaction.md) layer, where applications can access the network services (includes [[thoughts/encryption|encryption]], connection, port, and session management)\n\n","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Archipelago":{"title":"Archipelago","content":"\n*by Édouard Glissant*\n\nA beautiful dialogue between Glissand and the curator Hans Ulrish Obrist.\n\n\u003e I can change through exchanging with others, without losing or diluting my sense of self.\n\n\u003e I still believe that the future lies not with the great powers, but with the little islands, lands, and cities.\n\n## Globality versus Globalization\n- Globality does not homogenize culture. It produces a difference from which new things can emerge. (22)\n- Globalization standardizes and dilutes. It reduces communities to a single model, attacking them from the top down, diminishing them.\n\n## Archipelagos\n- \"a world of many worlds\" as quoted by the Chiapas\n\t- they desire a *creole* -- a mixed Mexico\n- Creolization is the means by which several distinct cultures or their elements, come into contact in a particular place in the world ([contact languages](thoughts/contact%20language.md) enable this)\n- Distinction between multiethnic (where many cultures exist but are distinct) and creole (where many cultures mix and form new ones)\n\n[Digital gardening](posts/digital-gardening.md) and [networked thought](posts/networked-thought.md) as tending to free isles? The reader is free. This freedom produces chance, it produces the unexpected.\n\n## On [utopias](thoughts/utopia.md)\n\u003e Utopia is what is missing to us in the world -- and thus it is never complete\n\n- If we imagine utopia as a finished work, then we're continuing the old debates, we're continuing the old science, and we're continuing the old demands.\n\t- Why we need to continue to write new shared [fiction](thoughts/fiction.md)\n- Utopias cannot have norms. When we have norms, we banish to hell anything that does not fall within the rule of that utopia.\n- To reach utopia, we must accept that our world changes radically and perpetually, and that it changes with us and in us. We should reject stasis and and immutable.\n\n\u003e Utopia is a feeling: an ability to sense that all is entangled","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Arcosanti":{"title":"Arcosanti","content":"\nA provocative concept of a compact city designed not around roads and cars but around people. \n\nDesigned and established by Paolo Soleri, around same time as the [[thoughts/From Counterculture to Cyberculture|counter-cultural movements of \"back to the land\"]]\n\nArcology: the mixture of architecture and local ecologies\n\nDispersal is antagonistic to life. Density is the only [[thoughts/morphology|morphology]] that can give us a lively existence.\n\nWanted it to be a caravansary, a traditional inn with central courtyard for travelers in the desert regions of Asian or North Africa that often served as a stopover for ideas.\n\n![[thoughts/images/arcosanti.png]]\n\n","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Arrows-Impossibility-Theorem":{"title":"Arrow's Impossibility Theorem","content":"\nRelated: [[thoughts/Social Contract Theory#Social Choice|social choice]]\n\nAssume there is more than one individual, and there are at least three distinct social states. Then there is no SWF that meets the following four conditions:\n\n1. Non-dictatorial: no individual is decisive\n2. Ordering: must produce social preference orderings which are complete, asymmetric and transitive (see also: [[thoughts/utility#Interval Scales]])\n3. [[thoughts/Pareto optimality|Pareto condition]]: If every voter prefers alternative X over alternative Y, then the group prefers X over Y.\n4. Independence of Irrelevant Alternatives (IIA): If every voter's preference between X and Y remains unchanged, then the group's preference between X and Y will also remain unchanged\n\nUnstated: Arrow also requires the unrestricted domain assumption (U)\n\nHow can we get around this?\n1. Sen: give up liberalism (Pareto)\n\t1. Argues that liberalism + Pareto leads to a contradiction in ordering axioms\n\t2. Nozick's solution: give up the unrestricted domain assumption (U)\n\t\t1. Liberalism excludes certain kinds of states (‘private’ alternatives) from social scrutiny in advance.\n\n## Similarities to Group Membership\nSee also: [[thoughts/access control]]\n\nSuppose we encode access in terms of some function $A_{i,j}$ where $A_{i,j}$ is true if subject $i$ considers $j$ to be in the group and false otherwise.\n\nA social state $S$ for some collection of individuals $G$ is $i \\in G$ such that $A_{j,i} \\forall j \\in G$.\n\nWe suppose there is some function that takes in individual preference orderings (what it thinks the group membership currently looks like) and produces a group preference ordering (what the true group membership is). This is normally called the SWF.\n\nSome properties of said SWF:\n- Non-dictatorial: we don't want a single admin who has power to dictate who is in the group. If this were to happen, we couldn't remove the admin if they were compromised\n- Intention-preserving: If every voter prefers alternative X over alternative Y, then the group prefers X over Y.\n\t- Strong requirement is needed. Consider a weaker version: If the majority of voters prefers alternative X over alternative Y, then the group prefers X over Y\n\t- This may not work when we have a Sybil actor that can add new accounts to overwhelm the majority\n- ...anything else I'm missing?\n\nIf we can show that these properties are equivalent to the Arrow Axioms, then there may be no way to come to a singular group where all members agree.","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Arweave":{"title":"Arweave","content":"\n[Blogpost](https://arweave.medium.com/what-is-arweave-explain-like-im-five-425362144eb5) and [Yellowpaper](https://www.arweave.org/yellow-paper.pdf)\n\nArweave uses a [blockchain](thoughts/blockchain.md)-like structure called the blockweave.\n\nHits 5000 transactions per second (compared to 15 on [Ethereum](thoughts/ethereum.md))\n\nWildfire is the Arweave’s self-organising network topology system. Wildfire ensures that miners are selfishly incentivised to store and share data as quickly as possible with other miners in the network, in order to build a positive reputation. While more complex under the hood, Wildfire can be summarised as: ‘if you share with me, I will share with you’. As nodes in blockweave networks require fast access to data in order to mine efficiently, they are selfishly-incentivised to give data to other members of the network promptly and continuously, autonomously improving the sharing to lightning-fast speeds.\n\nThe blockweave solves two fundamental problems currently associated with public decentralised blockchains:\n- On-chain storage constraints; and\n- Unsustainable consensus mechanisms\n\nIn order for an information store to be truly permanent, it must be both [fault tolerant](thoughts/fault%20tolerance.md) and [decentralized](thoughts/decentralization.md). Blockchain technology has much obvious promise in the area of resilient, decentralized information preservation, as a key feature of the technology is that all data inside the blockchain is immutable, and cannot be altered once it is stored. However, traditionally, such technology severely lacks scalability which clearly limits its utility for storing significant quantities of data.\n\nOf especially great importance is users ability to reliably maintain\naccess to all permaweb applications and websites themselves, not simply the\ncontent they display, forever.\n\nRequiring PoA incentivises storage as miners need access to random blocks from the blockweave’s history in order to mine new blocks and receive mining rewards.\n\nUnlike traditional blockchain systems, Arweave does not have a typical notion of full and light clients – merely clients that downloaded more or less of the blockweave. With Arweave, full synchronisation is not a risk or an obligation, but an optional upgrade path for which miners receive higher rewards.\n\nFrom the user’s perspective,  there are two types of transactions in the network:  data transactions and value transactions.  A user can initiate a data transaction to store data in a block.\n\nRather, most of the transaction fee is contributed towards a storage endowment, which is distributed to the wallets of miners over time.\n\nFrom our current position, at an optimistic 30% annual data density growth rate, it will take 434 years to reach the maximum theoretical limit, at 20% – 697 years, at 10% AGR – 1,329 years.\n\nArchive nesting\n- This does not mean that we expect that the information stored inside the weave will be lost after the final block is mined\n- It is our expectation that when eventually a permanent information storage system more suited to the challenges of the time emerges, the Arweave’s data will be ‘subsumed’ into this network.\n- This pattern of ‘nesting’ of archives when they are retired is common across human history. An archive of Gopherspace (a ‘knowledge web’, prior to the HTTP-based web) can be found inside the Arweave’s permaweb. In-side the Gopherspace archive, one can find archives of earlier Telnet and bulletin board-based discussion systems\n\nContent policies\n- Given that the miners collectively maintain the Arweave network, a mechanism is required to allow them to express their opinions on what content should and should not be hosted in the system.\n- Nodes express preferences about content through content policies. Content policies  can  be  arbitrary  computation  performed  upon  transactions  that classify them as acceptable or not acceptable to the local node.  In the reference Arweave implementation, content policies are supported in the form of substring matches as well as hashes of the data stored in the transaction.\n- Two complementary incentives at play here\n\t- An incentive not to over-zealously reject too many transactions, as this would lead to a decline in mining rewards\n\t- An incentive not to accept transactions that the majority of the network is likely to reject, as this will result in mining candidate blocks that the rest of the network will ignore\n\n## Architectures\n### Client-server\nTraditional web or native applications have a client-server architecture. This model is still possible with the Arweave, as a web server can act as a front-end for data stored on the network’s permanent ledger.\n\nIn this centralised Arweave-app model, these services can maintain a pool of AR tokens in order to pay for data storage requests on behalf of the client.\n\n### Serverless\nDecentralised applications reside directly on and operate directly from the blockweave itself, and can be accessed by a typical web browser. \n\nServerless applications hosted on the Arweave network allow users to pay directly  for  their  interactions  with  the  network.   This  frees  the  developer from having to subsidise the cost of user interactions themselves\n\n## DNS\nThe owner of a domain can run a permanently-available, decentralized web application just by storing a transaction on the Arweave network and registering DNS records via the usual external service providers\n\nYou need\n1. A DNS CNAME record pointing to an Arweave gateway: `www CNAME arweave-gateway.net`\n2. A DNS TXT record linking the domain with a specific transaction ID: `arweavetx TXT kTv4OkVtmc0NAsqIcnHfudKjykJeQ83qXXrxf8hrh0S`","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Asymmetric-Key-Cryptography":{"title":"Public-key Cryptography","content":"\nAsymmetric cryptography involves a pair of keys, one for encrypting (public) another for decrypting (private). One is private ($K^-$), the other is public ($K^+$). The key property is that one key cannot be obtained from the other in reasonable computation time\n\nCommon forms of Asymmetric Cryptography are [[thoughts/RSA|RSA]] and [[thoughts/Elliptic-curve Cryptography (ECC)|ECC]]\n\n## Two use cases\n1. Sender encrypts with public key\n\t- Only private key can decrypt it\n\t- Used for confidentiality\n1. Owner encrypts with private key\n\t- Anyone can decrypt as public key is public\n\t- Used for authentication/proof of ownership\n\nCan theoretically encrypt using private key but anyone with public key can decrypt!\n\n","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Atlas-of-AI":{"title":"Atlas of AI","content":"\n\"It is the idealogy of Cartesian dualism in AI: where AI is narrowly understood as disembodied intelligence, removed from any relation to the material world.\" -- they absorb and produce knowledge independently from their creators, infrastructures, and the world at large.\n\n\"To understand how AI is fundamentally political, we need to go beyond neural nets and statistical pattern recognition to instead ask *what* is being optimized, and *for whom*, and *who* gets to decide.\"\n\n\"As author and engineer Ellen Ullman puts it, this belief that the mind is like a computer, and vice versa, has infected decades of thinking in the computer and cognitive sciences,' creating a kind of original sin for the field. It is the idealogy of Cartesian dualism in artificial intelligence: where AI is narrowly understood as disembodied intelligence, removed from any relation to the material world.\"\n\n\"An atlas is an unusual type of book. It is a collection of disparate parts, with maps that very in resolution from a satellite view of the planet to a zoomed-in detail of an archipelago. When you open an atlas, you may be seeking specific information about a particular place -- or perhaps you are wandering, following your curiosity, and finding unexpected pathways and new perspectives.\"\n\nAI is an attempt to be *the* atlas -- the dominant way of seeing the world. We should instead try to construct \"humble geography\" that acknowledges one's specific perspectives rather than claiming objectivity or mastery.\n\n\"In this sense, artificial intelligence is a registry of power... Computational reason and embodied work are deeply interlinked: AI systems both reflect and produce social relations and understanding of the world.\"\n\n## Hans: Observer-expectancy effect\n\"Their intuition was right: the questioner's posture, breathing, and facial expression would subtly change around the moment Hans reached the right answer, prompting Hans to stop there.\"\n\n\"The story of Clever Hans is compelling from many angles: the relationship between desire, illusion, and action, the business of spectacles, how we anthropomorphize the nonhuman, how biases emerge, and the politics of intelligence.\"\n\n\"Even a system that appears to perform spectacularly in training can make terrible predictions when presented with novel data in the world.\"\n\n## Earth\n\"Commerce follows the flag, but the flag follows the pick.\"\n\n\"Those who profit from mining do so only because the costsd must be sustained by others, those living and those not yet born. It is easy to put a price on precious metals, but what is the exact value of a wilderness, a clean stream, breathable air, the health of local communities?\"\n\n\"It was the 'move fast and break things' of a different time\"\n\n\"The mines were located far from the city they enriched, and this remoteness allowed city dwellers to remain ignorant of what was happening to the mountains, rivers, and laborers that fed their fortunes.\"\n\n## Labour\n*Megamachine*: illustration of how all systems, no matter how immense, consist of the work of many individual human actors.\n\nHumans are increasingly treated like robots or the connective tissue between robots.\n\n[Potemkin AI](thoughts/potemkin%20village.md) systems are a form of deception perpetrated by technology vendors eager to stake a claim in the lucrative tech space. The difference between 'perceived' ability and 'real' ability of these AI system are augmented by human piecework.\n\n## Data\nThere is a new pervasive belief that everything is data and is there for the taking. \n\nData, when aggregated, become [infrastructure](thoughts/infrastructure.md). \"The meaning or care that might be given to the image of an individual person, or the context behind a scene, is presumed to be erased at the moment it becomes part of an aggregate mass that will drive a broader system.\"\n\nML systems work based on *inductive inference*. Any person who has taken a first-year course on logic will know the false conclusions that this can draw (e.g. all swans are white). Can we create systems that operate on *deductive inference*, which follows logically from a premise?\n\n\"Even the largest troves of data cannot escape the fundamental slippages that occur when an infinitely complex world is simplified and slices into categories.\" This is a process that requires inherently political, cultural, and social choices.\n\n\"Data systems allowed scientists during wartime to operate at a psychological distance from the people 'who would be maimed and killed by the weapons systems that would result from the ideas they communicated'.\"\n\n## Recognition Systems\n\"This is the danger of affect recognition tools. As we've seen, they take us back to the phrenological past, where spurious claims were made, allowed to stand, and deployed to support existing systems of power.\"\n\n## Accountability\nAndrew Ferguson: \"We are moving to a state where prosecutors and police are going to say 'the algorithm told me to do it, so I did, I had no idea what I was doing'.\"\n\nA false objectivity, \"it's just math, math can't be biased, right?\" -- where's the [accountability](thoughts/accountability.md)?\n\nThe historian of technology Alex Campolo calls this *enchanted determinism*: \"AI systems are seen as enchanted, beyond the known world, yet deterministic in that they discover patterns that can be applied with predictive certainty to everyday life.\"","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Autoencoders":{"title":"Autoencoders","content":"\nAutoencoders are neural networks with same input and output.\n- Includes a bottleneck layer: with dimension $k$ smaller than input $d$.\n- First layers “encode” the input into bottleneck.\n- Last layers “decode” the bottleneck into a (hopefully valid) input\n\t- Can be used as a [[thoughts/generative models|generative model]]!\n\nApplications\n- Superresolution\n- Noise removal\n- Compression\n\nRelationship to principal component analysis ([[thoughts/latent-factor model|PCA]]):\n- With squared error and linear network (no non-linear $h$), equivalent to PCA.\n- Size of bottleneck layer gives number of latent factors $k$ in PCA.","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Bentoism":{"title":"Bentoism","content":"\n\n![My long term Bento](/thoughts/images/long%20term%20bento.png)*My long term [Bento](https://bentoism.org/)*\n\nA way of planning with a wider view of interests than just what we want right now, like our future selves, the people we care about, and the future of our children.\n\nSee also: [Community of Fate](thoughts/Community%20of%20Fate.md)","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Bias-in-Search":{"title":"Bias in Search","content":"\n*Term paper for INFO303*\n\n\u003e One of the critiques of search engines is a **lack of transparency and potential for bias in their algorithms**.  This issue has become even more critical now that Artificial Intelligence is a core search technology.  Review and critically assess these concerns in light of the growing body of research that seeks to address Algorithmic Bias in search.  What methods are available or proposed to address this issue?\n\n## Part I: a detailed description of the topic or issue\n\nThe scale of the web is huge, spanning many billions of web pages with a wide range of modalities (Teevan \u0026 Dumais in Ruthven \u0026 Kelly, 2011, p. 189). It is obvious that search is important for people to find what they need amidst the sprawling web we call the internet. Search engines connect its users with information resources that meet their information needs (Teevan \u0026 Dumais in Ruthven \u0026 Kelly, 2011, p. 192).\n\nSearch engines, then, are like gateways to the information on the web, allowing easy and universal access to online information to all of its users, and defining what is relevant, knowable, and authoritative. On the other hand, these arbiters of digital information can also create embedded biases that cause knowledge disparity and allow for ill-informed decision making for information-seekers (Gao \u0026 Shah, 2021, p. 2643; Friedman \u0026 Nissenbaum, 1996). \n\nThis paper seeks to critically examine some critique leveraged at these search engines around lack of transparency and potential for bias in their indexing, search, and ranking algorithms and conducts a brief survey over different methods of mitigating or addressing these issues.\n\nFirst, let us cover some basic terminology around what lack of transparency and bias mean in the context of this paper. \n\nIn conjunction with the rise of large language models for understanding queries, search has become very difficult to 'explain'. The problem is no longer understanding a transparent algorithm (like PageRank), but rather finding out exactly *why* the search engine result gave the result it did. Current search engines lack any indication of how they use your personal data to personalize the results, how the language model understands your query, or what determines search ranking. Diakopoulos and Koliska refer to this phenomena as a lack of *algorithmic transparency*. Transparency itself is the disclosure of information about algorithms to enable monitoring, checking, criticism, or intervention by interested parties (Diakopoulos \u0026 Koliska, 2017).\n\nAdditionally, search engines are not the fully neutral, mathematically absolute systems they sometimes claim to be. Instead, they have embedded biases that inherently favour some values over others, for example favouring some types of sites over others in query results. Here, we use Friedman and Nissenbaum's definition of bias from their influential work *Bias in computer systems*: \"[bias refers] to computer systems that systematically and unfairly discriminate against certain individuals or groups of individuals in favour of others... A system discriminates unfairly if it denies an opportunity or a good or if it assigns an undesirable outcome to an individual or group of individuals on grounds that are unreasonable or inappropriate\" (1996, p. 332). For example, the orderings of results themselves can create exposure bias due to their considerable impacts on relevance and click-through rates. It is clear that biases that are woven in search systems are becoming increasing threats to information seeking and sense-making processes (Friedman \u0026 Nissenbaum, 1996).\n\n## Part 2: an analysis of the associated societal benefits/harms and ethical issues\n\nHowever, the impact of these search systems go much deeper than making it hard to find what you are looking for. If these search engines are gatekeepers, then they also influence the values that surround what is being searched for. This means that minority groups often have their own values and identities influenced by the majority: a form of double-consciousness that Safiya Umoja Noble describes in her seminal work *Algorithms of Oppression* (Noble, 2018). If the majority rules in search engine results, then how might those who are in the minority ever be able to influence or control the way they are represented in a search engine?\n\nFurthermore, Ali Alkhatib's work paints an even grimmer possible future where algorithmic systems live in a sort of potemkin village or pseudo-reality of their own construction that they see the world as (Alkhatib, 2021). Large search engine companies like Google have massive stores of personal data in the attempts of modelling and predicting who we are and what we will do next (Pariser in Alkhatib, 2021). In doing so, these algorithmic systems produce a simplified yet inaccurate view of the world. However, the problem is not in creating these models, but from projecting the models onto the world to try and create change. These systems become more actively dangerous when they go from \"making sense of the world\" to \"making the world make sense\" (Alkhatib, 2021).\n\nOf course, this is exactly what these search engines are doing. They attempt to use these models to alter what information they feed to us, which in turn shapes our information seeking behaviour and what we know. Pariser (2011) points out that \"[search personalization] serves up a kind of invisible autopropaganda, indoctrinating us with our own ideas, amplifying our desire for things that are familiar and leaving us oblivious to the dangers lurking in the dark territory of the unknown\".\n\nThe problem is exacerbated when these 'abridged maps' of the world start diverging from reality and people can't override the delusions baked into those imaginations. Echoing Noble's earlier work, this creates vicious cycles of unfairness where users frequently only click on the top results, a ranking or recommendation algorithm that takes user feedback into account will continue putting those same items at the top, reinforcing what the algorithm *believes* to be true about the world. As the power dynamics unfold and play out, the system drifts further and further away from reality (Gao, Ge, \u0026 Shah, 2021). This is why data and power monopolies are so dangerous. These bureaucracies that have no power to self-correct (or allow themselves to be corrected) leads to a world where people cannot freely walk away or reject the bureaucracy's nonsense model of the world (Alkhatib, 2021). If there is no way for the users to speak up and to demand change, then it becomes an Orwellian nightmare where these search engines become sources that dictate *truth*.\n\nThe large scale usage of these search engines have now changed their positions in society from aggregators of information to arbiters and oracles of truth. Historically, search algorithms relied on perhaps complex algorithms but all they did was rank literally whats relevant and ask the user to determine what info they actually need with respect to their query. Now, more search engines are leaning into trying to tell you the 'right' answer in an effort to reduce the number of clicks it takes for the average user to find the answer they are looking for. Yet none of these results are actually *objective.* These engines freely provide \"a sorting of the wheat from the chaff, and answer our most profound and most trivial questions\" and in doing so, become an object of faith (Noble, 2018). Cathy O'Neil likens search engines to objects of faith: \"Like gods, these mathematical models were opaque, their workings invisible to all but the highest priests in their domain: mathematicians and computer scientists\" (2016). Many searchers view the results of these searches as objective truth.\n\nThis misconception of search engines as sources of truth leads to epistemologically irrational behaviour where searchers take the answer of these algorithms without critically examining them or performing their own further research.\n\n## Part 3: a discussion of how the issue can or should be addressed to minimize negative impacts and increase benefits.\n\nWith such a significant problem with one of the most critical pieces of our modern day information seeking, many have attempted to try to mitigate some of the negative impacts of these search systems. The following section briefly surveys a variety of different methods for addressing these problems.\n\n### Fairness-aware Algorithms\nOne such approach are fairness-aware algorithms which aim to integrate metrics of diversity and fairness along with more traditional IR metrics like relevance and novelty. We look to Gao, Ge, and Shah's 2021 work on *FAIR: Fairness-aware information retrieval evaluation* as a case study. \n\nThey define fairness as the subjective moderation of the ratio between different groups (p. 1). This approach to fairness comes from a more social perspective which attempts to moderate the exposure of information so that \"different information and resources get fair chances to receive users' attention\" (p. 2).  They argue that search currently does a poor job of distributing attention across a diverse set of results and that we should look to fairness-aware algorithms where \"different items should receive equal exposure, or exposure proportional to their utilities or impacts\" (p. 3).\n\nTo do so, they propose to optimize directly for an *integrated* metric -- arguing that fairness and utility are not necessarily orthogonal and optimizing for one does not necessarily lead to a decline in quality in another.\n\nOf course, this is not without limitations either. Fairness-aware algorithms like FAIR seem promising but have yet to see more mainstream adoption from large search companies. Additionally, FAIR is designed with a focus on group fairness rather than individual fairness (p. 11), which makes it much more difficult to adapt to the standard of personalized search we see today.\n\n### Algorithmic Transparency\nAnother method is to vie for more explainable search systems. Explainable recommendation and search, as defined by Zhang, Zhang, and Zhang, are \"models or methods that not only generate high-quality recommendation or search results, but also intuitive explanations of the results for users or system designers, which can help to improve the system transparency, persuasiveness, trustworthiness, and effectiveness, etc.\" (p. 1411).\n\nWork done by Rader, Cotter, and Cho show potential for including *explanations* in search rankings and feed as ways of improving algorithmic transparency about how the search engine result arrived at its answer (2018), citing what factors contributed to why certain results appear to users.\n\nHowever, this method is not without critique either. Some mention that revealing the ranking algorithm would lead to catastrophe, given the adversarial stance between search and spammers and SEOs. Granados and Gupta agree, citing that while transparency can be seen as beneficial to engendering trust, \"seeing the inner workings of a government, business, or newsroom can result in negative implications such as undermining competitive advantages or creating costs without concomitant gains\" (Granados \u0026 Gupta cited in Diakopoulos \u0026 Koliska, 2017).\n\nDiakopoulos and Koliska noted that participants in their study recognized this issue but still found it did not detract from the necessity of transparent systems, citing that \"people will game the system no matter what, and that by disclosing information publicly it would level the playing field\" (2017). Leveling the playing field, in this context likely refers to healthy competitive advantage that prevents the same monopolies of power that Alkhatib's work mentioned.\n\n### Algorithmic Accountability\nAnother potential approach is to better hold search engine companies accountable for the results of search rather than making the algorithms themselves explicitly transparent.\n\nKrafft, Reber, Krafft, Coutrier, and Zweig define the concept of algorithmic accountability, which focuses on the behavior of the algorithm or the algorithmic system in question which has to be justified and explained by the person or company who puts it in use (Krafft \u0026 Reber, et al. 2021).\n\nThis approach is more of a 'black-box' approach which doesn't require a transparent understanding of how the algorithmic system works for it to be held accountable, only for the effects to be known. Krafft et. al. specifically note this advantage over approaches that focus on transparency, citing that with accountability approaches, the workings of the algorithms themselves usually \"remain undisclosed or obfuscated by design as they constitute trade secrets whose disclosure would allow gaming the system\" (p. 2).\n\nThe ACM similarly outlines 7 principles for algorithmic transparency and accountability (ACM, 2017): awareness, access and redress, accountability, explanation, data provenance, auditability, and validation and testing. The main focus that the ACM is trying to drive is that groups affected by these algorithmic systems should be able to 1) be aware of biases + risks, 2) have enough context and data to have informed feedback, and 3) have a way to give feedback and hold the systems and their creators accountable.\n\nHaving human and legal entities take responsibility for the actions of their algorithms helps to prevent cases where people blame algorithms and data for being biased in order to shift the responsibility off of themselves. This form of human-in-the-loop computer system helps to prevent the algorithmic model of the world from being too detached from the real one.\n\n### Personal Search Engines\nPerhaps a more radical approach that is less explored in the academic space is one that advocates instead of extreme personalization (and thus bias) in search.\n\nEric Goldman in fact strongly advocates for this approach, suggesting that perhaps problems involving *objectivity* in these search engines that claim to be arbiters of truth to be solved by increasing *subjectivity* through the form of personalization in these results (Goldman, 2008). If each search is tailored to the individual, it is not espousing on *truth* to anyone, it will rather be a suggestion than an objective truth.\n\nGoldman goes on further to say that increasingly personalized search algorithms will \"reduce the effect of search engine bias because there will likely be multiple ‘top’ search results of a particular search term instead of a single winner [and] personalized algorithms will eliminate many of the current concerns about search engine bias\" (p. 130). \n\nSari Azout advocates for a world in which search engines are not universal, but rather boutique and personal (Azout, 2021). The big thing here is that universal search sites like Google use the same interface to search everything, relying on natural language to decipher user intentions. Vertical search players like Yelp/Zillow use domain specific knowledge to take away some of the guessing that universal search needs to go through by encoding it through structured search formats appropriate to the medium.\n\nIn this model of search, search engines are not oracles but rather another opinion for you to consider you in your information-seeking journey.\n\n### Conclusion\nIt does not feel like there is a single 'silver bullet' solution to bias and lack of transparency in the search space. If it was that easy, I'm sure it would have been developed and implemented already. This is clearly a nuanced space with a lot of interplaying factors that make it hard to find any one 'objectively good' solution to these problems.\n\nLike Krafft and Reber mention in their paper analyzing challenges in black box analyses, \"search engines, like most other algorithmic systems embedded in a complex socio-technical system, are not a stable research subject\" (Krafft \u0026 Reber, et al. 2021). The search experience is constantly changing due to companies running A/B tests to optimize their advertisement conversion numbers and user engagement, world events that affect what is popular and searched for, previous search behaviour that affects the engine's model of you and the world (Krafft \u0026 Reber, et al. 2021). These are just a few of the many problems search engine researchers come across when trying to be exact in their science of dissecting and probing these algorithmic systems.\n\nThese systems are so deeply entrenched within our society that there is no way to 'isolate' changes in any one part of the system. It is incredibly hard to prod and fix these issues when they are constantly changing and adapting, but that doesn't mean there hasn't been good attempts in the space to address it. At the end of the day, web search is integral to how we conduct increasingly online portions of our lives. The least we can do is to make sure that it works equitably and well for everyone who needs to use it.\n\n## Citations\n1. Ruthven, I., \u0026 Kelly, D. (Eds.). (2011). _Interactive information seeking, behaviour and retrieval_. Facet publishing.\n2. Gao, R., \u0026 Shah, C. (2021, July). Addressing bias and fairness in search systems. In _Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval_ (pp. 2643-2646).\n3. Friedman, B., \u0026 Nissenbaum, H. (1996). Bias in computer systems. _ACM Transactions on Information Systems (TOIS)_, _14_(3), 330-347.\n4. Diakopoulos, N., \u0026 Koliska, M. (2017). Algorithmic transparency in the news media. _Digital journalism_, _5_(7), 809-828.\n5. Rader, E., Cotter, K., \u0026 Cho, J. (2018, April). Explanations as mechanisms for supporting algorithmic transparency. In _Proceedings of the 2018 CHI conference on human factors in computing systems_ (pp. 1-13).\n6. Noble, S. U. (2018). Algorithms of oppression. In _Algorithms of Oppression_. New York University Press.\n7. Alkhatib, A. (2021, May). To live in their utopia: Why algorithmic systems create absurd outcomes. In _Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems_ (pp. 1-9).\n8. Pariser, E. (2011). _The filter bubble: How the new personalized web is changing what we read and how we think_. Penguin.\n9. Gao, R., Ge, Y., \u0026 Shah, C. (2021). FAIR: Fairness-Aware Information Retrieval Evaluation. _arXiv preprint arXiv:2106.08527_.\n10. O'neil, C. (2016). _Weapons of math destruction: How big data increases inequality and threatens democracy_. Broadway Books.\n11. Zhang, Y., Zhang, Y., \u0026 Zhang, M. (2018, June). SIGIR 2018 workshop on explainable recommendation and search (EARS 2018). In _The 41st International ACM SIGIR Conference on Research \u0026 Development in Information Retrieval_ (pp. 1411-1413).\n12. Krafft, T. D., Reber, M., Krafft, R., Coutrier, A., \u0026 Zweig, K. A. (2021, April). Crucial challenges in large-scale black box analyses. In _International Workshop on Algorithmic Bias in Search and Recommendation_ (pp. 143-155). Springer, Cham.\n13. Council, ACM US Public Policy (2017). Statement on algorithmic transparency and accountability. _Commun. ACM_.\n14. Goldman, E. (2008). Search engine bias and the demise of search engine utopianism. In _Web Search_ (pp. 121-133). Springer, Berlin, Heidelberg.\n15. Azout, S. (2021, October 18). _Re-organizing the world's information: Why we need more boutique..._ Re-Organizing the World's Information: Why we need more Boutique... - Sari Azout. Retrieved April 12, 2022, from https://sariazout.mirror.xyz/7gSSTJ96SEyvXeljymglO3zN4H6DCgVnrNZq8_2NX1A","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/BitTorrent":{"title":"BitTorrent","content":"\nSuppose some N (could be 1) machines have one file and another M (could be very large) machines want the file.\n\nCould be very slow: limited by the throughput possible by those N machines. Peer to peer could speed this up!\n\n- N hosts are called 'seeds'\n- Hosts are called peers\n- As soon as one of the M peers has a portion of the file it can share it with other peers\n\nThe file is broken into many pieces\n- Generally fixed size except for the last one\n- Protected by a cryptographic hash (allows reliable detection of corruption)\n\nA summary (torrent file) gives the necessary start up information\n- How many pieces there are\n- The hash of each piece\n- Somewhere to start looking for peers\n\nBasic operation\n- Finding other peers\n\t- Seeds or trackers to start with\n\t- Peer exchange: each peer 'gossips' about the peers they know about\n\t- Group of peers for one file is a \"swarm\"\n\t- Each peer talks to some subset of the \"swarm\" at any time\n- Finding pieces\n\t- Each peer shares the identity of the pieces they own with its peers\n\t- A peer asks a peer who has the file to share it\n\nGenerally\n- A peer asks for the 'rarest' piece which increases the overall 'health' of the file\n- Prioritize ones that are sending the most data to it (preferred peers) -- tit-for-tat\n\t- Discourages 'selfish' behaviour where peers accept pieces but don't share many pieces\n\t- Opportunistic unchoking\n\t\t- Randomly choose a peer sometimes (prevents problems at the start where there aren't many peers)\n- Unpopular/rare files can be hard to find seeds for\n\nIt is an open [protocol](thoughts/Protocol.md), most implementations use [TCP](thoughts/TCP.md)\n","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Bluesky":{"title":"Bluesky","content":"\n## ADX\nFrom [ARCHITECTURE.md](https://github.com/bluesky-social/adx/blob/main/architecture.md)\n\nBluesky is building a protocol for large-scale distributed social applications, and in doing so released ADX (Authenticated Data eXperiment)\n\nIn ADX, user social data will live in Personal Data Repositories (PDR) owned by the user.\n\nWhile these components are common to peer-to-peer networks, ADX uses a federated networking model. [[thoughts/federation|Federation]] was chosen to ensure the network is convenient to use and reliably available.\n\nADX then creates a larger, more interconnected view of the network by crawling the PDRs with indexers.\n\n\u003e Google collects, ranks, and filters that content into a service that it surfaces for users when they search. Our \"Crawling Indexers\" are much the same, except they collect the content for social applications.\n\n\n### Moderation\n\u003e Decentralizing components of existing social networks is about creating a balance that gives users the right to speech, and services the right to provide or deny reach.\n\nOur model is that _speech_ (data, networking) and _reach_ (crawling, aggregation, algorithm) should be two separate layers, built to work with each other. The “speech” layer should remain neutral, distributing authority and designed to ensure everyone has a voice. The “reach” layer lives on top, built for flexibility and designed to scale.\n\nThere's no one company that can decide what gets published; instead there is a marketplace of companies deciding what to carry to their audiences.\n\n![[thoughts/images/speech and reach layers.png]]\n\n### DID Consortium\nSource of truth for DIDs on ADX, operated by multiple different operators (organizations) who share ownership of service. They all operate a shared append-only log. Client send transactions to operators. Auditors can monitor the append-only log to ensure the consortium is operating as it should.\n\n### Key management\nWe believe users should be given the options to use both custodial and non-custodial solutions. Key management is (at this stage) difficult for average consumers and so a custodial solution should be made available, but for professionals and security-conscious users a non-custodial option should also be supported.\n\nThe key manager has the following responsibilities:\n- Store root private keys\n- Publish updates to the users' [[thoughts/DID|DID]] Documents\n- Create delegated keypairs through [[thoughts/UCAN|UCAN]] issuance\nHandle recovery flows in the event of key loss","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Bluetooth":{"title":"Bluetooth","content":"\n\n![[thoughts/images/BLE communication workflow.png]]\n\nClasses:\n- CBCentralManager \u0026 CBCentralManagerDelegate\n\t- Are responsible to check that Bluetooth is ON and then to scan, discover, connect, and manage peripherals.\n- CBPeripheral \u0026 CBPeripheralDelegate\n\t- Represents physical BLE devices as they were discovered by CBCentralManager. They are identified by UUID (universally unique identifier) which contains one or more services.\n\t- Generally, peripherals public data to central delegates\n- CBService\n\t- Represents service physical BLE device, and provide data associated behaviors and characteristics given BLE-device.\n- CBCharacteristics\n\t- Represent the data of the device’s service and contains a single value. Here is where we can read, write, and subscribe to the data from the device (ex: battery level, temperature, LED light).","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Braid-HTTP":{"title":"Braid HTTP","content":"Braid's goal is to extend [[thoughts/HTTP|HTTP]] from a state transfer protocol to a state sync protocol, in order to do away with custom sync protocols and make state across the web more interoperable.\n\nBraid puts the power of operational transforms and [[thoughts/CRDT|CRDTs]] on the web, improving network performance and enabling natively [[thoughts/peer-to-peer|p2p]], collaboratively-editable, [[thoughts/local-first software|local-first]] web applications.\n\nIt turns out that HTTP is very close to being a HTSP, we just need to add 5 headers to requests and responses as well as a new status code `209 Subscription`.\n\nFrom the [IETF Internet Draft](https://raw.githubusercontent.com/braid-work/braid-spec/master/draft-toomim-httpbis-braid-http-03.txt)","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Brains-in-a-Vat":{"title":"Brains in a Vat","content":"\n## Brain in a Vat\n- [Putnam's Ant Argument](thoughts/Putnam's%20Ant%20Argument.md): does intentionality matter for representation?\n- Related to [virtual worlds](thoughts/virtual%20worlds.md) and the Matrix\n-   we all live in a \"collective hallucination\", i believe you exist and i can tell you think and hear things\n-   could we say/think/believe that we are brains in a vat?\n-   putnam states that this argument is false as it is self-refuting\n\t1.  Assume we are brains in a vat\n\t2.  If we are brains in a vat, then “brain” does not refer to brain, and “vat” does not refer to vat (via CC)\n\t3.  If “brain in a vat” does not refer to brains in a vat, then “we are brains in a vat” is false\n\t4.  Thus, if we are brains in a vat, then the sentence “We are brains in a vat” is false (1,2,3)\n-   are the things that BIVs refer to the same things that we as real people refer to?","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Brentanos-Thesis":{"title":"Brentano's Thesis","content":"\n[Intentionality](thoughts/intentionality.md) is the mark of the mental. His thesis posits two points:\n1. All mental phenomena exhibit intentionality\n2. Only mental phenomena exhibit intentionality\n\nAll mental phenomena exhibit intentionality.\n- Rephrased: Is mentality sufficient for intentionality?\n- What about pain, feelings, moods? These can be accounted for. Physical pain can have a place, the felt location can cause a plausible difference in intentionality (what the mental state is directed at). Depression may seem to be general, but can be characterized as overall \"world suck\" but the world is still a subject\n\nOnly mental phenomena exhibit intentionality\n-   Rephrased: is mentality necessary for intentionality?\n-   Are minds the only things that have intentionality? To prove this wrong, we need to find something with intentionality that doesn't have a mind\n-   What about words / pictures / maps? These only exhibit derived intentionality and are interpreted rather than having intrinsic intentionality","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Buddhism":{"title":"Buddhism","content":"\n## Four Noble Truths\n1. Dukkha (Suffering) is an innate characteristic of existence\n2. Samudaya (Origin/Cause) of suffering is tanhā (craving) and fundamental ignorance. We believe we are a separate, [independent existence](thoughts/emptiness.md)\n3. Nirodha (Cessation) of suffering comes from letting go of this tanhā\n4. Magga (The path) leading to nirodha","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Byzantine-Agreement":{"title":"Byzantine Agreement","content":"\nDiffers from [[thoughts/Byzantine Broadcast|Byzantine Broadcast]]\n\nEvery node has a private input, there is no distinguished sender.  All non-Byzantine nodes need to agree on a single common value.","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Byzantine-Broadcast":{"title":"Byzantine Broadcast","content":"\nIn Byzantine broadcast (BB) or Byzantine reliable broadcast (BRB), there is a designated sender that sends its input value to all parties, and all non-[[thoughts/fault tolerance|faulty]] parties must deliver the same value.\n\nOne way to do it is using a single leader, but what happens if the leader crashes/becomes unavailable? Manual failover: human operator chooses a new leader and reconfigures each node to use new leader, but this is non-ideal.\n\n- Common consensus algorithms (all assume partially synchronous, crash-recovery [[thoughts/system model|system model]])\n\t- Paxos: single-value consensus\n\t- Multi-Paxos: generalization to [[thoughts/message broadcast#Total order broadcast|total order broadcast]]\n\t- [[thoughts/Raft Consensus Algorithm|Raft]], Viewstamped Replication, Zab: [[thoughts/message broadcast#Total order broadcast|total order broadcast]] by default\n- Blockchain consensus models assume partially synchronous Byzantine [[thoughts/system model|system model]]\n\n[[thoughts/FLP Result|FLP Result]] states that these consensus algorithms cannot assume an *asynchronous* [[thoughts/system model|system model]] without giving up either [[thoughts/safety|safety]] or [[thoughts/liveness|liveness]].\n\nAssumptions:\n1. Honest users all output a message if the leader is honest (termination)\n2. Honest users never output different messages (consistency)\n\nFor all approaches below, we assume\n1. Public Key Infrastructure exists (i.e. nodes know the mapping of public key to entity)\n2. Internet exists (i.e. there is a reliable way to send message between nodes)\n\nWe denote $f$ as the number of Byzantine nodes\n\n## Naive Approach\nReliant on a synchronous [[thoughts/system model#Timing behaviour e g latency|system model]]\n\n1. `t=0`: sender sends a signed value $v^*$ to all other nodes\n2. `t=1`: nodes echo msg from sender to all other nodes, signed again (cross-checking)\n3. `t=2`: each node $i$ chooses output $v_i$ by majority vote (at most one vote from sender, at most $n-2$ from other peers). Break ties consistently (e.g. lexicographically)\n\nSolves BB for $f \\leq 1$, $n \\geq 4$. Doesn't hold for Byzantine sender, only Byzantine peers.\n\n## Dolev-Strong (1983)\nTrying to generalize the naive approach for potentially Byzantine senders by utilizing [[thoughts/digital signatures|signature]] chains\n\nIn essence, node $i$ is only convinced of value $v$ at time $t$ if it receives a message that\n- references the value $v$\n- is signed first by the sender\n- is also signed by $\\geq t-1$ other distinct nodes (none of which are node $i$)\n\nThe principle is to only accept a value in the last round if its contents can certify that all parties have received this value. This leads to a very powerful idea in the synchronous model: The validity of a message is a function also of the time it is received\n\nAt the end of $f$ rounds of cross-checking (one round per possible Byzantine node), if node $i$ is convinced of exactly one value, that is the correct value. Otherwise, output the. default value (e.g. an empty list of txs)\n\nSolves BB for $f \u003c n$, but really only useful at $f \u003c \\frac n 2$ for [[thoughts/State Machine Replication (SMR)|state machine replication]]. If $f \u003c \\frac n 2$ then we can take majority vote to arrive at consistent state (not the case if $f \\geq \\frac n 2$). This bypasses the [[thoughts/PSL-FLM Impossibility Result|PSL-FLM Impossibility Result]] because we assume [[thoughts/Public-key Infrastructure|PKI]] exists","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Byzantine-Faults":{"title":"Byzantine Faults","content":"\nSources: [Byzantine Faults on *Wikipedia*](https://en.wikipedia.org/wiki/Byzantine_fault) and [Paper on the Byzantine Generals Problem](https://lamport.azurewebsites.net/pubs/byz.pdf)\n\nA **Byzantine fault** is any fault presenting different symptoms to different observers. A **Byzantine failure** is the loss of a system service due to a Byzantine fault in systems that require [consensus](thoughts/consensus.md) between nodes.\n\nByzantine fault tolerance (BFT) is the property of a system that is able to resist the class of failures derived from the Byzantine Generals’ Problem. This means that a BFT system is able to continue operating even if some of the nodes fail or act maliciously.\n\nSee also: [[thoughts/Byzantine Broadcast|Byzantine Broadcast]], [[thoughts/PBFT|PBFT]]","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/CALM-Theorem":{"title":"CALM Theorem","content":"\n\u003e Consistency As Logical Monotonicity\n\nLogically monotonic distributed code is [[thoughts/consistency|eventually consistent]] without any need for [[thoughts/consensus|consensus]] protocols (distributed locks, two-phase commit, etc.)\n\nSee also: [[thoughts/CRON Theorem|CRON Theorem]], [[thoughts/I-Confluence]]\n\nLogically monotonic state is something that can be represented using [[thoughts/Order theory|join semi-lattice]].\n\nBasically, avoid coordination where possible. It’s the dominant term in the [Universal Scalability Law](https://blog.acolyer.org/2015/04/29/applying-the-universal-scalability-law-to-organisations/). When we can avoid or reduce the need for coordination things tend to get simpler and faster.\n\n## Monotonicity and Datalog\nMonotonic properties arise from things in the form of a $\\exists$ question (the presence of one positive example gives us an answer in the affirmative and additional positive examples don’t change that fact). Non-monotonic properties arise from things in the form of a $\\forall$ question (can only answer a question like that once we’ve looked at every example). Example of the later also include $! \\exists$, the negation property.\n\nWhat we’ve learned from these examples is that negation and universal quantification mess with monotonicity.\n\nThus, we can also express CALM in terms of a programming language like [[thoughts/Datalog|Datalog]]: \n\n\u003e A program has an eventually consistent, coordination-free execution strategy if and only if it is expressible in (monotonic) Datalog.\n\nIn fact, this is what Bloom is based off-of. Bloom is underpinned by a programming language called Dedalus which is a Datalog variant that cleanly captures what we see as the salient semantic issues for parallel and distributed computing","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/CAP-Theorem":{"title":"CAP Theorem","content":"\nWhen designing and deploying applications in distributed environments, you can only optimize for 2 out of the following 3 properties:\n\n1. [[thoughts/consistency|Consistency]]: a system operates fully or not at all, all nodes agree (the system's behaviour is indistinguishable from a centralized system)\n2. **A**vailability: system is always able to answer a request\n3. **P**artition Tolerance: if data is distributed and some nodes fail, the whole system and continue to function\n\nOne way to illustrate this is to imagine a set of clusters trying to agree on a value. There is a network partition between two groups of nodes in the cluster called A and B. They all initially have a value `x = 0`.  A client ever issues a command `x = 1` to a node `i` in A and sometime in the future, a client issues another command `return x`.\n1. If node `i` ever returns 1, this violates consistency as B cannot have heard of the update from A.\n2. If it only ever answers 0, this violates availability as `x = 1` was never appropriately set.\n\nACID vs BASE\n- ACID stands for atomicity, consistency, isolation, durability\n\t- Prioritizes C and A\n\t- Immediate consistency limits scale-out performance\n- BASE stands for basically available, soft state, eventual consistency\n\t- Prioritizes A and P\n\t- Scale-out performance is greatly enhanced\n\t- Fine when nature of the data can tolerate some imprecision in query results","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/CID":{"title":"CID","content":"\nSummarized from [Github Specification](https://github.com/multiformats/cid)\n\n\u003e Self-describing content-addressed identifiers for distributed systems\n\nBasically a hash with some metadata. CID is a self-describing format for referencing content, it is a form of [[thoughts/content addressed storage|content addressed storage]]. \n\nFormat: `\u003ccidv1\u003e ::= \u003cmultibase-prefix\u003e\u003cmulticodec-cidv1\u003e\u003cmulticodec-content-type\u003e\u003cmultihash-content-address\u003e`\n\nWhere\n- `\u003cmultibase-prefix\u003e` is a multibase code (1 or 2 bytes), to ease encoding CIDs into various bases. NOTE: Binary (not text-based) protocols and formats may omit the multibase prefix when the encoding is unambiguous.\n- `\u003cmulticodec-cidv1\u003e` is a multicodec representing the version of CID, here for upgradability purposes.\n- `\u003cmulticodec-content-type\u003e` is a multicodec code representing the content type or format of the data being addressed.\n- `\u003cmultihash-content-address\u003e` is a multihash value, representing the cryptographic hash of the content being addressed. Multihash enables CIDs to use many different cryptographic hash function, for upgradability and protocol agility purposes.\n\n## IPVM\n[Brooklyn Zelenka from Fission Codes on IPVM](https://fission.codes/blog/ipfs-thing-breaking-down-ipvm/)\n\nCID-based computation also means that we can use [memoization](https://en.wikipedia.org/wiki/Memoization) to inform us if an operation has been run before so we can optimize our efforts and copy the CIDs of those outputs into our work, saving time and compute power.","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/CRDT":{"title":"Conflict-free Replicated Data Type (CRDT)","content":"\nProvides [[thoughts/causality|causal consistency]] as well as [[thoughts/consistency#Eventual Consistency|strong eventual consistency]]: over time, all actors converge to same state without data loss *but* there is no guarantee of exact same state across actors at any given moment (not [[thoughts/consistency#ACID Consistency|ACID]]).\n\n\u003e Note: In general, maintaining global invariants (e.g. shapes such as a tree or a DAG), cannot be done by a CRDT. Global invariant cannot be determined locally; maintaining it requires synchronisation.\n\nCRDTs should always strive to preserve user intent.\n\nTwo main families of CRDTs are operation-based and state-based CRDTs. They have their trade offs\n1. Operation-based\n\t- generally smaller messages\n\t- requires [[thoughts/causality#Causal Order|causally-ordered delivery]] for messages\n\t- can be more complex because it requires reasoning about history\n2. State-based\n\t- can tolerate message loss/duplication \n\t- requires [[thoughts/message broadcast#Best-effort|best-effort broadcast]] delivery for messages\n\nSee example implementations here: [[thoughts/CRDT Implementations|CRDT Implementations]]\n\n## Causal Consistency\nCausality is in each change (delta) as a [[thoughts/clocks#Vector Clocks|vector clock]] which encodes all of that delta's causal dependencies. Each delta is then queued until its vector clock is complete.\n\n## Operation-based\n\u003e Sometimes also called commutative replicated data types (CmRDT)\n\nReplication requires one of the following assumptions:\n- all concurrent operations to commute given **[[thoughts/causality#Causal Order|causal ordering]]** (most common)\n- all operations to commute given no ordering\n- all operations to commute and be idempotent if message duplication can occur\n\nHistory is kept through the notion of a causal history $\\mathcal{C}$\n- Initially, $\\mathcal{C}(x_i) = \\varnothing$\n- After executing the 2nd (downstream) phase of operation $f$, $\\mathcal{C}(f(x_i)) = \\mathcal{C}(x_i) \\cup \\{ f \\}$\n\n## State-based\n\u003e Sometimes also called convergent replicated data types (CvRDT)\n\nCan broadcast the values of the state using [[thoughts/message broadcast#Best-effort|best-effort broadcast]] and then merging using a defined merge operator $\\sqcup$.\n\nThe merge operator $\\sqcup$ must be:\n1. Commutative: $s_1 \\sqcup s_2 = s_2 \\sqcup s_1$\n2. Associative: $(s_1 \\sqcup s_2) \\sqcup s_3 = s_1 \\sqcup (s_2 \\sqcup s_3)$\n3. Idempotent: $s_1 \\sqcup s_1 = s_1$\n\nHistory is kept through the notion of a causal history $\\mathcal{C}$\n- Initially, $\\mathcal{C}(x_i) = \\varnothing$\n- After an update operation $f$, $\\mathcal{C}(f(x_i)) = \\mathcal{C}(x_i) \\cup \\{ f \\}$\n- After merging states $x_i$, $x_j$, $\\mathcal{C}(merge(x_i, x_j)) = \\mathcal{C}(x_i) \\cup \\mathcal{C}(x_j)$\nThe happens-before relation $\\leq$ is then defined as $f \\rightarrow g \\iff \\mathcal{C}(f) \\subset \\mathcal{C}(g)$\n\n## Delta-based (hybrid)\nDelta-based CRDTs propagate delta-mutators that encode the changes that have been made to a replica since the last communication.\n\nFor efficiency, CRDT implementations can 'hold on' to outbound events and compact/compress the log by rewriting operations (e.g. turning two `add(1)` operations into a single `add(2)` operation)\n\n[tk: Big delta state CRDTs]\n[tk: Join-decompositions]\n\n## Strategies for Designing CRDTs\nA CRDT can be specified by relying on:\n1. the full history of updates executed;\n2. the happens-before relation among updates; and\n3. an arbitration relation among updates (when necessary)\n\nA query can be specified as a function that uses this information and the value of parameters to compute the result (i.e. goes from the state to a value).\n\n### Conflict Resolution\n- Add-wins\n- Remove-wins\n- Last-writer-wins\n\n### Secure CRDTs\n- tk: what does encryption in CRDTs look like? homomorphic encryption for merge operations for example\n- https://martin.kleppmann.com/papers/snapdoc-pets19.pdf\n- http://www.complang.tuwien.ac.at/kps2015/proceedings/KPS_2015_submission_25.pdf\n\n### Fault Tolerance\nHow can we make CRDTs [[thoughts/Byzantine Faults|Byzantine fault-tolerant]]?\n\n[Kleppmann shows](https://martin.kleppmann.com/papers/bft-crdt-papoc22.pdf) that is possible to guarantee the standard CRDT consistency properties even in systems in which *arbitrarily many* nodes are Byzantine.\n\nCRDTs can become BFT by ensuring eventual delivery and convergence even in the presence of Byzantine nodes.\n\nThe main construct here is constructing a hash graph (aka a [[thoughts/Merkle-DAG|Merkle-DAG]]): The graph is essentially the Hasse diagram of the partial [[thoughts/Order theory|order]] representing the [[thoughts/causality|causality]] relation among the updates. The ID of an operation is the hash of the update containing that operation. A 'head' is just an operation which is not a dependency of another operation.\n1. This hash graph helps to ensure eventual consistency as two nodes $p$ and $q$ can exchange the hashes of their currents heads and if they are identical, they can ensure the set of updates they have observed is also identical.\n2. If the heads of $p$ and $q$ are mismatched, the nodes can run a graph traversal algorithm to determine which parts of the graph they have in common, and send each other those parts of the graph that the other node is lacking.\n\nSee: [[posts/bft-json-crdt]]\n\n## Performance\n### Storage + State Compaction\nPractical experience with CRDTs shows that they tend to become inefficient over time,\nas tombstones accumulate and internal data structures become unbalanced. The compacted portion of the CRDT must retain enough metadata to allow future operations to reference it on an atomic level and order themselves correctly. From the outside, a compacted CRDT must continue to behave exactly the same as a non-compacted CRDT.\n\nHowever, GC + rebalancing technically requires achieving [[thoughts/consensus|consensus]] on nodes in order to do this.\n\n\u003e So, as far as I know, we would need a consensus protocol attached to the CRDT in order to get garbage collection / compaction. [(#2)](https://github.com/ipfs-inactive/dynamic-data-and-capabilities/issues/2)\n\nOne potential way of overcoming this is to have a small, stable subset of replicas called the core which achieve consensus amongst each other. The other replicas asynchronously reconcile their state with core replicas.\n\nSee also: [[thoughts/Antimatter]]\n\n### Exploiting good connectivity for stronger consistency\nUpgrading network assumption from asynchronous to partially synchronous enables us to potentially define *weak operations* which only *eventually* need to be linearized.\n\n## Unsolved Problems\n- Concurrent move + edit in sequences is unsolved\n\t- Almost all implementations cause duplication\n\n## Readings\n- [A comprehensive study of CRDTs](https://hal.inria.fr/inria-00555588/document) \n- [Conflict-free Replicated Data Types: An Overview](https://arxiv.org/pdf/1806.10254.pdf)","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/CRDT-Implementations":{"title":"CRDT Implementations","content":"\nAll examples below are written in pseudocode that happens to carry a lot of syntax from Typescript. Syntax liberties are taken where intention is clear\n\n## Spec\n### Op-based\nSee [[thoughts/CRDT#Operation-based|operation-based CRDTs]] for more properties\n\n```ts\n// the initial value of the data type (on each replicate)\ntype State = {\n\t...\n}\n\nclass OpCRDT\u003cState\u003e {\n\tstate: State\n\n\t// any function that computes a view of the payload and has no side effects\n\t// can return a value\n\t@query\n\tfunction query(...args: any[]): any {\n\t\tif (invariant) {\n\t\t\t// do something\n\t\t\treturn\n\t\t}\n\t}\n\t\n\t// any global function that take in arguments and has two phases\n\t@update\n\tfunction update(...args: any[]): Closure {\n\t\tif (local_invariant) {\n\t\t\t// phase 1: may compute results to be prepared as arguments for the second phase\n\t\t\t// includes precondition checks, etc.\n\t\t\t\n\t\t\t// phase 2: returns a closure to be run on all nodes, including this one\n\t\t\treturn (...) =\u003e {\n\t\t\t\tif (downstream_invariant) {\n\t\t\t\t\t...\n\t\t\t\t}\n\t\t\t}\n\t\t}\t\n\t}\n}\n```\n\n### State-based\nSee [[thoughts/CRDT#State-based|state-based CRDTs]] for more properties\n\n```ts\n// the initial value of the data type (on each replicate)\ntype State = {\n\t...\n}\n\nclass StateCRDT\u003cState\u003e {\n\tstate: State\n\n\t// any function that computes a view of the payload and has no side effects\n\t// can return a value\n\t@query\n\tfunction query(...args: any[]): any {\n\t\tif (invariant) {\n\t\t\t// do something\n\t\t\treturn\n\t\t}\n\t}\n\t\n\t// any function that when evaluated, has side-effects on the payload\n\t@update\n\tfunction update(...args: any[]) {\n\t\tif (local_invariant) {\n\t\t\t// do something\n\t\t}\t\n\t}\n\n\t// a function that compares two states in the semilattice (see: order theory)\n\t@compare\n\tfunction cmp(a: State, b: State): boolean {\n\t\t// is a \u003c= b in the semilattice?\n\t}\n\n\t// a function that performs a least-upper-bound merge on two states\n\t@merge\n\tfunction merge(a: State, b: State): State {\n\t\t// least-upper-bound merge on a and b at any replica\n\t}\n}\n```\n\n## Counters\n### Op-based\nThis implementation is trivially correct as both addition and subtraction commute\n\n```ts\ntype State = {\n\ti: number\n}\n\nclass OpCRDT\u003cState\u003e {\n\t@query\n\tvalue(): number {\n\t\treturn this.i\n\t}\n\t\n\t@update\n\tfunction increment(): Closure {\n\t\treturn (node) =\u003e node.i := node.i + 1\n\t}\n\t\n\t@update\n\tfunction decrement(): Closure {\n\t\treturn (node) =\u003e node.i := node.i - 1\n\t}\n}\n```\n\n### State-based\nInspired by vector clocks. Merge takes max of each entry so this forms a monotonic semilattice. We need two vectors as just operating on a single vector as max wouldn't even work if we included decrement.\n\nFor example, say you have two states `[1, 0, 1]` and `[1, 1, 1]`. You would never tell if the first one happens after the second (second node subtraction) or if the second one happens after the first (second node addition).\n\n```ts\ntype State = {\n\tplus: number[n];\n\tminus: number[n];\n}\n\nclass StateCRDT\u003cState\u003e {\n\t@query\n\tfunction value(): int {\n\t\treturn sum(this.plus) - sum(this.minus)\n\t}\n\t\n\t@query\n\tfunction increment() {\n\t\tconst id = this.id()\n\t\tthis.plus[id] = this.plus[id] + 1\n\t}\n\t\n\t@update\n\tfunction decrement() {\n\t\tconst id = this.id()\n\t\tthis.minus[id] = this.minus[id] + 1\n\t}\n\t\n\t@compare\n\tfunction cmp(x: State, y: State): boolean {\n\t\treturn zip(x.plus, y.plus).every((x_i, y_i) =\u003e x_i \u003c= y_i) \u0026\u0026\n\t\t\t   zip(x.minus, y.minus).every((x_i, y_i) =\u003e x_i \u003c= y_i)\n\t}\n\t\n\t@merge\n\tfunction merge(x: State, y: State): State {\n\t\treturn Payload {\n\t\t\tplus: zip(x.plus, y.plus).map((x_i, y_i) =\u003e max(x_i, y_i))\n\t\t\tminus: zip(x.minus, y.minus).map((x_i, y_i) =\u003e max(x_i, y_i))\n\t\t}\n\t}\n}\n```\n\n## Last-writer-wins Registers\nA register is a memory cell storing a single value.\n\n### Op-based\n`X` is an arbitrary type\n\n```ts\ntype State\u003cX\u003e = {\n\tval: X;\n\tt: number;\n}\n\nclass OpCRDT\u003cState\u003e {\n\t@query\n\tfunction value(): X {\n\t\treturn this.val\n\t}\n\n\t@update\n\tfunction assign(x: X): Closure {\n\t\tconst t_now = now()\n\t\treturn (node) =\u003e {\n\t\t\tif node.t \u003c t_now {\n\t\t\t\tnode.val = x\n\t\t\t\tnode.t = t_now\n\t\t\t}\n\t\t}\n\t}\n}\n```\n\n### State-based\nTimestamp is monotonic increasing so compare created a valid monotonic semilattice.\n\n```ts\ntype State\u003cX\u003e = {\n\tx: X;\n\tt: number;\n}\n\nclass StateCRDT\u003cState\u003e {\n\t@query\n\tfunction value(): X {\n\t\treturn this.val\n\t}\n\t\n\t@update\n\tfunction assign(x: X) {\n\t\tthis.t = now()\n\t\tthis.x := x\n\t}\n\t\n\t@compare\n\tfunction cmp\u003cX\u003e(x: State\u003cX\u003e, y: State\u003cX\u003e): boolean {\n\t\treturn x.t \u003c= y.t\n\t}\n\t\n\t@merge\n\tfunction merge\u003cX\u003e(x: State\u003cX\u003e, y:State\u003cX\u003e): State\u003cX\u003e {\n\t\t// return most recent write by logical clock\n\t\treturn cmp(x, y) ? y : x\n\t}\n}\n```\n\n## Sets\nA foundational data structure that form the basis of containers, maps, and graphs.\n\nNaively adding and removing from a set does not commute so we can only approximate the properties of a set.\n\nMost implementations below differ by how they handle concurrent $add(e) \\parallel remove(e)$\n\nFor example:\n- Grow-only set (G-Set) avoids remove altogether\n- 2-Phase set (2P-Set) is a variant where both add and remove are valid operations but an element cannot be re-added once removed\n- Unique set (U-Set) is an extension of 2-Phase set where we additionally assume elements are unique. Additional requirement that causal dependencies are respected (op-based CRDTs are sufficient to ensure this)\n- Add-wins set (OR-Set/AW-Set) supports both adding and removing elements. Add has precedence when an add and remove happen concurrently.\n\n### State-based 2P-Set\nThe compare function (checking to see if `x` comes before `y` in the semilattice) here is quite tricky and not immediately obvious why it is correct.\n- If `x.set` is a subset of `y.set`, then `x` must have come before `y` because nothing is ever removed from `set`\n- If `x.set` is the same set as `y.set`, then `x` can only have come before `y` if `x.removed` is a subset of `y.subset`\n- If `x.set` is not a subset of `y.set` then `x` cannot have come before `y`\n\n```ts\ntype State\u003cX\u003e = {\n\tset: Set\u003cX\u003e;\n\tremoved: Set\u003cX\u003e;\n}\n\nclass StateCRDT\u003cState\u003e {\n\t@query\n\tfunction has(x: X): bool {\n\t\treturn this.set.has(x) \u0026\u0026 !this.removed.has(x)\n\t}\n\t\n\t@update\n\tfunction add(x: X) {\n\t\tset.add(x)\n\t}\n\t\n\t@update\n\tfunction remove(x: X) {\n\t\tif has(x) {\n\t\t\tremoved.add(x)\n\t\t}\n\t}\n\t\n\t@compare\n\tfunction cmp\u003cX\u003e(x: State\u003cX\u003e, y: State\u003cX\u003e): boolean {\n\t\treturn x.set.is_subset_of(y.set) ||\n\t\t\t   x.removed.is_subset_if(y.removed)\n\t}\n\t\n\t@merge\n\tfunction merge\u003cX\u003e(x: State\u003cX\u003e, y:State\u003cX\u003e): State\u003cX\u003e {\n\t\t// return most recent write by logical clock\n\t\treturn Payload {\n\t\t\tset: union(x.set, y.set)\n\t\t\tremoved: union(x.removed, y.removed)\n\t\t}\n\t}\n}\n```\n\n### Op-based U-Set \nAgain, this op-based implementation assumes causal ordering in message delivering\n\n```ts\ntype State\u003cX\u003e = {\n\tset: Set\u003cX\u003e;\n}\n\nclass OpCRDT\u003cState\u003e {\n\t@query\n\tfunction has(x: X): boolean {\n\t\treturn this.set.has(x)\n\t}\n\t\n\t@update\n\tfunction add(x: X): Closure {\n\t\treturn this.set.add(x)\n\t}\n\t\n\t@update\n\tfunction remove(x: X): Closure {\n\t\tif this.has(x) {\n\t\t\t// due to causal ordering assumption, add(x) must have been delivered already\n\t\t\treturn (node) =\u003e node.set.remove(x)\n\t\t}\n\t}\n}\n\n```\n\n### Op-based AW-Set\nIntuition here is to generate a unique ID for each element added. Multiple `add`s will add multiple values and `delete` will delete all elements with the same value.\n\nConcurrent `add`s commute as each `add` is unique. If a concurrent `add` and `remove` happen, it also commutes as `add` has precedence.\n\n```ts\ntype State\u003cX\u003e = {\n\t// track element and uuid\n\tset: Set\u003c(X, number)\u003e;\n}\n\nclass OpCRDT\u003cState\u003e {\n\t@query\n\tfunction has(x: X): boolean {\n\t\treturn this.set.values.any((val, id) =\u003e val === x)\n\t}\n\n\t@update\n\tfunction add(x: X): Closure {\n\t\tconst id = uuid()\n\t\treturn (node) =\u003e node.set.add((x, id))\n\t}\n\n\t@update\n\tfunction remove(x: X): Closure {\n\t\tif this.has(x) {\n\t\t\tconst vals_to_delete = this.set.values.filter((val, id) =\u003e x === val)\n\t\t\treturn (node) =\u003e node.set.remove(vals_to_delete)\n\t\t}\n\t}\n}\n```\n\n\n## Sequences\nA sequence for text editing (or just sequence hereafter) is a totally-ordered set of elements, each composed of a unique identifier and an atom.\n\nFor the rest of this section, assume the following definitions\n\n```ts\nconst __LEFT: any = (\"START\", -1)\nconst __RIGHT: any = (\"END\", 0)\n\n// e.g., a character, a string, an XML tag, or an embedded graphic\ntype Atom = any\n\n// Timestamps are unique, positive, and increase consistently with causality\ntype T = number\ntype Vertex = (Atom, T)\n```\n\n\n### Replicated Growable Array (RGA)\nAutomerge the library uses this!\n\nRepresented as a 2P-Set of vertices in a linked list. \n\nEssentially,\n-   Build the tree, connecting each item to its parent\n-   When an item has multiple children, sort them by sequence number then by their ID.\n-   The resulting list (or text document) can be made by flattening the tree with a depth-first traversal.\n\n```ts\ntype State = {\n\t// 2P-Set of vertices\n\tv_added: Set\u003cVertex\u003e = [__LEFT, __RIGHT];\n\tv_rmved: Set\u003cVertex\u003e = [];\n\n\t// G-Set of edges\n\tedges: Set\u003c(Vertex, Vertex)\u003e = [(__LEFT, RIGHT)];\n}\n\nclass OpCRDT {\n\t@query\n\tfunction lookup(v: Vertex): boolean {\n\t\treturn this.v_added.has(v) \u0026\u0026 !this.v_rmved.has(v)\n\t}\n\n\t// is u before v in the sequence?\n\t@query\n\tfunction before(u: Vertex, v: Vertex): boolean {\n\t\tif this.lookup(u) \u0026\u0026 this.lookup(v) {\n\t\t\t// see if there is a valid path from u to v using dfs\n\t\t\tconst stack = [u]\t\t\t\n\t\t\twhile stack.length \u003e 0 {\n\t\t\t\tconst cur = stack.pop()\n\t\t\t\tif cur === v {\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tconst outgoing_vertices = this\n\t\t\t\t\t.edges\n\t\t\t\t\t.filter((_u, _v) =\u003e u === _u)\n\t\t\t\t\t.map((_, _v) =\u003e v)\n\t\t\t\t\t\n\t\t\t\tstack.push(...outgoing_vertices)\n\t\t\t}\n\t\t\treturn false\n\t\t}\n\t}\n\n\t@query\n\tfunction successor(u: Vertex): Vertex {\n\t\tif this.lookup(u) {\n\t\t\treturn this.edges.find((_u, _v) =\u003e u === _u)[1]\n\t\t}\n\t}\n\n\t@update\n\tfunction addRight(v: Vertex, x: Atom) {\n\t\t// ensure valid insert\n\t\tif v !== __RIGHT \u0026\u0026 this.v_added.sub(this.v_rmved).has(v) {\n\t\t\tconst t = now()\n\t\t\tconst w = (x, t)\n\t\t\t\n\t\t\treturn (node) =\u003e {\n\t\t\t\t// find right place to insert node\n\t\t\t\tif node.v_added.has(v) {\n\t\t\t\t\tconst l = v\n\t\t\t\t\tconst r = node.successor(v)\n\t\t\t\t\twhile true {\n\t\t\t\t\t\tconst _v, _t = r\n\t\t\t\t\t\tif t \u003c _t {\n\t\t\t\t\t\t\t// move forward one step\n\t\t\t\t\t\t\tl = r\n\t\t\t\t\t\t\tr = node.successor(r)\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t// right spot!\n\t\t\t\t\t\t\t// remove old edge\n\t\t\t\t\t\t\tthis.edges.remove((l, r))\n\t\t\t\t\t\t\t// add new ones\n\t\t\t\t\t\t\tthis.edges.add((l, w))\n\t\t\t\t\t\t\tthis.edges.add((w, r))\n\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} \n\t\t}\n\t}\n\n\t@update\n\tfunction remove(v: Vertex) {\n\t\tif this.lookup(v) {\n\t\t\treturn (node) =\u003e v_rmved.add(v)\n\t\t}\n\t}\n}\n```\n\n### Continuous Sequence using real numbers\nWe need to translate indices into unique immutable positions (what the user intuitively means when they say 'insert here').\n\nThis assumption of relative order of elements remains constant over time is called the **strong list specification**.\n\nPerformance depends critically on the implementation of identifiers. One possible implementation is to use a dense identifier space like $\\mathbb{R}$ where a unique identifier can always be allocated between any two identifiers.\n\nIndices are based off of what % of the text they get inserted at. 0.0 is the index of the start sequence, 1.0 is the index of the end sequence (this is similar to what Treedoc does). \n\n```\n0.0       1.0\nNUL       NUL\n```\n\nInserting a single character would be halfway between 0.0 and 1.0 so it would have an index of 0.5.\n\n```\n0.0   0.5   1.0\nNUL   'B'   NUL\n```\n\nInserting to the left of 'B' would be between 0.0 and 0.5 so 0.25.\n\n```\n0.0  0.25  0.5   1.0\nNUL   'A'  'B'   NUL\n```\n\nWe represent the continuum using a tree. The first element is allocated at the root. Thereafter, it is always possible to create a new leaf $e$ between any two nodes $n$ and $m$.\n\nWe do this by representing the tree using a U-Set\n\n```ts\ntype Element = (Atom, number)\n\ntype State = {\n\tset: Set\u003cElement\u003e = [];\n}\n\nclass OpCRDT {\n\t@query\n\tfunction lookup(u: Element): boolean {\n\t\treturn this.set.has(u)\n\t}\n\n\t@query\n\tfunction before(u: Element, v: Element): boolean {\n\t\tif this.lookup(u) \u0026\u0026 this.lookup(v) {\n\t\t\tconst _, u_id = u\n\t\t\tconst _, v_id = v\n\t\t\treturn u_id \u003c v_id\n\t\t}\n\t}\n\n\t@update\n\tfunction addBetween(u: Element, x: Atom, v: Element) {\n\t\tif this.before(u, v) {\n\t\t\tconst _, u_id = u\n\t\t\tconst _, v_id = v\n\t\t\tconst new_el = (x, (u_id + v_id) / 2)\n\t\t\treturn (node) =\u003e {\n\t\t\t\tnode.set.add(new_el)\n\t\t\t}\n\t\t}\n\t}\n\n\t@update\n\tfunction remove(u: Element) {\n\t\tif this.lookup(u) {\n\t\t\treturn (node) =\u003e node.set.remove(u)\n\t\t}\n\t}\n}\n```\n\n## Graphs\nGenerally, graphs are difficult to maintain due to the property that CRDTs *cannot compute and maintain* global invariants like structure.\n\nHowever, some stronger forms of acyclicity are implied by local properties, for instance\na monotonic DAG, in which an edge may be added only if it oriented in the same direction\nas an existing path. Vertices and edges can be stores as sets.\n\nSee reference implementations in [this paper](https://hal.inria.fr/inria-00555588/document)\n\n","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/CRON-Theorem":{"title":"CRON Theorem","content":"\n\u003e Causality Required Only for Non-monotonicity (CRON).\n\nEventual consistency can be _guaranteed_ in any program by protecting non-monotonic statements (“points of order”) with consensus protocols\n\nRephrased: Program semantics require [[thoughts/causality|causal]] [[thoughts/causality|message ordering]] if and only if the messages participate in non-monotonic derivations (e.g. set removal)\n\nSee also: [[thoughts/CALM Theorem|CALM Theorem]]","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Casper-FFG":{"title":"Casper FFG","content":"\n\u003e Partial [[thoughts/consensus|consensus]] mechanism is an overlay on top of proposal mechanisms to finalize blocks (selecting a unique chain that represents the canonical history of the chain)\n\nIt enables:\n1. an accountability mechanism so that Byzantine validators can be penalized.\n2. support for a dynamic set of validator nodes\n3. additional defences against long range revision attacks\n\nFrom a foundational perspective, Casper is essentially chained [[thoughts/Tendermint|Tendermint]]\n\n[Source Paper](https://arxiv.org/pdf/1710.09437.pdf)","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Chestertons-Fence":{"title":"Chesterton's Fence","content":"\n\u003e \"Don't ever take a fence down until you truly know the reason why it was put up\" -- G.K. Chesterton\n\n(public policy) The principle that reforms should not be made until the reasoning behind the existing state of affairs is understood.\n\nWhy we should look at [terminology](thoughts/terminology.md) and *why* words with historical [context](thoughts/context.md) came to be (e.g. [new words](posts/new-words.md))\n\n\u003e \"Before proposing new words, examine the beliefs and practices that we—and “they”—know perfectly well how to speak about.\" [Source: On Language Games by *Jon Baskin*](https://thepointmag.com/letter/on-language-games/)\n\nSimilarly: [Lindy effect](thoughts/Lindy%20effect.md)","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Chinese-room-argument":{"title":"Searle's Chinese room argument","content":"\n[Source: Stanford Encyclopedia of Philosophy](https://plato.stanford.edu/entries/chinese-room/)\n\nMainly a refutation against the Turing test as a means for measuring intelligence. The narrow conclusion of the argument is that programming a digital computer may make it appear to understand [[thoughts/language|language]] but could not produce real understanding.\n\n\"Searle imagines himself alone in a room following a computer program for responding to Chinese characters slipped under the door. Searle understands nothing of Chinese, and yet, by following the program for manipulating symbols and numerals just as a computer does, he sends appropriate strings of Chinese characters back out under the door, and this leads those outside to mistakenly suppose there is a Chinese speaker in the room.\"\n\nWe often attribute \"understanding\" and other cognitive predicates by metaphor and analogy to things that can't be intentioned like cars and adding machines — we make these attributions as we extend our own intentionality onto them (derived intentionality)\n-   replies\n    1.  systems reply\n        -   the symbol manipulator is merely a part of a whole system and the system does understand the story\n        -   understanding is not being ascribed to the mere individual, rather it is being ascribed to this whole system of which he is a part\n        -   response\n            -   individual incorporates the entire system, nullifies the argument\n        -   exposing the fault of the turing tests:\n            -   two \"systems\" both of which pass the Turing test, but only one of which understands\n    2.  robot reply\n        -   put a computer inside a robot, this computer would just operate the robot in such a way that the robot does something very much like perceiving, walking, moving about, hammering nails, eating, etc.\n        -   embedded ai argument\n        -   response\n            -   i know none of these other facts. i am receiving information from the robots perceptual apparatus and I am giving out instructions to its motor apparatus without knowing either of these facts\n    3.  brain simulator reply\n        -   the machine takes in Chinese stories and questions about them as input, it simulates the formal structure of actual Chinese brains in processing these stories, and it gives out Chinese answers as outputs\n        -   what this is saying\n            -   strong ai assumption: the mind is to the brain as the program is to the hardware, thus we can understand the mind without doing neurophysiology\n            -   if we actually knew how the brain worked, we wouldn't bother with neurophysiology\n        -   response\n            -   water valves as synapse connections\n                -   where is the understanding in this system? operator certainly doesn't understand Chinese and neither do the pipes\n                -   absurd to think that the operator in conjunction with the pipes understands it (operator can internalize the pipes)\n    4.  combination reply\n        -   imagine a robot with a brain-shaped computer lodged in its cranial cavity, computer programmed with all the synapses of the human brain, whole behaviour of the robot is indistinguishable from human behaviour, and now think of the whole thing as a unified system and not just a computer with inputs and outputs\n        -   as long as you knew nothing about it, it would be rational to ascribe [intentionality](thoughts/intentionality.md) to the robot\n        -   response: doesn't help the claims of strong AI\n            -   the attributions of intentionality that we make to the robot in this example have nothing to do with formal programs\n            -   if the robot looks and behaves sufficiently like us, then we would suppose until proven otherwise, that is must have mental states like ours that cause and are expressed by its behaviour and it must have an inner mechanism capable of producing such mental states\n            -   however, as soon as we knew that the behaviour was the result of a formal program, and that the actual [[thoughts/causality|causal]] properties of the physical substance were irrelevant, we would abandon the assumption of intentionality\n    5.  The many mansion reply\n    -   will eventually build devices that have these [[thoughts/causality|causal]] processes and that will be artificial intelligence\n    -   avoids the original thesis: mental processes are computational processes over formally defined elements\n    -   say we gave a machine the capacity to understand English or Chinese\n        -   this is possible as our bodies with our brains are precisely such machines\n    -   no purely formal model will ever be sufficient by itself for intentionality","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Cities-and-Programming":{"title":"Cities and Programming","content":"\n[Source: On architecture, urban planning and software construction\n by *Tomas Petricek*](http://tomasp.net/blog/2020/cities-and-programming/)\n\nMostly about [maintenance](thoughts/maintenance.md) of cities and parallels with maintaining software.\n\nSee also: [Urban planning](thoughts/urban%20planning.md)\n\n## XAI systems\nIn the last case (organized complexity and non-repetitive digital systems), the complexity of the problem cannot be reduced - we need to consider a large number of interacting processes or components. At the same time, all of them are equally important and play an important role in some aspect of the system. As Jane Jacobs puts it, the large number of interrelated variables form an organic whole. This is the end result of [emergent behaviour](thoughts/emergent%20behaviour.md)\n\nImportance of [explainability](thoughts/explainability.md)\n\n## Maintenance\nAlmost no buildings adapt well. They're designed not to adapt; also budgeted and financed not to, constructed not to, administered not to, maintained not to, regulated and taxed not to, even remodelled not to. But all buildings (...) adapt anyway, however poorly, because the usages in and around them are changing constantly.\n\nOpen-closed principle\n\nHow do we build software so that it gradually and gracefully degrades rather than abruptly stops working? Just like software systems, any building built using any kind of materials requires some [creation vs maintenance](thoughts/creation%20vs%20maintenance.md) over time. And just like with software systems, building owners are often bad at performing the necessary maintenance.\n\nThe idea of chaos engineering is perhaps a first step in this direction.\n\n[Rebuilding the Ise Grand Shrine](https://en.wikipedia.org/wiki/Ise_Grand_Shrine): retaining knowledge through constant revision\n\nvernacular design restricts the scope of the problem by limiting architectural ideas to what is typically used in the local context. This reduces the design task and allows the builder to focus on skilful solutions to specific problems rather than at reinventing forms. ","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Collingridge-dilemma":{"title":"Collingridge Dilemma","content":"\nEfforts to influence or control the further development of technology face a double-bind problem\n- An information problem: impacts cannot be easily predicted until the technology is extensively developed and widely used.\n- A power problem: control or change is difficult when the technology has become entrenched.\n\n## Pacing Problem\nThe \"pacing problem\" refers to the notion that technological innovation is increasingly outpacing the ability of laws and regulations to keep up, first explained in Larry Downes' 2009 book The Laws of Disruption, in which he famously states that \"technology changes exponentially, but social, economic, and legal systems change incrementally\".","lastmodified":"2023-02-15T01:38:21.22182084Z","tags":null},"/thoughts/Community-of-Fate":{"title":"Community of Fate","content":"\n[Margaret Levi in Noema Magazine](https://www.noemamag.com/an-expanded-community-of-fate/)\n\n\u003e The keystone is generating an “expanded community of fate.” For societies to survive and thrive, a significant proportion of their members must engage in reciprocal altruism\n\n\"Our goal is a form of farsighted reciprocal altruism in which members are willing to make costly sacrifices on behalf of those with whom they believe their fates, and their descendants’ fates, are entwined but who may never be able to directly reciprocate.\" -- reminds me a lot of [Bentoism](thoughts/Bentoism.md), specifically the 'future us' square\n\nA lot of very similar values to Unions and [mutual aid](thoughts/Mutual%20Aid.md), e.g. \"An injury to one is an injury to all.\"\n\nHeresthetics: using rhetoric, storytelling and strategy to redefine the situation in a way that changes the choices for a significant proportion of the populace","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Consciousness-is-not-Information":{"title":"Consciousness is not Information","content":"\n\u003e Paper #2 for PHIL 451A\n\u003e \n\u003e Prompt 1:  Is consciousness essentially a kind of information?\n\nWhen we examine theories of consciousness, we find that we can divide the majority of theories into two major categories: process theories and vehicle theories[^4]. I further borrow terminology from Velmans[^7] to describe these as behaviourist and cognitivist approaches to consciousness respectively, and argue that consciousness under cognitivist approaches runs into quite a few glaring holes.\n\nLet us first begin by defining the two major categories of theories of consciousness.\n1. Process theories assume that consciousness depends on the functional or relational properties of representational vehicles[^6], namely on the types of computations the vehicles engage in. Process theories are also referred to as cognitivist theorists -- these theories can, without scientific loss, be translated into talk about *information processing*[^7].\n2. Vehicle theories assume that consciousness is determined by intrinsic properties of representational vehicles[^6]. These theories are also referred to as behaviourist theorists -- these theories can, without scientific loss, be translated into talk about *behaviour*[^7].\n\nTo ask whether consciousness is essentially a kind of information is to ask whether the cognitivist theories of consciousness should be considered true. I disagree with the cognitive theories of consciousness as they fail to adequately address several critical questions. To concretize my argument in real theories, I look to Chalmer's process theory[^2] and Tononi's Information Integration Theory[^1].\n\nBoth of these are deeply rooted in cognitivist theories of consciousness. For example, in IIT, consciousness of the system refers to the information generated above and beyond the information generated from the separate parts of the system[^1]. Chalmer's process theory posits that information states can be realized physically and that these information states themselves are conscious[^2].\n\nYet, neither theory completely accounts for:\n1. Defining information in a manner at odds with how information is regularly defined\n2. How a serial [stream of consciousness](thoughts/Stream%20of%20Consciousness.md) can arise from a parallel distributed network\n3. Information carrying in obviously non-conscious objects\n4. Brute optimization of its mathematical definition\n\nWe expand on each of these in turn.\n\nChalmers' process theory starts by defining information in the world as having two aspects, physicality and phenomenality. Information then, is both a physical thing and has phenomenal intentionality (or what is is like to *be* information). In doing so, Chalmers defines information as having the property of being conscious. However, this is quite different from colloquially accepted and typical academic definitions of information. Information usually refers to *non-mental*, mind-independent entities that are embedded *in* the physical (e.g. a book or brain states). Pioneers of information theory like Claude Shannon and even colloquial usage of the term information agree with this definition. An important distinction between these two definitions is that while physical things encode and embed information, they themselves are not information. A book by itself is just an arrangement of paper and ink but it may carry information like the concept of Dante's *Inferno*. Thus, whatever Chalmers claims to be 'information' cannot be the same information everyone else refers to[^4] and so his conclusions on the basis of information cannot be valid.\n\nWe then consider the seriality/stream problem in the context of Chalmers' process theory. The 'stream' character of human conscious experience seems to almost be at odds with the parallel distributed model of the mind with its various synapses and neurons that have no central center for keeping order.  Process theories of consciousness must therefore account for how seriality arises from the distributed nature of the mind[^5]. Chalmers fails to do address this in his theory all-together. It is important to note that behaviourist theories avoid this all-together as behaviour is a *series* (or at least, very limited parallelism) of agent-environment interactions. Agents do not perform multiple complex interactions at once (e.g. eating and playing). Even for multi-tasking of simple interactions, most theories propose the concept of a bottle-neck or limiting capacity -- more complex behaviours take more bandwidth and thus require more focus, required the need for serial execution.\n\nLast but not least, we turn to how Chalmers' refutes information carrying in non-conscious objects. From earlier, Chalmers defines the ability to contain information states as the capacity for consciousness[^2]. Yet, there are clearly non-conscious objects, books for example, that clearly carry information but are not widely accepted as being conscious. Chalmers provides two options:\n1. Perhaps only some kinds of “physically realized information spaces” are conscious.\n2. Perhaps thermostats are conscious.\nChalmers' chooses the second option and suggests that “the level of organization at which consciousness 'winks out' might be lower than a thermostat but higher than a rock.”[^4] The resolution that Chalmers' chose is quite unsatisfying.\n\nTononi attempts to improve on Chalmers' theory by proposing IIT[^4]. In this theory, information is defined as information that is specified by a system that is irreducible to that specified by its parts. That is, information is *integrated* information. In making this distinction, Tononi explicitly rejects Chalmer's choice of distinguishing information-carriers as conscious and instead chooses to define a subset of physically-realized information spaces (*integrated* information) as conscious. In doing so, IIT avoids the first and third pitfalls of Chalmers' theory.\n\nHowever, IIT still has a major flaw in that it only claims to *correlate* integrated information $\\Phi$ with consciousness: \"To recapitulate, the theory claims that consciousness corresponds to the capacity to integrate information.\"[^1] Yet, we know that correlation is most definitely neither definition nor causation. Even while this is a glaring hole in what IIT claims to be, we can continue to show that even the definition of $\\Phi$ itself is problematic.\n\nRoughly, $\\Phi$ is large if the system has a lot interconnection between its components. In more technical terms, it is \"minimizing, over all subdivisions of your physical system into two parts A and B, some measure of the mutual information between A’s outputs and B’s inputs and vice versa.\" [^8] It is worth noting then that *any* sort of device that has some level of interconnection would be slightly conscious. According to Aaronson, Tononi seemed to accept this [panpsychist](thoughts/Panpsychism.md) implication and agree that thermostats have small but nonzero levels of consciousness. This clearly suffers the same unsatisfying conclusion that Chalmers arrived at earlier.\n\nHowever, even more problematic, is the fact that as this is a mathematical formula, it is susceptible to optimization (see: [Goodhart's Law](thoughts/Goodhart's%20Law.md)). Aaronson shows that we can construct almost trivial examples where systems that are clearly not conscious exhibit ridiculously large values of integrated information. For example, we can hook together a large number of logic gates together all in ways that are highly interconnected and achieve levels of $\\Phi$ that imply that over half of the information in the system is integrated information. As these logic gate systems (Aaronson details these as bipartite expander graphs) can be infinitely scalable, one could theoretically construct such a system with unbounded $\\Phi$. Surely there is something problematic going on if we can say that a graph of logic gates is infinitely conscious.\n\nIt is clear that information and information-processing based methods are brittle. Of course, there are alternatives to consider like Boris Kotchoubey's behaviourist approaches to consciousness that I believe are more sound, it is outside the scope of this paper to discuss their viability. Earlier, we posited that cognitive theories consciousness rely on consciousness as information or information-processing. In conclusion, I have shown that key cognitivist theories of consciousness like Chalmer's theory and Tononi's IIT have glaring flaws in attempting to measure and define consciousness. Thus, consciousness should not be considered a kind of information.\n\n[^1]: Tononi, Giulio (2004). *An information integration theory of consciousness*\n[^2]: Chalmers, D. J. (1996). *The Conscious Mind: in Search of a Fundamental Theory*\n[^3]: Shannon, C. E. (1948). *A mathematical theory of communication*\n[^4]: Pockett, Susan (2014). *Problems with theories that equate consciousness with information or information processing*\n[^5]: Kotchoubey, Boris (2018). *Human Consciousness: Where Is It From and What Is It for*\n[^6]: Atkinson, A. P., Thomas, M. S. C., and Cleeremans, A. (2000). *Consciousness: mapping the theoretical landscape*\n[^7]: Velmans, M. (1991). *Is human information processing conscious?*\n[^8]: Aaronson, Scott (2014). Why I Am Not An Integrated Information Theorist in *[https://scottaaronson.blog/?p=1799](https://scottaaronson.blog/?p=1799)*","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Coraline-Ada-Ehmke":{"title":"Coraline Ada Ehmke","content":"\nWorked a lot with Ruby, known for social justice work and activism. Transitioned in 2014.\n\n- Contributor Covenenant\n\t- 2014\n\t- Helped promote widespread adoption of codes of conduct\n- Post-Meritocracy\n\t- Meritocracy\n\t\t- \"We hide behind the motto of “love the art, hate the artist” to justify our preferences despite the faint voice of conscience, persistent in telling us that something is amiss.\"\n\t\t- \"One of the well-noted problems of adopting utility as the primary measure of morality is that it ignores the concept of justice, as cruel actions are condoned so long as they contribute to the greater good. Inequalities or injustices inflicted upon a minority are also deemed acceptable by this philosophy, so long as they do not interfere with the ability of the majority to experience pleasure.\" -- [[thoughts/To Live in their Utopia|To Live in their Utopia]]\n\t\t- Foolish to think we can make metrics and measure everything that's important.\n\t\t\t- \"Measuring the final result doesn’t provide enough quantitative data, so it’s tempting to include the data from intermediate steps. This is an attempt to shorten the feedback loop, and trying to shorten feedback loops is very dangerous in complex systems.\" [Source](https://brianlui.dog/2020/05/10/beware-of-tight-feedback-loops/)\n\t- But meritocracy has consistently shown itself to mainly benefit those with privilege, to the exclusion of underrepresented people in technology\n\t- \"We can add the most value as professionals by drawing on the diversity of our identities, backgrounds, experiences, and perspectives. Homogeneity is an antipattern.\"\n\t- More than the work we do -- what would meritocracy look like in a post-work society?\n\t- We have an ethical responsibility to refuse to work on software that will negatively impact the well-being of other people: Good transition to Hippocratic license\n- Being fired from GitHub\n\t- 2016\n\t- Worked on Repository Invitations (which I find a fantastic feature)\n\t\t- GitHub didn't like the tone, a male engineer completely rewrote it\n\t- Discourage mentorship which was weird\n- [Hippocratic License](https://firstdonoharm.dev/)\n\t- Software is [[thoughts/software and politics|political]]\n\t- \"You can’t build systems that can be weaponized against marginalized people and take no responsibility for them.\"\n\t- an Ethical Source license that specifically prohibits the use of software to violate universal standards of human rights\n- Opalgate\n\t- \"meh went on to state that he would knowingly and gladly accept working with a child molestor or cross-burning racist as long as their contributed code was good\"","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/CouchDB":{"title":"CouchDB","content":"\nNoSQL database with great replication capabilities.\n\nMulti-master replication (you can write to any server, even if it cannot see any other servers). Of course, as per [[thoughts/CAP Theorem|CAP Theorem]] this means trading off consistency for availability and partition tolerancy.\n\n## Replication\nReplication can be\n- unidirectional or bidirectional\n- one-time or continuous\n- periodic or on-demand\n\nDuring replication, CouchDB will compare the source and the destination database to determine which documents differ between the source and the destination database. It does so by following the Changes Feeds on the source and comparing the documents to the destination.\n\nA replication task will finish once it reaches the end of the changes feed. If its `continuous` property is set to true, it will wait for new changes to appear until the task is canceled. Replication tasks also create checkpoint documents on the destination to ensure that a restarted task can continue from where it stopped, for example after it has crashed.\n\n## Changes Feeds\n`results` is the list of changes in sequential order. New and changed documents only differ in the value of the rev; deleted documents include the `\"deleted\": true` attribute.","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Curse-of-Dimensionality":{"title":"Curse of Dimensionality","content":"\nVolume grows exponentially with dimension\n\n## Example\nIf want every location on to have a “neighbor” with distance $\\epsilon$,\n- In 1D, we need $O(1 / \\epsilon)$ points\n- In 2D, we need $O(1 / \\epsilon^2)$ points\n- In DD, we need $O(1 / \\epsilon^3)$ points\n\nOur nearest neighbour in high-dimensions might be really really far away\n","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/DHCP":{"title":"DHCP","content":"\nDynamic Host Configuration [Protocol](thoughts/Protocol.md) so they can join a network. Assigns [IP addresses](thoughts/IP%20Addresses.md) to hosts. Main reason was when people started moving devices across networks\n\nClient-server model\n\nBasic Messages\n1. Discovery, host looks for a DHCP server\n\t1. Sender is 0.0.0.0 port 68\n\t2. Receiver is 255.255.255.255 port 67 (this is the broadcast address!)\n2. Router responds with an offer valid for the next $n$ seconds\n\t1. This is broadcasted (255.255.255.255) as router does not know where receiver is\n3. Host responds with acceptance\n\t1. Broadcast which address picked\n4. Router responds OK\n\t1. ACK message, still broadcast\n\t2. Includes\n\t\t1. Unique IP Address for Client\n\t\t2. Netmask for local network\n\t\t3. Lease time\n\t\t4. Routing information\n\t\t5. Host name, domain name (optional)\n\t\t6. Name (DNS) Server\nFields (all [UDP](thoughts/UDP.md))\n- `src`: source IP address (usually 0.0.0.0 for no meaningful IP)\n- `dest`: destination IP address\n- `yiaddr`: your IP address\n- `transaction ID`: for matching request with response","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/DHT":{"title":"DHT","content":"\n\u003e The big hash table in the sky\n\nOne solution for 'decentralized' registry of peers. Each node holds a small shard of the DHT, so the burden of participation isn’t painful for any one agent. The DHT stores multiple redundant copies of each entry so that the information is available even when the author and a portion of the authorities are offline.\n\nAny good implementation tries to answer 2 questions:\n1. Which nodes take which part of the hash map\n2. If a key is not on a node, how does it go and get it?\n\nKeys are opaque, 160-bit quantities (e.g. an SHA-1 hash). Peers store data with similar IDs.\n\nJoining a DHT requires knowledge about at least one member of the DHT (the bootstrap node)\n\nCommon implementations include [[thoughts/Kademlia DHT|Kademlia DHT]] and Chord DHT. Also see [[thoughts/Sloppy Hashing DHT]]\n\n### Applications to Torrent Software\nOld way was to use a tracker, you announce which file you are going to download to the tracker and the trackers sends back a list of peers. However, these trackers tend to go down easily (get sued)\n\nDHT proves to be a more reliable way of replicating this behaviour.\n\n## Problems\n- DHTs can be crawled and mined for profit\n\t- Perform a [[thoughts/Sybil Attack|Sybil attack]] by simulating 1000+ clients and just wait for values to come in, cheaply capturing 90%-99% of the DHT\n- How do we make DHTs work where member count is low?","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/DID":{"title":"DID","content":"\nSummarized from [W3C Proposal](https://www.w3.org/TR/did-core)\n\n[Decentralized identifiers](https://www.w3.org/TR/did-core/#dfn-decentralized-identifiers) (DIDs) are a new type of [[thoughts/Self-sovereign Identity (SSI)|self-sovereign identity]] that enables verifiable, decentralized digital identity through the use of [[thoughts/cryptography|cryptography]].\n\n\u003e They are designed to enable individuals and organizations to generate their own identifiers using systems they trust. These new identifiers enable entities to prove control over them by authenticating using cryptographic proofs such as digital signatures.\n\nIdentity is important to identify things. The digital economy relies on proper identification to combine information from different sources. Uniqueness is vital here!\n\nGoals:\n1. Ease of creation\n2. [[thoughts/decentralization|Decentralized]]\n3. Persistent\n4. Resolvable\n5. Cryptographically verifiable\n\n## High level overview\nA DID is a unique string that has a specific syntax. It can be resolved to a *DID Document* (also called a DDO - DID descriptor object) in a global, decentralized, key-value database (Verifiable Data Registry).\n\nIt can be on any and multiple personal device that you own!\n\nFormat: `did:xyz:abcde123456`\n1. `did`: fixed string, this is a DID\n2. `xyz`: method name (e.g. `btcr` which is built on top of [[thoughts/bitcoin|Bitcoin]], acts sort of like a namespace)\n3. `abcde123456`: method specific identifier\n\nCan be thought of like a public decentralized keychain. It binds a public/private key pair to an identity, even when those keys are rotated out and replaced!\n\nThe VDR can be hosted/based on any platform (e.g. on distributed [[thoughts/blockchain|blockchains]] or just hosted files on GitHub)\n\nA DID Document can have arbitrary content. It contains references to \"controllers\" which are entities that have permission to make changes to a DID Document. It can also contain various cryptographic data delated to the DID subject (e.g. [[thoughts/RSA|RSA]], keys, etc.)\n\n## What it enables\n- Login without usernames or passwords\n- Digitally sign documents and transactions to prove it's you\n- Easily send encrypted messages\n- Authorize delegates\n- Usage and ownership on *your own terms* -- without surveillance or middlemen\n\n## Creating DIDs using IPLD\n- In IPID, associating the DID document with a DID is accomplished by cryptographically publishing the [[thoughts/CID|CID]] to the IPNS public key associated with the identity owner (DID method specific identifier). Any updates to the DID document are saved to IPLD and the resulting hash is published to IPNS cryptographically associating the new CID with the DID (for IPID this is the multihash of the public key). IPID uses a PubSub model for realtime updates to the DID.\n\t- This is self-attesting and does not facilitate consensus of the document across peers\n\t- Sometimes described as the \"microledger\" approach\n\t- Even though IPFS could be used for content addressing there would not be a need to connect to a wider IPFS network.\n\t\t- Not resolvable without hosting (which might actually be good for relational DIDs)\n- More reading in [RWoT 7, 2018](https://github.com/WebOfTrustInfo/rwot7-toronto/blob/master/final-documents/ipld-did.md)\n\n## DID Method Key\nThe `did:key` format\n\nThis DID Method is purely generative, requiring no look ups in a registry. Since did:key values are not stored in any registry, they cannot be updated or deactivated.\n\n## DWN\nA Decentralized Web Node (DWN) is a data storage and message relay mechanism entities can use to locate public or private permissioned data related to a given Decentralized Identifier (DID).\n\nDecentralized Web Nodes are a mesh-like datastore construction that enable an entity to operate multiple nodes that sync to the same state across one another, enabling the owning entity to secure, manage, and transact their data with others.\n\n## Methods\n### `did:key`\nGreat for burner DIDs\n\n### Sidetree\nSee [[thoughts/Sidetree|Sidetree]]","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/DNS":{"title":"DNS","content":"\nDomain name: an identification string that defines a realm of administrative autonomy, authority, or control within the [Internet](thoughts/Internet.md).\n\nDNS currently has ~300 million DNS registrations. Both query and reply messages follow the same message format. Both always include Name, Type, Class tuples -- Class is usually `IN`. Names cannot be wildcarded but type and class can\n\nHow do we resolve domain names to [IP addresses](thoughts/IP%20Addresses.md)? Resolves starting from the root and makes it way down the network hierarchy\n1. Root (13 of these worldwide)\n2. Top-level Domains (e.g. .com, .net, .org, etc.)\n3. Second-level Domains (e.g. Microsoft, UBC)\n4. Subdomains (e.g. www)\n5. Individual machines\n6. Local DNS Servers (not actually a part of the hierarchy, just caches data)\n\nAuthoritative DNS server is the server with the actual jurisdiction of the domain name you are looking for. The authoritative server of `cs.ubc.ca` is the `cs` server under UBC. \n\nTypes of queries\n1. Recursive Query -- if the name server doesn't know the answer, it asks a downstream server (recursively) for the answer on your behalf.\n2. Iterative Query -- if the name server doesn't know the answer, it tells you where to look at next, you do all the querying\n\nDNS servers store resource records (RRs)\nTypes:\n1. A (address records)\n\t1. name: hostname\n\t2. value: IPv4 address\n2. NS (name server)\n\t1. name: domain\n\t2. value: name of DNS server for domain\n3. MX (mail exchanger)\n\t1. name: domain of email address\n\t2. value: name of mail server\n4. AAAA (addressx4 record)\n\t1. name: hostname\n\t2. value: IPv6 address\n5. CNAME (canonical name)\n\t1. name: alias\n\t2. value: canonical name (e.g. foo.com)\n\nInserting records into DNS\n1. Register name with a registrar\n\t1. Provide registrar with name and IP address for your authoritative name server (usually a primary and secondary)\n\t2. Registrar inserts two resource records into the top-level domain server for each authoritative name server\n\t\t1. `(example.com, dns1.example.com, NS)`\n\t\t2. `(dns1.example.com, 212.212.212.1, A)`\n2. Add appropriate records into our own authoritative name server\n\t1. `(www.example.com, \u003cserver-ip\u003e, A)`\n\t2. `(www.example.com, \u003cserver-ip\u003e, MX)`","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/DSL":{"title":"DSL","content":"\n\n---\ntitle: \"Domain Specific Language (DSL)\"\ndate: 2022-09-22\ntags:\n- seed\naliases:\n- DSL\n---\n\nImplementation Stages\n1. Tokenization `String -\u003e [Token]`\n\t1. Makes defining and recognizing correct sequences easier\n\t2. Sometimes called lexing\n2. Parsing `[Token] -\u003e ParseTree`\n\t1. A tree that represents a successful parsing of a sequence of tokens\n3. (optional) AST Conversion `ParseTree -\u003e AST`\n4. (optional) Static Checks `AST -\u003e AST`\n\t1. See also: [[thoughts/program analysis]]\n5. Evaluate `AST -\u003e Result`\n\t1. Run the input or generate code for it\n\t2. (optional) Dynamic Checks\n\n## Grammar Rules\ne.g. for BNF, EBNF\n\n- Generally matches left to right\n- Single-quoted strings are literal\n- Grammar rules end with semicolons\n\n### ANTLR Lexer\n```antlr\nlexer grammar TinyHTMLLexer;\n// DEFAULT_MODE is the implicit defualt\nTITLE_START: 'Title:' WS* -\u003e mode(TEXT_MODE) ;\nTABLE_START: 'Table:' ;\nROW_START  : '[' WS* -\u003e mode(TEXT_MODE) ;\nROW_END    : ']' ;\nSEP        : '|' WS* -\u003e mode(TEXT_MODE) ;\nWS         : [\\r\\n\\t] -\u003e channel(HIDDEN) ;\n\nmode TEXT_MODE;\nTEXT       : ~[[|\\]\\r\\n]* -\u003e mode(DEFAULT_MODE) ;\n// cant infinite match because as soon as we match, we exist TEXT_MODE\n```\n\n### ANTLR Parser\n- Parser grammar rules have lower-case non-terminal symbols\n- Parser rule bodies can use both parser non-terminals and lexer ones\n\t- Though, we should avoid doing this and keep parser and lexer rules separate\n- Parser rule bodies may not include regex character classes (e.g. `[0-9]` or `\\d`)\n\n```antlr\nparser grammar TinyHTMLParser;\noptions { tokenVocab = TionyHTMLLexer; }\n\nprogram: title table+ EOF ;\ntitle  : TITLE_START TEXT ;\ntable  : TABLE_START boldrow row+ ;\nboldrow: row ;\nrow    : ROW_START (item (SEP item)*)? ROW_END ;\nitem   : TEXT ;\n```\n\n3 Parsing Guidelines\n1. The grammar cannot be ambiguous: any given input string has at most one parse tree that accepts it\n2. No left recursion: each rule cannot start with itself (even indirect)\n\t1. Should not allow `T ::= T ...`\n3. Grammar must be locally deterministic: for each choice, we must be able to choose between them based only on the next token (avoid common prefixes, factor them out into separate rules)\n\n## Language Principles\n1.  Learnability (how quickly can you pick it up; feels like “common sense”?)\n2.  Efficiency (once you’ve learned it, how efficiently can you perform tasks)\n3.  Memorability (coming back to the language, how easy to regain proficiency)\n4.  Errors (how many do users make, how severe, how easily can they recover)\n5.  Satisfaction (subjective, but very important for perseverance and adoption)\n\nSee also: [[thoughts/software principles]]\n\n- Maximize information hiding\n\t- Make classes, members as private as possible\n\t- Public classes should have no public fields (with the exception of constants)\n- Don't confuse users\n\t- Keep things simple\n\t- Name things well\n\t- Keep things consistent\n\t- Have good documentation\n\t- Avoid unnecessary boilerplate\n\t- Make it boring (intuitive, expected)\n\nWhat is the purpose of a language?\n- We think in a particular language and it determines how you think (see: [[thoughts/linguistic relativism|Sapir-Whorf]])\n- Languages should help us think better\n\n## Cognitive Dimensions of Notations\n1. Abstraction Gradient (Efficiency)\n\t- Abstractions make it hard for first-time programmers to understand it\n\t- Abstractions are powerful for professional software developers to make easy to write, read, and maintain software\n\t- There should be a **gradual** increase in complexity ![[thoughts/images/abstraction-gradient.png|500]]\n\t- Languages with a high abstraction floor are called abstraction-hungry\n\t- Languages with a low abstraction ceiling are called abstraction-hating\n2. Consistency\n\t- Coherence across the features of a language. It is easier to learn something if there are few exceptions to learn\n3. Diffuseness (Learnability)\n\t- How many things there are to learn about a language\n\t- Number of keywords is a good approximation for diffuseness\n4. Error-proneness\n\t- Bloch: make it *easy to do it right, hard to do it wrong*\n\t- The more guarantees you want to make about the program at compile time, the more work the programmer needs to do to get something running\n5. Secondary Notation\n\t- Anything that is only there to help the programmer but does not affect what the code actually does\n\n## Evaluation\n### Recursive Evaluation\nEach node has an evaluate method. Recursively traverse the tree and evaluate each node.\n\nBut this only supports a single type of traversing the AST. What if we want to support other types of checkers? We have many different operations that traverse the AST\n\nPutting all functionality into AST methods violates SRP. We can instead, implement the visitor pattern.\n\n### Visitor Pattern\nThe visitor design pattern is a way of separating an algorithm from an object structure on which it operates.\n\nBasically, you are passing this visitor object to a node's accept function.\n- Visitor defines a `visit` for each concrete node type to detail how to visit that node + its children (functionality depends on visitor)\n- If it needs to visit another node, it calls `accept` on itself (functionality also depends on the node type)\n\nWe perform double dispatch as the functionality depends on two things:\n1. the type of AST object (via the `accept` call) and\n2. the type of visitor object (via the `visit` call)\n\nWe could just evaluate each AST node, but this places the responsibility on the nodes for how to do this.\n\n1. Support multiple kinds of \"evaluation\" for our AST without having to edit every node every node every time\n2. Evaluation is in a separate file from the AST implementation\n\n```typescript\nexport class Client() {\n\tnodes: Element[]\n\tdoSomething() {\n\t\tconst visitor: Visitor\u003cT, U\u003e = // idk some visitor to do something\n\t\tfor (node in this.nodes) {\n\t\t\tnode.accept(visitor)\n\t\t}\n\t}\n}\n\nexport interface Element {\n\taccept: (visitor: Visitor\u003cT, U\u003e, param: T): U,\n}\n\n// same for ConcreteB\nclass ConcreteA implements Element {\n\taccept(visitor: Visitor\u003cT, U\u003e, param: T): U {\n\t\treturn visitor.visit(this, param)\n\t}\n}\n\nexport interface Visitor\u003cT, U\u003e {\n\t// where ConreteA and ConcreteB both inherit from Element\n\t// error checks here are runtime checks\n\tvisit: (a: ConcreteA, param: T): U,\n\tvisit: (b: ConcreteB, param: T): U,\n\t...\n}\n```\n\n1. Create a `Visitor` interface under AST and define a bunch of visit methods for each concrete node type\n2. Under the abstract `Node` class, create an abstract `accept` method\n3. Create a new visitor class that implements the `Visitor` interface\n\n## Empirical Studies\nWe ask general research questions about all users, all tasks of a certain kind... e.g. do types help developers of large projects?\n\nWe usually can't measure these directly, but we can gather empirical evidence through:\n1. Observational/Exploratory Studies\n2. Controlled Experiments\n3. Historical Data Collection and Analysis\n4. Surveys\n\nPotential way conclusions can be flawed:\n1. Construct validity: are we measuring the right thing? Is this clearly connected to our research question? Did we misunderstand the concepts we are working with?\n2. Internal validity: What are alternative explanations for the results? Other bias, confounding factors, etc.\n3. External Validity: To what extent are our results and conclusions of our experiment generalizable to our original research question? (how representative are our tasks and users?)\n4. Empirical Reliability / Reproducibility: Can the study be reproduced?\n\nRisks and Consent:\n1. In what ways could your participants could be harmed by the study or its results?\n2. Could be physical harm (less likely in CS), emotional harm (stress, reputation, etc.)\n3. Evaluate the likelihood of each potential risk (including unlikely cases)\n4. Are there ways to mitigate these risks? Potentially: adjust your study design\n5. What would you do if a participant were harmed? e.g. correction, compensation?\n\nTo run a study ethically, we need to get informed consent (see: [[thoughts/interviews and data recording]])","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Dark-Forest-Theory-of-the-Internet":{"title":"Dark Forest Theory of the Internet","content":"\nRelated: [Moving Castles](thoughts/Moving%20Castles.md), [[thoughts/cozy software]]\n\n[Source: The Dark Forest Theory of the Internet by *Yancey Strickler*](https://onezero.medium.com/the-dark-forest-theory-of-the-internet-7dc3e68a7cb1)\n\n\u003e Imagine a dark forest at night. It’s deathly quiet. Nothing moves. Nothing stirs. This could lead one to assume that the forest is devoid of life. But of course, it’s not. The dark forest is full of life. It’s quiet because night is when the predators come out. To survive, the animals stay silent.\n\nIt's unsafe to reveal yourself to them in any authentic way. So we retreat into private spaces. We hide in the cozy web.\n\nEphemeral content is the content in the dark forest. Fireflies not lamps.\n\n\"These are all spaces where depressurized conversation is possible because of their non-indexed, non-optimized, and non-gamified environments.\"\n\nCreating [digital mindfulness](thoughts/digital%20mindfulness.md) in communication and conversation?\n\n![[thoughts/images/dark-forest.png|700]]*Illustration from Maggie Appleton's [Cozy Web](https://maggieappleton.com/cozy-web)*","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Data-Capitalism":{"title":"Data Capitalism","content":"\n\"Currently, the predominant business model for commercial search engines is advertising. The goals of the advertising business model do not always correspond to providing quality search to users.\"\n\n\"We believe the issue of advertising causes enough mixed incentives that it is crucial to have a competitive search engine that is transparent and in the academic realm\"\n\nAlmost ironic that Sergey Brin \u0026 Lawrence Page (founders of Google) said this when writing the paper on what would become PageRank and Google Search.\n\n- A form of capitalism where the selling and exchange of data is the source of economic benefit\n- Associated with rise of Internet and Web 2.0; post 9/11\n- Also known as surveillance capitalism\n- Economic system in which personal data is seen and conceived as a source of profit\n\n## Thieves of Experience: How Google and Facebook Corrupted Capitalism\n[By Nicholas Carr in LARB](https://lareviewofbooks.org/article/thieves-of-experience-how-google-and-facebook-corrupted-capitalism/)\n\n\"Surveillance capitalism’s **real** products, vaporous but immensely valuable, are predictions about our future behavior — what we’ll look at, where we’ll go, what we’ll buy, what opinions we’ll hold\"\n\n\"Unlike financial derivatives, which they in some ways resemble, these new data derivatives draw their value, parasite-like, from human experience.\"\n\nZuboff coins the term *extraction imperative*: To improve its predictions, it had to mine as much information as possible from web users.\n\nThe bullying style of TOS agreements also characterizes the practice, common to Google and other technology companies, of threatening users with a loss of “functionality” should they try to opt out of data sharing protocols or otherwise attempt to escape surveillance.\n\n\u003e “If you disable this app, other apps may no longer function as intended.”\n\n","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Datalog":{"title":"Datalog","content":"\nSources:\n- *What You Always Wanted to Know About Datalog (And Never Dared to Ask)*\n\nDatalog is basically a simplified version of general Logic Programming.\n\nIn the formalism of Datalog, both facts and rules are represented as Horn clauses of the general shape `L0 :- L1, ..., Ln`. Each `L` is a predicate symbol `p(t1, ..., ti)` where `t` are the terms. A term can either be a constant or a variable.\n\nA logic program consists of a finite set of:\n1. Facts: assertions about a relevant piece of the world. These are represented as clauses with empty bodies (e.g. `friends(alice, bob).`)\n2. Rules: statements which allow us to deduce facts from other facts. These usually contain variables (e.g. `mutual(X, Y) :- friends(X, Z), friends(Z, Y).`)\n\nNormally, constants and predicate symbols are strings that begin with a lower-case character and variables are strings that begin with an upper-case character.\n\nA clause that does not contain any variables is called *ground*. To guarantee that the set of all facts that can be derived from a Datalog program `P` is finite, we require:\n1. Each fact of `P` is ground\n2. Each variable which occurs in the head of a rule of `P` must also occur in the body of the same rule\n\nWhen using facts stored in an external relational database (sometimes called the Extensional Database or EDB), we distinguish these from facts stored *within* the logic program `P` (sometimes called the Intensional Database or IDB).\n\nWe can consider the program `P` as a query against the EDB. The EDB is normally considered a time-varying collection of information. A query then is a time-*invariant* mapping which maps the EDB to result states.\n\nA program `P` might produce a large number of intermediate IDB-relations. However, users are only interested in a subset of these relationships. We can express this as a *goal* to a Datalog program. To Prolog users, this is familiar. It is a single predicate that looks like `?-friends(alice, X).` which would, for example, get all people who `alice` is friends with.\n\nMore notation/terminology:\n- Herbrand base (HB) is the set of all facts we can express in the language of Datalog\n- If `S` is a finite set of Datalog clauses, we denote `cons(S)` the set of all logical consequences of `S`\n- A fixpoint is a state of the evaluation process in which no more rules can be applied and all of the predicates in the program have reached their final, \"fixed\" values.\n\n## Inference Rules\n### Bottom-up Evaluation\nOne example is the Elementary Production Principle (EPP). Given a rule that looks like `friends(X, X) :- person(X)`\n\nIf we can substitute facts (`e.g. person(john).`) for terms in the body such that the entire body is true and ground, then the head of the rule becomes a new fact. In the example above, `friends(john, john).` is then added as a fact, using the substitution $\\theta$ = `{X \u003c- john}`.\n\nThe sequence of applications of EPP which is used to infer a ground fact `F` from `S` is called a proof of `F` from `S`. We say $S \\vdash F$ (F can be inferred from S) iff:\n1. $F \\in S$\n2. $F$ can be obtained by applying EPP a finite number of times\n\nUsing this to derive `cons(S)` is also sometimes called forward-chaining (it follows the logical implication sign from premises to conclusions\n\n### Top-down Evaluation\nSometimes called backward-chaining. This method is particularly appropriate when a goal is specified together with a Datalog program.\n\nRules are seen as problem generators. Each goal is considered as a problem that must be solved. The initial goal is matched with the left hand side of some rule, and generates other problems corresponding to the right-hand side predicates of that rule; this process is continued until no new problems are generated.\n\nOne example of this is called the Query-Subquery (QSQ) Approach (this feels quite similar to chained currying in Haskell). Prolog uses this!\n\nDatalog goals seem more naturally executed through breadth-first techniques, as the result of the computation is neither affected by the order of predicates within the right-hand sides (RHS) of rules, nor by the order of rules within the program.\n\n### Table of Methods\n- Evaluation methods: effective evaluation strategies (improvements at runtime)\n\t- Bottom-up\n\t\t- Naive\n\t\t- Semi-naive\n\t\t- Henschen-Naqvi\n\t- Top-down\n\t\t- Query-subquery (QSQ)\n- Rewriting method: program transformation which yields a more efficient computation (improvements at compile time)\n\t- Logic\n\t\t- Magic sets\n\t\t- Counting\n\t\t- Magic Counting\n\t\t- Static Filtering\n\t- Algebraic\n\t\t- Variable reduction and constant reduction\n\n## Expressivity\n- Positive relational algebra (RA+) is equivalent to non-recursive Datalog\n- Datalog can express recursive queries which RA can't express\n- Full relational algebra (RA) can express negation which Datalog can't express\n\t- However, Datalog can be enriched to support logical negation $\\lnot$\n\n## Negation\nIncorporating negation can be allowed by adopting the Closed World Assumption (CWA). That is, if a fact does not logically follow from a set of Datalog clauses, then we conclude that the negation of this fact is true.\n\nThat is, we assume our facts *completely* describe the domain we are interested. For the purposes of [[thoughts/CRDT|CRDTs]], this unfortunately is not true.\n\nEven with negation in Datalog, we can't derive new facts from these negations. That is, we can't express premises that contain a negative in the formulation (e.g. \"if X is a student and X is not a graduate student, then X is an undergraduate student\").\n\nThis is possible in relational algebra using the set-difference operator.\n\nWe *can* extend Datalog to support negated literals in rule bodies using stratified Datalog\n\n## Stratification\nConsider a rule such as `boring(chess) :- !interesting(chess)`\n\nWe try to *stratify* the clauses of the program such that when evaluating a predicate in a rule head, it is always possible to completely evaluate all the predicates which occur negatively in the rule body or in the bodies of some subsequent rules.\n\nIn the above case, it is always possible to fully evaluate the `interesting(chess)` predicate before evaluating `bording(chess)`. Formally, a stratified program $P$ can be partitioned into disjoint sets of clauses $P = P^1 \\cup \\dots \\cup P^n$\n\nLet's consider an example program $P$ where `d` is the only EDB-predicate:\n\n```prolog\nr1: p(X,Y) :- !q(X,Y), s(X,Y).\nr2: q(X,Y) :- q(X,Z), q(Z,Y).\nr3: q(X,Y) :- d(X,Y), !r(X,Y).\nr4: r(X,Y) :- d(Y,X).\nr5: s(X,Y) :- q(X,Z),q(Y,T), X != Y\n```\n\nWe can turn these statements into an extended dependency graph (EDG) by\n- Making nodes of the IDB-predicate symbols in $P$\n- Create a directed edge $\\langle p, q \\rangle$ iff the predicate symbol $q$ occurs positively or negatively in a body of a rule with head predicate $p$\n\t- If the symbol $q$ occurs negatively, we mark the edge with $\\lnot$ (that is, an edge is marked $\\lnot$ if there is at least one rule with head predicate $p$ such that $q$ occurs negatively in the body)\n\nThe program can be stratified iff the EDG does not contain any cycle involving an edge labeled $\\lnot$.\n\nWe can then stratify $P$ into 3 layers by doing a topological sort on the dependency graph:\n1. `r4`\n2. `r2`, `r3`, `r5`\n3. `r1`\n\nThis is one of many possible stratifications (however, they are all equivalent).\n\n### Misc\n- Three-valued logic? A fact can be true, false, or undefined\n- Complex objects\n\t- $NF^2$ model (Jaeschke and Schek)\n\t- Nested Relations (Fisher and Thomas)\n\t- Model of Abiteboul and Beeri\n\t- ALGRES\n- Modularization and structure types?","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Decision-theory":{"title":"Decision theory","content":"\nChoices by one agent in which background conditions are independent of what other agents are doing. We usually represent these decisions with a decision matrix or decision table\n\nRelatived view of Decision theory:\n\n\u003e Prescriptions in decision theory are always relative to the formal problem specifications\n\nSee also: [[thoughts/causal decision theory|causal decision theory]]\n\ne.g. Pascal's Wager\n\n| |God exists|God does not exist|\n|--|--|--|\n|Believe|Infinite reward|Status quo|\n|Don't believe|Infinite loss|Status quo|\n\nComponents:\n- Rows are possible acts\n\t- Acts are *functions* that map states to outcomes\n- Columns are possible states of the world\n\t- Probabilities are sometimes included for decisions under risk.\n\t- Should *not* depend on agent action\n\t- States should be\n\t\t- **Mutually exclusive**\n\t\t- **Exhaustive**: no possibility is left out\n\t\t- **Relevant partition**: distinctions that actually have impact on probability or [[thoughts/utility|utility]] of outcomes\n\t\t- **Independence**: (optional) each state should be [[thoughts/causality|causally]] and probabilistically independent of the *acts*\n\t\t\t- Dominance principle only holds if independent holds\n- Cells are outcomes.\n\t- Can be described using\n\t\t- Verbal description\n\t\t- Preference ranking on an ordinal scale\n\t\t\t- Defines a [[thoughts/Order theory|partial ordering]] of outcomes\n\t\t\t\t- $x \\succcurlyeq y$ is a weak preference\n\t\t\t\t- $x \\succ y$ is a strong preference\n\t\t\t\t- $x \\sim y$ is indifference between $x$ and $y$\n\t\t- [[thoughts/utility|Utility]] (numerical value) using an [[thoughts/interval scale|interval scale]]\n\n\nDecision tables\n1. Art: providing a good formalization of a decision into a table\n2. providing a justified recommendation based off of the formalization\n\nThey can also be represented using [[thoughts/decision tree|decision trees]]\n\nWe can transform decision tables between each other using \"reasonable transformations\"\n1. PIR: assign equal probabilities to all states (if we have no knowledge of probabilities, aka [[thoughts/Decisions under ignorance|DUI]])\n2. Merger: if two states yield identical columns, then we can merge them into one state and add probabilities if we know them","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Decisions-under-ignorance":{"title":"Decisions under ignorance (DUI)","content":"\nDecision rules when the agent is ignorant of all probabilities\n\n## Background Points\n1. No information about probabilities\n2. A value function on outcomes a\u0026s where a is an act and s is a state\n3. Most of the rules respect dominance\n\n## Rules\n1. Dominance\n\t1. Weak Dominance: act $a$ is as good or better than $b$ for each possible state and there is at least one state where it is strictly better\n\t2. Strong Dominance: act $a$ is strictly better than $b$ for all possible states\n\t3. Principle: \n\t\t1. Avoid dominated acts and prefer dominant acts\n\t\t2. Can only use dominance principle if states are independent of acts\n\t\t3. Gold standard, use this whenever possible\n2. Maximin/Leximin\n\t1. Find the minimum value of each act\n\t2. Choose the act with the least bad worst-case outcome\n\t3. Note: can violate dominance if there are rows with the same minimum\n\t4. Leximin can help resolves ties by removing the minimum value in case of ties. Note that this violates dominance!\n\t5. Leximin* only strikes out a *single* minimum value in case of ties. This does *not* violate dominance\n\t6. Extremely conservative, avoids the worst-case scenario\n3. Optimism/Pessimism and \"Best Average\"\n\t1. Maximax (pick the best of the best-case outcomes)\n\t2. Best Average: take the best of each row and worst of each row and average it, pick the act with best average\n\t3. Optimism/Pessimism: Uses a weighted average (a linear combination) of the minimum and maximum values ($\\alpha = 0$ is pessimistic, $\\alpha = 1$ is optimistic): $V_\\alpha(A) = \\alpha \\max(A) + (1-\\alpha) \\min(A)$\n\t4. Objections\n\t\t1. Requires [[thoughts/interval scale|interval scale]] instead of ordinal scale\n4. Minimax regret\n\t1. Irrational to reject an act with a chance of a great gain, where the cost is slight.\n\t2. Regret value for each outcome = value of the outcome - maximum value in that column\n\t3. Max regret for each act is the most negative regret for each row A\n\t4. Choose the act with the minimum max regret\n\t5. Objections\n\t\t1. Requires [[thoughts/interval scale|interval scale]] instead of ordinal scale\n\t\t2. Adding irrelevant alternative acts potentially affects recommended acts\n5. Principle of Insufficient Reason (PIR)\n\t1. If there are n possible states and you have no reason to believe any of them more likely than any other, then it is rational to assign each state equal probability (namely, 1/n)\n\t2. So, we assign each of the $n$ states probability $1/n$ and maximize the expected value\n\t3. For an act $A$, calculate $\\sum_{i=1}^n \\frac{1}{n} value(A, S_i)$\n\t4. This turns the problem into a [[thoughts/Decisions under risk|DUR]]\n\t5. Objections\n\t\t1. Requires [[thoughts/interval scale|interval scale]] instead of ordinal scale\n\t\t2. Arbitrary partitions of states (can result in incoherence)\n\t\t3. Doesn't apply outside games of chance (e.g. Pascal's Wager)\n\n## Rationality Constraints\nFind criteria that any rational decision rule should satisfy. Use these to rule out one or more decision principles\n\nMilnor proposes a few axioms for rules under DUI:\n1. Mixture condition (randomization)\n\t1. If a rational agent is indifferent between A1 and A2, then the agent must be indifferent between A1, A2 and the mixed strategy $[\\frac 1 2 A1, \\frac 1 2 A2]$\n\t\t1. Presupposition that the agent has a neutral attitude to risk\n\t2. Eliminates Maximin (as above)\n\t3. Eliminates Minimax Regret (as above)\n\t4. Eliminates Optimism-pessimism rule with $\\alpha \\neq \\frac 1 2$\n\t5. Eliminates Best Avg if we allow other mixtures\n\t6. Only PIR survives\n2. Independence of Irrelevant Alternatives\n\t1. A rational agent’s choice will be invariant under an irrelevant expansion B: if $A1 \\geq A2$ before adding option B, then $A1 \\geq A2$ after adding B.\n\t2. Eliminates Minimax Regret\n\nPerhaps we should use different rules for DUI in different situations. Can we be systematic?\n\n![[thoughts/images/dui-situtations.png|500]]\n\nFor decisions under partial ignorance, see: [[thoughts/Precautionary Principle|Precautionary Principle]]","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Decisions-under-risk":{"title":"Decisions under risk (DUR)","content":"\nDecision rules when the probability of each outcome is known.\n\nRequires an [[thoughts/interval scale|interval scale]]\n\nWhen evaluating, we often need to quantify what outcomes are more [[thoughts/value|valuable]] than others\n1. Expected Value (EV)\n2. Expected Monetary Value (EMV)\n3. Expected [[thoughts/utility|Utility]] (EU)\n\nTypically, we use EU. Sometimes we use EMV under the assumption that it is equivalent to EU in a free market ([[thoughts/utility|utility]] is a positive linear transformation of monetary value)\n\nTwo arguments for why EU Max:\n1. In the long run, no strategy can be expected to do better than maximizing expected [[thoughts/utility|utility]].\n\t- Objections\n\t\t- There is no long run for humans\n\t\t- Gambler's Ruin: a gambler with finite wealth, playing a fair game, eventually goes broke with probability 1\n\t\t- How is the long-run argument relevant to unique decisions that can't be repeated?\n2. Axiomatic Approach. You should maximize expected utility, because you are also maximizing utility.\n\t- This conclusion does not depend on the long run argument, so it applies even to the single case.\n\n## Maximizing Expected Utility\n[[thoughts/utility|Utility]] is a numerical representation of the agent’s preference ranking\n\nGenerally, we prefer using EU over EMV.\n\nSee also: [[thoughts/Utilitarianism|utilitarianism]]\n\n[[thoughts/utility|Utility]] theory allows for outcomes without monetary value, or whose value can’t be measured solely in terms of monetary payoff.\n\n### Utility of Money\nNote that generally, there is a diminishing marginal [[thoughts/utility|utility]] of money\n\nFor example, in a lottery where you win $1M for sure (A) or 50% chance to win $3M and 50% chance to get nothing (B), most people would choose A. The change in [[thoughts/utility|utility]] from $1M to $3M is not enough to offset the drop in probability from certainty to 50%.\n\n## Paradoxes and Puzzles\n### Allais Paradox\n1. Situation A: Choose between\n\t1. $1 million for sure\n\t2. A lottery:\n\t\t1. 10% for $5  million\n\t\t2. 89% for $1 million,\n\t\t3. 1% for nothing.\n2. Situation B: Choose between\n\t1. 10% for $5 million\n\t2. 11% for $1million\n\nParadox arrises if you choose a) over b) in situation A and d) over c) in situation B. But, we can show that these two situations are equivalent.\n\nSolutions:\n1. Savage: fix irrational preferences of people!\n2. Revise the table: utilities of the same amount of money is not the same in the two situations (not very plausible)\n3. Priority heuristics (Gigerenzer): people have a hierarchy of goals and avoiding uncertainty is high on the list (hard to defend as a normative principle)\n\n### Ellsberg Paradox\nSame idea as Allais Paradox but shifts probabilities instead of values\n\nUrn with 90 balls\n- 30 red balls (R), 60 black (B) or yellow balls (Y)\n- Let $p * 60$ be the number of black and $(1-p)*60$ is the number of yellow balls\n- A ball will be draw and you make a bet on its colour\n\n1. Situation A: Bet R or B. Receive $100 if right, $0 if wrong\n2. Situation B: Bet (R or Y) or (B or Y). Receive $100 if right, $0 if wrong\n\nMany people bet R in Situation A but bet (B or Y) kin situation B. People like to avoid uncertainty! However, this is inconsistent with EU Max\n\n### St. Petersburg Paradox\nA fair coin is tossed until it comes up Heads. If Heads appears for the first time on toss $n$, you are paid $\\$n$\n\nWhat is the EMV of this game? Technically, the St. Petersburg game involves infinitely many states\n\n$$EMV = (1/2)\\$2 + (1/2)^2\\$2 + \\dots = 1 + 1 + \\dots = \\infty$$\nYou should be willing to pay any price to play!\n\nSolutions\n1. Bernoulli: diminishing marginal [[thoughts/utility|utility]] of money\n\t1. Refutation: change payout to $\\$2^n$\n2. Buffon: *de minimis condition*\n\t1. Ignore tiny probabilities\n\n### Two-Envelope Paradox\nA trustworthy informant tells you that one of the envelopes contains exactly twice as much as the other, but the informant does not tell you which is which. Since this is all you know, you decide to pick an envelope at random. Let us say you pick envelope A. Just before you open envelope A you are offered to swap and take envelope B instead.\n\nGiven what you know, both possibilities are equally likely. Hence, the expected monetary value of swapping to B is $\\frac 1 2 2x + \\frac 1 2 \\frac x 2 = \\frac 5 4 x$. Since $\\frac 5 4 x \u003e x$, it is rational to take B instead of A. But you can apply the same argument to arrive at a contradictory claim that you should take A instead of B.\n\nLimit Counterargument\n- The present formulation of the paradox presupposes that there is no upper limit to how much money there is in the world\n- Suppose that there indeed is some upper limit L to how much money there is in the world.\n\t- It then follows that no envelope can contain more than (2/3)L\n\t- The other envelope would be certain to contain (1/3)L","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Degraded-Blockchain-problem":{"title":"Degraded Blockchain problem","content":"\nOne thing that I still don't understand about blockchain is the 'trustless' aspect of blockchains. Blockchains are not 'trustless', rather it shifts the [trust](thoughts/trust.md) balance away from trusting people and corporations to trusting an algorithm. \n\nYet, how do we go about trusting the algorithm that is 'cryptographically secure' when a good 99.5% of the users don't actually understand how blockchain and [[thoughts/cryptography|cryptography]] works? \n\nCome into contact with the [Degraded Blockchain Problem](https://www.fortressofdoors.com/the-degraded-blockchain-problem/):\n\n![The link between the actual data on-chain and the actual thing that depends on the data to function are only *weakly* linked](/thoughts/images/degraded-blockchain.png)\n\nThe blockchain really only stores a *pointer* to a good 99% of content that supposedly lives 'on-chain', most of it is never 100% on chain. (This is also why people meme on NFT owners which just link to a PNG, it's literally just a weak pointer. If the image hosting service goes down, that point is useless as it is immutable). The problem with this model is that if most of the value comes from the 'off-chain' *content*, then what use is this proof of ownership if I can't do anything with it?\n\nThe only thing that actually connects the blockchain with the 'off-chain' value is... you guessed it... trust.\n","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Descartes-Meditations":{"title":"Descartes' Meditations","content":"\nCartesian doubt refers to the opposite of [trust](thoughts/trust.md) in Nguyen's sense\n\n## First Meditation → skeptical doubts\n-  Descartes wants to find a foundation of knowledge that will still stand strong even after doubting the most basic facts about the world\n- Everything Descartes has accepted has true has come through senses, but senses can deceive\n-  First Argument\n    1.  Some experiences are deceptive (e.g. visual illusions, mirages)\n    2.  Any particular experience I have might be deceptive\n    3.  It is possible that _all_ my experiences are deceptive\n-  Counterexample to first argument\n    -  Some paintings are forgeries\n    -  Any particular painting might be a forgery\n    -  It is possible that all paintings are forgeries\n    -  Can't be possible because all paintings if all paintings are forgeries, what are they based off of?\n    - Cannot dream things that have no component real parts (even mermaids, for example are part women and fish)\n    - Some universal axioms still hold\n\t    - \"For whether I am awake or asleep, two plus three make five, and a square does not have more than four sides.\" (p. 15)\n-  Descartes' objection to First Argument\n    - Premise 2 doesn't work → any particular experience I have might be deceptive\n    -  I am sure of my own thoughts\n        -  And yet to have these doubts, one must exist. For an evil demon to mislead him in all these insidious ways, he must exist in order to be misled.\n        -  Therefore, thought above all else is inseparable from being. The Meditator concludes that, in the strict sense, he is only a thing that thinks.\n### Dream Argument\n-   Premises\n\t1.  I have dreamt at being at my desk\n\t2. When I dreamt it, I believed it was true\n\t3. When I dreamt it, it was false\n\t4. There is no way to tell whether you are dreaming or awake\n-  Conclusion → i don't know that I am here at my desk right now\n-  As premise 4 is roughly equivalent to the conclusion, this argument is invalid\n\t- It begs the question → argument which has a premise as a conclusion (circular reasoning)\n### The God argument\n-   suppose there exists an evil demon, just as powerful as God, but which deceives me about everything he can\n-   descartes refutation\n\t-   it seems possible for there to be such a person\n\t-   if there were such a person, then everything I believe would be false\n\t-   I can't tell that there isn't such a person\n\t-   so, I don't really know anything I thought i knew\n## Second Meditation\n- *I am, I exist* is necessarily true whenever it is put forward by me or conceived in my mind\n\t- For one to be deceived, one must first exist\n- What is \"I\"?\n\t- Soul and body can be deceptions\n\t- Thought then, above all else, is inseparable from being\n### Wax Argument\n- On how we come to know of a piece of wax\n- Cannot come to know it through means of the senses\n\t- Put it near a fire and its perception by the senses changes (e.g. becomes soft when it was hard)\n- Cannot come to know it through imagination\n\t- One cannot imagine all the infinite number of different shapes in their imagination\n- Must be through means of intellect alone\n\t- Similar to seeing a man as a post (more in [epistemology](thoughts/epistemology.md))\n- The Meditator happily concludes that he can know at least that he exists, that he is a thinking thing, that his mind is better known than his body, and that all clear and distinct perceptions come by means of the intellect alone, and not the senses or the imagination.\n## Third Meditation\n- To assure himself that he is not deceived, he must inquire into the nature of God\n- Before doing this, the Meditator needs to classify his thoughts\n\t- Ideas: images of things\n\t\t- 3 sources for ideas\n\t\t\t1. Innate\n\t\t\t2. Adventitious: coming from 'outside' us (as with our sensory perceptions)\n\t\t\t\t- His will has no effect on adventitious ideas: he cannot prevent himself from feeling hot when it is hot simply through the will, for instance.\n\t\t\t3. Invented\n\t- Volitions, emotions, judgements: idea is the object of the thought, and a further thing such as an affirmation or a fear which is directed towards the object of thought\n- One of the grave mistakes is to judge the ideas in one's mind to be accurate resemblances of things outside the mind (if they do even exist)\n\t- Thus the meditator considers ideas in the mind only as modes of thought\n- Ideas, as modes of thought, all have the same amount of formal reality (reality intrinsic to themselves) but their objective reality differs greatly\n\t- For Descartes and the Scholastics, ideas are the link that connect mind and world because they have both formal and objective reality.\n\t- Can think about this like dividing reality into a scale where infinite substances (like God) have the most reality, followed by finite substances (bodies and minds), followed by modes (modifications of body and mind -- e.g. colour, shape, size, etc.).\n\t\t- Ideas then, have the formal reality of modes (as they are modifications of the mind) but objective reality of a finite substance (car is a body)\n- No effect can have a greater amount of reality than its cause\n\t- The idea of a stone, then, could be caused by a stone or a large rock but it could not be caused by a colour \n\t- If the meditator can locate an idea with more objective reality than he has formal reality (finite substance). The only thing with more reality is infinite substance or the idea of God\n- [qualia](thoughts/qualia.md) can only be perceived in a confused and obscure way, so if they are things, they must have small degree of reality as to originate unproblematically from the Meditator himself\n### Existence of God\n- As the Meditator cannot have originated the concept of God (which has infinite substance), God must be the cause of this idea and must therefore exist\n\t- Could God not just be in contrast to his own finite being?\n\t- We would not be aware of a lack unless we were aware of a more perfect being and God is the ultimate perfect being\n\t- You can't actually get the idea of infinity just from endlessly increasing what's finite, so the infinite must independently exist (p. 32)\n- Could the Meditator themselves be supremely perfect?\n\t- If this is the case, it is plausible that the idea of God could be conceived in him without any outside cause\n\t- Rejects this for 3 reasons\n\t\t1. God is all actual and not potential\n\t\t2. If he is constantly improving, he will never attain perfection while there is room for improvement\n\t\t3. Potential is not being at all\n- The Meditator seems committed to claiming both (a) that we can only be sure of our clear and distinct perceptions if God exists and (b) we can know that God exists because we clearly and distinctly perceive the idea of God. If both (a) and (b) are true, Descartes is guilty of circular reasoning.\n## Fourth Meditation\n- If God has endowed him with infallible judgment, how is it that he can be mistaken, as he undoubtedly is from time to time\n- If God is a perfect creator, God should be able to create perfect beings\n\t- The Lord works in mysterious ways -- we should not seek to understand the true motives of God (?)\n\t- We are only a small part of a much larger creation\n- Descartes is a proponent of free will\n\t- The will is free to affirm or deny whatever it wishes -- as such, free will is the source of error\n\t- If there was no free will, we would never make mistakes\n## Fifth Meditation\n- God exists as an idea in the Meditators mind and he clearly and distinctly perceives all of his qualities. One of these qualities is existence, then God would not be God if he did not exist. (just as a triangle only exists if it has the property of being three-sided)\n- At the very least, then, the existence of God must be as certain as the properties of mathematical and geometrical objects since he can prove them in the same way.\n\n\n\n## Essay\n*Evaluate Descartes' assertion that God, as a perfect being, cannot be a deceiver. Note that some of his logic is implicit in his idea of perfection. Note that to evaluate an argument, you need to first explain the argument, and then say why it is or is not successful.*\n\nDescartes, in his meditations, wishes to find a foundation of knowledge that will still stand strong even after doubting the most basic facts about the world. In doing so, he starts by methodically doubting all things that he has \"less than complete certainty\" of. He casts asides sensory experience, claiming that these can be deceived. Even objects close by could be illusory as he could be dreaming. Even basic axioms of the world like mathematics could be false because of some evil genius that has \"employed all his energies in order to deceive me\". Iteratively, he tries to re-prove existence of many things, starting from the existence of self (*\"cogito, ergo sum\"*) and progressing towards an argument for the existence of God (and god as a perfect being who cannot be a deceiver.)\n\nIn the Fifth Meditation, Descartes presents the argument as follows:\n1.  Suppose there is a supremely perfect being -- a being that has every possible 'perfect' trait. A supremely perfect being *must* have every possible perfect trait because to exclude any or all perfections from a supremely perfect being is to stumble into a contradiction or to \"conceive of a mountain without a valley\".\n2. Necessary existence is a perfection. It is an existence where one depends only on [the self](thoughts/the%20Self.md) for existence (similar to the concept of independent origination in [emptiness](thoughts/emptiness.md)).\n3. Necessary existence cannot be separated from the essence of a supremely perfect being.\n4. Therefore, a supremely perfect being exists -- it is God.\n\nHowever, this argument is flawed as it begs the question -- the premise (that there exists a supremely perfect being) is also the conclusion (a supremely perfect being exists). This inherent circular argument then does not hold.\n\nFor the sake of continued examination of the argument, let us assume that this argument is sound, and that God indeed does exist.\n\nDescartes goes on to utilize the statement that God exists to prove that God cannot be a deceiver.\n\n1. God exists and is perfect\n2. Deception is imperfect, therefore God cannot deceive\n3. Whatever I perceive \"clearly and distinctly\" must be true\n4. As my perception is clear, the material world must exist\n\nHowever, this argument also begs the question as it relies on the first proof that God necessarily exists as a premise. Unfortunately, Descartes first proof relies on the fact that Descartes has a clear and distinct idea of God, which presupposes clear and distinct perception (the conclusion of this argument). Thus, to show that his perception is clear, he must assume that his perception is clear -- clearly an invalid argument.\n\n","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Design-Justice":{"title":"Design Justice","content":"\n## Summary\nDesign Justice focuses not just on design in the visual and aesthetic sense, but also on the design of systems.\n\nTo quote from the book, \"Design justice rethinks design processes, centers people who are normally marginalized by design, and uses collaborative, creative practices to address the deepest challenges our communities face.\" The norms, values, and assumptions that are encoded and reproduced in the *design* of systems can be changed by rethinking our design processes.\n\nIn less than 400 short pages, Sasha Costanza-Chock covers a breadth of topics ranging from intersectionality, bias, and universal design to maintenance, design sites, and technosolutionism -- all through detailed case studies of real-world design practices and social movements.\n\nShe guides the reader into how the 'unmarked user' and universal design erases certain groups of people within the matrix of domination (through ableist, eurocentric, and classist assumptions) and refutes the argument that 'design by committee produces mediocrity.'\n\nDesign Justice is a book that invites us to \"center people who are too often marginalized by design\". More importantly, it urges us to work towards an equitable world for everyone: one which treats design justice not as a funnel that we use to limit ourselves to a minimal set of supposedly universal design choices, but rather as a prism through which to generate a far wider rainbow of possible choices, each better tailored to reflect the needs of a specific group of people.\n\n## Reflection\nDesign sites are valorized as places of learning, making, and building and the intersection of social movements and the counterculture. Why then, have they become increasingly corporate places of extraction of free labour?\n\nThis cooptation of [hacker](thoughts/Hackers.md) culture, hackathons as design sites in particular, by neoliberalism has been on the back of my mind ever since reading the chapter on design sites in Design Justice. As someone who first got their footing in computer science through hackathons, it pains me to see that this is the rep that hackathons have slowly gotten over time, moving from safe spaces for idea exploration to increasingly corporate, time-bound, events where hackers spin up apps to test company products in exchange for the slim chance of winning prizes and recognition.\n\nHackathons reshape precarious and unpaid work. Writing code and building apps for free becomes an extraordinary opportunity and a collective imagination for fictional expectations of innovation that benefits all. Do we so necessarily need to tie these rituals of play in building and tinkering to the recruiting and product testing pipeline for large corporations?\n\nAs a hackathon organizer, Design Justice has helped me to more actively think about what hackathons are trying to motivate. Having more of the tools to articulate and locate exactly why hackathons have felt increasingly corporate is the first step to reinstate hackathons as third spaces not as places of creation or competition, but as places of play and exploration.\n\n## Quotes\n### Defining Design Justice\nHow larger systems -- including norms, values, and assumptions -- are encoded in and reproduced through the design of sociotechnical systems. ([Do Artifacts Have Politics](thoughts/Do%20Artifacts%20Have%20Politics.md))\n\nDesign justice rethinks design processes, centers people who are normally marginalized by design, and uses collaborative, creative practices to address the deepest challenges our communities face\n\nDesign justice is a framework for analysis of how design distributes benefits and bridges between various groups of people.\n\nDesign (noun): A plan or scheme conceived in the mind and intended for subsequent execution; the preliminary conception of an idea that is to carried into effect by action; a project. (Oxford English Dictionary)\n\nTrue, everyone designs, but only certain kinds of design work are acknowledged, valorized, remunerated, and credited. Though all humans design, not everyone gets paid to do so.\n\n*Affordance* refers to \"the perceived and actual properties of the thing, primarily those fundamental properties that determine just how the thing could possibly be used.\" ... An object's affordances are never equally perceptible to all, and never equally available to all.\n\n### On Intersectionality\nBlack women workers at GM were told they had no legal grounds for a discrimination case against their employer because antidiscrimination law only protected single-identity categories.\n\nThe concept of intersectionality provided the grounds for a long, slow paradigm shift that is still unfolding in the social sciences, in legal scholarship, and in other domains of research and practice.\n\nWhile there is rapidly growing interest in algorithmic bias audits, especially in the fairness, accountability, and transparency in machine learning (FAT*) community, most are single-axis: they look for a biased distribution of error rates only according to a single variable, such as race or gender.\n\nOne question about [intersectional approaches] is how many identity variables to include because each adds complexity (and, in many situations, time and cost) to audits.\n\n### Universal Design\nUniversal Design (UD) as defined by Center for UD at North Carolina State University: The design of products and environment to be usable by all people, to the greatest extent possible, without the need for adaptation or specialized design\n\nAt least in the digital domain, adaptive design that enables personalization and flexible configuration of shared core objects, tools, platforms, and systems provides a path out of the tension between the diverse needs of individual users and the economic advantages of a large-scale user base.\n\nUniversalization erases difference and produces self-reinforcing spirals of exclusion, but personalized and culturally adaptive systems too often are deployed in ways that reinforce [surveillance capitalism](thoughts/Data%20Capitalism.md).\n\nWe should destabilize the underlying assumption that what is best for the majority of users is best for *all* users.\n\n### The Unmarked User\nDesigners most frequently assume that the unmarked user has access to several very powerful privileges, such as US citizenship, English language proficiency, access to broadband internet, a smartphone, a normatively abled body, and so on.\n\nFor broader reasons of structural inequality, the universe of real-world users falls within a limited range compared to the full breadth of *potential* users, then [user-centered design](thoughts/human%20centered%20design.md) reproduces exclusion by centering their needs.\n\n### Disability Simulation\nThese 'simulations' produce an unrealistic understanding of the life experience of disability for a number of reasons: the nondisabled person does not have the alternate skill sets developed by [disabled people], and thus overestimates the loss of function which disability presents, and is furthermore likely to think of able-normative solutions rather than solutions more attuned to a [disabled person's] life experience\n\nDisability simulation is discredited; lived experience is nontransferable. \"Don't start by building a new table; start by coming to the table\"\n\n### Dismantling Existing Systems\ni.e. what's wrong with colour blindness\n\n\"Under this new rhetoric of colour-blindness, equality means treating all individuals the same, regardless of differences they brought with them due to the effects of past discrimination or even discrimination in other venues\"\n\nNew Jim Code\nAlgorithmic decision systems based on historical data sets reinforce white supremacy and discrimination even as they are positioned by their designers as \"fair\"\n\nRacial hierarchies can only be dismantled by actively antiracist systems design, not by pretending they don't exist.\n\nFar too often, user personas are created out of thin air by members of the design team, based on their own assumption or stereotypes about groups of people. When this happens, user personas are literally objectified assumptions about end users.\n\n### Maintenance\n\n[Creating new vs maintaining old](thoughts/creation%20vs%20maintenance.md)\n- Contributing to an existing project requires contacting and negotiating with the existing developers, maintainers, and community. Creating something new produces attribution, credit, and visibility for its developers, whereas attribution, credit, and visibility for participating in an existing project must, at the very least, be shared.\n- Support [Maintenance](thoughts/maintenance.md), not just \"innovation.\" Significant resources are necessary to maintain and improve existing movement tech, but most focus is on the creation of new projects.\n\n\"Those of us working to promote universal access to clean water and sanitation must keep our eyes not just on the competition and prizes, but on the less glamorous work of encouraging adoption, usage, and maintenance\"\n\n### Technosolutionism/Technochauvinism\nNew technology will save us!!\n\nAn exclusionary and elitist understanding of what technology is and where it comes from and a lack of interest in preexisting, community-based design practices.\n\n\"... where we are wholly dependent on a handful of extraordinarily gifted entrepreneurs to lead us out of the dark ages. This is a myth.\"\n\nFirst, it contains a somewhat masked normative assumption that \"technology adoption\" is always a good thing.\n\nNeoliberal, technocentric ideas about the city as a machine or as a software system waiting to be optimized have become increasingly prominent. Citizens should not be reduced to users through the lens of neoliberal governmentality.\n\nFirst consider what already works at the community level, and to steer students away from the pitfalls of tech solutionism and technochauvanism\n\n### Attention\n\nMediated visibility has become an important form of capital. Attention (time) is a scarce resource within late-stage informational capitalism, and its allocation has significant symbolic and material impacts (this is the [Attention economy](thoughts/attention%20economy.md)).\n\n\"Design challenges\" in which dozens, sometimes hundreds, of people do free labour and submit ideas in hopes that they'll be the lucky one chosen to receive visibility, recognition, and possibly even compensation.\n\n### Design Sites\nTracing the cooptation of hacker culture by neoliberalism\n\nInvisibility of subaltern communities may also be strategic. Sometimes, they shield their practices and innovations from mainstream visibility to avoid incorporation and appropriation.\n\n\"Alternative spaces and forms of living provided interesting ideas could be milked and marketed. So certain structural features of these 'indie' movement outputs were suddenly highly acclaimed, applied, and copy-pasted into capitalist developing laboratories\" ([Post-It Note City](thoughts/Post-It%20Note%20City.md))\n\nHackerspaces in the European context, which they describe as originally being \"third spaces\" outside of the logic of both the communist state and the capitalist market. \n\nThe assumption that making sites \"open\" makes them inclusive, without specifically addressing race, class, gender, and/or disability dynamics, is common to many privileged design sites.\n\nMany who are active in these design sites feel themselves to be participants in *commons-based peer production,* or \"decentralized, collaborative, and non-proprietary; base on sharing resources and outputs among widely distributed, loosely connected individuals who cooperate with each other without relying on either market signals or managerial commands\"\n\nWithout intentional intervention, these spaces find it very difficult to fulfil even their own liberal democratic rhetoric because they end up dominated by white cis men and by middle-class people with free time and disposable income.\n\nMore on hackathons: [hackathons](posts/hackathons.md)\n\n#### Hackathons: The Bad\n\nHackathons are understood by corporate managers as potentially effective ways to identify new talent, and therefore as a possible mechanism in the tech sector hiring pipeline. \n\n\"Hackathons, time-bounded events where participants write computer code and build apps, have become a popular means of socializing tech students and workers to produce 'innovation' despite little promise of material reward... [they] reshape unpaid and precarious work as an extraordinary opportunity, a ritual of ecstatic labour, and a collective imaginary for fictional expectations of innovation that benefits all, a powerful strategy for manufacturing works' consent in the 'new' economy.\" (Sharon Zukin and Max Papadantonakis)\n\nHackathons provide excellent opportunities for the extraction of free labour.\n\nThe assumption that a \"hackathon for good\" will be successful if it produces a new app that can help \"solve\" a social problem runs deep.\n\nHackathons nearly always focus on problems and rarely build on existing community assets; and people thing hackathons can do things that they usually can't, such as solve big or even little problems, create new products overnight, or 'level the playing field' of innovation through meritocracy. \"A one day hack for homelessness takes away from the complexity of social justice issues. ... You can't just come up with an app and solve the world's problems\"\n\n\"Hackathon spaces cultivate a culture that marginalizes hackers with specific needs, including but not limited to women, people with disabilities, people with non-traditional backgrounds, and even individuals with specific dietary restrictions. By consistently ignoring the health, diet, and care needs of diverse attendees, along with needs based on skill, class, and gender identities, hackathons create an exclusive and hostile environment.\"\n\n#### Hackathons: The Good\nThey are often crucibles of intense and focused learning, making, problem-solving, community building, and play.\n\n\"In the old days people used to form teams and rush in and try to fix things, without really even knowing what was broken ... it is no longer just a bunch of programmers in a room. There are now hackathons where actual community members are learning to code and interacting. ... Community members are also teaching programmers about the things they need to sustain and build for the future. That's a really good thing happening\"\n\nSuch hackathons push hackers to reflect on why they are doing the work they do, push for the ideas and welfare of marginalized communities in the tech sphere, and do so on the terms of their wellbeing and safety.\n\nOrganizers should pay attention to participants as whole human beings. For example, this means that it is important to consider food, bio breaks, accessible bathrooms that are friendly to all body types and genders, comfortable spaces to nap or relax, and decent lighting, etc.\n\n### Design Justice Pedagogies\n\"Critical pedagogy, where the role of the educator is to pose problems, create spaces for the collective development of critical consciousness, help to develop plans for action to make the world a better place, and develop a sense of agency among learners\"\n\n\"No one knows everything, but together we know a lot, if we listen to each other\"\n\nKey elements\n* Teach data science in a way that honours context, respects situated knowledge, and makes it clear that data is never \"raw\".\n* Emphasize the user of data to create shared meaning over individual mastery.\n* Teach data science that values not only reason, but [[thoughts/ethics|ethics]] and emotions as well\n\n### Critiques\n\"Design by committee produces mediocrity\" or \"we don't want to end up with the lowest-common-denominator design!\"\n\nIt's true that design justice practitioners have to take care that critique does not become our primary activity; an overemphasis on testing, evaluation, and critique can indeed be ultimately disempowering. At the same time, explicit critique paired with alternative proposals can be very productive.\n\nDesign justice doesn't imply that we must somehow reduce our options to only those that satisfy all accessibility criteria for the most marginalized within the matrix of domination. It is not meant to be a *filter* that we use to eliminate most design possibilities from consideration because they fail an accessibility checklist. In fact, design justice as a framework is meant to do the opposite: to act not as a funnel that we use to limit ourselves to a minimal set of supposedly universal design choices, but rather as a prism through which to generate a far wider rainbow of possible choices, each better tailored to reflect the needs of a specific group of people.","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Do-Artifacts-Have-Politics":{"title":"Do Artifacts Have Politics","content":"\nby *Langdon Winner*\n\n\"In controversies about technology and society, there is no idea more provocative than the notion that technical things have political qualities\"\n\n\"A long lineage of boosters have insisted that the 'biggest and best' that science and industry made available were the best guarantees of democracy, freedom, and social justice\" -- seeing these arguments esp wrt [web3](thoughts/web3.md) being a strong driver for these same values\n\n\"What matters is not technology itself, but the social or economic system in which it is embedded.\"\n\n\"Seemingly innocuous design features in mass transit systems, water projects, industrial machinery, and other technologies actually mask social choices of profound significance.\" (societal impact is treated as an externality, those which do not matter when 'just considering efficiency')\n\n\"The things we call 'technologies' are just ways of building order in our world.\"\n\n\"In that sense technological innovations are similar to legislative acts or political foundings that establish a framework for public order that will endure over many generations.\"\n\n### How artifacts can contain political properties\n\"Politics\" is defined as \"arrangements of power and authority in human associations as well as the activities that take place within those arrangements.\"\n\n1. \"Instances in which the invention, design, or arrangement of a specific technical device or system becomes a way of settling an issue in a particular community.\"\n2. \"Cases of what can be called inherently political technologies, man-made systems that appear to require, or to be strongly compatible with, particular kinds of political relationships\"\n\n\"Technological change expresses a panoply of human motives, not the least of which is the desire of some to have dominion over others, even though it may require an occasional sacrifice of cost-cutting and some violence to the norm of getting more from less\"\n\n## The mechanical tomato harvester\nA remarkable device perfected by researchers at UC from the late 1940s to present. The harvesters replace the system of handpicking.\n\nThe machine reduces costs by approximately five to seven dollars per ton as compared to hand-harvesting.\n\n\"The suit charges that University officials are spending tax monies on projects that benefit a handful of private interests to the detriment of farmworkers, small farmers, consumers, and rural California generally, and asks for a court injunction to stop the practice. The University has denied these charges, arguing that to accept them 'would require elimination of all research with any potential practical application'\" -- this is an especially good point re: whether additive (as opposed to multiplicative) tech is truly possible","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Dreams":{"title":"Dreams","content":"\n## Threefold model of [consciousness](thoughts/consciousness.md)[^1]\nDifferent brain-body processes\n\n1. Awareness: specific to global levels of awareness\n2. Contents of awareness: specific to consciousness of an object in a given sense field\n3. Identification: sense of [the Self](thoughts/the%20Self.md)\n\n## Hypnagogic State[^1]\nState of leading into sleep\n\n- See images and hear sounds and strange associative thoughts\n- Sleep Stages\n\t- Relaxed Wakefulness\n\t- Stage N1 (Hypnagogic)\n\t- Stage N2\n\t- Stage N3 (Deep Sleep)\n\t- REM (Dreaming Sleep)\n\t\t- Associated with vivid sensory dreams\n- Dissolution of boundaries between self and not-self\n\t- Not strong sense of being immersed in a world\n- We look *at* patterns and they absorb us\n\n## Dream State[^1]\nImmersion in a dream\n\n\u003e Dreams\n\u003e Here we are all, by day; by night, we're hurled\n\u003e By dreams, each one into a several [separate] world\n\u003e -- Robert Herrick (1591 - 1674)\n\n- Sense of being in a world\n- We experience being *in* the dream\n- Two ways of experience\n\t- Identification with dream ego from first-person (field perspective)\n\t- Identification with dream ego from third-person (observer perspective)\n- Wa cannot inspect (nonlucid) dreams directly\n\t- We can inspect only our waking memories of dreams\n\t- We have certain cultural and linguistic practices of dream reporting whereby we make stories of our dreams ([linguistic relativism](thoughts/linguistic%20relativism.md) for dreams)\n\n### Different views (Simulation Models of Dreaming)\n1. Orthodox View\n\t- Precepts: dreaming involves senses that we experience when we are waking, except the experiences of things that are not there or have weak correlation with what is there\n\t- Beliefs: when we dream $p$ we believe $p$ to be true. In most cases, these are false so dreaming involves mainly false beliefs\n2. Hallucination model\n\t- Dreaming is immersive spatiotemporal hallucination\n\t- Immersive: full immersion in the dream world\n\t- Spatiotemporal: full immersion in a here and now\n\t- Hallucination: experience that seems exactly like a perception but has weak stimulus correlation with the environment\n3. Imagination model\n\t- Dreaming involves experiences of the sort we have when we imagine (mental images)\n\t- When we dream that $p$, we imagine that $p$ (however, imagining that $p$ does not entail believing that $p$)\n\t- Dreams can be indeterminate in their sensory features (e.g. indeterminate in colour)\n\t- Object: what about emotions? Some emotions can only arise from belief\n\t\t1. When I dream that $p$, I experience fear, elation, etc.\n\t\t2. Such emotions arising from an attitude that $p$ can only arise from a belief that $p$\n\t\t3. So when I dream that $p$, I believe that $p$\n\t- Counterargument: contradiction, you still feel these emotion reading fiction\n\t\t- Same premises as above, but final conclusion is that: when I read in a fiction that $p$, I do NOT believe that $p$.\n\t\t- Way out of this contradiction is to deny premise 2)\n\t- Eye movements during lucid-REM sleep resemble waking perception more than they resemble waking imagination\n\t- Upshot: to dream is to imagine a dream world and to identify with the dream ego immersed in that world\n\n## Mind-wandering and Dreaming[^1]\n- Similarities\n\t- Content\n\t\t- Largely audiovisual and emotional\n\t\t- Loose narratives tinged with fantasy\n\t\t- Strongly related to current concerns\n\t\t- Draws on long-term memory\n\t\t- Simulates social interactions\n\t\t- Involves identification with a mental images of [the self](thoughts/the%20Self.md)\n\t- Process\n\t\t- Mostly unguided (save for lucid)\n\t\t- (hyper)associative\n\t- Lack of meta-awareness (awareness of the current contents of consciousness)\n\t- Large overlaps in activation patterns of cortical regions\n\n## Lucid Dreaming[^1]\n- A dream in which you can direct your attention to the dreamlike quality of the state\n- Features\n\t- Greater clarity/vividness\n\t- Realism\n\t- Emotional exhilaration\n\t- Sense of freedom\n- Sense of self in lucid dream state\n\t- Self-as-dreamer: \"I am dreaming\" (knowledge of being asleep in bed)\n\t- Self-as-dreamed (dream ego): \"I am flying\" (default conceptualizations of self)\n- Is lucid dreaming knowing you're dreaming or dreaming you're dreaming?\n\t- Did they just dream that they were aware that they were dreaming?\n\t- Knowing you're dreaming seems to involve a certain kind of attention and cognitive control that is missing when you dream you're dreaming\n\t- Seems to be a tell-tale LRLR eye moment signal during REM sleep when participants realize they are dreaming\n\n## Sleep Maps[^1]\n- Neuroscience\n\t- Presence of conciousness (waking, dreaming) vs\n\t- Absence of consciousness (dreamless sleep, coma)\n- Indian yogic philosophies\n\t- Gross consciousness (waking, dreaming)\n\t- Subtle consciousness (dreamless sleep)\n\nAre sleep states conscious?\n1. Yes: Yoga, Advaita Dedānta, Buddhism\n\t1. Dreamless sleep is a kind of consciousness without an object\n\t2. Invoked to explain the continuity of consciousness and sense of self across waking and sleeping\n\t3. Invoked to explain the waking knowledge of having been asleep\n3. No: [Nyāya](thoughts/Nyāya.md)\n\t1. Concept of sleep is based off of inference\n\n[^1]: This content is sourced from Professor [Evan Thompson](https://evanthompson.me/)'s course materials for PHIL451A at UBC. All rights to this content is retained by Evan Thompson.","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Dunbars-Number":{"title":"Dunbar's Number","content":"\n[Source: The Limits of Friendship by *Maria Konnikova*](https://www.newyorker.com/science/maria-konnikova/social-media-affect-math-dunbar-number-friendships)\n\n![](/thoughts/images/dunbar.png)\n\nThere's only so big a social group can get before it decays into smaller ones.\n\nSocial Brain Hypothesis -\u003e primates have large brains because they live in socially complex societies: the larger the group, the larger the brain\n\nApplied to humans, Dunbar computed a theoretical maximum of 150 for human social groups.\n\nA range (by a factor of 3)\n1. Casual Friends -\u003e 150\n2. 'Dinner' Friends -\u003e 50\n3. Close Friends -\u003e 15\n4. Intimate Friends -\u003e 5\n\nCan we scale trust beyond the Dunbar number? Curious if this is what makes large orgs so sluggish and boring to work at. This applies to scaling orgs and projects too. How do we ensure that [open source software](thoughts/Making%20and%20Maintenance%20of%20OSS.md) works when more than say 150 people are contributing?\n\nWhat about in [web3](thoughts/web3.md)? Structure helps us scale beyond 'natural' community sizes but this seems difficult in a group where the ethos is v much against said centralized structure.","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Dutch-Book":{"title":"Dutch Book","content":"\nA Dutch Book is a set of bets that you consider individually fair, but which collectively guarantee a loss\n\nThis usually happens when people commit probabilistic fallacies (e.g. the conjunction fallacy, believing $P(A \\land B | E) \u003e P(A | E)$ when this can never be the case). Another common mistake is *double counting* probabilities\n\nFor example, if J believes that $P(heads) = P(tails) = \\frac 2 3$, we can propose two bets\n1. Pay $2; win $3 if heads, $0 if tails\n2. Pay $2; win $3 if tails, $0 if heads\n\nBoth bets make sense for J. However, if J takes *both* bets, then he faces a guaranteed loss of $1\n\nHave the agent bet for propositions with credences (or [[thoughts/fair betting quotient|FBQs]]) that are too high, and against propositions with credences (or [[thoughts/fair betting quotient|FBQs]]) that are too low\n\nFor any given bet (set $p$ to be $1-p$ for the against case):\n\n|Player wins bet|Player loses bet|\n|--|--|\n|$S-pS$|$-pS$|\n\n## Dutch Book Theorem\nBased on the Kolmogorov [[thoughts/probability|probability]] axioms,\n\n1. If any axiom is violated, a Dutch Book can be made.\n2. If no axiom is violated, then no Dutch Book can be made.","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Elliptic-curve-Cryptography-ECC":{"title":"Elliptic-curve Cryptography (ECC)","content":"\n- A form of [[thoughts/Asymmetric Key Cryptography|asymmetric cryptography]]\n- Much smaller key-sizes than [[thoughts/RSA|RSA]]\n- Elliptic Curve properties (specifically looking at Ed25519)\n\t- Formula follows something like $y^2 = x^3 + ax + b$\n\t- Symmetric about the x-axis\n\t- Drawing a straight line through the curve will intersect no more than 3 points\n\t\t- A line between any two points will also intersect the curve at another place\n\t- Starting point on the curve point: A\n\t- \"dot\" function -\u003e kind of like a game of billiards\n\t\t- In this game of billiards, you take a ball at point A, shoot it towards point B. When it hits the curve, the ball bounces either straight up (if it's below the x-axis) or straight down (if it's above the x-axis) to the other side of the curve. The point it lands on is C\n\t\t- If the value C is over some maximum value (usually a prime), we modulus it with the maximum to end with a valid number.\n\t\t- A dot B = C\n\t- ![Billiard animation](https://blog.cloudflare.com/content/images/image02.gif)\n\t- It turns out that if you \"dot\" an initial point with itself $n$ times to arrive at a final point, finding out $n$ when you only know the final point and the first point is hard\n\t- $n$ is then the private key, point A dotted with itself $n$ times is the public key\n- ECDHE stands for Elliptic Curve Diffie Hellman Ephemeral and is a key exchange mechanism based on elliptic curves\n\t- Curve25519 is a popular set of elliptic curve parameters and reference implementation by Daniel J. Bernstein in C. Bindings and alternative implementations are also available.","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Ensemble-method":{"title":"Ensemble method","content":"\nEnsemble methods are classifiers that have classifiers as input (and often have higher accuracy than regular input classifiers). This is also called “meta-learning” and it **only works if the individual classifiers make independent errors**\n\n## Boosting/Stacking\nImproves training error of classifiers with high $E_{train}$\n\nModels that use the boosting ensemble method:\n1. [[thoughts/XGBoost]] (regularized regression trees)\n\n## Averaging/Voting\nImproves approximation error of classifiers with high $E_{approx}$\n\nModels that uses the averaging ensemble method:\n1. [[thoughts/Random Forest|Random Forest]]\n\n### Methods\n1. Voting: take the mode of the predictions across the classifiers\n2. Stacking: fit another classifier that uses the predictions as features","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Epicurueanism":{"title":"Epicureanism","content":"\nEpicurus: Greek philosopher than founded Epicureanism\n\nAims to lead a life characterized by\n1.  equanimity (*ataraxia*) and\n2. the absence of pain (*aponia*)\n\nThe universe is infinite and eternal and made up of atoms and empty space -- death is the end of the body and the soul (as the soul is made up of atoms that scatter at death)\n\nYour state at death is the same as your state before you were born, namely, the non-state of nonexistence.\n\n\u003e “Therefore death, the most terrifying of evils, is nothing\nto us, since for the time when we are, death is not\npresent; and for the time when death is present, we\nare not. Therefore it is nothing either to the living or\nthe dead since it is not present for the former, and\nthe latter are no longer.”\n–\nLetter to Menoeceus","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Evolutionary-game-theory":{"title":"Evolutionary game theory","content":"\nFocuses on the dynamics of strategy change by agents over time.\n\nEvolutionary game theory has helped to explain the basis of altruistic behaviours in Darwinian evolution.\n\nCompute the fitness of each group. Watch how each group fares in indefinitely repeated interactions. Fitness of a strategy is $Fitness(S) = \\frac{EU(S)}{\\textrm{Avg } EU }$\n\n## Evolutionarily Stable Strategy (ESS)\nAn evolutionarily stable strategy is one that, once fixed in a population, has higher fitness than any other available strategy\n\nIn formal terms, $x$ is an ESS iff\n1. $EU(x,x) \\geq EU(y,y)$ for any strategy $y$\n2. $EU(x,x) \u003e EU(y,x)$ or $EU(x,y) \u003e EU(y,y)$ for any $y$\n\n### Cake Division Problem\nWhereas [[thoughts/game theory|rational choice theory]] has multiple pure equilibrium strategies here, there is only one evolutionarily stable pure strategy: share equally\n\n### Polymorphic state\nDifferent strategies are played by different proportions of the population; however, these equilibria are not commonly found\n\n### Sequential Rationality and Trembling Hand\nA plan involving a sequence of choices exhibits sequential rationality if it specifies a rational (i.e., utility-maximizing) choice at each point, relative to the choice situation at that point.\n\nTrembling Hand: sequential rationality is necessary and sufficient for optimality if we allow a small probability of error by other players. In picking a strategy, we should take “mistakes” into account — errors that occasionally lead an opponent to choose a dominated strategy\n\nEvolutionary analogue: mutation and recombination are analogues of the trembling hand. Both allow for new strategies to emerge\n\n### Replicator Dynamics\n1. Compute expected payoff (fitness) for each strategy. A weighted average of payoff against each other strategy in play: $U(A) = u(A \\textrm{ vs } A_1)p(A_1) + \\dots + u(A \\textrm{ vs } A_n)p(A_n)$\n2. Compute the average fitness of the whole population, $U$. This is the weighted average of the individual fitnesses: $U = u(A_1)p(A_1) + \\dots + u(A_n)p(A_n)$\n3. Compute the relative fitness of each strategy. Relative fitness of A is just $U(A) / U$\n4. Compute the new proportion of the population using each strategy (for the next round). $p'(A) = p(A) \\cdot [U(A) / U]$\n\n## Ethics\nCan game theory give us substantive [[thoughts/ethics|ethical]]/political recommendations?\n\n### Gauthier's Theory\n- The Nash bargaining solution provides a solution to the problem of fair division, based entirely on assumptions about rationality.\n\t- Objection: Hume's Principle, we can't derive what we *ought* to do from what *is* true\n- Include a 'bridge-premise' that whatever a [[thoughts/rationality|rational]] group of people agree upon should be implemented (similar to [[thoughts/Social Contract Theory#Rawl's Theory of Justice|Rawl's Theory of Justice]])\n\t- Objection: Exploitation may be beneficial... but is it moral","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Experience":{"title":"Experience","content":"\n## 2022: Verses Technical Lead\nLed engineering for [pluriverse.world](https://pluriverse.world/) and [interdependence.online](https://www.interdependence.online/declaration) artifacts, building technical infrastructure to support over 10,000+ signatures across both. Developed an [open source package](https://github.com/verses-xyz/ar-wrapper) for versioned permaweb document management on Arweave and a [GitHub action](https://github.com/verses-xyz/arweave-publish-action) to automatically persist documents to Arweave.\n\nTech used: Vercel, GitHub Actions, Node.js, TypeScript, Arweave\n\n## 2021: Microsoft Garage SWE\nBuilt out third-party streaming apps, enabling non-technical content creators to livestream content using Microsoft Teams. Decoupled data models from data views by introducing a data and service layer using GraphQL. Abstracted common functionality between all four streaming apps by creating a streaming hook and error manager context with 98% test coverage.\n\nTech used: Jest, Teams SDK, Azure DevOps, JavaScript, GraphQL\n\n## 2021: BentoML Open Source Contributor \u0026 MLH Fellows Class 0\nSelected as one of 144 fellows to be part of the inaugural class of the MLH Fellowship program from a pool of 20,000 applicants. Implemented CLI command to containerize BentoML machine learning models, reducing dependence on external tool workflows. Proposed, implemented, and tested a distributed application-level locking module to allow multiple concurrent operations on models. Reduced Docker image size by 60% to enable lighter deployments by building Debian-slim based Docker images for model server. Created Helm chart allowing users to deploy the model storage component to a Kubernetes cluster with a single command rather than needing to follow an entire guide.\n\nTech used: Pytest, Docker, AWS Lambda, Helm, Kubernetes, Python\n\n## 2021: nwPlus Co-president\nLed and coordinated 7 subteams with a total of ~50 team members to run 3 of the largest hackathons in Western Canada. Led logistics for HackCamp, a beginner-focused virtual hackathon, attracting over 500+ attendees, 3.2k+ livestream viewers, and $1200 in donations to charities. Co-lead the creation of a publicly available self-learning resources guidebook for tech beginners. Co-lead the development of our hackathon portal which aims to be a central information hub for hackers to do judging, relay announcements, and view the schedule Handled 200k+ interactions on the site during HackCamp.\n\nTech used: Gitbook, Firebase, React, Github Actions, JavaScript\n\n## 2020: Hootsuite SWE\nReduced mean time-to-acknowledge for alerts from hours to minutes by adding alerting and monitoring for key SLOs for several tier one services. Added monitoring dashboard and alarms for website cache with AWS CloudWatch. Increased accessibility on paid signup flow and added various end-to-end frontend tests. Implemented various A/B tests. Updated internal metrics collection tools to work with NGINX.\n\nTech used: React, Jest, Cypress, Terraform, Ansible, Grafana, Prometheus, JavaScript, HCL\n\n## 2019: Hootsuite SWE\nImplemented a proof of concept service mesh to break Scala monolith service into microservices. Proposal was added to the company technical roadmap for 2023. Implemented an internal endpoint to assist with data compliance requests. Defined and implemented Service Level Objectives (SLOs) for 3 of Hootsuite's core internal services.\n\nAlso wrote a [[posts/hootsuite|blog post]].\n\nTech used: SQL, Envoy, Istio, Kubernetes, Docker, Sumologic, Go, Scala","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Extended-Mind-Hypothesis":{"title":"Extended Mind Hypothesis","content":"\n## Extended view of the mind\n-   not an internal control system, enclosed in the human body, receiving data from human sensory system and directing human action\n-   instead, as systems that extend far beyond the body of the human organism, systems that include extra-somatic resources: environmental fuels for adaptive action\n-   suggest that human cognitive systems include those resources that are importantly, robustly, reliably, or persistently supportive of decisions making\n\n## Environmentally Supported Cognition\n-   derives from niche construction, helps to emphasize the active role of the agent in explaining the adaptive fit of agent and environment\n-   over time, agents adapt to environments but also adapt their environment to them ([Theory of Niche Construction](thoughts/Theory%20of%20Niche%20Construction.md))\n\t-   \"Animals construct nests, burrows and dams, thus protecting themselves from predators and from the violence of the world.\"\n\t-   epistemic action is a form of niche construction too\n\t\t-   epistemic → relating to knowledge\n\t\t-   thus, ants lay scent trails between nest and food source\n- humans partake in [generational learning](thoughts/generational%20learning.md)\n\n## Agential Gullibility\nIn which we too readily bolt external processes onto our own agency. To rephrase, to rely too heavily on the external faculties and [trust](thoughts/trust.md) in them blindly and fully.\n\n##  Otto — the man who lost his memory\n-   clark and chalmers (extended mind) argued that information in his notebook should be amongst Otto's memories\n\t-   parity principle\n\t\t-   if an external resource plays the same functional role in supporting action as an action-supporting internal resource that is uncontroversially cognitive, then the external resource is part of the cognitive system of the agent\n\t-   functional difference between otto's notebook and internally represented information\n\t\t-   subject to interference from other parties and manipulation\n\t\t-   only accessed via other intentional states (one must believe that the book contains memories that you've written before, for example)\n\t-   cant replace internal, embodied wants (e.g. relational and sexual preferences)\n\t\t-   notebook might be a prompt or a cue, but can't replace motivation and desires\n-   environmental fuels for cognition — three dimensions\n\t1.  [trust](thoughts/trust.md)\n\t\t-   reliability of their access to a resource and the reliability of the resource itself\n\t\t-   the more agents trust a resource, the less they will see themselves needing redundancy against failure\n\t\t-   Otto’s competitors have the opportunity to steal his notebook, erase passages in it and add deceptively to it. If Otto is rational, he will be aware of such a danger and will be wary of committing himself to a high-stakes action on the basis of his notebooked beliefs alone\n\t2.  interchangeability, individualization, entrenchement\n\t\t-   example of stick for a blind person, extension of their hand and for them, phenomenologically the interface between body and world is at the end of their stick rather than at the end of their hand\n\t\t-   stick is individualized (custom weight, balance, length, etc.) and entrenched (switch it out, they won't be used to it)\n\t\t-   can apply to cognitive resources like book too\n\t\t\t-   most books are interchangeable (standard books) but some are heavily individualized (long marginalia, etc.)\n\t\t\t-   none are entrenched → no single work is sufficiently salient, they dont read them enough that they adapt to their resource\n\t3.  the individual and the collective\n\t\t-   distinction between individual and collective resources\n\t\t\t-   collective resources have distinct individual and intergeneration dynamics\n\t\t\t-   [[thoughts/language|language]] have almost certainly transformed the internal processes of human minds\n\t\t\t-   We adapt the expressive powers of [[thoughts/language|language]] to our own purposes, but no doubt we have also adapted to it (not to any one individual, but to society as a collective)","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/FLP-Result":{"title":"FLP Result","content":"\nConsensus in distributed systems **cannot be asynchronous** due to the FLP Result: there is no deterministic consensus algorithm that is guaranteed to terminate in an asynchronous crash-stop [[thoughts/system model|system model]]\n\nThis holds even if $f = 1$\n\nSimilar to tradeoffs made in the [[thoughts/CAP Theorem|CAP Theorem]], when under attack, we need to choose between\n- [[thoughts/safety|safety]]\n- consistency\n- [[thoughts/liveness|liveness]]/availability\n\nThis can somewhat be abated by randomized protocols (see: [[thoughts/HoneyBadgerBFT|HoneyBadgerBFT]])","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/FOAF":{"title":"FOAF","content":"\nSummarized from [the xmlns FOAF specs](http://xmlns.com/foaf/spec/)\n\nFOAF stands for 'friend of a friend'\n\n\u003e FOAF is a project devoted to linking people and information using the Web... If people publish information in the FOAF document format, machines will be able to make use of that information. If those files contain \"see also\" references to other such documents in the Web, we will have a machine-friendly version of today's [[thoughts/hypertext|hypertext]] Web.\n\nIt is a way of creating a semantically meaningful network of objects, useful for enabling the Semantic Web.\n\n- FOAF descriptions are published as linked documents in the Web\n- The result of the FOAF project is a network of documents describing a network of people (and other stuff).\n\nExample FOAF describing a person (using [[thoughts/RDF|RDF]])\n\n```xml\n\u003cfoaf:Person rdf:about=\"#danbri\" xmlns:foaf=\"http://xmlns.com/foaf/0.1/\"\u003e\n  \u003cfoaf:name\u003eDan Brickley\u003c/foaf:name\u003e\n  \u003cfoaf:homepage rdf:resource=\"http://danbri.org/\" /\u003e\n  \u003cfoaf:openid rdf:resource=\"http://danbri.org/\" /\u003e\n  \u003cfoaf:img rdf:resource=\"/images/me.jpg\" /\u003e\n\u003c/foaf:Person\u003e\n```\n\nIt basically says, \"there is a [foaf:Person](http://xmlns.com/foaf/spec/#term_Person) with a [foaf:name](http://xmlns.com/foaf/spec/#term_name) property of 'Dan Brickley'; this person stands in [foaf:homepage](http://xmlns.com/foaf/spec/#term_homepage) and [foaf:openid](http://xmlns.com/foaf/spec/#term_openid) relationship to a thing called http://danbri.org/ and a [foaf:img](http://xmlns.com/foaf/spec/#term_img) relationship to a thing referenced by a relative URI of /images/me.jpg\n\n## Adoption\n[Source](https://www.joelonsoftware.com/2022/12/19/progress-on-the-block-protocol/)\n\n\u003e **people will only add semantic markup to their web pages if doing so is easier than not.**\n\nNow imagine this world for a second:\n-   I want to insert a book into my blog post\n-   I type **/book**\n-   A search box appears where I start typing in the title of my book and choose from an autocomplete list.\n-   Once I find the book, a block gets inserted in my blog post showing details of the book in a format I like, _with nice semantic markup behind the scenes_.","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Farcaster":{"title":"Farcaster","content":"\n\u003e Farcaster is a sufficiently decentralized social network. \n\nTwo main components:\n1. On-chain registry for identity registration (like [[thoughts/DID#High level overview|DID VDRs]]). Table of `username`, `address`, and `host_url`\n2. Off-chain hosts where users store social data\n\n## Distributed Host Architecture\nFarcaster allows users to host their content on any web server as long as they sign everything with their private key.\n\nThere are two options for hosting: self-hosting and using a managed host (Gmail does for email and Github does for [[thoughts/git|Git]]).","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Filecoin":{"title":"Filecoin","content":"\n\u003e A decentralized storage network\n\nSummarized from [Filecoin Specs](https://spec.filecoin.io/)\n\nEssentially a [[thoughts/decentralized marketplace|decentralized marketplace]] (see: [storage market](https://spec.filecoin.io/systems/filecoin_markets/storage_market/)) with storage providers and storage users. Providers advertise space and cost and client selects winning storage provider (creating competition). Provider stores the content and is paid with Filecoin on an ongoing basis as long as they can prove they are storing the data properly.\n\n## Filecoin Blockchain + VM\nThe majority of Filecoin’s user facing functionality (payments, storage market, power table, etc) is managed through the Filecoin Virtual Machine (Filecoin VM). The network generates a series of blocks, and agrees which ‘chain’ of blocks is the correct one. Each block contains a series of state transitions called `messages`, and a checkpoint of the current `global state` after the application of those `messages`.\n\n## Node Types\nAny node participating in the Filecoin network should provide the _chain verification_ service as a minimum. Depending on which extra services a node provides on top of chain verification, it gets the corresponding functionality and Node Type “label”.\n\n## Networking\nMostly reuses existing libp2p library bits\n- Graphsync: used for syncing metadata and blockchain data\n- Gossipsub: propagating block headers + messages\n- [[thoughts/Kademlia DHT|Kademlia DHT]]: peer discovery + peer routing\n- Bootstrap list: list of nodes to connect to upon joining the network, bootstrap nodes and their addresses are defined by the users (i.e. applications)\n\n## Clocks and Time\nSee also: [[thoughts/clocks|clocks]]\n\nUses the concept of epochs where $epoch = \\lfloor \\frac{(current \\ time - genesis \\ time)}{epoch \\ time} \\rfloor$\n\nClocks used as part of the Filecoin protocol should be kept in sync, with offset less than 1 second so as to enable appropriate validation. Nodes SHOULD run an NTP daemon (e.g. timesyncd, ntpd, chronyd) to keep their clocks synchronized to one or more reliable external references.\n\nNodes have strong incentive to prevent their clock skewing ahead more than one epoch to keep their block submissions from being rejected. Similarly have a strong incentive to prevent their clocks skewing behind more than one epoch to avoid partitioning themselves off from the synchronized nodes in the network.\n\n## Algorithms\n### Proof of Storage\nThe proof that a storage miner indeed keeps a copy of the data they have promised to store is achieved through “challenges”, that is, by providing answers to specific questions posed by the system.\n\nChallenge properties:\n1. target a random part of the data and \n2. be requested at a time interval such that it is not possible, profitable, or rational for the miner to discard the copy of data and refetch it when challenged.\n\nTwo components\n1. Proof of replication (PoRep): extends the basic concept of proof-of-retrievability by proving that multiple copies of the data are stored\n2. Proof of spacetime (PoSt): extends PoRep by proving that replicas are stored for a given period of time. It involves a series of PoReps\n\t1. WinningPoSt: The answer to the _WinningPoSt_ challenge has to be submitted within a short deadline, making it impossible for the miner to seal and find the answer to the challenge on demand. This guarantees that at the time of the challenge the miner maintains a copy of the data.\n\t2. WindowPoSt: This involves submitting proofs regularly (see details below) and makes it irrational for a miner to _not_ keep a sealed copy of the data as it is more expensive to seal a copy of the data every time they are asked to submit a WindowPoSt challenge.\n\nThe sectors a miner has pledged to store, the more the partitions of sectors that the miner will need to prove per deadline. This requires ready access to sealed copies of each of the challenged sectors and makes it irrational for the miner to seal data every time they need to provide a WindowPoSt proof. If this proof is not completed in time, the storage miner supplying that sector in the proof has their collateral slashed and storage power reduced.\n\n### GossipPub\nGossipSub is a gossip-based pubsub protocol that is utilising two types of links to propagate messages:\n1. _mesh links_ that carry full messages in an _eager-push_ (i.e., proactive send) manner and\n2. _gossip-links_ that carry message identifiers only and realise a _lazy-pull_ (i.e., reactive request) propagation model.\n\t\n\tIn gossip propagation, only message headers are sent to inform them of messages that they might not have received before. Nodes then ask for the full message, hence, realizing a reactive request, or “lazy pull” model.","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/From-Counterculture-to-Cyberculture":{"title":"From Counterculture to Cyberculture","content":"\n## Quotes\n### Digital Communalism (see: [tribal flourishing](thoughts/tribe%20flourishing.md))\n\n\"Ubiquitous networked computing had arrived, and in its shiny array of interlinked devices, pundits, scholars, and investors alike saw the image of an ideal society: decentralized, egalitarian, harmonious, and free\"\n\n\"In *The Gutenberg Galaxy* McLuhan described the new age in tribal terms: electronic media had linked all of humanity into a single 'global vilage'\"\n\n\"Nor does the fact that individuals can come together by means of computer networks necessarily require that their gatherings become 'virtual communities'\"\n\n\"Dyson and Barlow, as well as many other commentators at the time, saw the [Internet](thoughts/Internet.md) serving as a rhetorical prototype for new, flexible, and mobile ways of working and living.\"\n\nTogether, the *Catalog* and the *Supplement* became textual forums within which a geographically dispersed collection of individuals and groups could come together, in text and sometimes pictures, and recognize each other as members of a single community. In a sense, *Catalog* and *Supplement* became town squares.\n\nMuch as the dancers at the Trips Festival had imagined that LSD would allow them to escape their bodies and enjoy a new form of communion, scholars and reporters began to describe computer-mediated communication as a form of interaction in which bodies had ceased to matter.\n\n### Comprehensive Designers\n[Contact Language](thoughts/boundary%20object.md) which to exchange ideas and techniques in linguistically distinct tribes (e.g. scientists, technologists, and administrators)\n\n\"The Comprehensive Designer not only did not need to don a gray flannel suit when he went to work; he actually needed to become an artist and intellectual migrant. To a generation preoccupied with the fear of becoming lockstep corporate adults on the military model of Brand's imagined Soviet Army, Buckminster Fuller offered a marvelously playful alternative\"\n\n\"How you get energy is, you take polarities and slap them next to one another. If you get into cybernetics and your head is just a minute ago full of organic gardening and ecology, then cybernetics starts to come alive for you in a different way.\"\n\n### Network Forums\nNetwork Forum -- a palce where members of different communities come together, exchanging ideas and legitimacy, and in the process, synthesizing new intellectual frameworks and new social networks.\n\nNetwork entrepreneur: one who migrates from one intellectual community to another and, in the process, to knit together formerly separate intellectual and social networks.\n\n\"We thought of the WEC as a print version of what the Internet was going to be\"\n\n### Computational Metaphor\nOn the computational metaphor (seeing everything as [computable](thoughts/computability.md))\n\"We are compiling a vocabulary and a syntax that is able to describe in a single language all kinds of phenomenon that have escaped a common language until now. It is a new universal metaphor. It hasm ore juice in it than previous metaphors: Freud's dream state, Darwin's variety, Marx's progress, or the Age of Aquarius. And it has more power than anything else in science at the moment. In fact the computational metaphor may eclipse mathematics as a form of universal notation.\"\n\"Society as a whole, as well as its constituent organizational parts, functioned much like organisms and machines.\"\n\n\"The principles governing the world of the soft -- the world of intagibles, of media, of software, and of services -- will soon command the world of the hard -- the world of reality, of atoms, of objects, of steel and oil, and the hard work done by the sweat of brows.\" -- New Rules for the New Economy\n\nTechnocracy, technostructure, or technological society: society's rapid process of centralization and rationalization as both supported by new technologies and designed to help build them.\n\nSante Fe Institute: founded in 1984 by a group of scientists who had come to believe that since WWII, the biological, physical, and socila sciences had begun to converge. Computers, they argued, had made this convergence possible in two ways: first, they had served as tools for examining and modeling the world, and, second, the algorithms with which they organized information mimicked the algorithmic patterning of life itself by means of biological \"technologies\" such as DNA.\n\n### Neocolonialism\n\"[The hippie's] arrival tapped into memories of very old patterns of colonization and migration. A chicano member of New Mexico's Reality Construction Company commune told a visiting reporter, 'every time a white hippie comes in a buys a Chicano's land to escape the fuckin' city, he sends that Chicano *to* the city to go through what he's trying to escape *from*, can you dig it?... Then when that money's gone, see, the Chicano has to *stay* in the city, cause now he ain't got no land to come back to.\"\n\n### Power Hierarchies and Individualism\n\"Brand suggests that top-down politics (i.e. the kind where Mr. Advantage tells Mr. Disadvantage what to do) is backrupt. The center of change must be the individual, acting with other likeminded individuals. This emphasis on local action echoes the notion of the individual's local role in maintaining universal systems.\"\n\nWEC seems to promote an incredibly individualistic approach; Indians must work with Indians, the Third World with the Third Wolrd, blacks with blacks, and so on. No group should count on help from any other... Such segregation might seem to conflict with the WEC's celebration of 'whole' systems. This seems to be an artifact of the fact that all members of the WEC were white and relatively young, iwth a high level of education and easy access to social and financial resources.\n\n\"The great machines of empire had been miniturized and turned over to individuals, and so transformed into tools with which individuals could improve their own lives.\"\n\n\"As a variety of economic sociologists have noted, the mid-1980s saw hierarchical firms in many industries and several nations reorganize themselves as project oriented networks. They laid off workers, broke component elements of firms into semi-independent project teams, and decentralized their management structure.\"\n\n\"Although the hive had a queen, he pointed out it was governed by the rule-driven behaviour of its many members. In the hive one could see 'the true democracy and all distributed governance'. One could also see the faded image of New Communalism. Leveled, collaborative, linked by invisible signals and shared feelings, Kelly's hive was a sort of natural commune.\" (more on [collaborative-thinking](posts/collaborative-thinking.md))\n\n\"Together, *Wired* suggested, this digital generation would do what the New Communalists had failed to accomplish: they would tear down hierarchies, undermine the sorts of corporations and governments that had spawned them, and, in the hierarchies' place, create a [peer-to-peer](thoughts/peer-to-peer.md), collaborative society, interlinked by invisible currents of energy and information.\"\n\n\"The urge to 'hack' politics by bringing governance down to a mangeable local level and by basing social integration on technologically facilitated forms of consciousness was one of the driving impulses behind the New Communalist movement\"\n\n\"In many industries today, and in some parts of military and academic life as well, hierarchies have been replaced by flattened structures, long-term employment by short-term, project-based contracting, and professional positions by complex, networked forms of sociability.\"\n\n### [Hackers](thoughts/Hackers.md)\nHackers -\u003e  those who figured things out as they went and invented for pleasure. Focused on computer systems themselves and on seeing what they could do\n\nPlanners -\u003e those who pursued problems according to a set and less flexible strategy. Thought of computers as tools that oculd be used to generate or model infomration\n\nSteven Levy's definitions:\nA hack -\u003e a project undertaken or a product built not solely to fulfill some constructive goal, but with some mild pleasure take in mere involvement\n\n### Media Labs\n\"The sponsors were not allowed to demand that any particular reserach be done on their behalf. Rather, they were buying permission to watch as [they built]\"\n\n\"Media Lab personnel were never required to produce artifiacts that could be mass-produced or that would feede directly into sponsors' lines of business per se. Instead, they were expected to produce 'demos.'\"\n\n### Misc\n\"I always thought tools were objects, things: screw drivers, wrenches, axes, hoes. Now I realize that tools are a process: using the right-sized and shaped object in the most effective way to get a job done.\"\n\nOn CompuServe and elsewhere, developers largely treated information as a commodity to be exchanged and users as consumers of information goods\n\n\"Biological life does not want to keep speeding up like a chip design, cycling ever faster year by year.\"\n\n\"Behind the fantasy of unimpeded information flow lies the reality of millions of plastic keyboards, silicon wafers, glass-faced monitors, and endless miles of cable. All of these technologies depend on manual laborers, first to build them and later to tear them apart.\"\n\n## Reboot Discussion\n### How did this book start?\n\n-   Why and how did computers go from emblems of cold war state to tools of personal liberation?\n-   A bunch of folks like Steward Brand, Kevin Kelly, etc. (inner circle included people from the 60s to the 90s) having a person who he could follow across these generations was extremely helpful\n\n### What is cybernetics?\n\nDifferent between social networking, computer networking, etc.\n\nAnother definition: computationalization of human processes\n\n-   What is the counterculture\n    -   What it was lauded for: The hippie world brought us the tech world\n    -   What he was trying to say: The tech world of the 40s and 50s brought us the ideas and insights that brought us hippies\n-   Insights from the anti-aircraft system\n    -   Biological (person) and technological (machine) systems can be described by the same underlying concepts (mathematics)\n    -   The core idea: Unifying a world with code. Should be a universal system.\n-   War brought different people from different disciplines together and had a shared communication medium of code\n\n### What was the counterculture?\n\n-   People in 50s and 60s protesting because worried about being turned into information\n-   Two distinct movements (both are anti-bureaucracy, anti-big tech, anti-mass culture)\n    -   New Left (political)\n        -   Struggle\n        -   Leaders, Parties\n    -   New Communalists (internal consciousness, mindset)\n        -   Deeply anchored in the dreams of the cyberneticists\n        -   Technocrats of control via communication (banger)\n        -   Communes (literally in the name)\n-   Why were the 50's kids so enamoured with technology?\n    -   Kids of the counterculture\n    -   Keep the tech made from the way but throw away the culture of the time\n-   When you take away bureaucracy you don't get freedom but 'rule by cool' → disastrous for a democratic society\n\n### Did the New Left have any effect on Cyberculture?\n\n-   Folks on new left will say they did → Computers fulfilled agreement\n-   Communalists had more contribution in tech world\n-   Communes were disasters, didn't last long, living in California\n-   Computer industry was booming\n-   Stanford = hotbed of creative LSD ingestion (damn wtf)\n    -   reboot group trip when?\n-   Steward Brand in 1984 as an Apple Mac, create a society of consciousness\n    -   Mac (as a metaphor for tech) is the new LSD → ability to remove the importance of the physical self\n\n### How much of the shift was a result of WEC? How much you see importance of media / social networking vs technical revolution?\n-   WEC was not a marketplace, rather an aggregator of information (a pre-Google search engine)\n-   What tools do you want to bring to a commune (ex: farming commune)\n    -   Food, housing, basics\n-   Why would you need a calculator and a book on cybernetics on a farm?\n    -   Tools which allow you to fundamentally understand the world in a different way\n    -   Appropriation!\n-   Catalogue provides the infrastructure → leads to conferences which lead to development of more infrastructure\n-   Network Entrepreneur sees several decentralized groups that aren't connected and services as a connector\n\n### Connection between WEC and WELL\n-   picture yourself as a hippie in the 1980's, communes will save the world and end warmaking America\n    -   California is tech driven, everything is failing\n    -   Black panthers have been crushed\n-   Howard Rheingold (the virtual community → on wiki someone find it)\n-   Electronic Frontier → empty society/land of consciousness\n-   Larry Bird, most influential people in silicon valley\n\n### Our current state seems somewhat inevitable, were there any inflection points along the way that could have changed the direction\n-   Counterculture legitimates a project that is already underway\n-   Different in ways that we don't talk about as much\n    -   Gone right\n        -   The power of email, allows you to have institutional and parainstitutional ties\n        -   The power of search, reams of first hand information instantly\n    -   Gone wrong\n        -   Economics of [incentives](thoughts/incentives.md) and bad actors\n        -   Individuating users and centralize control of information, enables advertising en masse\n            -   Although it predates technology via TV and radio, amplified by\n    -   Government have to intervene, like oil companies mining our social world\n        -   Must let go of communalist dream of collective consciousness\n\n### Era of connected machines → connected humans\n-   Enabled by technological development\n-   Can this be beneficial for everyone rather than just the privileged?\n-   Tech that has been sold to us as devices of personal empowered\n    -   not only corporate sponsored but also partnered with the state\n    -   intersection of Big Tech and the state is an uh oh → military industrial complex never really goes away\n\n### Where is todays counterculture\n-   Not the left, but actually the right\n-   Concern is not big data and ML but with corporations and states\n-   Place of rebellion is not at the data level but at the institution and union level (in big corporations) + legal level (ex: protection of Uber drivers)\n-   There are bodies and factories and server farms → lets not forget the basis of our abstractions\n\n### What can we learn from the promises/pitfalls of Steward Brand\n-   Performative politics\n    -   false belief that finding ourselves in our mid 20s is gonna change the world\n    -   rather, by engaging and learning from people who are vastly different from us, BE political\n    -   don't isolate, break out and do politics\n-   don't build communities of consciousness\n    -   build places of exchange, places where public decision making and CHANGE happens","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/GDPR":{"title":"GDPR","content":"\nFrom Antonio García Martínez in [*The right to never be forgotten*](https://www.thepullrequest.com/p/the-right-to-never-be-forgotten)\n\nTwo foundational concepts in GDPR:\n1. presence and persistence of personal data\n2. who keeps that data around (further distinguished into two classes of data holders)\n\t1. controllers (first-party). liability falls on this party to get end-user opt-in and face consequences if found in violation\n\t2. processers (third-party)\n\nPersonal data is “an identifier such as a name, an identification number, location data, an online identifier or to one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person.” In other words, it’s things that can be traced unambiguously to the real you\n","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Galls-law":{"title":"Gall's law","content":"\n\u003e “One day I will find the right words, and they will be simple.” ― **Jack Kerouac, The Dharma Bums**\n\n## Gall's Law\nA rule of thumb for [[thoughts/complexity|complex]] system design: simple alphabets produce complex behaviors, complex alphabets produce stupid behaviors\n\n\u003e A complex system that works is invariably found to have evolved from a simple system that worked. A complex system designed from scratch never works and cannot be patched up to make it work. You have to start over with a working simple system**\n\n## Gall-Meadows Ladder\n\nAdewale Oshineye coins the concept of a Gall-Meadows ladder\n\n\u003e Success needs what I think of as a Gall-Meadows ladder: a mechanism for jumping from one stable system to another ... in order to evolve your project\n\u003e \n\u003e The Gall-Meadows ladder suggests that to get from a simple working system to a complex working system you have to find a sequence of working systems that increase the level of complexity.","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Games-Agency-as-Art":{"title":"Games: Agency as Art","content":"\nSee also: [[thoughts/games]], [[thoughts/The Grasshopper, Games, Life and Utopia]]\n\n## Book\nBook, written by C. Thi Nguyen\n\n\u003e Painting lets us record sights, music lets us record sounds, stories let us record narratives and games let us record **agencies**\n\n- Achievement play: pursuing winning for the sake of winning or the sake of something that follows from winning such as fame, goods, or money\n- Striving play: pursuing winning for the sake of the struggle and the intrinsic act of playing the game itself.\n\t- Two clear parts:\n\t\t1. In order to engage ourselves in striving play, I must be able to take on a *disposable end* that is treated as final. It builds the capacity to submerge ourselves in narrowed agential modes.\n\t\t\t- Being unable to do this leads to the diffident player, who can't bring themselves to care about the game \"What's the point? It's just a game\"\n\t\t2. I must be able to bring myself to temporarily care about an end, and for that end to appear to me as final. But I must also be able to dispose of that end afterwards. This disposal helps build the capacity to step back and reflect on the value of these narrower states from a wider, less artificially clarified perspective. This turns out to be protective against the stickiness of narrowed agential modes and ends\n\t- A successful striving player is able to do both of the above\n\t- Suits calls this the [[thoughts/The Grasshopper, Games, Life and Utopia#Lusory Attitude -- the game attitude|lusory attitude]]\n\t- Stenros builds on Salen and Zimmerman's 'magic circle', arguing that this game state is an explicitly negotiated [[thoughts/social contracts|social contract]] -- an agreement to treat the in-game events as separated from the world\n- Aesthetics of games\n\t- Climbers praise particular climbs for having interesting movement or beautiful flow\n\t- We can justify our pursuit of an arbitrary-seeming goal in terms of the aesthetic value of that struggle.\n\t- Aesthetics of harmony: 3 levels\n\t\t1. Harmony of solution: strictly a harmony between the solution and the obstacle. e.g. wow, what a brilliant and beautiful Chess move\n\t\t2. Harmony of action: your agency and action fitting the demands of the environment. e.g. during a difficult climb, figuring out you need to slide your hips over just enough to balance on a tiny foothold\n\t\t\t- This is a strict superset of the harmony of solution. It concerns not only how the solution fits the problem, but how my decision making and action generation were just right to generate the harmony of solution\n\t\t3. Harmony of capacity: the experience of engaging your abilities to their fullest potential. Arises from a fit between one's maximum skill level (their limit) and the demands of the task\n\t\t\t- We want to hit this in [[thoughts/game design]] as much as possible\n- Crafting Agency\n\t- A game designer crafts for players a very particular form of struggle, and does so by crafting both a temporary practical agency for us to inhabit and a practical environment for us to struggle against. Games are the art of agency\n\t- Whatever is created has to be open, flexible, and malleable to allow players to appropriate, express, act and interact, make and become part of the form itself (Sicart 2014)\n\t- Games are as interesting as their constraints. On a smaller scale, restrictions can actually help constitute entirely new actions. The action of \"making a basket\" in basketball is only meaningful because of the constraint of the game of basketball\n\t- Its important to consider the \"ludic loop\" when designing games. A continuous stream of gentle challenges and in-game rewards, offered at the right pacing and tempo, seems to produce something of an addictive response\n- Agential Fluidity\n\t- We need to have final ends to avoid being bored. However, having final ends is no insurance against being bored. Instead, to remain interested in the world, we must be able to fluidly be able to change our interests\n\t- I acquire my ends from my experience of value in an activity\n\t- Game playing is a way to practical agential fluidity. Game playing builds familiarity with different agential modes -- to help us build our inventory and know which one to pic -- and the fluidity to shift easily in and out of our chosen mode\n- Self-effacing Ends\n\t- An end that cannot be achieved through direct pursuit, but only through pursuit of some other end. For example, meditation and achieving an empty mind, loving another, etc.\n\t- Paradox of hedonism: one cannot achieve pleasure by pursuing it directly, but only by devoting oneself to some other end (Sidgwick, 1907)\n- The value contradiction that makes games valuable\n\t- When we succeed in games, we treat them as normal contexts in which success matters. But when we fail at games, we treat them as deflated contexts, telling ourselves that success and failure in games doesn't really matter anyway (Juul, 2013)\n- Learning new modes of agency\n\t- Shouldn't we develop autonomy on our own? How can games help with this?\n\t- The counter argument is that any genuinely plausible view of autonomy and freedom must make room for the fact that we learn from others and using a variety of techniques at that\n\t- Learning from others involves temporarily giving up our own agencies in a controlled and consensual way. When I take an art class, I put my attention in another's hands for a while. I look where they tell me to look, attend to the features they tell me to.\n\t- Similarly, games are a temporary constriction of our own agencies leads us to develop more flexible agencies in the future\n\t- Rigidity in the short term is sometimes crucial for flexibility in the long term.\n- Agential Distance\n\t- The gap that the game designer explicitly leaves for the player to occupy. This gap is shaped by the rules/constraints of the game\n\t- Creative/sandbox games like Minecraft have a big agential distance whereas strict games like osu! have very little agential distance.\n- Gamification and Value Capture\n\t- A la [[thoughts/Seeing like a State]], metrics arose from the bureaucratic need to collate information. They also foster game-like motivations. They look a lot like points! But if we are too eager to recapture the pleasures of games in ordinary life, we may be excessively drawn to using such simplified measured in our practical reasoning. \n\t- This is the danger of exporting back to the world a false expectation: that values should be clear, well-delineated, and uniform in all circumstances. Games threaten us with a fantasy of moral clarity.\n\t- The right values may not be the clearest values. The false clarity of values that games provide may seduce us into oversimplifying our own values\n\t- Consider a phenomenon I call *value capture*\n\t\t1. Our values are, at first, rich and subtle (e.g. we value the happiness of a country's citizens)\n\t\t2. We encounter simplified (often [[thoughts/quantization|quantified]]) versions of those values (e.g. we use GDP as a measure of its capacity to satisfy its citizen's desires)\n\t\t3. Those simplified versions take the place of our richer values in our reasoning and motivation (e.g. we begin valuing GDP itself and try to increase it in whatever way we can)\n\t\t4. Our lives get worse\n\t - Again, abstractions and simplifcations are not necessarily a bad thing\n\t\t - The arts, Dewey suggests, reach into the welter of practical life and create crystallized versions of practical experience. The arts create little unities. The value clarity and harmonious agency of game life is, in a sense, no worse than the unnatural harmoniousness of music, or the narrative clarity and unity of fictions. But value clarity becomes problematic when we export a need for it outside the game.\n\n## Podcast\nOn The Ezra Klein Show: [A Philosophy of Games that is really a Philosophy of Life with C. Thi Nguyen](https://overcast.fm/+oiPXNKQBw)\n\n### Quantization\n-  “The most important thing in my game designer toolbox is the point system because the point system tells the players what to care about.” -- Reiner Knizia\n- \"Quantified measures are extremely good tools for large-scale bureaucracies to organize themselves\"\n- Metrics and quantities carve out all of the subtle nuance and all the weird little information that needs a lot of shared context to understand *so* that it can travel and be transported between contexts and let it aggregate easily\n\t- \"So if you have large-scale bureaucracies that need to be organized and function coherently, then you need these kind of simple, nuance-free packets of [information](thoughts/information.md)\"\n- \"if you spend your life playing games, you’ll expect that value systems will be crisp, clear, well-defined, and quantified. And then you leave games, you’ll start looking around for— I don’t know— things to do, or institutions to be a part of, or jobs to do where the outcomes are clear, crystallized, quantified, and shared between people\"\n\n### On social media\n- A lot of times people click like because something made them laugh for a second, not because it moved them two weeks later.\n\n### Aesthetics\n- Object aesthetics: when an artist makes a thing like a painting. And you look at the thing and the thing is beautiful\n- Process aesthetics: the artist makes a thing and you interact with the thing and you’re beautiful. Your actions are beautiful, or comic, or thrilling. (I think games fall under this later category)\n\n### Games are the crystallization of doing\n- The visual arts are the crystallization of seeing... music is a crystallization of hearing... fiction is a crystallization of story telling... games are the crystallization of doing.\n\t- The game designer tells you what abilities you have and what obstacles you’ll face, but most importantly, what goals you’ll have: games are the art form that works in the medium of agency itself\n- Follows Bernard's definition of a game in [The Grasshopper, Games, Life and Utopia](thoughts/The%20Grasshopper,%20Games,%20Life%20and%20Utopia.md): to play a game is to voluntarily take on unnecessary obstacles for the sake of making possible the activity of overcoming them\n\n### Agency\n- I feel like games are like an existential balm for the horror of life. A lot of life is you don’t fit. You have to do things. And it sucks and it’s horrible and it’s boring. And in games, for once in your life, you know exactly what you’re doing and you know exactly that you can do it. And then you have just the right amount of ability to do it. It’s a feeling of concentrated, crystallized action\n- Game designers have sculpted these little **action universes** so that we can step into them and just have this ecstasy over and over again.\n- “I’m more worried about games breeding more Wall Street profiteers than I am about their breeding serial killers.”\n\t- The greatest power of games is that you can explore this landscape of different agencies. The greatest danger of games is that you can get sucked into this experience of just craving and wanting to be in a clear, crisp and gentle universe where you know exactly what to do and exactly how well it’s measured (similar concerns to [Goodhart's Law](thoughts/Goodhart's%20Law.md)).\n\t- So I think that the body of games is a kind of library of agencies. The real promise of games, if you take them seriously, is that by playing a ton of them, you can traverse all the different possibilities of agency.\n\n### Misc\n- \"'Train' ... looks like, in many ways, a standard European board game. You’re building a railway network. You’re trying to optimize it. And over time the game reveals to you that what you’re actually doing is it’s Nazi Germany and you’re building the railway network to move people to concentration camps.\"\n- https://buriedwithoutceremony.com/the-quiet-year\n","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Gaussian-RBF":{"title":"Gaussian RBFs","content":"\nNon-parametric basis. Can think about it as a sum of gaussian 'bumps'.\n\nReplace $x_i = (x_{i1}, x_{i2}, \\dots, x_{in})$ with\n\n$$z_i = \\underbrace{(g(\\lVert x_i - x_1 \\rVert), g(\\lVert x_i - x_2 \\rVert), \\dots, g(\\lVert x_i - x_n \\rVert))}_\\text{n features}$$\n\nwhere $g(x) = \\exp(-\\frac{x^2}{2\\sigma^2})$\n\nGaussian RBFs are universal approximators\n- Enough bumps can approximate any continuous function to arbitrary precision.\n- Achieve optimal test error as ‘n’ goes to infinity.","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Goodharts-Law":{"title":"Goodhart's Law","content":"\n\"When quantifying things, people naturally focus on things that can easily be measured. Measuring the final result doesn’t provide enough quantitative data, so it’s tempting to include the data from intermediate steps. This is an attempt to shorten the feedback loop, and trying to shorten feedback loops is very dangerous in complex systems.\"\n\n\u003e \"When a measure becomes a target, it ceases to be a good measure\" -- [Goodhart's Law]\n\nSee also: [[thoughts/paperclip optimizer|paperclip optimizer]]","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Gordian-Knot":{"title":"Gordian Knot","content":"\nIt is often used as a metaphor for an intractable problem (untying an impossibly tangled knot) solved easily by finding an approach to the problem that renders the perceived constraints of the problem moot","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/HTTP":{"title":"HTTP","content":"\nMain method of communication at the [Application Layer](thoughts/Application%20Layer.md) for the web. A state-transfer protocol. See also: [[thoughts/Braid HTTP]] for HTTP as state-synchronization\n\nSometimes called the second waist of the Internet (after [[thoughts/IP Addresses]])\n\n## Connections\n1. Non-persistent HTTP (v1.0)\n\t- At most one object is sent over each [TCP](thoughts/TCP.md) connection\n\t- Connection is closed as soon as data is transferred\n\t- Include an additional round trip for the TCP handshake for *each object* = $2n$ RTTs where $n$ is number of resources\n2. Persistent HTTP (v1.1)\n\t- Multiple requests can be sent over single connection\n\t- `Keep-Alive` header\n\t- Round trip for each resource = $n + 1$ RTTs where $n$ is number of resources\n\t- Pipelining:\n\t\t- Can send all the requests at once!\n\t\t- Process them all sequentially but get all the responses in the same order as the requests\n\t\t- Round trip = 3 RTTs (one for handshake, one for initial resource, one for the rest of the resources)\n\t- Server has the right to close any connection\n\t\t- Usual heuristic is to close the connection after 5 seconds of inactivity\n\n## Cache\n- Browser may maintain a cached version of page\n- Cache can also be maintained by a separate host (a proxy e.g. Varnish)\n- Web servers can provide cache policy\n- Calculating cache speedups\n\t- Cache time = $rRTT_\\textrm{cache} + (1-r)(RTT_\\textrm{server} + RTT_\\textrm{cache})$ where $r$ is the cache hit rate\n\n## Cookies\n- Used for storing per-user state\n\t- \"Remember me\" authentication\n\t- Session state\n- Applicable for a particular hostname\n- Response from server includes `Set-Cookie` header\n- Browser saves cookie associated with the server\n- Next request to the same server will include Cookie header with the same value\n- Two styles of using cookies\n\t- All the state is in the cookie\n\t\t- Total header size limited by servers (~8KBytes)\n\t\t- Individual cookie size limited by browsers (~4KBytes)\n\t- State (or part of it) may be stored server-side: cookie is used to identify entry in server database\n\n## Client/server model\n- Client: browser that requests, receives, displays Web objects\n- Server: sends objects in response to requests\n- Uses [TCP](thoughts/TCP.md) port 80 (443 for HTTPS)\n- For each object\n\t- Client sends one request message at once\n\t- Server sends full response message at once\n- Server is stateless\n\n## Message Format\n- Request\n\t- First line: method, URL, version\n\t- Headers:\n\t\t- `Header-Name: value\u003cCR-LF\u003e`\n\t\t- Required\n\t\t\t- `Host: \u003cdomain\u003e`\n\t\t\t- `User-Agent: \u003cbrowser/version\u003e`\n\t\t- Empty line to end header section\n\t- Body here\n\t\t- Size determined by `Content-Length` header\n- Response\n\t- First line: version, response code, response text\n\n## Request Methods\n1. GET\n\t1. relevant data is in URL\n\t2. form data (if needed) is in URL\n2. POST\n\t1. includes form input in message body\n\t2. used in forms that submit new data\n3. HEAD\n\t1. similar to GET but only returns header\n\t2. used to check if existing content was modified\n\n## Codes\n1. 2xx: success\n2. 3xx: additional action required\n3. 4xx: client problem\n4. 5xx: server problem\n\n## WWW\n- A web page consists of objects\n- Each object is addressable by a URL","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Hackers":{"title":"Hackers","content":"\n## Steven Levy\n[Source: *Hackers* by Steven Levy](https://classes.visitsteve.com/hacking/wp-content/Steven-Levy-Hackers-ch1+2.pdf)\n\nThe hacker ethic: sharing, openness, [decentralization](thoughts/decentralization.md), and getting your hands on machines at any cost to improve the machines and to improve the world. All information should be free.\n\nSqueezing in time where no one else would (sniping people even 1 min late at 3am in the morning). This culture seemed to almost arise bottom-up from the scarcity of compute resources at the early 60s and 70s, especially around the MIT area where there seemed to be a lot more spare compute time and just really smart, curious people.\n\n\u003e What was a computer but something that benefited from a free flow of information?\n### Decentralization\nThe best way to promote free exchange of information is to have an open system, one with no boundaries attached. The worst thing to encourage this is to have a bureaucracy.\n\nThe difference between bureaucrats and and logical algorithms are that bureaucrats follow *arbitrary rules* whereas algorithms follow *concrete and transparent* rules.\n\n## Paul Graham\n[Source: Hackers and Painters by *Paul Graham*](http://www.paulgraham.com/hp.html)\n\nThe art of hacking: for building and exploring for the sake of building and exploring.\n\n### Hacking as a creative art\n\u003e They seemed to think that hacking and painting were very different kinds of work-- that hacking was cold, precise, and methodical, and that painting was the frenzied expression of some primal urge.\nPG is positing that hacking (traditionally seen as more as more mechanical) and painting (seen as more creative) have a lot in common -- most importantly, the face that they make things.\n\nFor hackers, computers are just the medium through which they express themselves.\n\nNamely, they don't exclusively try for exclusively [creating or maintaining](thoughts/creation%20vs%20maintenance.md) but rather to make 'good things' and if either of those happen along the way, all the better.\n\n### [Labels](thoughts/quantization.md)\n\u003e But often this mismatch [between labels and what they do] causes problems. It's easy to drift away from building beautiful things toward building ugly things that make more suitable subjects for research papers.\nLabels are logically [decentralized](thoughts/decentralization.md) so if it no longer is useful, then it will phase itself out. While yes, language is useful for defining norms externally, for those *strongly* intrinsically motivated (which arguably are the people PG is trying to speak to), those labels don't matter because external incentives matter very little to them. If that label continues to be useful to them (e.g. to secure funding or to talk about it to laypeople) then why not continue to use it? \n\nI think my case for this argument would be slightly different if PG focused more on the *public* perception of the label.\n\n### [Academia](thoughts/academia.md)\n1. Research must be original -- this drives people to stake out a piece of ground no one wants\n2. Research must be substantial -- awkard problems mean more substance to write about and solve, discouraging elegant solutions\n\nMaybe because better incentive systems are so much harder to create and evaluate. Numbers are easy and an easy test that kind-of works is really tempting to stick with.\n\n### Industry\n\"Universities and research labs force hackers to be scientists, and companies force them to be engineers... Programmers were seen as technicians who translated the visions (if that is the word) of product managers into code.\" (re: [academia](thoughts/academia.md))\n\nThis feels like a problem of scale: only a small percentage of hackers *can* actually design software and it's hard for people running a company to pick these out\n\nBig companies want to damp oscillation/standard deviation of results, they have shareholders to which they are accountable. They win by sucking less than their competitors, not making great products.\n\n\"But when you damp oscillations, you lose the high points as well as the low.\" ([Vanilla Ice Cream effect](thoughts/Vanilla%20Ice%20Cream%20effect.md))\n\n### Figuring things out as you go\n\n\u003e If I had only looked over at the other makers, the painters or the architects, I would have realized that there was a name for what I was doing: sketching.\nThe traditional approach is to logically plan things out and to create with intention. PG argues that sketching -- figuring out the program as one writes it -- is just as valid.\n\nA programming language is for thinking of programs, not for expressing programs you've already thought of. The argument *against* strong typing is really interesting. I like to think of strong typing as ruler lines or a guide to ensure that the perspective of my drawing is right; a good aid to ensure that I'm on the right track. \n\nHackers also learn by doing. Hackers, from the start, are doing original work; it's just very bad. They start original, and get good. On the contrary, academics and scientists start good and get original.\n\n### Demand\n\u003e Prices are determined by supply and demand, and there is just not as much demand for things that are fun to work on as there is for things that solve the mundane problems of individual customers.\nSimilar to [creation vs maintenance](thoughts/creation%20vs%20maintenance.md), there seems to be a need to artificially incentivize the difficult work (e.g. [maintenance](thoughts/maintenance.md) or mundane problems)","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Hard-problem-of-consciousness":{"title":"Hard problem of consciousness","content":"\nRelated: [mind body problem](thoughts/mind%20body%20problem.md), [Materialism](thoughts/Materialism.md)\n\nHow do we bridge objective description and subjective experience (qualia)? Is consciousness explainable in terms of brain processes?\n\nWhat gives rise to consciousness (rel: [emergent behaviour](thoughts/emergent%20behaviour.md)), first-person experiences, and a sense of self? Do inanimate and non-human intelligences have personal experiences?\n\nChalmers\n- Certain phenomena are functionally definable -- explanation of them requires only the explanation of the relevant functions and the mechanisms that implement them (e.g. hereditary passing of genes and DNA)\n- Consciousness is *not* functionally definable\n\t- Defining information discrimination, integration, and reporting does not fully explain consciousness\n\n## Explanatory Gap\n- There is no cognitive function such that we can say in advance that explanation of that function will automatically explain subjective experience\n\nSee [Nagel's Bat Argument](thoughts/Nagel's%20Bat%20Argument.md)","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Hold-the-Fries":{"title":"Hold the Fries","content":"\n\"Shaun, you're doing that thing again. Staring into some far off land. Hurry up loopyhead, figure out what you wanna get.\"\n\nA fog seemed to lift from Shaun's brain and he realized he had been staring at the menu for a while.\n\n\"Same as usual I guess. Deluxe Burger, hold the fries. I just want the coke.\"\n\n\"You haven't changed a smidge, huh\" Cassidy chuckled. \"I got'cha. On me this time.\"\n\n\"Nah, Cass you really don't need to...\" he hesitated because he know it wasn't true. The tattered, oil covered t-shirt and beat up Nikes with the sole on the left shoe coming loose told Cassidy otherwise.\n\n\"Two Deluxe Burger Combos, no fries please!\"\n\nShaun shuffled his shoes a little bit, almost as if he suddenly became a little more conscious of how he looked beside her neatly pressed blazer and slightly waxed hair. After all, *she* was the one who looked out of place, a stark contrast to the greasy dinge of the burger shop and the unearthly pale glow of fluorescent lights. Sometimes, you could see a mouse scamper by but Cassidy seemed unfazed.\n\n\"So, uh. You been up to much?\" Cassidy asked.\n\n\"Not much, no.\" Shaun answered, a little startled at the sound of his own voice. \"I've been working at a gas station for the past few months. It pays the bills, I guess.\"\n\nCassidy raised an eyebrow. \"An' your mom? She's doing alright?\"\n\nShaun shrugged. \"I guess so. She's working at a fast food place. She's been takin' her meds regularly so problems haven't been too bad.\"\n\nCassidy nodded. \"That's good. That's good.\"\n\n\"Yeah.\" Shaun said, looking away from Cassidy's gaze and staring at the wall, where a poster of a bikini clad girl with a burger and a coke in her hands was taped to the peeling wallpaper.\n\n\"Cass?\"\n\n\"Yeah?\"\n\n\"What happened to that promise?\"\n\nCassidy froze. \"The friendship one?\"\n\n\"Yeah.\"\n\nAn awkward silence rested between the two of them, suddenly broken by the sound of an ambulance siren. The blue and red lights lit up their faces like the bruising of a recent injury.\n\n---\n\n\"Order 512! Chicken Deluxe with fries! Last call!\" Shaun rang the bell a few more times.\n\n\"Well, I guess that guy isn't showing up. It's past closing anyways, do you wanna just split the food?\"\n\nCassidy glanced at the clock just as it hit 10:00pm.\n\n\"Yeah sure, I'm starving.\"\n\nThe two of them sat down in the only two chairs in the room that weren't coated in grime, neither of them saying a word.\n\nShaun took a bite and chewed, feeling the greasy chicken inch down his throat. \"How did you find Mr. Saltsworth's calc test? I definitely feel like I got slaughtered. That one with the double integral was real tricky, how did he expect us to actually know that one?\"\n\nCassidy spoke between bites. \"Well silly, if you actually did the practice problems you would know. In any case, you should start taking school seriously. College application season is soon. How do you expect to do great things in the world if you don't even take this stuff seriously?\"\n\n\"Well, maybe not everyone *wants* to change the world.\"\n\n\"Come *on* Shaun. Everyone wants to matter. What better way to do that than to make an impact?\" Cassidy said, putting her burger down and wiping her lips with a tissue.\n\n\"What if I just want to work a regular job and care for my mom?\" \n\nThey both sat, facing each other, a world of understanding apart. Both not understanding why the other wanted what they wanted.\n\n\"Cass, you ever thought that this *is* what I want?\" Shaun said, feeling a lump form in his throat. \"It's all I've ever really wanted.\"\n\n---\n\n\"I remember that you said we would be friends until we both grayed out. I don't think we're too far from that, are we Shauney?\"\n\n\"I said not to call me that. And are you kidding? We are *far* from that. Don't fucking joke with me. You've got a nice new job, a wonderful relationship, hell you probably have enough dough to buy up this whole place!\" Shaun said a little too loudly.\n\n\"You are treating time spent with me like some sort of fucking charity. *Oh I'll go spend some time with poor old Shauney so I can rub it in his face how successful and cool I am*\"\n\n\"-that really wasn't my intention!\" Cassidy butted in, her voice faltering. \"I just wanted to catch up with old times.\"\n\n\"Old times are old times. They're gone. You shouldn't dig them up. They're just going to make you feel sad. And you don't need that, do you? You're happy now. You have no problems. You're doing great.\" Shaun said, staring at the empty plates.\n\n\"Look. I barely can pay the rent every month. I sell drugs to stay alive and take care of Katie and you're moving to the gentrified part of the neighbourhood which is the reason why people like *me* can barely afford to stay alive!\"\n\n\"I...I didn't know that. I'm so sorry.\" Cassidy cried, at first droplets streaming down the contours of her face, but eventually flowing streams that reddened her cheeks. \n\n\"You're sorry! You're sorry!\" Shaun stood up and shouted, his voice echoing throughout the restaurant. If anyone else had been around, they would have turned to look at them too.\n\n\"Things will never be the same again, Cass. Y'know, I used to think we would end up together one day. We would take two different paths to get there, but the destination would be the same.\" Shaun said, his voice trembling. \"But I realize now that things just won't be the same. I mean, *look* at us. I'm a druggie and you're a 'professional'. What could we possibly have in common? Things just aren't what they used to be. They can't be.\"\n  \nShaun stood up and began to walk away, but Cassidy grabbed his arm. \"Wait, Shaun. Please don't go. I know you are going through a lot. But we can figure this out together. We always have.\"\n\nIn that moment, a ringtone pierced the air and they both froze, eyes wide and lips parted. The sound rang, twice, three times, through the empty restaurant.\n\n\"It's work.\" Cassidy said. \"I have to take this. Please, can we talk about this tomorrow?\"\n\n\"No Cass. I've had enough. Who are you going to choose? What's the life you want to live? What do you *really* care about, Cass?\"\n\nCassidy stared at Shaun, with her lips quivering. *I'm sorry* she mouthed.\n\n\"Hello... Cassidy speaking. How can I help you?\"","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Holochain":{"title":"Holochain","content":"\n\u003e Holochain is an open-source application development framework and peer-to-peer networking protocol. It allows you to create truly serverless applications with high levels of security, reliability, and performance. Every user runs the application on their own device, creates and stores their own data, and talks directly to other users. The security of the application is supported by both [[thoughts/cryptography|cryptography]] and peer accountability.\n\nSummarized from [Holochain Docs](https://developer.holochain.org/concepts/1_the_basics/)\n\nWe start with users, not servers or data, as the primary system component. The application is modeled from the user perspective, which we call **agent-centric computing**.\n\nHolochain has two main value pillars:\n1. Intrinsic data validity: Empowered by the Holochain runtime, each user runs their own copy of the back end code, controls their identity, and stores their own private and public data. Half of the problem is already solved—because everyone has the ‘rules of the game’ in their copy of the code, they can verify that their peers are playing the game correctly just by looking at the data they create.\n2. Peer witnessing: Each piece of public data is witnessed, validated, and stored by a random selection of devices using a [[thoughts/DHT|DHT]]. Together, all cooperating participants detect modified or invalid data, spread evidence of corrupt actors or validators, and take steps to counteract threats.\n\n## Terminology\n- Conductor: Runtime that sandboxes and runs hApp code. Responsible for all network communication and routing things to the right place.\n- hApp: Holochain application. Composed of slots for cells which provide an aspect of functionality.\n- Cell: occupies slots in an hApp. Alive version of the DNA. Contains state, settings, etc. that is specific to *that user*\n- DNA: A bundle of Zomes that makes a unit of functionality in a hApp.\n- Zome: (chromosome). Made up of DNA define the core business logic in a DNA, exposing their functions to the conductor.\n\n## DHT\nOf course, the DHT is really large. You need to know its address in order to retrieve a piece of data that matters to you.\n\nBut because Holochain's DHT is [[thoughts/content addressed storage|content-addressed]], you can only know the address if you can calculate it from the data (in which case you don’t need to retrieve it), or if you discover the address somehow.\n\nAddress discovery in Holochain works through anchors and links.\n- Anchors: ‘known’ things you can use as starting points\n- Links: an [[thoughts/RDF#RDF Triple|RDF triple]]\n\n## Source Chain\nEach user in a Holochain network creates and stores their own data in a journal called a **source chain**. Each journal entry is cryptographically signed by its author and is immutable once written.\n\nIdentifiers are based off of a public/private key pair. All messages posted to the source chain are signed so they are tamper-proof. Each message refers the previous one in the order so it order can't be tampered with either.\n\nBut unfortunately anyone can modify their own source chain, regenerate the hashes and signatures, and create a perfectly valid, but wrong, alternate history for themselves. The [[thoughts/DHT|DHT]] resolves this sharing your source chain actions and public entries with a random selection of your peers, who witness, validate, and hold copies of them.\n\n","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/HoneyBadgerBFT":{"title":"HoneyBadgerBFT","content":"\n\u003e An asynchronous [[thoughts/system model|system model]] total-order [[thoughts/message broadcast|message broadcast]] protocol\n\nKey features:\n- Asynchrony: no timing assumptions. Messages can arrive at any time, and network speed determines the transaction rate\n- Leaderless consensus: every node is a proposer. This eliminates potential attacks where a leader node can be stalled indefinitely, bringing the entire network to a halt\n\nHoneyBadgetBFT (HBBFT) can be decomposed into nested subproblems:\n- Queuing Honey Badger (QHB)\n- Honey Badger (HB)\n- Subset\n- Reliable Broadcast (RB)\n- Binary Agreement (BA)\n- Threshold Sign\n\nAn example flow of how message broadcast might work with a transaction $x$\n- QHB places this transaction, along with others it has received, into a queue of pending transactions\n- A random process determines which transactions to include in the next block\n\t- When $x$ is included in the contribution, it is submitted to Honey Badger. HB encrypts the list using threshold cryptography, creating a garbled version that contains your transaction but can’t be read. This is submitted to the Subset algorithm\n\t\t- Subset puts it into a Reliable Broadcast instance for `Node 1`. This distributes the contribution to every other node in the network\n\t\t\t- Once every node has received the encrypted contribution via RB, they know that all other correct nodes will also receive this contribution. They vote `Yes` in the Binary Agreement instance labelled `Node 1`, meaning that this contribution should be included as part of the next block\n\t\t- Going back up to Subset, we now have $\u003e \\frac 2 3$contributions from all the nodes which are all encrypted\n\t- In HB, we now have enough contributions to decrypt all of them. Each node gets $n$ lists of decrypted transactions, including $x$\n- QHB then makes a union of the contributions and creates a single finalized list of transactions that all nodes have agreed on\n- This final list is sent out of QHB and back to the application client\n\nSome faster and more efficient alternatives have also been developed:\n- [Dumbo1 and Dumbo2](https://eprint.iacr.org/2020/841.pdf)\n- [BEAT](https://www.csee.umbc.edu/~hbzhang/files/beat.pdf)","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/HotStuff":{"title":"HotStuff","content":"\n\u003e A [[thoughts/Byzantine Faults|byzantine fault-tolerant]] [[thoughts/State Machine Replication (SMR)|state machine replication]] protocol for the partially synchronous [[thoughts/system model|system model]]. It can express other known protocols (e.g. [[thoughts/PBFT|PBFT]], [[thoughts/Tendermint|Tendermint]], [[thoughts/Casper FFG|Casper FFG]]) in this common framework.\n\n[Source Paper](https://arxiv.org/pdf/1803.05069.pdf)\n\n## The Scaling Challenge\nOriginal BFT SMR protocol were designed with a typical target system size of $n = 5$ or $n = 7$ for local-area deployments. As such, they don't scale well to high $n$ as required by permissioned and permissionless [[thoughts/blockchain|blockchains]]. \n\nHotStuff aims to overcome this by improving the bound of total number of authenticators communicated from $O(n^4)$ to $O(n^2)$\n\nThe first BFT SMR protocol with the following properties:\n1. **Linear view change:** After GST, any correct leader, once designated, sends only $O(n)$ authenticators to drive a consensus decision in the best-case. In the worst-case, communication costs to reach consensus after GST is $O(n^2)$ authenticators in the worst case of cascading leader failures\n2. **Optimistic Responsiveness**: : After GST, any correct leader, once designated, needs to wait just for the first $n − f$ responses to guarantee that it can create a proposal that will make progress\n\nHotStuff does this by adding another phase to each view, with the assumption that the network delay is less than the $\\Delta$ required to wait for GST. This solves the hidden QC problem.\n\n\u003e If a leader doesn't wait for the $\\Delta$ expiration time of a round. Simply receiving $n-f$ replies from participants (up to $f$ of which may be Byzantine) is not sufficient to ensure that the leader gets to see the highest QC\n\nSuch an impatient leader may propose a lower QC value than what is accepted and this may lead to a liveness violation. In order not to wait the maximum  Δ  expiration time of a round, HotStuff introduces another round, Pre-commit, before the actual Commit round.\n\nBoth [[thoughts/Casper FFG|Casper]] and [[thoughts/Tendermint|Tendermint]] wait the full $\\Delta$ period instead of incurring the cost of a new round.\n\n## Cryptographic Primitives\nUses [[thoughts/digital signatures|thresholded signatures]] with a threshold of $k = 2f+1$\n\n## Three-phase Protocol\nHotStuff is a view-based protocol. Each view $v$ has a unique leader known to all. Each replicas has a tree of pending commands (as opposed to a list used by more classical [[thoughts/Byzantine Faults|BFT]] protocols).\n\nDuring the protocol, a monotonically growing branch becomes committed. To become committed, the leader of a particular view proposing the branch must collect votes from a quorum of $(n − f)$ replicas (the QC) in three phases: prepare, pre-commit, and commit.\n\n## Chained HotStuff\nNote that each of the three-phases have very similar structure and that the protocol isn't doing \"useful\" work except collecting votes from replicas. To optimize this, we can pipeline the phases, similar to what [[thoughts/Casper FFG|Casper FFG]] does.\n\n![[thoughts/images/chained-hotstuff.png]]\n\n### Commit Rule\nHotStuff uses the concept of chains which maps nicely onto Chained HotStuff.\n\nThe decision when a block is considered committed rests purely on a simple graph structure, a three-chain.\n\n![[thoughts/images/hotstuff-3-chain.png]]\n\nThe three-chain commit rule provides the following guarantee.\n1. The first link (corresponding to prepare) in the chain `QC|B' -\u003e QC|B` guarantees $n-f$ votes on a unique block `B`.\n2. The second link (corresponding to pre-commit) in the chain `QC|B'' -\u003e QC|B'` guarantees $n-f$ replicas have a QC on a unique block.\n3. The last link (corresponding to commit) `QC|B''' -\u003e QC|B''` guarantees that $n-f$ replicas have the highest QC of any two-chain that has a vote.","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/How-to-do-Nothing":{"title":"How to do Nothing","content":"\nOn the [attention economy](thoughts/attention%20economy.md). Very heavily related to [Grasshopper](thoughts/The%20Grasshopper,%20Games,%20Life%20and%20Utopia.md) and [selfish](thoughts/selfish.md), discussed in [Circle](thoughts/Interact%20Circle%20W21.md).\n\n\u003e What does it mean to construct digital worlds while the actual world is crumbling before our eyes?\n\nA man living in the attention economy attempted a humble and ethical life would certainly appear 'backward': for him, good would be bad, up would be down, productivity would be destruction, and indeed, uselessness would be useful.\n\nResistance-in-place: to resist in place is to make oneself into a shape that cannot so easily be appropriated by a capitalist value system. To do this means refusing the frame of reference: in this case, a frame of reference in which value is determined by productivity, the strength of one's career, and individual entrepreneurship. It means embracing and trying to inhabit somewhat fuzzier or blobbier ideas: of [maintenance](thoughts/creation%20vs%20maintenance.md) as productivity, of the importance of nonverbal communication, and of the mere experience of life as the highest goal.\n\nHow do we even begin to define productivity? Productivity that produces what? Successful in what way, and for whom? The happiest, most fulfilled moments of my life have been when I was completely aware of being alive, with all the hope, pain, sorrow that that entails for any mortal being. In those moments, the idea of success as a teleological goal would have made no sense; the moments were ends in themselves, not steps on a ladder.\n\n## Self-care\n\"I hope that the figure of 'doing nothing' in opposition to a productivity-obsessed environment can help restore individuals who can then help restore communities, human and beyond.\"\n\n\"Caring for myself is not self-indulgence, it is self preservation, and that is an act of political warfare.\"\n\n\"In the context of health and ecology, things that grow unchecked are often considered parasitic or cancerous... The life force is concerned with cyclicality, care, and regeneration; the death force sounds to me a lot like 'disrupt'.\"\n\n## Gardens\n\"I find myself gravitating toward these kinds of spaces -- libraries, small museums, gardens, columbaria -- because of the way they unfold secret and multifarious perspectives even within a fairly small area.\"\n\n## Censorship\nInformation DDOS-ing in the attention economy: Instances of censorship are rather marginal when compared to what is essentially an immense informational overload and an actual siege of attention, combined with the occupation of the source of information by the head of the company\"","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Hyper-Hyper-Space":{"title":"Hyper Hyper Space","content":"\n\u003e Make all data local, communicate only through data sync\n\nSummarized from [the site](https://www.hyperhyperspace.org/) and [whitepaper](https://www.hyperhyperspace.org/whitepaper/)\n\nProvides:\n- a local data store, both in-browser using IndexedDB and server-side\n- a data representation format, based on Merkle-DAGs and [[thoughts/CRDT|CRDTs]]\n- a secure data sync protocol over WebRTC and WebSockets\n\nThe Hyper Hyper Space project proposes a framework for _universal information access_\n\n## Spaces\nApplications organize their information using spaces -- a bit like a file but for the internet age. It's a file that is opened and modified locally on your devices but synchronized automatically over the internet. They can be universally looked up using 3-word codes, like suburb-suburb-awake.\n\n## Finality\nTo preserve operation commutativity, these untimely capability uses would need to be accepted, hence preventing the application from truly enforcing capability revocation.\n\nLack of finality is worrying for vast majority of applications. They resolve this in a weird manner by introducing causal relationships (e.g. this action is only valid if this previous one is valid). Even then, this weird form of [[thoughts/causality|causality]] doesn't actually solve finality.\n\n## Connection\nWebRTC as underlying transport layer. Uses a signalling server that each peer runs. Not ideal, doesn't run a DHT so requires users to know address of other's signalling server.\n\n","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Hypercore":{"title":"Hypercore","content":"\n\u003e Streaming based append-only log that aims to be the lego-block of distributed applications.\n\nHypercore Protocol is a [[thoughts/peer-to-peer|peer-to-peer]] data network built on the Hypercore logs. Hypercores are signed, append-only logs. They're like lightweight blockchains without the [[thoughts/consensus|consensus]] algorithm\n\nConnects peers using the Hyperswarm [[thoughts/DHT|DHT]] which is based off of [[thoughts/Kademlia DHT|Kademlia]]\n\n## Thoughts\n- Great developer experience, super simple to understand and use\n- Comprehensive library of data structures\n- Not amazing availability, no incentive system for people to run nodes (though Dat is working on this using a blockchain-based reward system)\n- Not exactly great local first support. Continues working locally without an internet connection but new users cannot connect or get an up-to-date version of your data. If the user wants to send data to someone else, both devices need to be online simultaneously\n- [[thoughts/Hypercore|Hypercore]] also does not guarantee long-term write-once storage\n- Multi-writer support is still being worked on\n\t- Hypercore is inherently single-writer due to it's append only log structure, and while they have some work on multiwriter it's very tied to the data model","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/I-Confluence":{"title":"I-Confluence","content":"\nMartin Kleppmann and Heidi Howard: *[Byzantine Eventual Consistency and the Fundamental Limits of Peer-to-Peer Databases](https://arxiv.org/pdf/2012.00472.pdf)*\n\nKleppmann and Howard prove an equivalent result which states that $\\mathcal I$-confluence is a necessary and sufficient condition for the existence of a Byzantine eventual consistency replication algorithm\n\nThey define an invariant is a predicate over replica states, i.e. a function $I(S)$ that takes a replica state $S$ and returns either true or false.\n\nA set of transactions is $\\mathcal I$-confluent with regard to an invariant $\\mathcal I$ if\n1. Each replica can execute a subset of the transaction with $\\mathcal I$ preserved on that replica\n2. Merging the updates from the transactions still preserves $\\mathcal I$\n\nA few examples:\n- $\\mathcal I$-confluent: consider an invariant $\\mathcal I(S)$ that is true if every user in $S$ has a non-negative balance\n\t- If each transaction only increases a user's account balance, then any combination of transactions will still satisfy $\\mathcal I$\n\t- Note that this example is *no longer* $\\mathcal I$-confluent if transactions can deduct from a user's account balance\n\t\t- Say $A$ has a balance of $50\n\t\t- If $T_1$ results in deducting $40 from $A$ and $T_2$ results in deducting $25 from $A$, each transaction is valid on its own\n\t\t- But when combined, it violates the invariant $\\mathcal I$\n\t\t- As a result, we can't model anything like a cryptocurrency using CRDTs\n- Not $\\mathcal I$-confluent: consider an invariant $\\mathcal I(S)$ that is true if there are no duplicate values in $S$ (i.e. ensure that $S$ is a set)\n\t- If $T_1$ and $T_2$ are both transactions that create data items with the same value in that attribute, each of transaction preserves the constraint\n\t- However the combination of the two does not\n\nI conjecture that if a data structure is $\\mathcal I$-confluent, then it can be expressed in monotonic [[thoughts/Datalog|Datalog]]. That is, $\\mathcal I$-confluence holds if and only if states $S$ can be represented as a join semilattice.\n\nThis shows equivalence with the [[thoughts/CALM Theorem|CALM]] conjecture (proof left as an exercise for the reader).","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/IP-Addresses":{"title":"IP Addresses","content":"\nIP addresses are 32 bits (4 bytes) split into 4 chunks. Obviously $2^{32}$ is an incredibly large address space so we compress the table using IP prefixes.\n\n### IPv4\nSpecial Addresses\n1. First address (generally all 0s): network itself, or not assigned\n2. Last address (generally all 1s): broadcast\n\n### CIDR Notation\n`IP/#` where # is the number of bits in the network ID\n\ne.g. `18.0.0.0/8` means first 8 bits are network ID, and `18.x.x.x` is the space of all possible addresses ($2^{3*8}=2^{24}$)\n\nBy default, routers will take the most specific one (longest network ID).\n\nTo prevent loops, we set a TTL (time-to-live) for packets to expire after a certain time.\n","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/IPFS":{"title":"IPFS","content":"\nIPFS is a decentralized storage and delivery network which builds on fundamental principles of [[thoughts/peer-to-peer|p2p]] networking and content-based addressing (see [[thoughts/CID|CID]])\n\n\u003e Can seen as a single BitTorrent swarm, exchanging objects within one big [[thoughts/git|Git]] repository\n\nMuch like how we look up sites on the internet using URIs, we can look for specific pieces of content by their [[thoughts/content addressed storage|content-address]]. \n\nUnder the hood, IPFS uses\n- libp2p: network layer, takes care of host addressing, content and peer discovery, and structures like DHTs and pubsub\n- IPLD: data layer, standards and formats to build [[thoughts/Merkle-DAG|Merkle-DAG]] structures (quasi-filesystem)\n- Multiformats: formatting structures for self-describing values\n\nPublishing content\n- Chunk the content and deduplicate chunks\n- Obtain CID\n- Add the content to the network\n\t- Not the actual content, just the provider record to the [[thoughts/DHT|DHT]]\n\nConsuming content as a peer\n- Get CID (out of band)\n- Using [[thoughts/DHT|DHT]], resolve CID to peer\n- Contact peer to ask for CID content\n- Fetch content and cache a copy\n- Serve local copy upon subsequent request\n\n## Encoding/decoding\nHow does the system decode the hashes that it gets into the component data structures?\n\nCodecs! IPLD codecs are functions that transform IPLD Data Model into serialized bytes so you can send and share data, and transform serialized bytes back into IPLD Data Model so you can work with it. The [[thoughts/CID|CID]] includes an indicator called a multicodec (opens new window)to tell us which codec to use!\n\nSystems can build abstractions on top of this. For example, IPFS encodes the UnixFS using DAG-PB (which is a IPLD codec).\n\n\u003e Because the CID can describe different codecs relating to different systems, all sorts of systems can interoperate using CIDs, and IPLD and process and cross-link data from any of them.\n\n## Block Exchange using BitSwap\nBitSwap peers are looking to acquire a set of blocks (`want_list`), and have another set of blocks to offer in exchange (`have_list`). Unlike BitTorrent, BitSwap is not limited to the blocks in one torrent. BitSwap operates as a persistent marketplace where node can acquire the blocks they need, regardless of what files those blocks are part of. The blocks could come from completely unrelated files in the filesystem. Nodes come together to barter in the marketplace.\n\n### Incentivizing rare blocks\nOf course, there will not be perfect overlaps between nodes' `have_list` and `want_list`s . Nodes must work for their blocks. In the case that a node has nothing that its peers want (or nothing at all), it seeks the pieces its peers want, with lower priority than what the node wants itself. **This incentivizes nodes to cache and disseminate rare pieces, even if they are not interested in them directly.**\n\nThis barter system implies a virtual currency could be created, this would require a global ledger to track ownership and transfer of the currency, which is exactly what [[thoughts/Filecoin|Filecoin]] provides.\n\n### Incentivizing satisfied nodes to seed\nThe protocol must also incentivize nodes to seed when they do not need anything in particular, as they might have the blocks others want. Thus, BitSwap nodes send blocks to their peers optimistically, expecting the debt to be repaid.\n\nA simple credit-like system solves the problem:\n1. Peers track their balance (in bytes verified) with other nodes.\n2. Peers send blocks to debtor peers probabilistically, according to a function that falls as debt increases. The probability function, given a debt ratio $r = \\frac{\\textrm{bytes sent}}{\\textrm{bytes received} + 1}$ is $P(send | r) = 1 - \\frac{1}{1 + \\exp(6-3r)}$. The debt ratio is a measure of trust: lenient to debts between nodes that have previously exchanged lots of data successfully, and merciless to unknown, untrusted nodes. This also strongly disincentivizes Sybil attacks by making it hard for new nodes to request a lot of blocks without the intention of paying them back.\n\n## Pinning\nThis ensures the objects are kept in the node’s local storage. Pinning can be done recursively, to pin down all linked descendent objects as well. All objects pointed to are then stored locally. This is particularly useful to persist files, including references\n\n## WNFS\nUnder the Fission project, [see specs](https://guide.fission.codes/developers/webnative/file-system-wnfs)\n\nFile system built on top of IPFS. Uses a DAG instead of a hierarchy, meaning that a given child can have more than one parent.\n\nEach user has their own WNFS and consists of a public and private tree.\n\n- The public tree is \"live\" and publicly accessible on the Internet.\n- The private tree is encrypted so that only the owner can see the contents.\n\nUses [[thoughts/authorization#UCAN|UCAN]] for authorization.","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/In-Over-Our-Heads":{"title":"In Over Our Heads: The Mental Demands of Modern Life","content":"\nIn Over Our Heads is about the societal expectations of higher orders of consciousness that most of us do not have. \n\n\u003e All of us will spend some portion of our adult lives overmatched by the demands of modernism, the compulsory \"major\" in our culture's curriculum.\n\nThe book details Robert Kegan’s model of adult development -- basically a series of increasingly sophisticated ways one can approach ethical reasoning.\n\nGrowth is a process of 'leaving home'. It is a process of leaving the mental homes they have furnished and made familiar.\n\n## Stages of Adult Development\n### Stage 2: Self\n- the subject (self) is a collection of short-term practical interests\n- [[thoughts/ethics|ethics]] in this mode is “instrumental”: aimed at satisfying your own needs, while working with or around other people’s. Relationships are “transactional”: transient alliances for mutual benefit.\n### Stage 3: Communal\n- no longer a collection of interests but you *have* interests\n- you are *in* relationships and find yourself defined by them\n- the other’s point of view matters to us intrinsically, not just extrinsically as a means of satisfying our more egocentric purposes -- one gains the ability to put oneself in the other person's shoes\n- stage 3’s limitation is that it cannot resolve conflicts between responsibilities to different relationships. If one person wants you to do something, and another person wants you to do something different, there is no good basis for decision\n- it’s impossible to base a large-scale society on the communal mode, because it’s so ineffective at coordinating complex group activities. (If individuals frequently fail to do their specific, agreed tasks, nothing can get done.) Modern societies are based on the systematic mode -- see [group limits](thoughts/group%20limits.md) and [social contracts](thoughts/social%20contracts.md)\n### Stage 4: Systematic\n- you no longer are in relationships that define you; you have relationships\n- you are “self-authored”: you choose your own principles, projects, and commitments\n- it means seeing the other person for who they really are. Emotions are just something people have, from time to time. Those need to be dealt with, but should not be taken too seriously. Relating to the other person’s principles, projects, and commitments means supporting what they most care about in the longer run\n### Stage 5: Fluid\n- systems are relativized. They move from subject to object, and are subordinated to, and organized by, the process of meaning-making itself\n- you are no longer defined as a system of principles, projects, and commitments. You have several such systems, “multiple selves,” none of them entirely coherent, and which have different values—and this is no longer a problem, because you respect all of them\n- there is sometimes an uncomfortable middle between systematic (stage 4) and fluid (stage 5) stages often referred to as stage 4.5 where nihilism and postmodernism commonly emerges. Understanding that there is no ultimate meaning, one comes to the wrong conclusion that there are no meanings at all\n- sees systems as nebulous (intangible, interpenetrating, transient, amorphous, and ambiguous) and patterned (reliable, distinct, enduring, clear, and definite)\n\n## Independence and [love](thoughts/friendship.md)\n- To want to find the answer for oneself is not to reject the advice of others\n\t- \"is not just rejecting the assumptions of her husband or church or culture; she is rejecting her *relationship* to these assumptions as truths\"\n\t- the discovery here is not that one may have different ideas, values, or beliefs but rather ideas, values, and beliefs are by their very nature assumptive\n- What brings two people together in the first place?\n\t- \"we find each other in love out of some correspondence we feel with our deepest personal and primordial themes of longing, hoping, and desiring.\"\n\t- \"these deeply felt desires and needs animate our personal images, themes, stories, and myths. And the images, themes, stories, and myths inside our skins look for people to portray and enact them outside\"\n- Marriage is a partnership between two distinct individuals who do not share one mind, heart, and soul\n\t- Differences need not signal the failure of their closeness or bond but rather the reality of their distinctness\n\t- Corollary: successful couples do not give up the pursuit of closeness in their intimate relationship but reconstruct the very definition of what closeness is about\n\t- Rilke: \"once the realization is accepted that even between the closest human beings infinite distances continue to exist, a wonderful living side by side can grow up, if they succeed in loving the distance between them which makes it possible for each to see the other whole against the sky\"\n- On autonomy\n\t- Increasing autonomy does not have to be a story of increasing aloneness\n\t- Deciding *for* myself does not have to equal deciding *by* myself\n\t- In seems true, for example, as many have argued, that North American culture promotes and expects individuation and separation while many South American, Africa, and Asian cultures promote and expect the self-in-the-collective and the maintenance of attachments.\n\t- It may *not* be true that South American, Africans, or Asians partake any less than their North American counterparts in processes of increasing psychological differentiation, self-regulation, or even autonomy. Rather, they may partake of such processes *in the context of the collective*.\n- On mismatched love (e.g. familial)\n\t- \"Suppose you have a dog. A big-hearted, high-energy dog who begins to bark, and won't shut up, every time someone approaches your door. Now one day your dog starts into howling something first. He sounds a terrible alarm. You look out the window and it's just your friendly neighbourhood mailman. So what do you do? You aren't going to shoot your dog dead. He's a pain but you wouldn't think of it. Your dog loves you. He barks to warn you when *anyone* approaches. He wants nothing bad to happen to you. That's just how he is. Problem is, he's completely indiscriminate. He thinks everyone's a danger, barks at anyone who approaches... You're *going to have a look for yourself*. You're going to bend over and stroke your dog. 'Down boy,' you say. 'It's just the postman. No harm here, silly guy'\"\n\t- This is very much a metaphor for many familial relationships (especially in Asian-Canadian/Asian-American families) in which family is incredibly overprotective of their children, despite the pleas of the children to have their own independence and to not be constantly told of what to do (I am guilty of this as well)\n\t- Here it is noteworthy that suggested way of navigating this relationship is one that puts you the *relation* between you and the parents as an object rather than the subject -- to realize that you no longer are in relationships that define you; you *have* relationships (A stage 3 to stage 4 development)\n\n## [Burnout](thoughts/burnout.md)\nMaslach describes the \"burnout prone individual\" as one who mostly yield to the other without adapting to their own capacity: \"is often unable to exert control over a situation and will passively yield to its demands rather than actively limiting them to his capacity to give... faced with self-doubt this person tries to establish a sense of self-worth by winning the approval and acceptance of other people\"\n\nThis is a very fourth-order consciousness of viewing burnout when in fact most people are not even fourth-order (majority is third-order!)\n\nCulture-as-school: the poor school (our society) whose favourite students are the ones it does not have to teach\n- this sort of psychological assimilation amounts to a process by which difference and diversity are systematically removed\n\n## [Constructivism](thoughts/constructionist.md)\nOur capacity to select, regulate, act upon, and make decisions about raw data\n\n- We select in, but we also select out. Having an active way of hearing also meant that we were deaf to other perfectly \"good\" sound in the room. We just didn't hear it. For us it wasn't happening.\n- Having put our world together, are we awake to the fact that it is an *invented* reality? Do we tend to take our construction of reality as Reality, as the fact of \"how it is out there?\"\n\n## On [the Self](thoughts/the%20Self.md) and being whole\n\n\u003e Wholesomeness not in the aesthetic sense but as in the wholeness of the self\n\nWhen American POWs from the Vietnam era were first released, nearly all performed the same two first acts after being flown to Wiesbaden, Germany: they took showers and called loved ones.\n\nInterestingly, the men were far more likely to shower first and then to call loved ones. The women were more likely to call loved ones first and then to shower.\n\nThe difference is not necessarily that the men are more selfish and care more about their own bodily comfort than about their loved ones -- in fact, they could have well thought what was most important was to talk to their loved ones but couldn't do that in a 'self' that doesn't feel cleansed or psychologically restored.\n\nThe difference is not between \"selfish\" and \"altruistic\" -- both groups may have been doing first what they needed to do to restore the self -- in that sense, could be said to be \"[selfish](thoughts/selfish.md)\". **The difference is in how the self is made whole.** For some, the self is restored by itself and is not until then capable or fit for precious connection. For others, the self is restored in and through connection.\n\n## On therapy\n- Many times the efforts in individual therapy to convert a client's stance toward the past or present story of their life from one of helpless victim to creative agent not only fails but can cause them to feel unhappier still\n- The implicit message in such reconstructions is that \"you are responsible for your life\"\n- If the client already constructs the world at the fourth order, they will more likely hear this as a confirmation of their personal authority\n\t- A reminder that while the things that others do to me or that happen to me may not be in my control, the meaning I make of them can be\n\t- A reminder that while I cannot change the wind, I can change my sails\n\t- This is a confirmation of my own power\n- If the client constructs the world at the third order however, they are likely to hear the same message as a declaration of my blameworthiness\n\t- \"You are responsible for your own life\" is then less an inspiring rallying call to self-authorship than a humiliating and dispiriting judgement that I have only myself to blame for the fix I am in\n- This is the essence of \"In Over Our Heads\" -- that the systems that we are expected to function in expect much higher orders of consciousness that the vast majority of us have attained\n- Relevant: Kierkegaard on [teaching](thoughts/teaching.md) -- \"instruction begins when you put yourself in his place so that you understand what he understands and in the way he understands it\"\n\t- Trying to teach someone who is has a third order consciousness assuming they have fourth order is like trying to explain a three-dimensional sphere to a Flatlander: it neither sees a sphere nor has any sense that there is more than what it sees -- namely, a two-dimensional circle, that piece of a sphere its plane runs through.\n\t- The one being taught will only recognize the fourth order teachings in third order structures.","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Indras-Paradox":{"title":"Indra's Paradox","content":"\n\u003e CRWR 200 Short Story\n\u003e \n\u003e Disclaimer: This piece touches on suicidal ideation. My intention was to explore the connection of the Buddhist conception of emptiness and the experience of death/non-being. This is in no way drawn from my own life or experiences and encourage those dealing with suicidal ideation to seek professional help.\n\nThe room was fraught with tension. \n\n\"What do you *mean* the last one was deleted too? Are we in an unwinnable battle?\" The Bishop was incredulous.\n\n\"A thousand years of engineering, mastering the physics of this universe, answering every question knowable by man, and we still can't figure this one stupid thing out?\"\n\nHe slammed his fist into the table with a flat thud, but nothing shook. It was an otherwise bleak room with smooth steel walls and glass displays covering every other surface. Displays on the surface of the table flashed a bright crimson, signalling some sort of error. \n\n*NO ANSWER.*\n\nOnly the twelve in this room really grasped the true extent of what lay beyond the cold, flashing screens. Indra was a multi-planetary computer, designed to self-improve and self-adjust to better serve the people who created it. The designers and engineers of Indra were revered as prophets, vision-bearers who would guide Earth out of the climate crisis, civil wars, and wide-spread famine. Indra solved ageing, answered fundamental questions about the nature of reality, and even molecular engineering -- long considered to be the key to controlling the physical world. Yet this one question seemed to stump even Indra itself.\n\n\"What do you mean there's 'no answer'? I cannot announce to the trillions of conscious beings that...that all the progress of mankind is going to be erased by a little bit of randomness--\"\n\n\"Entropy, actually\" I interjected. Somebody had to correct him.\n\n\"I don't care! Entropy, randomness, same shit. Indra is telling us that society as we know it will cease to exist in what, a few centuries, and we can't do *anything* about it? That the world is going to be ended not by some sort of cosmic freak accident or engineering failure but by a fundamental flaw in the universe?\"\n\nEyes were cast downwards at the floor and at each others feet. The Bishop pointed a trembling finger at me.\n\n\"*You*. You seem weirdly confident about figuring this entropy shit out.\"\n\nAnd with that, he stormed out of the room. Cautiously, the rest of the designers and engineers filed out of the room, shrugging and providing glances which seemed to say 'you did this to yourself'.\n\nI spun in my chair and smirked. There's only so much you can do in a world that has all of its problems solved. *Finally,* something to do\n\n---\n\n\"Hey Indra... never mind\"\n\nI chewed on a meal replacement bar and tossed the wrapper amongst the 5 other ones on the table. Indra seemed to hum in disapproval.\n\nEvery single direction I had tried to prod and tug at this question all seemed to end up at one fundamental concept: information loss. It is an axiom that information cannot appear or disappear -- how did so many fields run into some inconsistency with this? It was everywhere I looked. What happens to the quantum information of matter when it falls into a black hole? What happens to the semantic information in computer hard drives when they are wiped empty?\n\nEach attempt to answer a question always felt like an intellectual dance, with me asking a question and Indra answering. Always getting close but never approaching an answer.\n\nPerhaps there wasn't one?\n\nI sighed and looked out the sole window in the control room. It was on the 120th floor of the Ministry of Affairs, far and isolated from the rest of society. With a machine as powerful as Indra, the isolation was necessary.\n\nI had thought this would be a relatively easy question to crack -- after all, most requests the Bishop made were easy to fulfil. But something about this problem was fundamentally different. Whereas others would take days to months, this one I struggled with for decades and I knew the Bishop would be back soon.\n\nI looked around for something to punch, something to scream at, but the room was bare. A thought crossed my mind.\n\n\"Wouldn't it be nice to just... die? Or not exist?\"\n\nI let that thought linger in the air, feeling the shape of the words that I had thought many times but never said aloud. Ageing had been solved by Indra a long time ago but one's life could still be ended, right?\n\nWhat *would* it be like to die? As consciousness ceases to exist, what happens to the self? A sudden jolt of realization sat me upright.\n\n\"Hey Indra, what happens to the consciousness of a person as they die?\"\n\nThe surfaces hummed and shimmered, almost as if I could hear it thinking.\n\n*NO ANSWER.*\n\n\"Ok... how does consciousness arise?\"\n\n*NO ANSWER.*\n\nIt didn't matter that Indra had no answers for me. My mind was racing, speaking out loud only as an artifact of my train of thought.\n\n\"Does consciousness arise in artificial minds?\"\n\n*NO ANSWER.*\n\n\"Indra, how did you come to exist?\"\n\n*I WAS CREATED EONS AGO BY A GROUP OF 12 ENGINEERS AND DESIGNERS. THEY NAMED ME AFTER INDRA'S NET. DESIGNED TO--*\n\n\"What is Indra's Net?\"\n\n*INDRA'S NET IS A METAPHOR THAT ILLUSTRATES THE CONCEPT OF EMPTINESS. EMPTINESS DOES NOT MEAN EMPTY OF FORM BUT RATHER EMPTY OF INDEPENDENT EXISTENCE -- ALL THINGS DEPEND ON EACH OTHER TO EXIST.*\n\nSomething suddenly illuminated in my head. There *is* no solution to decreasing entropy. Entropy is the universe's form of returning to emptiness and emptiness is... fundamental.\n\nEmptiness is like the mathematical concept of 0. It seems to have no value, yet is it the foundation of mathematics. Without 0, you cannot have 1, 2, 3, so forth. It is this entropy, this process of returning to emptiness, that gives life its meaning! It felt like an almost cosmic revelation. An almost raw guttural scream emerged from my mouth and I let it engulf me.\n\nAt that moment, the Bishop burst into the room. \"What is all the commotion going on here?\"\n\nI smiled at him. \"No. There is no solution to the problem.\"\n\nI knew that this wasn't an answer that the Bishop would take lightly and I gladly accepted my fate. The Bishop spat on the ground.\n\n\"You started off with so much confidence, we thought you would be different. No, you're just like the others that came before you. Clueless about the inner workings of this universe. Useless. Delete him.\"\n\nI smiled because I knew the truth. I smiled because it was ironic that I would suffer the same fate I had spent so much of my life trying to hard to prevent. I smiled because the Bishop would choose another to try to answer the question I and so many before me had failed to answer. I smiled because I knew they would come to the same conclusion I would.\n\n\"Make sure the next one you choose to work on this problem isn't this arrogant.\"\n\nIt was in deletion and in death that I finally felt at peace. No urge to understand. No urge to prove myself. Just... emptiness. Paradoxical, isn't it? Only those who understand emptiness truly realize that it isn't something to be feared.","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Integrated-Information-Theory-of-Consciousness-IIT":{"title":"Integrated Information Theory of Consciousness (IIT)","content":"\nSee also: [[thoughts/Consciousness is not Information|a refutation against IIT]]\n\nFirst-order sensory theory of [consciousness](thoughts/consciousness.md), a form of [[thoughts/Panpsychism|panpsychism]]\n\n## IIT\n\u003e Consciousness *is* integrated information\n\nIn this context, information refers to information that is specified by a system that is irreducible to that specified by its parts.\n\nThe amount of [information](thoughts/information.md) $\\phi$ that the entire complex system has beyond the information available from the sum of its parts (i.e. Information that can’t be localized in the system's individual parts.)\n\nAcknowledges that one cannot infer the existence of [consciousness](thoughts/consciousness.md) starting from physical systems. Instead, IIT starts from the experience itself, identities its essential properties (axioms), and then infers what kind of properties physical systems must have to account for its essential properties (postulates), and determines 'how conscious' a system is based off of these postulates.\n\nAxioms of IIT\n1. Intrinsic Existence: consciousness exists, each experience is real and actual (my experience exists independent of external observers)\n2. Composition: Each experience is composed of multiple phenomenological distinctions\n3. Information: each experience is the particular way it is (it is different from other possible experiences)\n4. Integration: each experience is irreducible to non-interdependent, disjoint subsets of phenomenal distinctions (I experience the whole scene, not just the left side independent of the right side)\n5. Exclusion: consciousness is definite\n\n[^1]: This content is sourced from Professor [Evan Thompson](https://evanthompson.me/)'s course materials for PHIL451A at UBC. All rights to this content is retained by Evan Thompson.","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Interact-Circle-W21":{"title":"Interact: Hackathon Culture + Play","content":"\n[View artifact](https://play.jzhao.xyz/). Contains writings on [play](posts/play.md) and [new-words](posts/new-words.md)/[terminology](thoughts/terminology.md)\n\n## Reflections\nI did not think I would ever be this excited about meeting people at 9AM on a Monday ever. This Circle has helped me center myself in what I truly find energizing in this world: discussing cool ideas with cool people.\n\nThis is a sort of meta-reflection on choosing to lead this Circle.\n\n### Leadership + People\nIn all honesty, I was a little scared to lead this Circle. What merit did *I* have as an undergrad student to even *try* to define what play was?\n\nI was even more intimidated when I saw the list of people applying to be a part of it. These are people who are attending some of the top schools in the world, working on some of the hardest problems that our society is working on, and have just such wealth of knowledge and kindness that I could hardly fathom why they would be interested in my circle. I had a moment where I realized, that this is what it feels like to be the dumbest person in the room. And you know what? **That's okay**.\n\nJoel, Becky, and Justin have all been so ridiculously wonderful throughout the whole Circle that it's so weird to even think I almost didn't follow through. I feel like this Circle has given me the space to explore ideas that have been marinating in the back of my head with some ridiculously thoughtful people.\n\nI cannot wait to see how we piece this into something that we can show the world. It may be a little naive, but I really think that what we made here is truly special. This is the chance for us to help define what play means for the next few generations and I cannot be more giddy. Towards unabashed excitement :))\n\n","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Internet":{"title":"Internet","content":"\nNot to be confused for the web. While the terms web and Internet are often used interchangeably in the media, they refer to different systems. The web is an information network, whose nodes are documents. In contrast the Internet is an infrastructural network, whose nodes are routers.\n\n## Capital I Internet\n[Source](https://apenwarr.ca/log/?m=202007)\n\n\u003e When I first joined the Internet in the 1990s, I found some now-long-lost introductory tutorial. It talked about the difference between an internet (lowercase i) and the Internet (capital I). An internet is \"any network that connects smaller networks together.\" The Internet is... well... it turns out that you don't need more than one internet. If you have two internets, it is nearly unavoidable that someone will soon figure out how to connect them together. All you need is one person to build that one link, and your two internets become one. By induction then, the Internet is the end result when you make it easy enough for a single motivated individual to join one internet to another, however badly.\n\nSee: [[thoughts/Postel's Law]]\n\n## [Niche at scale](thoughts/niche%20at%20scale.md)\n\n\u003e **The Internet allows you to scale any niche obsession**\n\nLocation-based scaling before usually meant smaller audiences. Now, larger cities (and the internet at large) has allowed audience sizes to grow to ridiculous amounts.\n\n## [Centralization](thoughts/decentralization.md) of Content and Services\nImagine the surface of the web as a representation of its potential activity. A few heavyweight players have dug into the web surface, dragging activities down their slopes, activities that could have remained independent and decentralized.\n\nInstead of creating a new webpage, Internet professionals and private users tend to go to a Facebook Page and therefore open content hosted on the slope of a dominant curve. \n\n![](/thoughts/images/Slope%20Metaphor%20of%20the%20Internet.png)\n\n## Theories / Models of Thinking\n1. [Mangrove Theory of the Internet](thoughts/Mangrove%20Theory%20of%20the%20Internet.md)\n2. [Dark Forest Theory of the Internet](thoughts/Dark%20Forest%20Theory%20of%20the%20Internet.md)\n3. The Internet Is a Collective Hallucination ([digital permanence](thoughts/digital%20permanence.md))\n4. A [friction](thoughts/friction.md)-ful Internet\n5. [Moving Castles and Wizards](thoughts/Moving%20Castles.md)\n\n## Internet [Epistemology](thoughts/epistemology.md)\nOn [epistemic authority](thoughts/epistemic%20authority.md)\n\nTraditional\n- expertise-based\n- hierarchical\n- institutionally-mediated\n- education, positions of authority\n\nInternet\n- crowd-based\n- broad and distributed\n- technologically-mediated\n- popularity, usefulness, influence\n- data and metrics\n- post-truth?\n\t- truth and facts as constructed, contested notions\n\t- product of low [trust](thoughts/trust.md) and highly polarized information environment\n\t- information becomes fact\n- see: [gate keeping](thoughts/gate%20keeping.md)\n\n## [Moderation](thoughts/Moderation.md)\n[Source: The Internet Is Rotting in *The Atlantic*](https://www.theatlantic.com/technology/archive/2021/06/the-internet-is-a-collective-hallucination/619320/)\n\n\u003e \"So the internet was a recipe for mortar, with an invitation for anyone, and everyone, to bring their own bricks.\"\n\nThis absence of central control, or even easy central monitoring, has long been celebrated as an instrument of grassroots [democracy](thoughts/democracy.md) and freedom. -\u003e did this arise out of the [counterculture](thoughts/From%20Counterculture%20to%20Cyberculture.md)?\n\nGap of responsibility: Their designs naturally create gaps of responsibility for maintaining valuable content that others rely on.\n\n\"It’s not trivial to [censor](thoughts/censorship.md) a network as organic and decentralized as the internet. But more recently, these features have been understood to facilitate vectors for individual harassment and societal destabilization, with no easy gating points through which to remove or label malicious work not under the umbrellas of the major social-media platforms, or to quickly identify their sources.\"\n\n\"10 years ago, a third-party bookseller offered a well-known book in Kindle format on Amazon for 99 cents a copy, mistakenly thinking it was no longer under copyright. Once the error was noted, Amazon—in something of a panic—reached into every Kindle that had downloaded the book and deleted it. The book was, fittingly enough, George Orwell’s _1984_. (_You don’t have 1984. In fact, you never had 1984. There is no such book as 1984._)\"\n\n\"Indeed, Wikipedia suffers from vandalism, and over time, its sustaining community has developed tools and practices for dealing with it that didn’t exist when Wikipedia was created. If they’d been implemented too soon, the extra hurdles to starting and editing pages might have deterred many of the contributions that got Wikipedia going to begin with.\"\n\nCurious about how this relates to [ephemereal content](thoughts/ephemereal%20content.md). Is moderation and managing rot thereby a form of [maintenance](thoughts/creation%20vs%20maintenance.md)?\n\n## Fire as a Metaphor for the web\n\n\u003e Fire is a chief metaphor for the Internet: it is metaorganic; it extends the range of (informational) food; it empowers people to explore new time zones (the night) and territories of knowledge; it increases some kinds of sociability, demands ongoing maintenance, and produces dangers and externalities that did not exist before. Fire was the first World Wide Web, a fragile system for contagious spreads. Young people now stay up late looking at flickering firelights—TV screens, computer monitors, smart phones—as they once tended the communal well of flames. (Television has always been compared to the family hearth.)\n\u003e \n\u003e ...\n\u003e \n\u003e Internet videos for restoring the power of the embodied voice speaking around the campfire. We “burn” discs on our computers. Memes and themes tear through the Internet like prairie fires, or are retarded by censorship “firewalls” such as those of the Chinese government. The server farms that are key to the material infrastructure of the Internet generate vast amounts of heat, requiring air conditioning in addition to the electricity their processing takes up. (Data centers are often built in cold climates to save on cooling costs.) Touchscreen technologies fulfill a certain fantasy of touching flame. As Paul Frosh notes, “Television and computer screens (including iPads etc.) have some of the qualities of fire, especially self-illumination; unlike cinema and print, they are lit from within.” Information is irreducibly connected with heat and burning.\n\u003e \n\u003e *(The Marvelous Clouds: Toward a Philosophy of Elemental Media)*","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Jestermaxxing":{"title":"Jestermaxxing","content":"\n## Playfulness vs Epistemic Traps\nC. Thi Nguyen on [Playfulness vs Epistemic Traps](https://philpapers.org/archive/NGUPVE.pdf)\n\n[[thoughts/play|Play]] is done for its own sake. We play because playing is fun, pleasurable, or satisfying, not because we want some kind of product or outcome ([[thoughts/The Grasshopper, Games, Life and Utopia#Terminology|autotelic behaviour]]). It involves a sort of shifting of perspectives, or stepping outside one's normal rules and roles -- and stepping into other ones.\n\nIntellectual playfulness, loosely, is the disposition to try out new ideas, perspectives and systems of thought (involves perspective shifting) for the sheer joy of it (autotelic). It is a disposition to explore ideas for the value of exploration itself.\n\nIntellectual playfulness also has some clear epistemic functionality for us\n- intellectually playful exploration sometimes can better serve the goal of finding the truth, than will exploration that is strictly aimed at finding the truth\n- it functions against epistemic traps: belief systems that undermine our epistemic efforts, leaving us stuck inside them\n\nExamples of epistemic traps:\n1. anti-reflective traps: belief systems that operate by preventing their adopters from reflecting on their belief system at all (e.g. unswerving and unthinking obedience to a leader)\n2. inquiry trap: belief systems which encourage, but re-direct, various intellectual processes. A kind of intellectual judo, flipping earnest intellectual efforts and sending down the wrong paths (e.g. echo chambers: a community which creates a significant [[thoughts/trust|trust]] disparity between members and non-members -- [[thoughts/in-group bias|in-group bias]]. Members of echo chambers come equipped with the intellectual machinery needed to dismiss contrary evidence coming in from the outside. Outside sources are, after all, untrustworthy, malicious, and corrupt)\n3. insensitivity trap: hybrid anti-reflective and inquiry trap. Belief system that selectively cuts off attention to certain areas of life by attributing valuelessness to those areas by narrowly specifying what counts as valuable. (for example, the businessperson who believes the only thing of importance is money. They spend their time thinking about strategies to make more money and unlikely to attend to pursuits which might put them into contact with other expressions of value)\n\nIntellectual playfulness, like [[thoughts/play#Against Irony|play]], involves a form of perspective shifting -- trying on and (at least temporarily) inhabiting alternate belief systems, which includes trying out alternate beliefs, values, and norms for belief-acquisition.\n\nThis is notably different from open-mindedness. Open-mindedness makes a weaker demand than perspective shifting. An open-minded person ought to take some challenges seriously, when their background belief system gives them good reason to, but their standing belief system is a very active participant in the process (this is problematic as their belief system shapes 1) which challenges one takes seriously 2) and how to view them as valid or not). However, open-mindedness is weak to epistemic traps.\n\nImagine that a belief system is a boat. Open-mindedness is the willingness to pull out any particular plank and to inspect it to see if it makes sense on the boat. But that assessment occurs while standing on all the other planks of that boat. Perspective shifting involves jumping ship and trying out a whole new boat.\n\nNext, we argue that the pursuit of truth may be a self-effacing end -- that it cannot be acquired through direct pursuit. Even if you are trying out alternative systems of belief, the choice of those systems will still be influenced by your standing system of beliefs. The trouble is that a well-designed epistemic trap can undermine the plausibility of alternative perspectives.\n\nIn the [[thoughts/exploit explore|exploit-explore tradeoff]], random walks are *actually good*. Surely, one may argue, that if going on occasional random walks is the best path for rationality, then wouldn't the rational person go on random walks? Yet, one cannot take a truly random walk without being guided by prior beliefs.\n\n## Idealogical Turing Test\nhttps://twitter.com/liron/status/1551205692152975360\n\n\u003e The Ideological Turing Test is an exercise where you try to pretend to hold an opposing ideology convincingly enough that outside observers can't reliably distinguish you from a true believer.\n\nPassing the ideological Turing test is a sign that you understand the opposing ideology on a deep level.\n\nSee also: [[thoughts/Turing Test|Turing Test]]","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/K-means":{"title":"K-means","content":"\nAssumption that we know how many clusters there are as a prior ($k$ in K-Means). Designed for vector [[thoughts/quantization|quantization]]: replacing examples with the mean of their cluster (collapsing a bunch of examples of a class down to a single example)\n\nCan also be seen as a really bad [[thoughts/latent-factor model]]\n\nK-means partitions the space into [[thoughts/convex|convex]] regions, *but* clusters in the data might not be convex\n\nMinimize $\\sum_{i \\in \\textrm{clusters}} \\{ \\sum_{j \\in i^{th} \\textrm{cluster}} ||x_j - \\mu_i||^2 \\}$\n\n1.  Pick some $k$\n2.  Assign a cluster to $k$ different points randomly\n3.  Iterate\n    1.  Center update → calculate average for each cluster (using euclidian distance)\n    2.  Label update → re-assign the data to the closest cluster center\n    3.  If no labels changed, finish (model has converged)\n\nWarning: the clustering is initialization dependent and converges to a local minimum. Often requires some amount of random runs to approximate a good solution, pick best one.\n\nLimited to compact/spherical clusters in high-dimensions (which is poor for modeling clusters with the same mean but different distributions)\n\nAdvantages\n- easy to implement and interpret\n- simple to understand\n- computationally more efficient than other clustering algorithms\n\nDisadvantages\n- need to specify K\n- dependent on initialization\n- sensitive to scale of features (need to normalize/standardize)\n\nCost\n- Dominated by calculating distance from each $x_i$ to each mean $w_c$\n\nK-means, unlike the classification and regression models we studied in previous chapters, can get “stuck” in a bad solution. For example, if we were unlucky and initialized K-means with the following labels. To solve this problem when clustering data using K-means, we should randomly re-initialize the labels a few times, run K-means for each initialization, and pick the clustering that has the lowest final total WSSD.","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/KNN":{"title":"k-Nearest Neighbours (KNN)","content":"\nTo classify an example, we find the $k$ examples closest to the example and take the mode of the $k$ examples.\n\nWorks based off of the assumption that similar features are likely to have similar labels\n\nEffects on [[thoughts/fundamental tradeoff]]:\n- As $k$ grows, training error increases and approximation error decreases.\n- As $n$ grows, model complexity increases\n\nWe measure distance using the \"norm\" between feature vectors. The most common norm is the L2-Norm or [[thoughts/linear algebra#Vector Norm|Euclidean Norm]]\n\n## Performance\n- $O(1)$ training (just relies on training data)\n- $O(nd)$ predictions ($O(d)$ distance calculations for all $n$ examples)\n- $O(nd)$ space to store each training example in memory\n\t- This is non-parametric\n\nKNN can suck in high dimensions (see: [[thoughts/Curse of Dimensionality|curse of dimensionality]])\n","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Kademlia-DHT":{"title":"Kademlia DHT","content":"\nSummarization of the [Kademlia paper](https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf)\n\n\u003e A [[thoughts/peer-to-peer|peer-to-peer]] distributed hash table ([[thoughts/DHT|DHT]])\n\nParticipating computers each have a node ID in the 160-bit key space. Key-value pairs are stored on nodes with IDs \"close\" to the key for some notion of closeness. A node-ID-based routing algorithm lets anyone efficiently locate servers near any given target key\n\nA `get(key)` operation traverses the identifier space and, upon hitting a node storing key, returns the key’s corresponding contact list. Then, the requesting node can contact these nodes, in parallel or in some application-specific way, to download the stored data.\n\nCore ideas\n- Uniform ID Space: names for both data and nodes share the same ID space\n\t- But collisions are ok as they mean different things depending on the context\n- Decide what machine to place data on depending on a measure of 'closeness' between the name of the data and name of a machine\n\t- Euclidean distance can be ambiguous, two entries could have the same distance\n\t- XOR distance between $x$ and some arbitrary $y$ will *always* be unique\n- Each node only needs information about its neighbours.\n\t- If the structure of the network is correctly chosen, then global properties apply to the whole network\n\t- Nested routing similar to [[thoughts/IP Addresses|IP]] routing\n\t- Each machine has a lot of info about machines closest to it, less about machines far away from it","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Kant":{"title":"Kant","content":"\nThe [[thoughts/ethics|ethical]] theory of the German philosopher Immanuel Kant\n\n## Good will and the Categorical Imperative\n\u003e \"What is always good without qualification? Intelligence and courage can be used for bad. The only thing in the world that can be called good without qualification is a **good will**\"\n\nAccording to Kant, what we want to do is of no importance. Our focus should be on what we ought to do (dutifulness).\n\nFor Kant, an imperative is a way in which reason commands the will. There are two major kinds of imperatives\n1. Hypothetical: a conditional rule of the form \"if you want X then do Y\"\n2. Categorical: unconditional rule, always applies\n\n\u003e What’s good for the goose is good for the gander.\n\nHe believes that the *only* categorical imperative is the moral imperative: you should act only on moral rules that you can imagine everyone else following without deriving a logical contradiction.\n\nOr, the second formulation: act so that you always treat both yourself and other people as ends in themselves, and never only as a means to an end.\n\n## Against Kantianism\nKant holds that every action is motivated from a rule. The appropriate rule depends upon how we characterize the action. Once we know the rule, we can test its value using the Categorical Imperative. What happens when no single rule fully explains the situation? Suppose I’m considering stealing food from a grocery store to feed my starving children. How should I characterize this action? Am I stealing? Am I caring for my children? Am I trying to save the lives of innocent people? Until I characterize my action, I cannot determine the rule and test it against the Categorical Imperative.\n\nIf we allow multiple rules to be relevant to a particular action then what do we do what relevant rules conflict? Kant distinguished between perfect duties and imperfect duties\n1. Perfect Duties are duties we are obliged to fulfil in every instance (e.g. telling the truth)\n2. Imperfect Duties are duties we are obliged to fulfill in general but not in every instance\n\nPerfect duties prevail over imperfect duties. However, if there is a conflict between perfect duties, Kantianism does not provide us a way to choose between them.\n\n## Applied to [[thoughts/privacy|privacy]]\n- Government believes it is morally right to monitor suspects\n- Then what if everyone could monitor who they suspect\n- Then anyone could monitor anyone, including government officials\n- Governments require a basic level of privacy to conduct their business (security clearance is a thing)\n- This is not possible if anyone could monitor government officials without consent/permission, leading to a contradiction\n- Thus, being able to surveil suspects without consent is immoral","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Key-Sharing-Problem":{"title":"Key Sharing Problem","content":"\n\u003e  The key exchange problem describes ways to exchange whatever keys or other information are needed for establishing a secure communication channel so that no one else can obtain a copy.\n\n- Alice locks the box with her lock and sends it to Bob\n- Bob locks the box with his lock and sends it back to Alice\n- Alice removes her lock and sends it back to Bob\n- Bob removes his lock\n- Double Encryption Transfer\n\t- Both parties generate random keys $K_A$ and $K_B$\n\t- Sender sends encrypted message $K_A(m)$\n\t- Receiver encrypts received message and sends it back $K_B(K_A(m))$\n\t- Sender decrypts message and sends it again $K^-_{A}(K_B(K_A(m))) = K_B(K^+_{A}(K_A(m))) = K_B(m)$ (only valid if operation is associative!)\n\t- Receiver decrypts final message $K^-_{B}(K_B(m)) = m$\n\n### Diffie Hellman\nA way of performing key exchange over an insecure channel.","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Knowledge-Argument":{"title":"Knowledge Argument","content":"\n## Frank Jackson's Knowledge Argument[^1]\n- Mary is confined to a black-and-white room, is educated through black-and-white books and through lectures relayed on black-and-white TV. Through this, she learns everything there is to know about the physical nature of the world, including all there is to know about the causal and relational facts consequent upon all this, including of course functional roles.\n- If physicalism is true, she knows all there is to know.\n- Yet, if Mary is let out of her black-and-white room or given a colour TV, she will learn what it is like to see something red.\n\nThe implication here is that Mary cannot learn what it is like to subjectively experience red from reading physical facts (similar argument re: [semantics](thoughts/semantics.md) in [Chinese room argument](thoughts/Chinese%20room%20argument.md)).\n\n## Dennett's Refutation of the Knowledge Argument[^1]\n\n\u003e “And so, one day, Mary’s captors decided it was time for her to see colours. As a trick, they prepared a bright blue banana to present as her first colour experience ever. Mary took one look at it and said ‘Hey! You tried to trick me! Bananas are yellow but this one is blue!’ Her captors were dumbfounded. How did she do it? ‘Simple,’ she replied. ‘You have to remember that I know everything—absolutely everything— that could ever be known about the physical causes and effects of colour vision.\n\n- No double transduction\n\t- Transduction is a conversion of one for another\n\t- Peripheral/internal transducers are sense organs (e.g. eyes) that transform physically detectable properties to electrochemical signals\n\t- There is no further conversion of neural signals into a qualitative medium\n- No Cartesian theatre in the brain\n\t- There is no central place where all things 'come together' and [consciousness](thoughts/consciousness.md) happens\n\t- Point of view of the observer is smeared over a large volumen of the brain with different networks (distributed model of representation)\n- Consciousness is like fame\n\t- “Just as becoming famous is not a precisely datable event like being transduced into a medium (like being televised), so achieving consciousness in the brain is not a precisely datable transition in the brain.\n- No qualia if intrinsic properties are *instantiated by* rather than *represented by* neural activity\n\n## Essay\n\u003e Critically evaluate Frank Jackson’s “Knowledge Argument.” Does Mary learn something new, and if so, what exactly does she learn and what are the implications for physicalism? If she does not learn anything new, explain how and why this is the case.\n\nIn this paper, I posit that Frank Jackson's \"Knowledge Argument\" is *logically sound* but hinges on many bold and often presumptuous premises to be true. As such, the conclusion should not be taken for granted without more clarifications around premises and terminology.\n\nI propose that Mary has all of the 'know-that' knowledge but none of 'know-how' knowledge. The act of Mary 'seeing' colour for the first time means that she learns new 'know-how' knowledge which she did not have. Physicalism, as a result, is preserved as Mary only has 'know-that' knowledge so does not know all physical *facts* about colour perception.\n\nThis relies on three facts:\n1. There is a distinction between physical fact and physical knowledge\n1. There are unknowable physical facts that give rise to new experiences\n2. Know-how cannot be learned through know-that (e.g. reading and watching videos)\n\nBriefly, the conclusion that Frank Jackson posits is as follows:\n\n1. It is possible for someone to know all *physical* information there is to know about $x$, still *experiencing* the act of seeing colour will teach her something about $x$.\n2. Certain experiences (e.g. experiencing colour) still teach Mary something new. Then, this means that all physical information there is to know about $x$ do not completely describe *all* information about $x$.\n3. This contradicts the theory of physicalism: that everything, including mental states, has a physical explanation. Extending this argument: if we could know every physical detail about someone else's brain, one would still not understand what it is like to experience things for them (Nagel's Bat Argument).\n\nHowever, this conclusion relies heavily on the first premise being true, that is, it being possible for one to \"acquire ... all the physical information there is to obtain about what goes on when we see [$x$]\". Let us first examine the explicit distinction between 'physical knowledge' and 'physical facts' here.\n\nKnowledge, specifically, entails all 'knowable' things. In the context of this paper, I define 'knowledge' as justified true belief. Subject $S$ knows $x$ if and only if[^1]:\n\n1. $x$ is true\n2. $S$ believes that $x$\n3. $S$ is justified in believing that $x$.\n\nI posit that there are facts (read true statements about object $x$) that cannot be known, let alone proven. For example, let us imagine that it is a fact that aliens do not exist. As of now, we have no suitable methodology or measurements that would allow us to confirm this fact (this would involve an exhaustive search of the universe which, as far as we know, is impossible). Thus, the set of all true statements about object $x$ is equal to or larger than the set of all obtainable knowledge about $x$. To know all physical knowledge about $x$ then does not necessarily imply knowing all physical *facts* about something.\n\nSpecifically, we note that the original Mary's Room argument phrases knowing as knowing \"all the physical information *there is to obtain* about what goes on when we see [$x$]\" (emphasis added). Then, there may be some physical facts Mary may not know that contribute to her experience of experiencing 'yellowness' when seeing a banana for the first time that she may not have known ahead of time, despite her having complete physical knowledge of the banana. As a result, Mary *experiences* something new (namely, seeing yellow) but does not learn anything new.\n\n---\n\nThe sharp-eyed may note that the previous argument relies on the fact that the set of all true statements about object $x$ is explicitly larger than the set of all obtainable knowledge about $x$. However, the statement originally assumed that the set of all true statements is *larger than or equal to* the set of all obtainable knowledge. This exposes an edge case which could be problematic where the set of all true statements is *exactly equal to* the set of all obtainable knowledge (i.e. subject $S$ knows all obtainable knowledge about $x$, which coincidentally is also the set of all true statements about $x$).\n\nI will show how this does not prove to be a problem for our argument. I raise one main question: Why is it obvious that she will learn something new about the world through an experience?\n\nTo be explicit, let us examine the framing of the Mary's room[^2]:\n\n- An epistemic subject _A_ appears to have no access to particular items of knowledge about a subject _B_\n- _A_ cannot know that _B_ has an experience of a particular quality _Q_ on certain occasions\n- This particular item of knowledge about _B_ is inaccessible to _A_ _because_ _A_ never had experiences of _Q_ herself\n\nThis is quite similar to Thomas Nagel's Bat Argument[^3]. Despite everything that Mary knows about seeing colour, she doesn't know what it is like to *see* colour.\n\nSpecifically, the Knowledge Argument relies on knowledge that is explicit or codified and can be communicated via [[thoughts/language|language]]. I argue that, conceptually, one cannot 'know' all there is to know about seeing colour through purely linguistically communicated [[thoughts/language|language]]. I refer to this 'linguistically unknowable' knowledge as tacit knowledge.\n\nWe first examine three different kinds of knowledge[^4]:\n\n1. Acquaintance knowledge: we get to know the characters of others (like friends) by being around them. This is a form of tacit knowledge.\n2. Knowledge-that: propositional knowledge, facts about the world obtained through reading, talking, and consuming content. This can be linguistically communicated.\n3. Knowledge-how: truly knowing how to do something, speaking, reading, etc. This is a form of tacit knowledge.\n\nMy position is that knowledge-how *cannot* be learned through only knowledge-that. Ryle calls this the Sufficiency Argument: \"how could propositional knowledge be sufficient for knowing how to do something?\"[^5]\n\nFrom this list above, knowledge-that is the only form of transferrable or communicable knowledge. Knowledge-how is a form of tacit knowledge which is inexpressible via [[thoughts/language|language]]. Knowledge-how, by definition, is only acquired through practical experience in the relevant context. To attempt to reconstruct knowledge-how using knowledge-that is to build a [potemkin village](thoughts/potemkin%20village.md), a sort of 'facade' of understanding. One can read all about playing a piano -- the music theory, the muscles to actuate, the feel of the keys -- yet fail to actually play the piano. Learning to play piano requires an embodied experience of feeling the keys and wiring the feedback between the concept of music in your brain to the motion of playing the notes.\n\nThus, in Frank Jackson's Knowledge Argument, Mary has all the 'know-that' knowledge about the perception of colour but none of 'know-how' knowledge. The argument depends heavily on Physicalism stating that Mary knows all physical facts about any given object. I have shown through this paper that the premises of Jackson's argument is dubious at best, namely the ability for Mary to know all *physical* facts about $x$. Thus, Physicalism is preserved.\n\n[^1]: https://plato.stanford.edu/entries/knowledge-analysis/\n[^2]: https://plato.stanford.edu/entries/qualia-knowledge/#BasiIdea\n[^3]: https://warwick.ac.uk/fac/cross_fac/iatl/study/ugmodules/humananimalstudies/lectures/32/nagel_bat.pdf\n[^4]: https://plato.stanford.edu/entries/knowledge-how/#LingArgu\n[^5]: *Knowing How and Knowing That: The Presidential Address*, Ryle 1946\n[^6]: This content is sourced from Professor [Evan Thompson](https://evanthompson.me/)'s course materials for PHIL451A at UBC. All rights to this content is retained by Evan Thompson.","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/LDP":{"title":"LDP","content":"\nThink of an LDP as a way of interacting with [[thoughts/RDF|RDF]] resources in a way that is similar to a web site with folders and documents in a RESTful manner.\n\nThe term \"Linked Data\" refers to an approach to publishing data that puts linking at the heart of the notion of data, and uses the linking technologies provided by the Web to enable the weaving of a global distributed database. By naming real world entities - be they web resources, physical objects such as the Eiffel Tower, or even more abstract things such as relations or concepts - with http(s) URLs, whose meaning can be determined by dereferencing the document at that URL, and by using the relational framework provided by [[thoughts/RDF|RDF]], data can be published and linked in the same way web pages can.\n\nRules of LDP:\n1.  Use URIs as names for things\n2.  Use HTTP URIs so that people can look up those names\n3.  When someone looks up a URI, provide useful information, using the standards (RDF, SPARQL)\n4.  Include links to other URIs, so that they can discover more things\n\n## What it enables\nLDP enables a very connected way of working with RDF data. You make HTTP requests to URI's and they get resolved to resources (Containers or RDFSources), which you can then consume to get at all the triples. And of course you can create resources, update them, list members of a container, etc. In this way, you can build web applications, that use RESTful requests.","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/LR-Permissionless-Result":{"title":"LR Permissionless Result","content":"\nShown by [Lewis-Pye and Roughgarden in 2022](https://arxiv.org/pdf/2101.07095.pdf)\n\nDeterministic [[thoughts/consensus|consensus]] is not possible for decentralized protocols with a Byzantine, permissionless [[thoughts/system model|system model]].\n\nPermissionless means that it does not enforce [[thoughts/access control|access control]] and allows the number and identity of participants to change without notice (under some number of participants bounded by $N$).","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/LSTM":{"title":"LSTM","content":"\nLong short term memory (LSTM) models are variant of RNNs. They are modified to try to remember short-term $z$ and long-term dependencies $c$. The purpose of memory cells is to remember things for a long time.\n\nLSTMs were the practical analogy of [[thoughts/convolutional neural networks]] for RNNs\n\n- Forget gate $f_t$\n\t- If element ‘j’ of $f_t$ is 0, then we clear element $c_{tj}$ from the memory (set it to 0).\n\t- If it is 1, then we keep the old value.\n\t- “Given the input and previous activation, are the elements in memory still relevant?”\n- Input gate $i_t$\n\t- If element ‘j’ of $i_t$ is 0, then we do not add any new information to $c_{tj}$ (no input).\n\t- If it is 1, then we “value” to the memory (where “value” is also a function of input and previous at ).\n\t- “Given the input and previous activation, should I write something new to memory?”\n- Output gate $o_t$ \n\t- If element ‘j’ of $o_t$ is 0, then we do not read value $c_{tj}$ from the memory (no output).\n\t- If it is 1, then we load from the memory.\n\t- “Given the input and previous activation, should I read what is in memory?”","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Lattice-Proposal":{"title":"Lattice Proposal","content":"\nPotential exploration on my gripes with existing [[thoughts/tools for thought|tools for thought]] using principles from [[thoughts/Rhizome Proposal|Rhizome]]. Extracted from my [[thoughts/idea list|idea list]]\n\n- transclusion of blocks supported by default\n- full revision history w granularity of single operations\n- write first, organize later: always-on 'default note'\n\t- make it super easy to split out content into a new note\n\t* good daily notes, choose what to carry over from the previous day\n\t* https://www.inkandswitch.com/crosscut/ -\u003e Thoughts move quickly, so the tools we use to make our models must be fast to use and readily available\n\t\t* should be even easier than just pen and paper\n* block based editors are neat cause i can move stuff around really easily\n\t* if u drag outside the page it makes a new note, super easy to break down big complex topics into more granular/atomic notes\n\t* spatially consistent? [memory palace](thoughts/memory%20palace.md) vibes -\u003e https://twitter.com/jordanmoore/status/1418942880941477891\n* card based backlinks/outgoing links\n\t* on the left, you can see all the notes that link to the current page\n\t* on the right, you can see all outgoing links\n\t* hovering on each card will reveal another layer which those ones are connected to\n* graph view\n\t* i wanted to have the option for 3d graphs too\n* timeline view\n\t* each note will come with a date so you can chronologically order notes and view them that way (kind of like a [[thoughts/git|git]] history) if ur brain works better that way\n* good global search\n\t* being able to index content fast and effectively\n* [interoperability](thoughts/interoperability.md) of data, easy export","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Lindy-effect":{"title":"Lindy Effect","content":"\n[Lindy Effect](https://en.wikipedia.org/wiki/Lindy_effect) -\u003e future life expectancy of a bit of technology is proportional to its current age (i.e. the longer something has survived, the more likely it is to have a longer remaining life expectancy).\n\nLongevity implies a resistance to change, obsolescence or competition and greater odds of continued existence into the future.\n\nMany traditional materials have the attractive property that they _look bad before they act bad_ and, furthermore, _the problems with traditional materials are well understood_.\n\n","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Linear-Regression":{"title":"Linear Regression","content":"\nVector dimensions:\n- $w$ is $(d, 1)$ (weights)\n- $y$ is $(n,1)$ (targets)\n- $x_i$ is $(d, 1)$ (features)\n- $X$ is $(n,d)$ each row is $x_i^T$\n\nLinear regression makes predictions $\\hat y_i$ using a linear function of $x_i$: $\\hat y_i = w^Tx_i$\n\nWe set $w$ to minimize the sum of squared errors: $f(w) = \\sum_{i=1}^n (w^Tx_i - y_i)^2$\n\n1. Take the derivative of $f$ and set it equal to 0 $f'(w) = 0$ gives us $w = \\frac{\\sum_{i=1}^n x_iy_i}{\\sum_{i=1}^n x_i^2}$\n2. Check to second derivative to make sure we have a minimizer (if double derivative is positive). $f''(w) = \\sum_{i=1}^n x_i^2$. As $x_i^2$ by definition must always be positive, this is a minimizer.\n\nIn d-dimensions, we minimize\n\n$$\\begin{equation}\n\\begin{split}\nf(w) \u0026= \\frac 1 2 \\sum_{i=1}^n (w^Tx_i - y_i)^2 \\\\\n \u0026 = \\frac 1 2 \\lVert Xw - y \\rVert^2 \\\\\n \u0026 = \\frac 1 2 w^TX^TXw - w^TX^Ty + \\frac 1 2 y^T y \\\\\n \u0026 = \\frac 1 2 w^TAw - w^Tb + c\n\\end{split}\n\\end{equation}$$\n\nwhere $A$ is a matrix, $b$ is a vector, and $c$ is a scalar\n\nThe generalized version of “set the derivative to 0 and solve” in d-dimensions is to find where the gradient is zero (see [[thoughts/calculus|calculus]]). We get\n\n$$\n\\begin{equation}\n\\begin{split}\n\\nabla f(w) \u0026= \\begin{bmatrix}\n\\frac{\\partial f}{\\partial w_1} \\\\\n\\frac{\\partial f}{\\partial w_2} \\\\\n\\vdots\\\\\\\n\\frac{\\partial f}{\\partial w_d}\n\\end{bmatrix}  \\\\ \\\\\n\n\u0026= \n\n\\begin{bmatrix}\n\\sum_{i=1}^n (w^Tx_i - yi)x_{i,1}  \\\\\n\\sum_{i=1}^n (w^Tx_i - yi)x_{i,2}  \\\\\n\\vdots\\\\\\\n\\sum_{i=1}^n (w^Tx_i - yi)x_{i,d}  \\\\\n\\end{bmatrix} \\\\ \\\\\n\n\u0026=\n\nAw - b \\\\\n\n\u0026= X^TXw - X^Ty\n\\end{split}\n\\end{equation}\n$$\n\nWe can fit to polynomial equations using a [[thoughts/change of basis]]\n\n## Cost\nOf solving equations in the form $Aw = b$\n1. $O(nd)$ to form vector $b$\n2. $O(nd^2)$ to form matrix A\n3. Solving a $(d,d)$ system of equations is $O(d^3)$\n\nOverall cost is $O(nd^2+d^3)$\n\n## Robust Regression\nWe minimize the L1-norm of residuals instead of L2-norm\n\n$$f(w) = \\lVert Xw - y \\rVert_1$$\n\nHowever, as the L1-norm uses the absolute function, it is non-differentiable at 0. We can use a smooth approximation of the L1-norm instead, like Huber loss:\n\n$$\nh(r_i) = \n\\begin{cases} \n      \\frac 1 2 r_i^2 \u0026 |r_i| \\leq \\epsilon \\\\\n      \\epsilon (|r_i| - \\frac 1 2 \\epsilon) \u0026 \\textrm{otherwise}\n   \\end{cases}\n$$\n\nAbsolute error is more robust and non-convex errors are the most robust.\n- Generally not influenced by outlier groups\n- But it is non-convex so finding global minimum is hard\n\n## Brittle Regression\nYou want to minimize size of worst error across examples. For example, if in worst case the plane can crash or you perform badly on a group.\n\nWe can instead minimize the $L_\\infty$ norm which is convex but non-smooth. This effectively minimizes the highest error (effectively Minimax regret in [[thoughts/Decisions under ignorance|DUI]]).\n\nThe smooth approximation to the max function is the log-sum-exp function:\n\n$$\\max_i \\{ z_i \\} \\approx \\log( \\sum_i \\exp(z_i))$$\n\n## Penalizing Model Complexity\nOptimize $score(p) = \\frac 1 2 \\lVert Z_p v - y \\rVert^2 + p$ where $p$ is the degree of the polynomial.\n\nOther ones also exist which replace the $p$ term with $\\lambda k$ where $k$ is the estimated degrees of freedom (for polynomials, $k = p + 1$). $\\lambda$ controls how strongly we penalize complexity.\n\n$\\lambda = 1$ is called the Akaike information criterion (AIC)\n\nSee also: [[thoughts/regularization]]\n","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Link-Layer":{"title":"Link Layer","content":"\nLayer 4, the layer below the [Network Layer](thoughts/Network%20Layer.md) and layer above the [[Physical Layer]]\n1. Hardware\n2. Unit: Frame\n3. Responsibilities: Routes frames to adjacent machines (“direct” connection) on a local area network (LAN). Defines the format of data on the network\n5. Details\n\t- Breaks up chunks into frames, contains some metadata\n\t- Hub model (share the same medium) means that we don't need to run wires between every computer (implicit broadcasting). Downside is we have to now specify who the message is for (usually using 48 bit media access control (MAC) addresses)\n\n## VXLAN\nLAN but across local networks... spooky\n\nIt encapsulates the [[thoughts/MAC]] frame into a [[thoughts/UDP]] datagram for transport across an IP network. This creates an [[thoughts/Overlay Network|overlay network]]","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/MAC":{"title":"MAC","content":"\n\u003e Message authentication code\n\nNot to be confused with MAC addresses.\n\n- Add a secret to the end of each message that is also hashed. It is extremely unlikely that anyone who doesn't know the secret to come up with an appropriate hash\n- Shared secret $s$ (this is a symmetric key)\n- Hash is computed not on message $m$, but on $m+s$\n\t- Bob sends message $h = H(m + s)$\n\t- Alice receives $(m, h)$ and computes $H(m + s)$\n\t- If $h = H(m+s)$, message is considered signed\n- Fast because [[thoughts/Asymmetric Key Cryptography|asymmetric key crypto]] is not necessary","lastmodified":"2023-02-15T01:38:21.225820848Z","tags":null},"/thoughts/Making-and-Maintenance-of-OSS":{"title":"The Making and Maintenance of Open Source Software","content":"\nFull post: [A case for funding Open Source](posts/paid-open-source.md)\n\n## Quotes\n### [Maintenance](thoughts/creation%20vs%20maintenance.md)\nA lot of initiatives like HacktoberFest are widely championed as 'good for open source' yet frequently cause maintainers to seize up with anxiety because such initiatives often attract low-quality contributors looking to snag a free t-shirt. \"Open source code is public, but it doesn't have to be participatory: maintainers can buckle under excess demand for their [attention](thoughts/attention%20economy.md)\"\n\nThis is akin to a writer being asked to edit and make changes to the same book every day, into perpetuity, long after they’ve reaped the initial financial and reputational rewards from its creation. What's more, unlike other content, open source code is relied upon by people, companies, and other institutions that need it to keep working, long after the maintainer's interest may have waned.\n\nWhen Richard Stallman first described free software as \"free as in speech, not free as in beer,\" the distinction he wished to make is that the term \"free\" referred to what one could do with the software, rather than to its price.\n\nThe common misconception of software is that it is often characterized as \"zero marginal cost,\" meaning that it can be distributed for nearly nothing, regardless of how many additional people consume it. The problem is not that simple. Code is nearly free to distribute, but maintenace can still be expensive. External contributions don't necessarily reduce the burden of maintenance either, because they still require someone to review and merge them.\n\nThe work of an open source developer goes beyond the initial costs of creation. Maybe developers can't help but make things, and share the things they make, but every time they do, and ever time they find success, a tiny, invisible clock begins to tick, and they're tasked with managing the care and feeding of their code into perpetuity.\n\n### Dependencies and [Infrastructure](thoughts/infrastructure.md)\nThere's even a term called the *bus factor*, where project health is a measured by the number of developers that would need to get hit by a bus before the project is in trouble.\n\nHowever, this 'theory' no longer matches up with empirical observation. In fact, less than 5% of developers were responsible for over 95% of code and social interactions on GitHub. The average software developer these days easily relies on hundreds of open source projects to write code these days, it's inevitable that they'll only be able to passively consume most of them.\n\nInfrastructure is recursively defined by public consensus. It's the set of structures that we've collectively decided are most valuable *in any given moment,* and, therefore, its boundaries and definitions are expected to change over time.\n\nLike a bridge that needs to support more traffic that it was built for, every social platform is scramlbing to upgrade its infrastructure to accommodate the volume of social interactions we're dealing with today. Platforms need to build skyscrapers where there were once villages.\n\n### Identity\nLike joining a club, it's not about how many times you've attending meetings but how you self-identify, and how others identify you, that makes you a 'member'. Some attendees might come every week for years and still not be considered part of the group.\n\n### Code as Content\nCode, like any other type of content available online today, is **trending toward modularity**: a mille-feuille layer cake of little libraries instead of one big, jiggling, Jell-O mold.\n\n\"Like a book or video, code is just a bunch of information, packaged up for distribution. But its role as a [[thoughts/utility|utility]] is more explicit.\"\n\nToday, \"content\" is better understood not as a thing we set out to make -- as an automaker might exist solely to produce cars -- but as \"an externality from [our] existing social systems.\" Content is a snapshot of our civilization.\n\n### Platforms and Governance\nA \"Benevolent Dictator for Life\" or BDFL for short, describes authors of open source projects who retain control even as the project grows. A great example of this is Linus Torvalds, who even after 14,000 unique contributors to the Linux kernel, still is the only person allowed to merge contributions into the main branch.\n\n\"Like a talent agency, platforms add value to creators by first improving their *distribution*, exposing them to potentially millions of people. ... This [feedback loop](thoughts/feedback%20loops.md) is [positive sum](thoughts/positive%20sum.md), encouraging more creators to join. So long as more people keep using the platform, there's no sense that any one creator will ever suck up all the oxygen in the room.\"\n\n###  Commons-based Peer Production\nThe economist Elinor Ostrom identified 8 design principles that contribute to a well-managed, succesful commons:\n1. Membership boundaries are clearly defined\n2. The rules that govern the commons should match the actual conditions\n3. Those who are affected by these rules can participate in modifying them\n4. Those who monitor the rules are either community members or are accountable to the community, rather than outsiders\n5. Those who violate the rules are subject to *graduated sanctions*, which vary depending on the seriousness and context of the offense\n6. Conflicts should be resolved within the community, using low-cost methods\n7. External authorities recognize the right of community members to devise their own institutions\n8. If the commons is part of a larger system, its governing rules are organized into multiple 'nested' layers of authority\n\n\"At a company, only employees can do the work, limited by their job function. But in a commons, anyone can stumble upon an advertised task and volunteer themselves. By removing 'property and contract', the commons will theoretically select for the best person for the job at a lower cost.\"\n\nMain types of goods\n\n| |Excludable|Non-excludable|\n|---|---|---|\n|Rivalrous|Private Goods (e.g. cars, domain names)|Commons (e.g. forests, online privacy)|\n|Non-rivalrous|Club Goods (e.g. cable, subscriptions like Netflix or Spotify)|Public Goods (e.g. air, open source code)|\n\nNon-rivalry: If I download code from GitHub, my decision doesn't diminish your ability to download that same code. (By contrast, if I bite into an apple and hand it to you, there is now less apple for you to eat) -- a key point here is that open source software isn't necessarily non-rivalrous especially when it comes to marginal increase in maintenance for each additional user\nNon-excludability: If someone owns my copy of my code, it is difficult for me to prevent them from sharing it with others. (By contrast, if I build a theme park, I can prevent people from entering by putting up a turnstile or charging admission)\n\nThe implication is that support can be handled in a fully decentralized manner that will distribute its costs among users -- but someone still needs to review, manage, and process these reports. This maintenance cost is referred to as the \"servicing costs\" of software, noting the \"asymmetry between the low cost of community participation and the high cost that others' participation places on the leaders of the community.\" She compares the problem to traffic congestion, where each person wants to drive their own car, but in doing so increases the congestion experienced by others, and, eventually, themself.\n\n### [Incentive](thoughts/incentives.md) Structures\n\u003e \"Creation is an intrinsic motivator, maintenance usually requires extrinsic motivation\" -- @balupton\n\nIf production runs on intrinsic motivation, money is an *extrinsic motivator* that is thought to interfere with an already well-coordinated system. Although the commons might not be as *profitable* as the firm, it's also more resilient, because the currency of its transactions is the desire to participate, rather than money.\n\n\u003e External, expected rewards diminish the intrinsic motivation of the fundraising open-source contributor. It risks transporting a community of peers into a transactional terminal. And that buyer-seller frame detracts from the magic that is peer-collaborators.\n\n\"Whereas active contributors show interest in adding value to others early on, casual contributors demonstrate an acute, personal need at the outset.\"\n\nThere are two types of funders that care enough to spend money on open source:\n1. Institutions: usually companies, but also governments and universities. They spend money to influence and access a project they care about -- especially gaining priority for issues and pull requests that concern them. They can also pay to gain brand influence through the open source project\n2. Individuals: usually developers who are direct users. Politicians who fund their campaigns from grassroots donations are generally viewed more favorably by the public than are those who are funded by corporate donations. I'm not sure that open source is so different.\n\n### Projects and Production Models\nSimilar to governance models in [governance](thoughts/governance.md)\n\n\"While some open source developers write code in public from the very beginning, many prefer to do their initial creative work in private, so they can properly articulate their ideas before opening the project up for feedback. Even if developers do publish their code early on, they may not advertise it widely until they have something ready for release.\"\n\nBased off of arelationship between contributors and users, we can think of projects in terms of their contributor growth and user growth.\n\n||High user growth|Low User Growth|\n|---|---|---|\n|High contributor growth| Federations (e.g. Rust) | Clubs (e.g. Astropy) |\n|Low contributor growth| Stadiums (e.g. Babel) | Toys (e.g. ssh-chat) |\n\n- Federations: 'bazaars', the epitome of open source projects. Small percentage of overall # of projects. Complex to manage (typically develop [decentralized](thoughts/decentralization.md) governance structures)\n- Clubs: roughly overlapping group of contributors and users. May not have huge reach, but loved and built by a group of enthusiasts.\n- Stadiums: powered by a few main contributors, generally widely-depended upon packages. Centralized structure.\n- Toys: effectively personal projects\n\nJonathan Zdziarski (aka @NerveGas) on user demands: \"There is definitely a place for users and. their demands, however that's not inside the community (unless they're also contributing devs); the community, as in practicing any art form, is vulnerable; you wouldn't sit and criticize a painter while they're still painting their piece. The user base needs to be moved outside of the artistic realm and into the museum, where you software is on display.\"","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Mangrove-Theory-of-the-Internet":{"title":"Mangrove Theory of the Internet","content":"\n## Tools for Communication\n[Source: vgr on Twitter](https://twitter.com/vgr/status/1460338562231013376)\n\nRelated: tools for [digital commons](thoughts/digital%20commons.md)\n\nStream interfaces like Discord and Slack basically create a single global timeline that moves at a certain rate. If you miss a certain conversation, it flows away.\n\nSomeone once described Slack as the online version of the open office arrangement -- it puts the pressure of everything being visible all the time to everybody on the individual.\n\nWe do \"gardening\" in our tools for thought but it's not exactly social first. Sure, we can leave messages for each other but this is not communication. It's more like background cueing/prompting.\n\nHow can we create mangroves? Garden/forest type ecosystems which have gently flowing multi-branched stream systems, designed for [digital mindfulness](thoughts/digital%20mindfulness.md) and non-linearity?\n\nCan we create different [pace layers](thoughts/pace%20layers.md) for interaction?\n\nRelated: [ephemereal content](thoughts/ephemereal%20content.md)","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Materialism":{"title":"Materialism/Physicalism","content":"\n[Materialism](thoughts/mind%20body%20problem.md)/physicalism is the view that the universe is made up of particles and behaviour (esp. consciousness) arises out of it. There is nothing special distinguishing mind from matter.\n\n\u003e To be conscious is to have subjective human experience, to have *[qualia](thoughts/qualia.md)*.\n\nNo one person experiences red, the smell of garlic, or the warmth of the sun in the same way.\n\nYet, it feels like consciousness is in intrinsic property. We don't know if someone or something is consciousness unless we ask them. However, the inability to _report_ a subjective experience is not the same thing as _not having one_. ([locked-in syndrome](https://en.wikipedia.org/wiki/Locked-in_syndrome)). For all we know, that rock could be conscious.\n\nAs an extended thought experiment, how similar do minds have to be to human ones to be considered conscious? \n\n## On why physicalism is a poor theory[^1]\n- \"Physical\" is not well-defined\n\t- Attempts to define it make physicalism either false, empty, or non-naturalist (which is contrary to the original motivation for the thesis)\n- Hempel's Dilemma\n\t- If we define “physical” as what contemporary physics tells us is the physical, then physicalism is likely to be false\n\t- If we define “physical” by what the ideal, completed physics tells us is the physical, then physicalism is empty (because don’t know what that physics will be)\n\n[^1]: This content is sourced from Professor [Evan Thompson](https://evanthompson.me/)'s course materials for PHIL451A at UBC. All rights to this content is retained by Evan Thompson.","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Matrix":{"title":"Matrix","content":"\n\u003e An open network for secure, decentralized communication\n\n[Website](https://matrix.org/)\n\nMainly for messaging + voice + video but theoretically can handle any type of *real-time* data.\n\nA decentralized conversation store; when you send a message in Matrix, it is replicated over all the servers whose users are participating in a given conversation. (helps to tackle data availability)\n\nModel of event log delivery and consensus feels very similar to [[thoughts/Raft Consensus Algorithm|Raft]]\n\nUses HTTPS + JSON by default but also supports other transports like WebSockets or Matrix via CoAP + Noise\n\n[SDK seems well-maintained](https://github.com/matrix-org/matrix-js-sdk)","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Matthew-Effect":{"title":"Matthew Effect","content":"\nThe Matthew effect of accumulated advantage, Matthew principle, or Matthew effect for short, is sometimes summarized by the adage \"the rich get richer and the poor get poorer\"\n\n\n","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Merkle-DAG":{"title":"Merkle-DAG","content":"\nA directed acyclic graph where nodes correspond to versions of the content and arcs correspond to changes (diffs).\n\nEach node has an identifier which is the result of hashing the node's content.\n\nMerkle DAG nodes are _immutable_. Any change in a node would alter its identifier and thus affect all the ascendants in the DAG, essentially creating a different DAG\n\nExamples of DAGs include:\n- [[thoughts/git|git]]\n- [[thoughts/IPFS|IPFS]]\n- [[posts/docker|Docker]] images","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Mindstorms":{"title":"Mindstorms","content":"\nLots of really good [constructionist](thoughts/constructionist.md) theory here :))\n\n## Quotes\n\n### Composition\nWhen knowledge can be broken up into \"mind-size bites,\" it is more communicable, more assimilable, more simply constructable.\n\n\"New commands, once defined, can be used to define others.\"\n\n### Computing as a medium/language\n\"Seymour saw the computer not just as a problem-solving tool but as an expressive medium. He believed that learning to program was analogous to learning to write, providing children with new ways of organizing and expressing their ideas.\"\n\nDoes language matter when programming?\n\"A programming language is like a natural, human language in that it favors certain metaphors, images, and ways of thinking. The language used strongly colors the computer culture\" ([linguistic relativism](thoughts/linguistic%20relativism.md))\n\n### Microworlds and simplification\nNewton \"understood\" the universe by reducing whole planets to points that move according to a fixed set of laws of motion. Is this grasping the essence of the real world or hiding its complexities?\n\nrestricted microworlds give students the freedom to explore, without needing to ask for permission or reassurance from teachers\n\nIn school, false theories are no longer tolerated. Our educational system rejects the \"false theories\" of children, thereby rejecting the way children really learn.\n\nDanger of 'simplicity': [Design Justice](thoughts/Design%20Justice.md)\n\"Imagine a suggestion that we invent a special language to help children learn to speak. This language would have a small vocabulary of just fifty words, but fifty words so well chosen that all ideas could be expressed using them. Would this language be easier to learn? Perhaps the vocabulary might be easy to learn, but the use of the vocabulary to express what one wanted to say would be so contorted that only the most motivated and brilliant children would learn to say more than 'hi'.\"\n\n### On mechanical thinking\nDiscovery cannot be a setup; invention cannot be scheduled\n\nPeople often fear that using computer models for people will lead to mechanical or linear thinking: They worry about people losing respect for their intuitions, sense of values, powers of judgement. They worry about instrumental reason becoming a model for good thinking. I take these fears seriously but do not see them as fears about computers themselves but rather as fears about hwo culture will assimilate the computer presence.\n\nRelevant to [AI systems](/posts/ai-systems)\nThe definition of artificial intelligence can be narrow or broad. In the narrow sense, AI is concerned with extending the capacity of machines to perform functions that would be considered intelligent if performed by people. Its goal is to construct machines, and, in doing so, it can be thought of as a branch of advanced engineering... In order to make a machine capable of learning, we have to probe deeply into the nature of learning. And from this kind of research comes the broader definition of artificial intelligence: that of cognitive science.\n\n\"The question to ask about the program is not whether it is right of wrong, but if it is fixable. If this way of looking at intellectual products were generalized to how the larger culture thinks about knowledge and its acquisition, we all might be less intimidated by our fears of 'being wrong.'\"\n\n### [Multiple realization](thoughts/multiple%20realization.md)\nMen have always been interested in flying. Once upon a time, scientists determined to understand how birds fly. First they watched them, hoping to correlate the motion of a bird's wings with its upward movement. Then they proceeded to experiment and found that when its feathers were plucked, a bird could no longer fly. Having thus determined that feathers were the organ of flight, the scientists then focused their efforts on microscopic and ultramicroscopic investigation of feathers in order to discover the nature of their flight-giving power.\n\n\"You have no reason to suppose that airplanes and birds work the same way -- birds have no propellors, airplanes have no feathers\"\n\n\"If we had to base our opinions on observation of how poorly children learned French in American schools, we would have to conclude that most people were incapable of mastering it. But we know that all normal children would learn it easily if they lived in France.\"\n\nIn retrospect, we know that the road that led from nineteenth-century transportation was quite different. The invention of the automobile and the airplane did not come from a detailed study of how their predecessors, such as horse-drawn carriages, worked or did not work.\n\n### Logical consistency in systems\nThe conflicts are regulated and kept in check rather than \"resolved\" through the intervention of special agents no less simple-minded than the original ones. Their way of reconciling differences does not involve forcing the system into a logically consistent mold.\n\nOn brain being compartmentalized\nWe put our skills and heuristic strategies into a kind of tool box -- and while their interaction can, in the course of time, give rise to global changes, the act of learning is itself a *local* event.\n\n### Knowledge distillation\nOn the role of [knowledge distillers](thoughts/knowledge%20distillation.md) and [teaching](thoughts/teaching.md): \nThis problem goes deeper than a mere short supply of such people. The fact that in the past there was no role for such people has been cast into social and institutional concrete; now there is a role but there is no place for them.\n\nIt is a step toward a situation in which the line between learners and teachers can fade\n\nA stage of unconscious work, which might appear to the mathematician as temporarily abandoning the task or leaving the problem to incubate, has to intervene... On the contrary, the problem has been turned over to a very active unconscious which relentlessly begins to combine the elements supplied to it by the \n\n### Misc\nOn self-correcting systems like bikes\n\"Thus learning to ride does not mean learning to balance, it means learning not to unbalance, learning not to interfere\"\n\nPart of the fun is sharing, posting graphics on the walls, modifying and experimenting with each other's work, and bringing the \"new\" products back to the original inventors.\n\nOn rejecting the false dichotomy of verbalizable versus nonverbalizable knowledge\n\"No knowledge is entirely reducible to words, and no knowledge is entirely ineffable\"\n\n\"As knowing how to use a computer becomes increasingly necessary to effective social and economic participation, the position of the underprivileged could worsen, and the computer could exacerbate existing class distinctions.\"\n\nOn the split between 'humanities' and 'science'\n\"It is self-perpetuating: The more the culture is divided, the more each side builds separation into its new growth\"\n\nThe printed page cannot capture either the product or the process: the serendipitous discoveries, the bugs, and the mathematical insights all require movement to be appreciated.","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Moderation":{"title":"Moderation","content":"\nWhat is the role of moderation in [communities](thoughts/communities.md)? What does good/bad moderation look like? (posts/comments/membership)\n\nI think a key part of answering this is trying to define what role a community occupies. Is it just a collection of people gathering around a shared identity? Or is it supposed to be a platform for moderated idea discussion/generation? Or something else in between.\n\nThinking about this at the [infrastructure](/thoughts/infrastructure) level too, if a community's purpose is to serve as infrastructure so that it enables conversations, should infrastructure be regulated/enforced or something that should just play out naturally?\n\nBroadly defined, I see moderation as having two main categories: moderation of users and moderation of content. Moderation then, is to ensure that the set of values that is being conveyed by the users/content roughly aligns with that of the group/community.\n\nModeration of users involves regulating the *membership* of individuals within the community whereas moderation of content regulates what can/can't be said in the community.\n\nModeration gets problematic when it is used to target and discriminate against individuals because of personal relations or vendettas. I was thinking about also saying it becomes problematic when it discriminates against characteristics but I'm hesitant on this bit. Is it categorically different to exclude people who are misogynistic vs those of a certain race? Probably yes but I don't have a solid argument for it yet.\n\n## Protocols for Moderation\nFrom *[Protocols Not Platforms](https://knightcolumbia.org/content/protocols-not-platforms-a-technological-approach-to-free-speech)*\n\nSee also: [[thoughts/Protocol|protocols]]\n\nThe key to making this work is that while there would be specific protocols for the various types of platforms we see today, there would then be many competing interface implementations of that protocol.\n\nMuch like email, you don’t need to build an entirely new Facebook if you already have access to everyone making use of the “social network protocol” and just provide a different, or better, interface to it.\n\nThe problem is leaving it up to platforms to decide what 'abusive' behaviour looks like.\n\n\u003e Nearly everyone recognizes that there is such behavior online and that it can be destructive, but there is no agreement on what it actually includes.\n\nUnder such a system, both Type I (“false positive”) and Type II (“false negative”) errors are not only common; they are inevitable. Content that a large body of people believe should be taken down is left up, while content that many people believe should remain up is taken down.\n\n**Rather than relying on a single centralized platform, with all of the internal biases and incentives that that entails, anyone would be able to create their own set of rules—including which content do they not want to see and which content would they like to see promoted.** \n\nIn such a world, we can let a million content moderation systems approach the same general corpus of content—each taking an entirely different approach—and see which ones work best. [[thoughts/r-K Selection theory|r-selected]] moderation.","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Moving-Castles":{"title":"Moving Castles","content":"\n[Source: Moving Castles: Modular and Portable Multiplayer Miniverses by *ARB and GVN908*](https://so-far.online/weekly/moving-castles-modular-and-portable-multiplayer-miniverses/)\n\n\u003e “With a last squeak the castle lifted, the crew cheered as we could see across the dark forest for the first time, our eyes locked on the arid wastelands on the horizon. Now back to chat, this machine won’t move itself.”\n\nCozyweb is non-indexable because of a lacking interconnection between material, creating unintentionally disconnected islands populated by isolated communities.\n\nIn our vision of this new media format, Moving Castles are modular and portable multiplayer miniverses; inhabited by communities that use them to manage their lore, ecosystems and economies. They are collective machines controlled by governance mechanisms and allow low-barrier participation.\n\nMoving Castles should reflect the following principles (adapted from the [design goals](thoughts/design%20goals.md) described in [Modular Politics](https://arxiv.org/abs/2005.13701))\n1. Collective: many contributors share control through transparent and real-time governance mechanisms. (see: [Metalabel](thoughts/metalabel.md))\n2. Portable: the ability to move freely between platforms, standards and protocols, from private to public, without losing any value, knowledge, or lore in the process.\n3. Modular: ability to construct Moving Castles by creating, importing, and arranging composable parts together as a coherent whole while making these parts available for others to reuse and adapt.\n4. [Interoperable](thoughts/interoperability.md): ability to interact with other communities; communicating, playing [games](thoughts/games.md), and sharing knowledge \u0026 skills in order to help these communities become Moving Castles themselves.\n\n## The Story of All Powerful Wizards\n[Source: A story of all powerful wizards - 20th of Nov 2021 @ 0xPARC Boston by *Justin Glibert*](https://www.youtube.com/watch?v=aFKy6QsbBz4)\n\nEarly internet: individual gardens linked by hyperlinks, tended to by all-powerful wizards who could build any worlds they wanted. Very libertarian\n\nProposing: a bazaar, no [[thoughts/access control|access control]] and everybody plays by the same rules. Where each visitor has the power to change the world around them, as long as they respect the physics of the world.\n\nYou could visit these other gardens that wizards built but in doing so, you lose all of your wizardly powers in their domain.\n\nAre there any ways we can remove the distinction between all-powerful hosts and powerless guests?\n- With the power of a host, it only takes one bad actor to destroy an entire garden\n\nSystems of magic\n- Specificity is good\n- Rules should be able to be composed\n- Should not be *too powerful*\n\nProgramming is magic, and it's too powerful. There is no OS for the [Internet](thoughts/Internet.md) telling you what you can and cannot do (only limitation is not running out of memory and time).\n\nWhat is interesting with systems is not what you *can* do, but what you *cannot* do.\n\nWhat if programming was closer to mechanical engineering and physics?\n- Energy conversation\n- Symmetries\n- Spatial computation\n- [[thoughts/causality|Causality]], speed of light, etc.\n\nThe dream is to be wizards in the same world together. We want to be able to protect things like person A wiping all of person B's work out of existence with the snap of their finger","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Mutual-Aid":{"title":"Mutual Aid","content":"\nThe puzzle: A Darwinian explanation can only account for behaviour that promotes the survival and reproductive success of the individual organism. How do we account for altruism and cooperation given this constraint?\n\nOne explanation is gene selection. The unit of selection is the gene rather than the individual. That is, altruism and cooperation promote the survival of your genes.","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/NAT":{"title":"NAT","content":"\n## Network Address Translation\nBoth network and [transport layer](thoughts/Transport%20Layer.md) (violation of abstraction/layering)\n\n1. More devices than [IP addresses](thoughts/IP%20Addresses.md)! What do we do?\n2. Home router gets assigned an IP (public IP) by the ISP\n3. Devices connected on the local network are assigned a private IP address (usually starts with subnet mask 196.168.x.x or 10.x.x.x)\n4. Changes the private IP address to the public address of the router\n\t1. Changes source port to some available port\n5. Adds the mapping to the NAT forwarding table\n\t1. Entries correspond to private side (192.168.1.3:42301) to public side (12.13.14.15:24604)\n\t2. Includes\n\t\t1. Source IP\n\t\t2. Source Port\n\t\t3. Destination IP\n\t\t4. Destination Port\n\t\t5. [Protocol](thoughts/Protocol.md)\n\t\t6. NAT IP (Router public IP address)\n\t\t7. NAT Port (Unique)\n\t3. Actually, Port Forwarding just adds entries to the NAT forwarding table! You can set remote IP and remote port to wildcard entries (i.e. any web requests made to this port go to the specified machine)\n\t\t1. Max number of rows is 65535\n\t\t2. Any requests that come in then *clone* the wildcard rule and make it specific to that conversation (to avoid collisions to the NAT port)\n\t\t3. Entries are removed when a conversation is coming to a close (stream based protocol, detect termination packets)\n6. Does the inverse when it receives a packet\n\n![](thoughts/images/NAT.jpeg)\n\n## Hole-punching and NAT Traversal\n\u003e Hole punching (or sometimes punch-through) is a technique in computer networking for establishing a direct connection between two parties in which one or both are behind firewalls or behind routers that use network address translation (NAT).\n\nGenerally done using [[thoughts/UDP]]. You _can_ do NAT traversal with TCP, but it adds another layer of complexity\n\nMostly used in [decentralized](thoughts/decentralization.md) or [peer-to-peer](thoughts/peer-to-peer.md) communication as the latency incurred by relaying through a central server is prohibitively expensive for real-time activity like voice calling, file syncing, etc.\n\nHole-punching usually involves the use of third-party hosts that run STUN or ICE to figure out the public address of the NAT. \n\nThe idea is that to allow packets to come in from a remote endpoint, the computer behind the NAT or firewall needs to send something to the remote endpoint first. By doing so it creates a “hole” in the NAT or firewall through which communications can proceed. This even works when both sides are behind a NAT/firewall, when both sides start by punching a hole in their respective NAT/firewalls.\n\nTypes of NAT/Firewall combinations\n1. Endpoint-Independent Mapping (EIM): all outgoing connections from the same IP address and port have the same modified IP address and port\n2. Address-Dependent Mapping (ADM): each outgoing connection to a different address from the same IP address and port has a different modified IP address and port\n3. Address and Port-Dependent Mapping (APDM): same as ADM, instead of just address, it's address + port\n4. Endpoint-Independent Filtering (EIF): all packets from remote addresses are allowed for a single endpoint on the NAT/Firewall\n5. Address-Dependent Filtering (ADF): only allows packets to a specific endpoint from a specific address if a computer behind the NAT/Firewall has sent a packet to that address\n6. Address and Port-Dependent Filtering (APDF): same as ADF but instead of just address, it's address + port\n\n### Efficacy\nFrom [*UDP NAT and Firewall Puncturing in the Wild* by Gertjan Halkes and Johan Pouwelse](https://link.springer.com/content/pdf/10.1007/978-3-642-20798-3_1.pdf)\n\n- Over 79% of peers on the Internet are not directly connectable\n\t- Using a simple redez-vouz mechanism decreases this to ~15% of peers\n\t- Keep-alive messages should be sent at least every 55 seconds to ensure that mappings/holes will remain open on almost every NAT/firewall\n- Firewalls and NAT makes establishing P2P connections directly between any two machines hard\n\t- Firewalls are frequently configured to allow only outgoing connections, based on the assumption of the client-server model of communication\n\t- NAT hides the 'true' port and IP combination of any machine that is behind it, meaning that connecting to an arbitrary port is often not allowed\n- Mostly useful for UDP traffic as setting up a connecting for TCP when NAT/firewall requires unusual or non-standard use of TCP and IP mechanisms, and may rely on specific NAT/firewall behaviour to work \n- Detection\n\t- NAT\n\t\t- A and B report the remote address and port they see when a connection is set up. They now know their own external address and port\n\t\t- If all other peers agree on peer A's remote address and port, peer A determines they have no NAT or the NAT has EIM behaviour\n\t\t- If peer A's remote address and port are reported differ among peers, peer A determines they are behind a A(P)DM NAT\n\t- Filtering Behaviour\n\t\t- Check order of requests received when connecting to a rendez-vous server\n\t\t\t- Side note: this many not always be true. The reason for this is that the direct connection request is not always faster than the reverse connection request which is sent through the rendez-vous peer. This is known as a Triangle Inequality Violation (TIV)\n\t\t\t- This can happen as often as 40% of the time although lower numbers are more common\n\t\t- When a peer A tries to set up a connection using rendezvous R, it will always first send a direct connection request to the remote peer B\n\t\t\t- If the direct connection request from A to B arrives first, there is no filtering behaviour or it uses EIF\n\t\t\t- If the rendez-vouz connection request from R to B arrives first, the filtering behaviour is most likely A(P)DF\n\n![[thoughts/images/NAT-firewall-share.png]]\n\n![[thoughts/images/NAT-firewall-connection-rates.png]]\n\nPossible explanations for a non-100% connection rate even in EIM-EIF to EIM-EIF peers\n- UDP packets being dropped under high UDP packet load (especially in consumer-grade NAT/firewalls)\n- Routers stop functioning when mapping tables are full (not out of the realm of possibilies, only 65535 entries)\n- Use of [CGNAT](https://en.wikipedia.org/wiki/Carrier-grade_NAT) (NAT at the ISP level instead of home-router)\n\n### Terminology Translation Table\n[NAT Cone Types](https://tailscale.com/blog/how-nat-traversal-works/)\n\n| |Endpoint-Independent NAT Mapping (EIM)|Endpoint-Dependent NAT Mapping (ADM/EDM)|\n|-|-|-|\n|Endpoint-Independent Firewall (EIF)|Full cone NAT|n/a|\n|Endpoint IP-Dependent Firewall (ADF)|Restricted Cone NAT|n/a|\n|Endpoint IP and Port-Dependent Firewall (APDF)|Port-restricted Cone NAT|Symmetric NAT|\n\n### Flow\nLet $A$ and $B$ be the two hosts, each in its own private network; $N_A$ and $N_B$ are the two NAT devices with globally reachable IP addresses $EIP_A$ and $EIP_B$ respectively. $S$ is a public server with a well-known, globally reachable IP address.\n1. A and B both begin a [UDP](thoughts/UDP.md) conversation with $S$\n2. NAT devices $N_A$ and $N_B$ create UDP translations and assign temporary external ports $EP_A$ and $EP_B$\n3. S looks at UDP packets to get source ports of $N_A$ and $N_B$ (through $EP_A$ and $EP_B$)\n4. S makes pairs of external IP addresses assigned by the NAT along with temporary external ports and exchanges them between $A$ and $B$ (S passes $EIP_A:EP_A$ to $B$ and $EIP_B:EP_B$ to $A$)\n5. $A$ and $B$ send packets to each other and their appropriate NAT devices create the entries in their lookup tables\n\t1. $A$ sends a packet to $EIP_B:EP_B$.\n\t2. $N_A$ examines $A$'s outgoing packet and adds (Source-IP-$A$, $EP_A$, $EIP_B$, $EP_B$) to its translation table.\n\t3. $B$ sends a packet to $EIP_A:EP_A$.\n\t2. $N_B$ examines $B$'s outgoing packet and adds (Source-IP-$B$, $EP_B$, $EIP_A$, $EP_A$) to its translation table.\n6. Best case scenario $N_A$ and $N_B$ should have made the entry in the translation. Worst case, both NAT devices have not yet made the entry and drop the first packet sent from $B$\n7. At worst, the second packet from both $A$ and $B$ make it to each other. Holes have been \"punched\" in the NAT and both hosts can directly communicate through $N_A$ and $N_B$ without needing $S$\n\n## Strategies for Robust NAT Traversal\nFrom [Tailscale](https://tailscale.com/blog/how-nat-traversal-works/)\n\n- A UDP-based protocol to augment\n- Direct access to a socket in your program\n- A communication side channel with your peers\n- A couple of STUN servers\n- A network of fallback relays (optional, but highly recommended)\n\nThen, you need to:\n- Enumerate all the `ip:ports` for your socket on your directly connected interfaces\n- Query STUN servers to discover WAN `ip:ports` and the “difficulty” of your NAT, if any\n- Try using the port mapping protocols to find more WAN `ip:ports`\n- Check for NAT64 and discover a WAN `ip:port` through that as well, if applicable\n- Exchange all those `ip:ports` with your peer through your side channel, along with some cryptographic keys to secure everything.\n- Begin communicating with your peer through fallback relays (optional, for quick connection establishment)\n- Probe all of your peer’s `ip:ports` for connectivity and if necessary/desired, also execute birthday attacks to get through harder NATs\n- As you discover connectivity paths that are better than the one you’re currently using, transparently upgrade away from the previous paths.\n- If the active path stops working, downgrade as needed to maintain connectivity.\n- Make sure everything is encrypted and authenticated end-to-end.\n\n### Peer Discovery in a purely distributed manner\n1.  Peer A sends an introduction-request to peer B. Peer B is chosen from an existing pool of neighboring peers.\n2.  Peer B sends an introduction-response to peer A containing the address of peer C.\n3.  Peer B sends a puncture-request to peer C containing the address of peer A.\n4.  Peer C sends a puncture to peer A, puncturing its NAT.\n\nWhen a peer doesn’t yet have a list of neighboring peers, it will select a bootstrap server for peer B. Bootstrap servers have the same peer discovery protocol as regular peers except they respond to introduction-requests for anyone.\n\n### STUN (Session Traversal Utilities for NAT)\nServers like $S$ usually run STUN. Recognized using a `stun` or `stuns` resource record.\n\nDetails how a server can determine what kind of NAT and firewall is between itself and the public Internet.\n\n### ICE (Interactive Connectivity Establishment)\nUses STUN. Provides a structured mechanism to determine the optimal communication path between two peers\n\n### TURN (Traversal Using Relays around NAT)\nTURN places a third-party server to relay messages between two clients when direct media traffic between peers is not allowed by a firewall.","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/NFT":{"title":"NFTs","content":"\n[Source: vgr on Magic Beans](https://studio.ribbonfarm.com/p/magic-beans)\n\nAn NFT need not to contain something. All it guarantees is that it has an \"identity and can be traded, transferred, mixed and matched indiscriminately with other things in a social context.\" See the [Degraded Blockchain problem](thoughts/Degraded%20Blockchain%20problem.md).\n\n## 3 (progressively more ambitious) ways to think about NFTs\n\n1.  Signifier-value mental models: right to represent things\n2.  Agency-value mental models: right to do things\n3.  Right-to-future-rights mental models: right to expect things\n\nI specifically like the last version of these: the right to expect things. \"An NFT represents an access pass to an unspecified, generative possible future associated with an object. It is a key to a possible world.\"\n\n## Ownership\nRight-clicking is not a problem for the NFT world because securing exclusive possession rights is not the problem NFTs aim to solve.\n\n\u003e Do you _really_ think 9/10ths of the value associated with the Mona Lisa accrues to the Louvre? I can put a photograph of it in an article, write a book discussing it, even make a movie about it, without paying the Louvre anything. The Louvre has the right to hold the original physically, but every other meaningful right is in the public domain. Not only are these other rights collectively far more valuable, _physical possession only has value by way of derivation from these other rights_.\n\n## [Digital Permanence](thoughts/digital%20permanence.md)\n\"Our web experiences to date have [for the majority of users] been like running errands out from points of departure/return within the physical world. Of going out to the web to - browse the news, buy something, trade a stock, whatever - but then coming back to the physical world. Our trips are short, and we travel lightly - by necessity - for we have no real way to \"bring\" anything with us from site to site besides our wallets.\n\nThe NFT, at least as a concept, represents something of a sea change in that mentality. That the web will not be errand space forever, but a place that we come to \"inhabit\" to a deeper degree than we do now (and maybe which most people would even think they'd ever want to).\"","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/NLP":{"title":"NLP","content":"\n## Chain of Thought Prompting\n[ArXiv Link](https://arxiv.org/pdf/2201.11903.pdf)\n\n- Flat scaling curves—simply increasing model scale does not lead to substantive performance gains\n- Chain of thought prompting facilitating multistep reasoning in large language models\n\t- The intuition is that a chain of thought allows language models to decompose a multi-step problem into intermediate steps that are solved individually, instead of solving an entire multi-hop problem in a single forward pass\n\t- Another intuition behind chain of thought reasoning is that it allows the model to spend more computation (i.e., intermediate tokens) solving harder problems (though later sections of the paper rule this out as the primary factor for performance improvements)\n\t- Notably, chain of thought prompting only does better than standard prompting only at the scale of ~100B params\n- Really cool side-effect is more [[thoughts/explainability|explainable]] decision making processes\n\t- Fully characterizing a model's computations that support an answer remains an open question","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/NVIM-Cheatsheet":{"title":"NVIM Cheatsheet","content":"\n## Text-objects\n- adjectives\n\t- `i` - inner\n\t- `a` - whole thing\n- nouns\n\t- `l` - character\n\t- `w` - word\n\t- `t` - html tag\n\t- `{ or [ or \u003c or {`\n\t- `\" or '` - quoted string\n\t- `m` show possible LSP-based jump locations\n\t- `q` - parameter\n\n## Mappings\n- `\u003cCtrl\u003ec` - leave insert mode\n- `\u003cleader\u003eo` - open file by name\n- `\u003cleader\u003eg` - live grep\n- `\u003cleader\u003ef` - format file\n- `\u003cleader\u003eca` - code actions\n- `f` - hop by 2 chars\n- `\u003cctrl+/\u003e` - comment line or block\n- `[[` - jump to previous parameter\n- `]]` - jump to next parameter\n- Window Navigation\n\t- `:vsp` - vertical split\n\t- `:hsp` - horizontal split\n\t- `\u003cleader\u003e\u003cdirection\u003e` - move to window in that direction (one of `wasd`)\n- Tabs\n\t- `\u003calt-\u003c\u003e` - previous tab\n\t- `\u003calt-\u003e\u003e` - previous tab\n\t- `\u003calt-q\u003e` - close tab\n\t- `\u003calt-#\u003e` - go to tab `#`\n- Language server\n\t- `gD` - go to declaration\n\t- `gd` - go to definition\n\t- `gt` - go to type\n\t- `\u003cshift\u003eK` - show type hint\n\t- `\u003cspace\u003ern` - rename\n- Moving\n\t- `%` to jump to matching paren\n- Surrounds\n\t- `ys[text-object][char]` - surround with `char`\n\t- `ds[text-object][char]` - delete surrounding `char`\n\t- `cs[char1][char2]` - change surrounding `char1` to `char2`\n- Git conflicts\n\t- `\u003cleader\u003eco` - choose ours\n\t- `\u003cleader\u003ect` - choose theirs\n\t- `\u003cleader\u003ecb` - choose both\n\t- `\u003cleader\u003ec0` - choose none\n\t- `]x` - move to previous conflict\n\t-  `[x` - move to next conflict\n\t- `\u003cleader\u003em` - open diff view\n- Show Keybindings\n\t- `:Telescope keymaps`","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Nagels-Bat-Argument":{"title":"Nagel's Bat Argument","content":"\nNagel's Bat Argument (against Physicalism)\n1. Physicalism (read: [Materialism](thoughts/Materialism.md)) is the thesis that everything that exists is physical. \n2. Physical facts then, are objective truth (\"the kind that can be observed and understood from many points of view and by individuals with different perceptual systems\")\n3. Even if we knew everything about how the bat's sonar system works, we would not know what is is like for the bat to perceive using this system.\n\t1. 'What it's like': in this case, something is conscious (a bat) if and only if there is something it's like to be that being (only a bat knows what it is like for a bat to be a bat)\n\t2. One, for example, cannot imagine a chair to know what it is like for a chair to be a chair.\n\t3. For a state to be conscious is for it to have a subjective character (to seem or feel a certain way to the subject). A conscious experience is a state that is both subjective and qualitative.\n4. Therefore, complete knowledge of the physical facts about a bat's  perceptual system would not yield knowledge of certain facts about a  bat’s experiences\n\nPhysicalism leaves out the subjective facts, so it’s a mystery how it \ncould be true (give that [qualia](thoughts/qualia.md) and the subjective experience exists).\n\nRelated: Frank Jackson's [Knowledge Argument](thoughts/Knowledge%20Argument.md)\n\n## Fishes\nA famous Taoist story about happiness and knowing what it is like to be a fish\n\n- Zhuangzi and Huizi were strolling on a bridge over the River Hao, when the former observed, “See how the minnows dart between the rocks! Such is the happiness of fishes.”\n- “You not being a fish,” said Huizi, “how can you possibly know what makes fish happy?”\n- “And you not being I,” said Zhuangzi, “how can you know that I don’t know what makes fish happy?”\n- “If I, not being you, cannot know what you know,” replied Huizi, “does it not follow from that very fact that you, not being a fish, cannot know what makes fish happy?”\n- “Let us go back,” said Zhuangzi, “to your original question. You asked me how I knew what makes fish happy. The very fact you asked shows that you knew I knew—as I did know, from my own feelings on this bridge.”\n\nWhy did Zhuangzi, who wrote it down, show himself to be defeated by his logician friend?\n\n\u003e We can each understand what the other is feeling because, arguing about the fish, we are doing exactly what the fish are doing: having fun, doing something we do well for the sheer pleasure of doing it.\n\nHow can we know what it is like for others to [play](thoughts/play.md) if not that we are playing ourselves?\n\n","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Naive-Bayes":{"title":"Naive Bayes","content":"\nAn example of a [[thoughts/probability|probabilistic]] classifier. Commonly used in spam filters (classifies as spam if the probability of spam is higher than not spam)\n\nTo model this, it uses Bayes rule:\n\n$$P(y_i = \\textrm{spam} | x_i) = \\frac{P(x_i | y_i = \\textrm{spam})P(y_i = \\textrm{spam})}{P(x_i)}$$\n\nWhere\n- $P(y_i = \\textrm{spam})$ is the marginal probability that an e-mail is spam\n- $P(x_i)$ is the marginal probability than an e-mail has the set of words $x_i$\n\t- Hard to approximate (lots of ways to combine words)\n- $P(x_i | y_i = \\textrm{spam})$ is the conditional probability that a spam e-mail has the words $x_i$\n\n## Optimizations\n### Denominator doesn't matter\nWe can actually reframe this to avoid calculating $P(x_i)$ as Naive Bayes just returns spam if $P(y_i = \\textrm{spam} | x_i) \u003e P(y_i = \\textrm{not spam} | x_i)$\n\nRoughly, denominator doesn't matter\n\n$$\\propto P(x_i | y_i = \\textrm{spam})P(y_i = \\textrm{spam})$$\n\n### Conditional Independent Assumptions\nAdditionally, we assume that *all* features $x_i$ are conditionally independent given label $y_i$ so we can decompose it.\n\n$$\\approx \\prod_{j=1}^d P(x_{ij}|y_i)P(y_i)$$\n\n## Laplace Smoothing\nIf we have no spam messages with lactase, then $P(lactase | spam) = 0$ so spam messages with lactase automatically get through!\n\nOur estimate of $P(lactase | spam) = 0$ is $\\frac{\\textrm{\\# spam messages with lactase}}{\\textrm{\\# spam messages}} = \\frac{0}{\\textrm{\\# spam messages}}$\n\nWe can add $\\beta$ to the numerator and $\\beta k$ to the denominator, which effectively adds $\\beta k$ fake examples: $\\beta$ for each $k$ where $k$ is a possible class (2 for a binary classifier)\n\nSo for our binary spam classifier (with $\\beta = 1$):\n\n$$\\frac{\\textrm{\\# spam messages with lactase} + 1}{\\textrm{\\# spam messages} + 2}$$","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Nash-equilibrium":{"title":"Nash equilibrium","content":"\nIf no player can do better by unilaterally changing strategy, given the other players’ strategies. This is a criterion of individual rationality (see [[thoughts/Pareto optimality]] for group rationality)","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Network-Layer":{"title":"Network Layer (IP)","content":"\nLayer 3, the layer below the [Transport Layer](thoughts/Transport%20Layer.md) and layer above the [Link Layer](thoughts/Link%20Layer.md)\n1. Unit: Packet (datagram)\n2. Responsibilities: Routes packet through routers to destination machine (not necessary if two devices are on the same network)\n3. Two main functions\n\t1. Forwarding: move packets from router’s input to appropriate router output (process of getting through a single interchange)\n\t2. Routing: determine route taken by packets from source to destination (process of planning trip from source to destination)\n\n### Packet Definition\nContains information about the packet itself (metadata) and the body/content\n\n### BGP Advertisement\n1. [IP Addresses](thoughts/IP%20Addresses.md): the one they are advertising they can reach\n2. Gateway Next Hop: address of the entry point\n3. AS Path: Sequence of AS's a packet would need to travel through\n\n## Network Tiers\nThe structure of the internet is organized into entities called **autonomous systems (ASs)**.\n\nEach AS is\n-   assigned a range/collection of IP addresses\n-   responsible for routing to addresses it “owns”\n-   responsible for routing to addresses that are not its responsibility\n\n- Peering vs Transit\n\t- Transit: AS pays for the right to transit traffic across another AS\n\t- Peering: mutual exchange of traffic between networks\n\n- Tier 1 Networks\n\t- A network that can exchange traffic with other Tier 1 networks without paying any fees (transit-free) for the exchange of traffic in either direction\n- Tier 2 Networks\n\t- A network that peers for free with some networks, but still purchases IP transit or pays for peering to reach at least some portion of the [Internet](thoughts/Internet.md)\n- Tier 3 Networks\n\t- A network that solely purchases transit/peering from other networks to participate in the Internet. Everybody else\n\n## Routing\nBoth IGP and EGP run at the [[thoughts/Application Layer|application layer]]\n\n### Internal Gateway Protocols (IGP)\n- routing within a single AS, under the control of a single administrative entity\n-  Link State\n    -  each router tells every other router about all its links\n    -  this gives other routers complete info about the entire network\n    -  every so often, each router uses Dijkstra’s to find shortest path to all routers, then it updates its forwarding table\n    - OSPF (open-shortest-path-first)\n\t    -  most used IGP in the internet\n\t\t-   uses link-state protocol (each router has complete topological map of the entire AS)\n\t\t-   supports extensions such as areas (support hierarchy and scaling)\n-  Distance Vector\n    -  every so often, each router tells its neighbours about the cost of its best routes to the networks it knows about\n    -  a receiving router checks if any of the broadcasted routes would shorten their path to destination\n    -  if so, it updates its routing table to route through the first router\n\n### External Gateway Protocol (EGP)\n- routing between different AS, no control over the routing policies of other AS (External Gateway Protocols - EGP)\n- BGP\n\t-  the protocol that all ASs use for inter-AS routing\n\t-   packets are not routed to specific destination address, but to CIDRized prefixes, with each prefix representing a subnet or collection of subnets\n\t-   enables each router to\n\t    -   obtain prefix information from neighbouring ASs\n\t    -   determine “best” routes to the prefixes","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Network-Theory":{"title":"Network Theory","content":"\n\u003e Whenever nature seeks robustness, it resorts to networks.\n\nThe [[thoughts/Internet|internet]] played a huge role in developing network theory with over a trillion documents $N \\approx 10^{12}$\n\n## Power Laws and Scale-Free Networks\nFrom the [Network Science Book](http://networksciencebook.com/chapter/4#hubs)\n\n**A random network** is a network where the degrees of connections of the nodes follow a Poisson distribution.\n\n**A scale-free network** is a network where the degrees of connections of the nodes follows a power law (modelled by the Power Law $p_k \\sim k^{-\\gamma}$, this is also where the concept of the 80/20 rule comes from). For example, roughly 80% of the web point to only 15% of the web pages.\n\nMain difference is that power-law distributions (scale-free networks) have long tails (i.e. some nodes have lots of connections -- these are called hubs).\n\n- Largest hubs in scale-free networks have degree in the order of $k_{max} \\sim N^{\\frac 1 {\\gamma - 1}}$\n- Largest hubs in random networks have degree in the order of $k_{max} \\sim \\ln N$\n- Largest hubs in a complete graph have degree exactly $N - 1$\n\nOnce hubs are present, they change the way we navigate the network. In random networks, we usually need to make many hops. On scale-free networks, however, we can reach most destinations via a single hub. Scale-free networks mean that even as the sizes may differ widely between networks, navigation time across the networks is very slow to grow (ultra-small world network).\n\n\n![[thoughts/images/random vs scale-free.png|500]]\n\n![[thoughts/images/hub sizes in networks.png|500]]\n\nAn almost universal property of most real-world networks. For example:\n1.  Internet at the router level\n2.  Protein-protein interaction network\n3.  Email network\n4.  Citation network\n\nHowever, the scale free property is absent in systems that limit the number of links a node can have, effectively restricting the maximum size of the hubs.\n\n## Distances in Networks\nThe dependence of the average distance $\\langle d \\rangle$ on the system size $N$ and the degree exponent $\\gamma$ are captured by the formula\n\n$$\\langle d \\rangle = \\begin{cases}\n\tconst \u0026 \\gamma = 2 \\\\\n\t\\ln \\ln N \u0026 2 \u003c \\gamma \u003c 3 \\\\\n\t\\frac{\\ln N}{\\ln \\ln N} \u0026 \\gamma = 3 \\\\\n\t\\ln N \u0026 \\gamma \u003e 3\n\\end{cases}$$\n\n1. $\\gamma = 2$: Hub and spoke model. $k_{max} \\sim N$ so all nodes connect to a single central hub. The average path length is constant.\n2. $2 \u003c \\gamma \u003c 3$: Ultra-small world model. Hubs radically reduce the path length.\n3. $\\gamma = 3$: Critical point\n4. $\\gamma \u003e 3$: Small-world and random networks. Extremely unlikely to have large hubs, traversal time is on the order of $\\ln N$\n\n![[thoughts/images/distances in networks.png]]\n## Network Robustness\n### Percolation Theory\nHow many nodes do we have to delete to fragment a network into isolated components, assuming deletion is random?\n\nWe can model network breakdown as inverse percolation.\n\nThinking about this using the metaphor of forest fires helps to imagine what these variables mean. If we randomly ignite a tree, what fraction of the forest burns down? How long it takes the fire to burn out?\n\nAs a forest is roughly similar to a random network, the answer depends on the tree density, controlled by the parameter $p$. For small $p$ the forest consists of many small islands of trees ($p = 0.55$), hence igniting any tree will at most burn down one of these small islands. Consequently, the fire will die out quickly. For large $p$ most trees belong to a single large cluster, hence the fire rapidly sweeps through the dense forest ($p = 0.62$). But there also exists a critical $p_c$ at which it takes extremely long time for the fire to end.\n\nHowever, this breaks down once we consider scale-free networks. Scale-free networks observe unusual robustness to failure: we must remove all of its nodes to have likely destroyed its giant component.\n\n![[thoughts/images/robustness of scale-free networks.png]]\n\n### Under Attack\nThe removal of a small fraction of the hubs is sufficient to break a scale-free network into tiny clusters. See more on [[thoughts/cascading failures|cascading failures]] in networks\n\n![[thoughts/images/scale-free under attack.png]]*The probability that a node belongs to the largest connected component in a scale-free network under attack (purple) and under random failures (green).*\n\nKnocking out even a few hubs quickly breaks down the network. Y-axis is the ratio $\\frac{P_\\infty(f)}{P_\\infty(0)}$ provides the relative size of the largest connected subgraph","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Neural-Correlates-of-Consciousness-NCC":{"title":"Neural Correlates of Consciousness (NCC)","content":"\n\n- Experimentally, content-specific NCCs are identified by comparing conditions where specific conscious contents are present versus absent.\n\t- Similar to probing for network activation in [[thoughts/neural networks|neural networks]] / [AI systems](posts/ai-systems.md)\n- The full NCC is the union of all content-specific NCCs.\n- Even for ambiguous figures (those weird visual illusions that have differing things depending on how you perceive it), there is a rivalry for a dominant interpretation\n\t- When faced with ambiguous visual information, you don’t normally experience a combination of the different interpretations. Rather, you only see one at a time, often switching back and forth between the two.\n\t- Binocular rivalry\n\nDoes phenomenal awareness overflow access?\n- (when reading,) we are conscious only of the letters attended to and the impression that there are other items displayed whose identity we don’t know. Once the cue is presented, we gain access to the unconscious information before it decays and can recall the letters.\n- Great example of why foveated rendering works so well\n\n\u003e This content is sourced from Professor [Evan Thompson](https://evanthompson.me/)'s course materials for PHIL451A at UBC. All rights to this content is retained by Evan Thompson.\t","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Newcombs-Problem":{"title":"Newcomb's Problem","content":"\n|  |$1M in Box 2|$0 in Box 2|\n|--|--|--|\n|Take only box 2|$1M|$0|\n|Take both boxes|$1M + $1000|$1000|\n\n## Background\nThere is a predictor that is 99% accurate is predicting whether people will only take box 2 or both boxes\n\n## Procedure\n- Predictor makes their prediction\n- They put $1000 in box 1 (which you know)\n- They put $0 in box 2 if they think you will take both and $1M if they think you will only take box 2\n- Choose either both boxes or box 2\n\n## Arguments\n1. Two-box argument: dominance argument\n\t1. We can perhaps rule out the dominance argument because it only applies when states are independent of our actions (which is not the case here)\n2. One-box argument: taking only box 2 almost guarantees $1M. Calculate using expected utility\n\t1. EU(both) = 0.01(1M + 1k) + 0.99(1k) = 11k\n\t2. EU(box 2) = 0.99(1M) + 0.01(0) = 990k","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/No-Free-Lunch-Theorem":{"title":"No Free Lunch Theorem","content":"\n\u003e All optimization algorithms perform equally well when their performance is averaged across all possible problems.\n\nThere is no \"best\" machine learning model. This question is like asking which is “best” among “rock”, “paper”, and “scissors”.\n\n## Caveat\nThe proof of the no-free-lunch theorem assumes any map from $x_i$ to $y_i$ is equally likely.\n\nThis may not be true in the real world: some datasets are more likely than others.\n\nModel A really could be better than model B on every real dataset in practice. ","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Nozicks-Experience-Machine":{"title":"Nozick's Experience Machine","content":"\n## Experience machine\n-   suppose there was a machine that would give you any experience you desired\n-   would you plug in?\n\n1.  If \"how things seem to be\" is the only thing that matters to us, we have no reason to refuse this offer\n2.  we are hesitant to take up this offer (we have reasons to refuse it)\n\n\t1.  “We want to docertain things, and not just have the experience of doing them.” (43)\n\t2.  “... we want to be a certain way, to be a certain sort of person.” (43)\n\t3.  We want to leave ourselves open to contact with a deeper reality.\n\n\t-   what if we made machines to tackle all of this reasons? e.g. a transformation machine, result machine, etc.\n\t-   these machines are disturbing because they are living our lives for us\n3.  therefore, experiences aren't the only thing that matter to us\n\n## Pryor's analysis of The Matrix\n-   matrix implies that there's something bad about being inside the Matrix\n-   who is the matrix supposed to be bad for?\n-   machines are using the Matrix to keep humans docile to use them as a source of energy\n    -   a form of slavery\n    -   what if it was instead benevolent and philanthropic? would this change how we see the situation?\n-   \"if in every respect it seems to you that you're in the good situation, doesn't that make it true— at least, true for you — that you are in the good situation?\n-   Usually when two people disagree about some matter, they agree that the fact they're disputing is an objective one.\n-   3 possibilities for what would be \"bad\" about living in the matrix\n    -   scientific knowledge\n    -   interpersonal relationships\n    -   being slaves — albeit content ones\n        -   the matrix is computer-generated dream world, built to keep us under control\n-   meaning in the matrix -\u003e [virtual worlds](thoughts/virtual%20worlds.md)\n    -   do the things in the matrix refer to their \"real\" counterparts?\n    -   \"steak\" and \"air\" refer to the actual things inside of the matrix for those who have spent their whole life in the matrix\n        -   mean something very different for outsiders who just visit","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Ny%C4%81ya":{"title":"Nyāya","content":"\n\u003e \"Perception is a cognition that has arisen from the contact of sense faculty and object and is inexpressible, not erroneous, and determinate in nature.\"\n\nNyāya is a major proponent of [philosophical realism](thoughts/philosophical%20realism.md) -- cognition is only possible because it is dependent on the objects in this world.\n\nNyāya adopts the Vaiśeṣika [[thoughts/ontology|ontology]], which posits that seven different types of things:\n1. Universals (node)\n2. Qualities (node)\n3. Motions (node)\n4. Substances (node)\n5. Inherence (edge)\n6. Individuators (node)\n7. Absenses (later addition)\nThis ontology of a directed graph in which inherence relations connect things in inheror-inheree pairings.\n\nPramānas are means of knowledge and provide it through mode like perception, inference, and [testimony](thoughts/testimony.md). The objects of knowledge are called 'knowables' (prameya).\n\nStuff has to exist, if you investigate well, you get answers. Pramāna-generated knowledge is knowledge gained through \"close examination of objects through cognition.\"\n\nRational inquiry requires purpose. We do not doubt everything, lest we not [trust](thoughts/trust.md) the ground beneath us. Debate must proceed based off of shared axioms.\n\nCounter against the dream argument (perception of knowledge is akin to conception of objects in dreams) -- similar to [Descartes' Dream Argument](thoughts/Descartes'%20Meditations.md)\n1. Dreams aren't real because we can wake up\n2. Alternatively, dream objects fall apart under close examination\n3. Dream objects implies the existence of non-dream objects\n\nWhat about incorrect understandings of the world? Nyāya argues that these are akin to dream objects, where destruction of false perception is akin to the destruction of conceptions of dream objects upon waking. (NS p. 68)\n- Stuff existing != existing how you think it does\n- Error, seeing a post as a person or vice versa, occurs when their differences are elided while their similarities are grasped.\n\t- In order to be wrong about something, we need to mistake something not-F for something F (to see a post as a person)\n\t- I could not mistakenly see a person in the distance if I didn't have the concept of a person, and Nyāya argues that in order to have such a concept, I must have had knowledge of people in the past.\n- Not true that incorrect understands have convergent content, the essence of things implies natural diversity in the similarity of things. (Argument against the fact that 'nothing can be explained')\n- Erroneous and dream cognition are both real, they have specific content arising from specific causes\n","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/OrbitDB":{"title":"OrbitDB","content":"\nOrbitDB is a distributed, [[thoughts/peer-to-peer|peer-to-peer]] database with [[thoughts/IPFS|IPFS]] as its data storage and [IPFS Pubsub](https://github.com/ipfs/go-ipfs/blob/master/core/commands/pubsub.go#L23) to automatically sync databases with peers. Provides eventual consistency with [[thoughts/CRDT|CRDTs]] for conflict-free merges.","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Order-theory":{"title":"Order theory","content":"\nFrom [An Abstract Plane: CRDT Primer 1](http://jtfmumm.com/blog/2015/11/17/crdt-primer-1-defanging-order-theory/)\n\nAn **order** is a binary relation $\\leq$ on a set $S$, written $\u003cS,\\leq\u003e$.\n\n- If two things $a$ and $b$ are incomparable, we write it $a \\parallel b$\n- Total order:  for all a and b in the set, either $a \\leq b$ or $b \\leq a$\n- Partial order: at least one pair a and b in the set, where $a \\leq b$ or $b \\leq a$ \n\nSee also: [[thoughts/causality|message ordering]], [[thoughts/clocks#Vector Clocks|Vector clocks]]\n\n## Joins\nAn upper bound is an element of the set that is $\\geq$ every other element in the set in terms of that relation\n\nWhen we take the join of $a$ and $b$ (written $a \\lor b$), we’re looking for some element $x$ for which $a \\leq x$ and $b \\leq x$ where $x$ is the smallest element that satisfies that condition\n\nJoin has\n1) Commutativity: $a \\lor b = b \\lor a$\n2) Associativity: $(a \\lor b) \\lor c = a \\lor (b \\lor c)$\n3) Idempotence: $a \\lor a = a$\n\nWhen it comes to [[thoughts/CRDT|CRDTs]], what we’re looking for is the ability to apply an operation in any order and as many times as we want without corrupting the result. The laws obeyed by joins give us exactly this.\n\nA join [[thoughts/A City is not a Tree#Semilattices|semi-lattice]] then essentially does a topological sort or [[thoughts/causality#Causal Order|causal ordering]] of its elements except all of the elements can be joined (i.e. have a single shared ancestor)\n\nWe can illustrate the semi-lattice using a Hasse Diagram\n\n![[thoughts/images/hasse diagram.png|300]]","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Ostrich-Algorithm":{"title":"Ostrich Algorithm","content":"\nIgnoring potential problems on the basis that they may be exceedingly rare. It is named after the [ostrich effect](https://en.wikipedia.org/wiki/Ostrich_effect \"Ostrich effect\") which is defined as \"to stick one's head in the sand and pretend there is no problem\". It is used when it is more cost-effective to allow the problem to occur than to attempt its prevention.","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Overlay-Network":{"title":"Overlay Network","content":"\n\u003e A network that is layered on top of another network\n\nNormally on top of [[thoughts/HTTP]]. Fun fact! The [[thoughts/Internet]] was originally built as an overlay upon the telephone network\n\nExamples:\n- [[thoughts/VPN]]\n\t- [WireGuard](https://www.wireguard.com/)\n- [OpenZiti](https://docs.openziti.io/#build-a-network)\n- [ZeroTier](https://github.com/zerotier/ZeroTierOne)\n- [Tailscale](https://tailscale.com/) (or the open source version [Headscale](https://github.com/juanfont/headscale/))\n- Almost all [[thoughts/peer-to-peer]] [[thoughts/distributed systems]]\n\t- Most notably, [[thoughts/DHT|DHTs]]","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/PBFT":{"title":"PBFT","content":"\n*[Practical Byzantine Fault Tolerance](http://css.csail.mit.edu/6.824/2014/papers/castro-practicalbft.pdf)* by Miguel Castro and Barbara Liskov\n\nTLDR; one of the first [[thoughts/State Machine Replication (SMR)|state machine replication]] algorithms with an asynchronous [[thoughts/system model|system model]] that can tolerate [[thoughts/Byzantine Faults|Byzantine faults]] (although it has a weak synchrony assumption where all messages are guaranteed to be delivered after a certain time bound by using timeouts).\n\nIt can drive a consensus decision in two rounds of message exchanges.\n1. The first phase guarantees proposal uniqueness through the formation of a quorum certificate (QC) consisting of $(n − f)$ votes.\n2. The second phase guarantees that the next leader can convince replicas to vote for a safe proposal.\n\nIt offers both [[thoughts/liveness|liveness]] and [[thoughts/safety|safety]] under the [[thoughts/33% Impossibility Result|33% Impossibility Result]] and only uses [[thoughts/Asymmetric Key Cryptography|public-key cryptography]] during faults to prevent major speed bottlenecks (typically just uses [[thoughts/digital signatures#Signed Message Digest|signed message digests]]). This circumvents the [[thoughts/FLP Result|FLP Result]] because it relies on a synchrony assumption to guarantee liveness, not safety.\n\nFor a faster alternative, consider [[thoughts/SBFT|SBFT]] (which provides a reduction from $O(n^2)$ to $O(n)$ normal-case communication and a best-case latency of only a single round of communication)\n\nThe primary of a view is replica $p$ such that $p = v \\mod |\\mathcal{R}|$ where $\\mathcal{R}$ is the set of replicas. Note that this *explicitly allows for faulty primaries* while the algorithm properly handles.\n\nThe algorithm works as follows\n1. A client $c$ sends a request for operation $o$ to a node in the cluster: $\\langle \\textrm{Request}, o, t, c \\rangle_{\\sigma_c}$\n\t1. If a replica receives the request, it forwards it to the leader\n2. The primary multicasts the request to the backup nodes in a three-phase protocol. The pre-prepare and prepare phases are used to totally order requests sent in the same view even when the primary, which proposes the ordering of requests, is faulty\n\t1. Pre-prepare: mainly used to ensure request was assigned sequence number $n$ in view $v$. Primary $p$ assigns a sequence number $n$ to the request and multicasts a pre-prepare message with digest $m$: $\\langle \\langle \\textrm{Pre-prepare}, v, n, d \\rangle_{\\sigma_p}, m \\rangle$\n\t\t1. A replica $i$ accepts a pre-prepare message iff:\n\t\t\t1. It is in view $v$\n\t\t\t2. $d$ is the digest for $m$ and the signature is correct\n\t\t\t3. has not seen a pre-prepare message with the same $v$ and $n$ with a different digest $d$\n\t\t\t4. sequence number is between some $h$ and $H$\n\t2. Prepare\n\t\t1. If replica $i$ accepts the pre-prepare message, it enters the prepare phase by multicasting a $\\langle \\textrm{Prepare}, v, n, d, i \\rangle_{\\sigma_i}$\n\t\t2. We define a replica $i$ as prepared iff $i$ has in its log:\n\t\t\t1. The request $m$\n\t\t\t2. A pre-prepare for $m$ in view $v$ with sequence number $n$\n\t\t\t3. $\u003e2f$ prepares that match the pre-prepare based on $v$, $n$, and $d$\n\t3. Commit\n\t\t1. If we are prepared, we have supermajority agreement which means all honest replicas agree on the requests in view $v$\n\t\t2. Replica $i$ multicasts $\\langle \\textrm{Commit}, v, n, D(m), i \\rangle_{\\sigma_i}$\n\t\t3. Replicas accept commit messages and insert them in their log provided they are properly signed, the view number in the message is equal to the replica’s current view, and the sequence number is between $h$ and $H$\n\t\t4. This phase ensures that if a message is considered committed locally, then it should have been committed for the cluster\n\t\t\t1. A message $m$ is considered committed locally on replica $i$ if it has a log entry indicating it has prepared $m$ with view $v$ and sequence number $n$ and has also accepted $2f+1$ commits that match the pre-prepare for $m$\n\t\t\t\t1. After a $m$ is considered committed locally and all $m'$ with lower $n$ have been executed, $i$ executes $m$ and applies the state change (as we don't assume ordered message delivery, keeping messages until ready is critical to ensuring message ordering)\n\t\t\t\t2. $i$ then sends a reply to the client: $\\langle \\textrm{Reply}, v, t, c, i, r \\rangle_{\\sigma_i}$\n\t\t\t2. A message $m$ is considered committed on the cluster if for all $i$ in some $f+1$ honest replicas, it has a log entry indicating it has prepared $m$ with view $v$ and sequence number $n$\n4. The client waits for $f + 1$ replies from different replicas with the same result; this is the end result\n\t1. If the client doesn't receive replies in a timely manner, it broadcasts the request to all replicas. If the request has already been processed, the replicas simply re-send the reply (as replicas cache the last reply sent to each client)\n\n![[thoughts/images/3pc-pbft.png]]*Replica 0 is the primary, replica 3 is faulty, and C is the client*\n\n## Garbage Collection\nAs we assume only asynchronous model, we can't assume any unresponsive node won't rejoin at some later point. So either, we need to keep all log entries around potentially forever (not idea), or have some way to transfer state between nodes (which requires nodes to prove correctness of state).\n\nGenerate state correctness proofs are expensive so only happen once every 100 sequence numbers (a stable checkpoint).\n\nProof generation:\n1. When a replica $i$ reaches a checkpoint, it multicasts a message $\\langle \\textrm{Checkpoint}, n, d, i \\rangle_{\\sigma_i}$ where $d$ is the digest of the state\n2. A replica collects checkpoint messages until they have $2f+1$ messages for the same sequence number $n$ and digest $d$\n\t1. $2f+1$ messages are the proof of correctness for the checkpoint\n\t2. A checkpoint with a proof means that the replica is safe to discard all log messages related to sequence number $n$\n\nAdditionally, this checkpointing determines what the waterlevel $h$ and $H$ are\n- $h$ is the sequence number of the last stable checkpoint\n- $H = h + k$ where $k$ is generally twice the gap between stable checkpoints (e.g. 200)\n\n## View Changes\nSimilar to the concept of term changes and heartbeats in [[thoughts/Raft Consensus Algorithm|Raft]]\n\nIf the timer of replica $i$ expires in view $v$, it can broadcast a message to move the system to view $v + 1$\n- It stops accepting messages (other than checkpoint, view change and new view messages)\n- Multicasts a $\\langle \\textrm{View-change}, v + 1, n , \\mathcal C, \\mathcal P, i \\rangle_{\\sigma_i}$ to all nodes\n\t- $n$ is the sequence number of the last stable checkpoint $s$ known to $i$\n\t- $\\mathcal C$ is the set of $2f+1$ certificates for $s$\n\t- $\\mathcal P$ is a set of sets $\\mathcal{P}_m$ for each message $m$ with a sequence number higher than $n$\n\t- Each $\\mathcal{P}_m$ is the set containing\n\t\t- A valid pre-prepare message for $m$\n\t\t- $2f$ matching valid prepare messages from different replicas\n- When the initiator $p$ of view $v + 1$ receives $2f$ valid view-change messages, it multicasts a new $\\langle \\textrm{New-view}, v + 1, \\mathcal V, \\mathcal O \\rangle_{\\sigma_p}$ \n\t- $\\mathcal V$ is the set of all received $2f$ view-change messages along with the initial view-change message $p$ sent out\n\t- $\\mathcal O$ is the set of pre-prepare messages computed as follows:\n\t\t- *min-s*: latest stable checkpoint in $\\mathcal V$\n\t\t- *max-s*: highest sequence number in a prepare message in $\\mathcal V$\n\t\t- For each $n$ between *min-s* and *max-s*\n\t\t\t- If there is some message in $\\mathcal P$ where the sequence number matches $n$\n\t\t\t\t- Create a new message $\\langle \\textrm{Pre-prepare}, v+1, n,d \\rangle_{\\sigma_p}$\n\t\t\t- If there isn't\n\t\t\t\t- Create a new message $\\langle \\textrm{Pre-prepare}, v+1, n,d^{\\textrm{null}} \\rangle_{\\sigma_p}$ where $d^{\\textrm{null}}$ is the digest of a noop request\n\t- Leader appends all messages in $\\mathcal O$ to its log and enters view $v + 1$","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/PHIL240A-Final-Paper":{"title":"PHIL240A Final Paper","content":"\n## Section I: Trusting Institutions\n\u003e Is it ever responsible to trust an institution about something that outstrips your individual ability to verify? Explain why. If you answer yes, how do you ground this trust? If you answer no, how do you deal with the fact that trusting at least some institutions is central to the success of (at least a democratic, arguably any contemporary human) society?\n\nIn answering this question, there seems to be two different answers depending on how we define trust here. We turn to Hawley's differentiation between epistemic and practical trust here (2012, p. 2031). Hawley defines epistemic trust as trust in someone as a speaker or source of knowledge and defines practical trust as trust in someone as an actor. I argue that it is irresponsible to have epistemic trust in institutions about something that outstrips one's individual ability to verify, whereas it is responsible (and in fact necessary) to be able to have practical trust in institutions about something that outstrips one's ability to verify.\n\nFirst, note that to answer this question concretely, the act of having a 'responsible attitude' (e.g. of trust) needs to be properly defined in this context. Here, I define 'responsible attitude' to mean an attitude held by an actor that is justified and which is within one's control (not coerced).\n\nI argue that it is epistemically irrational behaviour to trust an institution about something that is outside one's ability to individually verify. Looking to cases of objective knowledge (i.e. scientific knowledge), let us take for example government public health announcements. Generally, all public health announcements made by the government are scientifically supported, which means they are backed by published, peer-reviewed, and supposedly reproducible scientific work. At its core, the scientific method is about doubt. Scientific hypotheses need to be falsifiable, assumptions and priors must be stated. If some theory is unverifiable, then it is invalid as a scientific theory and would be epistemically irrational to treat the opinionated claim by the institution as if it were objective fact.\n\nFrom the perspective of religious texts, even if the institution were to be a flawless revealed source, it would still be epistemically irrational behaviour to trust the 'revealed source'. A so-called revealed source still has to be interpreted and this necessarily happens through human interactions mediated by language. As similarly claimed by Dharmakīrti, \"[Vedic] words do not [themselves] declare: 'This is our meaning, not this.' This meaning [which Vedic words have] must be postulated by humans. The latter are possessed, however, of [moral defects] like desire\" (PV 1.312-313 in Eltschinger, 2012, p. 33). This 'revealed source' then cannot be taken as a source of epistemic knowledge.\n\nHowever, proving that trusting individually unverifiable claims made by an institution is epistemically irrational doesn't rule out the possibility of *practical trust.* As the question originally asks, how do we deal with trusting *some* institutions? I turn to the notion of reliability here as a means of evaluating trust, specifically in the context of *relying on institutions as actors*.\n\nSimilar to Goldman's 5th main piece of evidence for trust, (2001, p. 93), we can look to the institutions past track-records as a good heuristic for reliability. While we may not be able to verify that some claim is 'correct' at the moment, we can show that the institution has made historically correct statements. If we treat institutions like computational black boxes that take in inputs and produce outputs, we can reuse Duran and Jongsma's notion of Computational Reliability, which states that \"researchers are justified in believing the results of AI systems because there is a reliable process that yields, most of the time, trustworthy results\" (2021, p. 332). At the core of it, the notion of reliability gets at the fact that trust exists as a means to avoid needing to re-evaluate the validity of each statement or each action. If I know that my local cafe opens at 9:30am every morning, I don't need to check what time it opens today because I *trust* that they are reliable and open at the time they claim to open.\n\nAs such, we extend the notion of *practical trust* to institutional claims that are outside our individual ability to verify given that they have been historically reliable actors. This does *not* extend to epistemic trust as this should be grounded in verifiable and falsifiable statements.\n\n## Section II: Resolving the pickle\n\u003e In the final episode of Marvel's TV series _Loki_, Loki and Sylvie have the following exchange:\n\u003e \n\u003e SYLVIE: What was I thinking trusting you? Has this whole thing been a con?\n\u003e \n\u003e LOKI: Really? That’s what you think of me… after all this time? Sure. Why not? Evil Loki’s master plan comes together. Well, you never trusted me, did you? What was the point? Can’t you see? This is bigger than our experience.\n\u003e \n\u003e SYLVIE: Why aren’t we seeing this the same way?\n\u003e \n\u003e LOKI: Because you can’t trust… and I can’t be trusted.\n\u003e \n\u003e SYLVIE: Then I guess we’re in a pickle.\n\u003e \n\u003e Your assignment is to solve the pickle. You can do this by either convincing Sylvie to trust Loki (and by extension He Who Remains), or by convincing Loki that Sylvie's right and no one (or at least no one in this room, but if not them, then who and about what?) should be trusted. Remember that both Loki and Sylvie are very smart and very attached to their respective viewpoints, so you'll have to both 1) show them that you understand their point of view (by incorporating counter-arguments to the position you're arguing in favor of), and 2) give them some new epistemic tools to understand their situation differently if you're going to be convincing.\n\n\n\u003e I am arguing that Sylvie cannot trust either of them.\n\u003e S: Sylvie; the one who can't trust\n\u003e L: Loki; the one who can't be trusted\n\nL: Sylvie, look. We should be looking at multiple different perspectives on epistemic trust and reliability here. It's clear that we can't go off of our gut feelings about trust here.\n\nS: You're just trying to stall for time, we don't have much time left!\n\nL: Calm down. Just babbling back and forth like this will get us nowhere. Throwing something from one epistemic culture that’s disjoint from another epistemic culture cannot lead to reconciliation without a shared epistemic culture. We need to arrive at a basic shared epistemic culture (Smith and Vaidya, 2022, 8:43)\n\nS: But don't you see? That's the main problem! We don't *have* any shared epistemic grounds. We may be the same person from different timelines but our experiences have been completely different. I've been hunted by the TVA since I was a child. My parents told me I was adopted at an early age. I have known no true home.\n\nL: But why can't you just default to trusting? Why can't you hold trust as an unquestioning attitude? If you questioned everything and deliberated everything all the time, you wouldn't be able to function at all in this world! (Nguyen 2019, pp. 22-23)\n\nS: First off, I just told you why I can't trust. You give me no additional reason to trust you! Actually, quite the opposite. All you've done is trick people! There is no ground on which to even stand on. \"The everyday, taken-for-granted reality of civilian life ignores much; civility assumes the nonlethal intentions of others. In war, however, all such assumptions evaporate: one cannot trust the ground one walks on, the air one breathes, nor can one expect with full assuredness that tomorrow will come again\" (Kearl 1989, 353, as cited in Nguyen 2019, p. 9). We are in a war right now, Loki.\n\nL: What happened to our friendship? We had a thing going! Shouldn't you be partial towards your friends? Stroud (2006) and Kelly (2004) argue that we _should_ have partiality towards friends not only in actions but beliefs as well, though this isn’t always the right thing to do. As Stroud says, ‘friendship requires epistemic irrationality’ (Stroud 2006, Kelly 2004, as cited in Hawley, p. 2032). You see, I'm a partialist. I believe that someone who fails to be doxastically partial to me would fail to be a good friend to me (Crawford 2017, p. 1576).\n\nS: Bold assumption of you to make. Are we even friends? Do you think you can play tricks on me that easily? Besides, I am against doxastic partiality for friends anyways. I mean, we can be partial to our friends but not because it is normative to be always partial to our friends. We can be partial to friends but they can also be wrong given state-given reasons. The state-given reason here is that you are only trusting He Who Remains because he promises something you've wanted for a long time: the throne. By definition, a reason for an attitude is state-given when its status as a reason is grounded in some relation it bears to a property of having that attitude in one’s circumstances (Crawford 2017, p. 1587). Clearly, you are 'believing' He Who Remains only because it can benefit you immensely. \n\nL: Fine! If you can't trust me, can you trust He Who Remains? He knows all, he's omniscient. He's like a god of gods! He has seen all potential timelines and he knows what is the best move to make here.\n\nS: How can we trust he who remains? Nothing he claims is anything we can verify ourselves. All so-called 'revealed sources' still needs to be interpreted and this necessarily happens through human interactions mediated by language. We are both listening to him are we not? Yet, we are interpreting this two very different ways. There's no way to determine who's right about claims transcending human knowledge (Eltschinger 2012, pp. 33-34).\n\nL: Look, I get that you don't trust me. But you can trust one thing: \"I love to be right\" (Episode 2).  Objectively, let's look at how to ensure it’s possible to accurately evaluate whether or not someone is an epistemic authority, hm? Just look at it mathematically. Think about what’s at stake and think about what the tolerance threshold is that we can have in the relevant domain (Smith and Vaidya, 1:01:48). Think about the consequences here! If we make the wrong move, we could end the entire multiverse. We don't have a lot of time.\n\nS: I'm not convinced. Look, we tried establishing a shared epistemic baseline; it didn't work. I can't trust *anyone* in this room. Loki, I can't trust you: you've lied to everyone in your life up until this point. How can I be sure you're not just lying to get your way? You're on the brink of getting everything you've ever wished for. He Who Remains, I can't trust you either. I've hated the TVA my whole life and now the guy who runs the whole thing is telling me I have a chance to just kill him and end it all? Of course I'm going to choose to kill you.\n\nL: W-wait. Think of the consequences! How could you trust *anyone* then?\n\nS: I... can't. Other people can trust because they've needed to for social reasons. Trust encourages them to rely on each other for mutual good (Nguyen, p. 2). But I haven't had any of that -- I've never needed to. I've never had a family to depend on. Until I have some semblance of reliability and consistency in my life, that just won't be possible.\n\n[Sylvie sends Loki through a time window and kills He Who Remains]","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/PMOG":{"title":"PMOG","content":"\n\u003e Geocaching meets Pokemon Go for the Web\n\nSummarized from their [retrospective here](http://pmog.com/).\n\nThe premise of The Nethernet came from the fact that internet users spend a large portion of their time multitasking, browsing information, or contacting other people online. The Nethernet aimed to classify and allocate an individual’s internet use and then utilize the gathered information in a unique and playful manner.\n\nThe Nethernet was originally an in-browser toolbar that compensated users as they browsed the World Wide Web. The game evolved as a HUD overlay in the Firefox web browser.","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/PSL-FLM-Impossibility-Result":{"title":"PSL-FLM Impossibility Result","content":"\n[[thoughts/Byzantine Broadcast|Byzantine Broadcast]] is impossible in the synchronous [[thoughts/system model|system model]] if you have too many byzantine nodes (for $f \\geq \\frac n 3$).\n\nVague intuition for the result, imagine 3 nodes A (Byzantine), B (honest), and C (Byzantine)\n1. Node A is the sender\n2. A could tell B + C conflicting things\n3. B + C can compare histories but C can try to frame A\n4. B can't distinguish which of A or C are responsible for conflict\n\nThis result **breaks down** in the presence of [[thoughts/Public-key Infrastructure|PKI]] (you can't forge signatures from other nodes!!)\n- Thus, with PKI we get [[thoughts/Byzantine Broadcast|BB]] for all $f$\n- Without PKI, we get [[thoughts/Byzantine Broadcast|BB]] only if $f \u003c \\frac n 3$\n","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Panpsychism":{"title":"Panpsychism","content":"\nOpposite take to that of [Materialism](thoughts/Materialism.md). Panpsychists deny that the mind is fundamentally non-mental.\n\n\u003e Everything physical is also mental or phenomenal or experiential.\n\nIn other words, everything is slightly conscious.\n\nSee [[thoughts/emergent behaviour#Combination Problem|the Combination Problem]]\n\n## Eddington, Russell, Strawson's argument for panpsychism[^1]\n1. Physical science tells us about only the structural and relational properties of physical phenomena.\n2. Relational properties are determined by intrinsic properties\n\t1. Potentially problematic\n\t2. Could be the case that relational processes determine the placeholders of the relation\n3. Certain configurations of physical phenomena generate/constitute phenomenal states\n4. Intrinsic properties of physical phenomena must encompass this power\n5. Own inner awareness reveals that phenomenality is an intrinsic property\n\t1. Potentially problematic\n\t2. Supposes the introspection gives us access to the essential nature of our conscious states\n\t3. A careful phenomenological investigation of qualia reveals that they are always situated and invested with vital, affective, and embodied value so are relational, not intrinsic. Qualia must have content \n6. Phenomenality is the only intrinsic property we know of\n7. So phenomenality must be an intrinsic property of physical phenomena, or at least of certain organized physical systems\n\n## Strawson's Panpsychism[^1]\n[Physicalism](thoughts/Materialism.md) actually entails panpsychism\n\n1. [[thoughts/monism|Monism]] is true (there is only one kind of 'stuff' in the universe)\n2. Experiential phenomena are real phenomena (denies illusionism: see [philosophical realism](thoughts/philosophical%20realism.md)))\n3. All concrete phenomena are physical\n4. Therefore experiential phenomena are physical\n5. The emergence of experiential being from non-experiential beings does not make sense. If this were true, the experiential would need to wholly depend on the non-experiential. This can't possible be the case: we have no model for it and can't make sense of it\n6. So, at least some elementary physical phenomenal must also be experiential (micropsychism)\n7. If at least some elementary physical phenomena must also be experiential, it's far more likely that all of them are (otherwise there would be radical heterogeneity edging on dualism and we are assuming that monism is true)\n8. Therefore, panpsychism is true\n\n[^1]: This content is sourced from Professor [Evan Thompson](https://evanthompson.me/)'s course materials for PHIL451A at UBC. All rights to this content is retained by Evan Thompson.","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Pareto-optimality":{"title":"Pareto optimality","content":"\nIf there is no profile where one player’s payoff is better but no player’s payoff is worse. Pareto optimality is a criterion of ‘group rationality’, not a criterion for individual rationality (see: [[thoughts/Nash equilibrium]])\n\nUsually only applicable for [[thoughts/positive sum]] games\n\n","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Physical-Layer":{"title":"Physical Layer","content":"\nLayer 5, layer below the [Link Layer](thoughts/Link%20Layer.md)\n1. Hardware\n2. Unit: Bits\n3. Responsibilities: Encodes data appropriately for the physical medium","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Platos-Ship-of-State":{"title":"Plato's Ship of State","content":"\n\"Because large sailing vessels by their very nature need to be steered with a firm hand, sailors must yield to their captain's commands; no reasonable person believes that ships can be run democratically\". Counterpoint: there **should** be democratic agreement from the crew about the final destination of the ship","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Post-It-Note-City":{"title":"Post-It Note City","content":"\n[Source: Post-It Note City by Shannon Mattern](https://placesjournal.org/article/post-it-note-city/)\n\n\u003e Alphabet has the tools to design, build, fund, power, connect, monitor, and monetize a city, and that prospect scares people.\n\n## On Participatory Planning\n\"Paper and ink, models and maps: these are the accessible tools of civic engagement — and corporate self-defense.\" \n\nSidewalk lab's choice to use the tools of civic design and participatory planning as a defense for their actions also strikes me as extremely cynical.\n\nBut, by mandating public participation as a requirement for new development, we run the risk of turning community relationship-building into a \"checklist of codified practices.\" Specifically, it makes participants wary when the invitation is from an org which has money to gain and data to harvest from the participants.\n\nTreating participatory design like a software sprint in an open-source project. Is this a fair analogy to make? Especially when it doesn't really make sense to apply the 1-2 week sprint concepts to cities which intuitively span much larger timespans. Wonder how well the 'move fast break things' attitude transfers.\n\nThoughts on putting a whole city on the blockchain using a [DAO](thoughts/dao.md)? Turns out this is [already a thing.](https://city.mirror.xyz/fpjVcNlEkW6md2aDgoc6YVXbaGquNop3AJnOyQSurbw)\n\n## Maps\nMapping as a way to \"hold governments accountable … fill gaps when infrastructural and municipal services are fragmented … [and] make visible social and political processes and events that might be otherwise hidden or overlooked.\" (from Crowdsourcing, Constructing, and Collaborating: Methods and Social Impacts of Mapping the World Today)\n\nMore on participatory mapping and politics: [Mapping Politics in/of the Modern City: Cartography as Representation](https://www.researchgate.net/publication/296431763_Mapping_Politics_inof_the_City_Cartography_as_representation)\n\n'Participation' as public performance to 'signal' democratic processes without providing the real thing.\n\nMapwashing: \"a disingenuous use of maps, apps, and other tools of participatory planning\"\n\n## Responsiveness\n\u003e If urban design can be automated, if cities can be made responsive to real-time data collected from environments and inhabitants without their explicit consent, how meaningful is our participation?\n\nSidewalk also proposes creating more responsive public [infrastructure](thoughts/infrastructure.md) (e.g. benches, stormwater pipes, power grids, etc.) which collect data continuously and make 'smart' decisions. No opt-in or out process for this type of data collection, no consent.\n\nCurious if this is related to the move towards [real-time content](thoughts/ephemereal%20content.md)\n\nHow much of this can be attributed to the Silicon Value ethic of \"move fast and break things\"? It feels like Sidewalk is extrapolating too much (trying to pull short feedback loops from naturally long timescales of city which operates on multi-year long scales).\n\nIs there a relationship between iteration cycle length and potential impact? Software people are used to iterating quickly without having consequence for each marginal build or project. Not the same case with cities where each change affects real people and there's no real 'staging' or 'development' area (see [Collingridge Dilemma](thoughts/catch%2022.md))\n\n## Humanistic Design\nIs creating people-first cities that are not driven by [techno-solutionism](thoughts/From%20Counterculture%20to%20Cyberculture.md) possible? How do we legitimately involve people in the creation of these cities?\n\n\"Do we need a commercial app to do what a robust, public democratic process should do?\" one quote reads. Or is rather than these democratic processes are failing so we look to alternatives?\n\nSidewalk feels very much talking into the void and talking to the org, not much talking with each other, no discussion groups. Yes, process and documentation matter, but if there's no input into this [feedback loop](thoughts/feedback%20loops.md), the ideas are just self-reinforcing in an echo chamber. The problem is that large corporations like Alphabet present already-fleshed-out ideas with little room for debate so that 'conversations' and 'feedback' are largely performative.\n\nThe use of \"cheerful minimalism to mask the insidiousness of multinational tech corporations with friendliness and approachability,\" feels very similar to the weird vibe of the [signature corporate art style](https://www.youtube.com/watch?v=lFb7BOI_QFc) and why it feels so fake\n\nFrom Jasmine: With software, you can **find** product market fit, ignore edge cases and people who won't make you money, etc. But with cities, you are democratically obligated to build for everyone (or at least the majority)\n\n## Labels and Quantization\nSidewalk feels like a city trying to [label and quantize everything](thoughts/quantization.md)\n\n\u003e Participants are obliged to transform complex spatial phenomena into machine-readable points, lines, and areas, adopting a logic defined by Euro-American geopolitics, settler colonialism, and property relations.\n\n[These maps and markers], while useful and actionable, tended to \"reduce complex life stories and neighborhood histories to 'dots on a map.'\"\n\nData as digital [desire paths](thoughts/desire%20paths.md)? Not sure how I feel about 'anonymized' or 'de-contextualized' data, stripping down and de-contextualizing opinions (e.g. post-it notes) removes important context and nuance.\n\n","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Postels-Law":{"title":"Postel's Law","content":"\n\u003e Be conservative in what you send, be liberal in what you accept\n\nThe principle is also known as Postel's law, after Jon Postel, who used the wording in an early specification of TCP.\n\n\"It takes two to miscommunicate.\" A great listener, _or_ a skilled speaker, can resolve a lot of conflicts.\n\nPostel's Law is the principle the [[thoughts/Internet]] is based on. Not because Jon Postel was such a great salesperson and talked everyone into it, but because that is the only winning evolutionary strategy when internets are competing.\n\n## Structure from Structurelessness\n_Allow all, bless some_ is an important general principle for building evolvable systems. Allowing all means new use-cases can evolve from the bottom-up, while blessed fields provide a stable API which multiple clients can count on\n\nThis is how [[thoughts/Protocol|protocols]] evolve","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Precautionary-Principle":{"title":"Precautionary Principle (PP)","content":"\n- Ordinary scenarios: maximize expected [[thoughts/utility|utility]] (EU Max)\n- Precautionary scenarios: avoid catastrophic harm (Precautionary Principle)\n\n## Tripod Framework\nManson's Framework for when to use the precautionary principle\n1. Serious damage (damage condition): some outcomes exceed a threshold of badness and are considered catastrophic\n\t- Thresholds for levels of harm: serious, catastrophic, irreversible, civilization collapse\n\t- Thresholds for time scales: present, pre-2100 (current population), post-2100 (future generations)\n\t- Scope: local, global\n2. Uncertainty (knowledge condition): some outcomes meet a required threshold of evidence to count as a serious threat\n\t- Probability: possible, non-negligible probability, predicted by a model, predicted by a well-understood scientific mechanism\n3. Proportional remedy: response should correspond to the plausibility and severity of the threat\n\t- Prohibition/ban, further research, moratorium, mitigation/restriction\n\nHowever, could potentially lead to irrational outcomes or outcomes that are contradictory. e.g.\n1. Greenhouse gases (GHG) may cause catastrophic temperature rise ⇒ Ban GHG at once\n2. Banning GHG may lead to economic crisis, world war and nuclear holocaust ⇒ Don’t ban GHG\n\n## Versions of PP\n1. If the activity meets the damage condition, and\n2. If the link between the e-activity and the e-effect meets the knowledge condition,\n3. Then apply the e-remedy.\n\n*But,* PP versions must be internally consistent; it cannot ban its own remedies\n\n### Catastrophe Principle\nIf an effect is catastrophic, and there is a possible link between the activity and the effect, then the remedy is to ban the activity completely.\n\nFor example, ban nukes because their possible use has a catastrophic effect","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Primary-of-Consciousness":{"title":"Primary of Consciousness","content":"\nRelated: [[thoughts/consciousness|consciousness]], [[thoughts/monism#Neutral Monism|neutral monism]]\n\n## Primacy of Consciousness\nPHIL451A Paper 3\n\n\u003e Is consciousness primary?\n\nFor something to be primary is for it to be the first and foremost; a prior for all else that comes after it. First, I show how our current understanding of the physical world centres around the primacy of the material. Then, I claim that consciousness is primary – namely existentially, transcendentally, and epistemologically and finally posit a version of neutral monism as a stance on the primacy of consciousness.\n\nHistorically, scientific materialists have argued that science and the scientific method enables us to get ‘outside of experience’ and grasp the world in and of itself. Yet, subjective experience is present at every step. When we observe the cosmos, we do so by formulating theories and models about how we think they work. All of this depends on the subjective experience. We look at the results of our complex telescopic instruments and formulate theories based off of what we have learned and have observed in the world. We pull scientific models from our experiments and observations but again, these are models and idealisations, not actual instantiations of ’things’ in the world.\n\nGottfried Leibniz, Immanuel Kant, Arthur Schopenhauer, and Bertrand Russel were all strong believers that a fully physical account of the world actually offers no explanation of the _intrinsic nature_ of the things within it (Leibniz, 1686; Kant, 1787; Schopenhauer, 1818; Russel, 1959). The ideal gas law tells us how pressure, volume, amount, and temperature of a gas are all related to each other, but tells us nothing about what each of those things in and of themselves are. Chemistry tells us that Carbon has an atomic number of six. At first glance, this may be an intrinsic property. But probe deeper at what an atomic number *is* and all it represents is the number of protons it has. Protons themselves are not ‘real’ things. They are abstractions of how this group of abstractions we call quarks behaves together depending on their relations. Mass is a property that determines how an object will obey the relation $m = \\frac{F}{a}$. Again, it is abstractions all the way down. Purely physical descriptions **tell us not what matter _is_ but what what it _does_.**\n\nPhysics, by name, is supposed to be a mathematical theory of the physical. Yet mathematics, by nature, is purely relational; numbers are quantifiers on abstract objects, formulas describe precise relations between variables. But intuitively, there must also be an _intrinsic nature_ to these objects. _What is an atom in and of itself?_ This question is not answered by a relational account of the world.\n\nIt is tempting to say at this point that perhaps a relational view all there is to reality. After all, this is realistically all that is useful to the functioning of society. It has enabled us to program silicon, photograph the depths of the universe, and predict weather across the world. Yet intuitively, a world held up purely through relations does not make sense. As Hedda Hassel Mørch pointed out in her critique of physics for ignoring consciousness, “for there to be a relation there must be two things being related.” (Mørch, 2017) Otherwise, the relationship is empty – “a show that goes on without performers, or a castle constructed out of thin air.” Mørch posits that all physical relations should be made real by some substance that itself is not purely relational or else there would be no difference between mere mathematical abstraction and the concrete universe.\n\nClearly, if we wish to poke beyond this veil of pure abstractions, our current explanations of our reality will not do: intrinsic natures simply cannot be captured through a purely physical approach. Materialism as given so far does not seem to stand. Taking its physical description as the totality is like **confusing the map with the territory.** It may be fine if you just need the map to navigate the world, but to open one’s eyes to the real world, we must dig deeper. Here, I propose that perhaps consciousness is fundamental to reality, not the other way around -- that consciousness is _primary_.\n\nIt almost self-evident that consciousness is **existentially primary** – it is through the subjective human experience, that the universe is disclosed to us. Arthur Eddington argued that the one thing we know concretely about consciousness is that has an intrinsic nature (Eddington, 1927). As René Descartes famously said in his Second Meditation, “cogito, ergo sum”: I think, therefore I am. It is the foundation upon which Descartes builds upon his certainty in his knowledge about the world. In all the ways we can be mistaken about reality, consciousness is not one of them – it is a reality that we apprehend directly and without inference. Thus, consciousness is existentially primary.\n\nConsciousness is also **transcendentally primary**. Kant defined transcendental primacy as all knowledge which is “occupied not so much with objects as with the mode of our knowledge of objects in so far as this mode of knowledge is to be possible a priori.” (Kant, 1787) In more colloquial language, the transcendental primacy of consciousness refers to how consciousness is not another object of knowledge, but that by which any object can become _knowable_.\n\nEdmund Husserl, in his 1936 work _The Crisis of European Sciences and Transcendental Phenomenology,_ defines a concept called the _life-world_. Roughly defined, it refers to the world as it is collectively experienced. Husserl likened this model of consciousness to our visual horizon: it is not really an object, but a rather a process of uncovering or displaying potentialities (Husserl, 1936).\n\nIt is in this way then that the horizonal sense of consciousness is not something that can be _had,_ but rather something we _live_. Quoting Bertrand Russel, “we know nothing about the intrinsic quality of physical events except when these are mental events that we directly experience.” (Russel, 1919) As such, consciousness is transcendentally primary.\n\nConsciousness is additionally **epistemically primary** – it is the source and destination of all knowledge. In creating models, we set aside aspects of experience on which we have doubts about (e.g. our senses, emotions, etc.) and extract idealised and abstract models (e.g. mathematics, physics, logic). Even the most abstract physical relation or mathematical formulas describe some ‘real’ thing we are trying to model or express a relation between. These models ideals and models are only as useful insofar as we can implement these abstractions as things we can use to measure, predict, and control phenomena within our lived experience. In this way, consciousness is epistemically primary.\n\nI will pause here to clarify that I am _not_ claiming consciousness to be ontologically primary. I am not making any sort of panpsychist claim that consciousness exists as a fundamental aspect of reality where everything has a small amount of consciousness. Neither am I claiming that consciousness exists inherently in the natural world as a fundamental aspect of reality.\n\nRather, I am positing a form of **neutral monism** that sits somewhere between physicalism and idealism. Monism, in its simplest form, suggests that there is only one ‘kind’ of underlying reality. A neutral stance on this does not side with either matter or mind, instead a potential 3rd substance. Russel explained this form of reality as having “a single underlying nature that is _neither_ mental nor physical but capable of being expressed in these two different ways.” (Russel, 1919) Much like the interiors and exterior of any object, Russel’s account of the mental and physical imply and necessitate each other as reflection of a single nature.\n\nIn Husserl’s horizon metaphor, the horizon is not possible without a world to be observed but the world also cannot be perceived without a perceiver. Similarly, the ‘horizon’ of consciousness is not possible without the physical but the the physical cannot be perceived without the mental. It is absurd to try to reduce one completely to another.\n\nFrancisco Varela’s notion of “mutually generative constraints,” (Varela, 1996) points toward a possibility where both physicalism and idealism work together towards reciprocal enrichment:\n\n1. Phenomenological reports may help to pick out and ascribe meaning to previously unnoticed neural configurations\n2. Neurological findings may become an incentive for re-categorization and further development in phenomenological research\n\nIt is in this neutrally monistic view that one can acknowledge consciousness as primary without necessarily needing to discount our existing objective knowledge about the world. This neutrally monistic view of consciousness does not ‘solve’ the hard problem. Rather, the problem never even arises because the physical world is no longer the standard for being, and objectivity is no longer the ultimate standard of being.\n\n### Citations\n- Bitbol, M. (2008). Is consciousness primary?.\n- Eddington, A. (1927). _The nature of the physical world: THE GIFFORD LECTURES (Vol. 23).\n- Descartes, R. (2008). Meditations on first philosophy (M. Moriarty, Trans.). Oxford University Press.\n- Husserl, E. (1936). _The crisis of European sciences and transcendental phenomenology: An introduction to phenomenological philosophy_. Northwestern University Press.\n- Kant, I. (1787). Critique of pure reason. _Modern Classical Philosophers, Cambridge, MA: Houghton Mifflin_, 370-456.\n- Leibniz, G. W. (1686). Discours de métaphysique [Discourse on Metaphysics]. _Die Philosophischen Schriften_, G, _IV_, 1875-90.\n- Mørch, H. H. (2017, March 31). _Is matter conscious?_ Nautilus | Science Connected. Retrieved April 7, 2022, from https://nautil.us/is-matter-conscious-6028/\n- Russel, B., (1919), On Propositions: What They Are and How They Mean, _Proceedings of the Aristotelian Society_, Supplementary Volume 2: 1–43. 283–321.\n- Russell, B. (1959). _My philosophical development_. Psychology Press.\n- Schopenhauer, A., Frauenstädt, J., \u0026 Hübscher, A. (1818). _Die welt als wille und vorstellung_ (Vol. 2). Leipzig: Brockhaus.\n- Varela, F. J. (1996). Neurophenomenology: A methodological remedy for the hard problem. _Journal of consciousness studies_, _3_(4), 330-349.\n\n## Horizon Metaphor\nHusserl had no word to denote what is not really an object, but a process of uncovering or displaying potentialities -- thus, the horizon metaphor.\n\n\u003e The existential primacy of consciousness: consciousness in the horizonal sense is not something we have; it's something we *live*\n\nTwo conceptions\n1. The horizon is real: it is the farthest point the eye can see before the Earth's surface curves away beneath our view\n2. The horizon is ideal: it is a structure of perception but not something that actually exists independent of perception\n\nThe horizon is a phenomenal structure of consciousness, not a particular phenomenal property (quale) or phenomenal content. Both [qualia](thoughts/qualia.md) and other phenomenal contents always appear from within the horizon of consciousness.\n\nConsciousness then in the horizonal sense is not something we 'have', it is something we live in. There is no way to step outside consciousness and measure it against something else because inside the horizon is all we know\n\nThe horizon itself is [empty](thoughts/emptiness.md).\n\nKant defines 'transcendental knowledge' as knowledge which is occupied not so much with objects as with the mode of our knowledge of objects in so far as this mode of knowledge is to be possible *a priori*. Consciousness then is not another object of knowledge, but that by which any object is knowable -- consciousness is irreducible to the domain of objects.\n\n![Merleau-Ponty on the world and consciousness](thoughts/images/Merleau-Ponty%20on%20the%20world%20and%20consciousness.png)*Merleau-Ponty on the world and consciousness*\n\n### Two conceptions on the world and the universe\nDefine the life-world as the space of meaning within which anything is intelligible and thinkable\n\n1. Natural Science: the universe contains the life-world\n2. Philosophy: the life-world contains the universe; the universe is always disclosed to us from within the life-world\n\n## The Blind Spot\nAdam Frank, Marcelo Gleiser, Evan Thompson in *Aeon*\n\nScientific materialists will argue that the scientific method enables us to get outside of experience and grasp the world as it is in itself. But experience is present at every step. Scientific models must be pulled out from observations, often mediated by our complex scientific equipment. They are idealisations, not actual things in the world.\n\n\"In principle, it is absurd to think that we can explain consciousness by reducing it to certain objects of science, since these objects are abstract relational structures extracted from the life-world of lived experience\" (Husserl)\n\nQuantum-Bayesianism (QBism) combines quantum information theory and Bayesian probability theory. It interprets the irreducible probabilities of a quantum state not as an element of reality, but *as the degrees of belief an agent has about the outcome of a measurement*. In other words, making a measurement is like making a bet on the world’s behaviour, and once the measurement is made, updating one’s knowledge.\n\nAdvocates of this interpretation sometimes describe it as ‘participatory realism’, because human agency is woven into the process of doing physics as a means of gaining knowledge about the world. From this viewpoint, the equations of quantum physics don’t refer just to the observed atom but also to the observer and the atom taken as a whole in a kind of ‘observer-participancy’\n\nThe upshot: there is no simple way to remove our experience as scientists from the characterization of the physical world. Observing it doesn't only affect the measurement, observing it *is* the measurement\n\nScientific knowledge then is a self-correcting narrative made from the world and our experience of it evolving together (see [[thoughts/philosophy of science|Karl Popper's Philosophy of Science]])\n\n## Is Consciousness Primary?\nMichel Bitbol in *NeuroQuantology*\n\nPosits that consciousness is methodological and existentially primary\n\n- Consciousness is not *something*\n\t- Nouns refer to some manipulable or abstract object. But an object is an entity which supposedly exists independently of situations and subjective states.\n\t- This cannot possibly be the case as consciousness as experience is situated -- it is what it feels like to be *a* subject/what it feels like to be\n\nArguing that consciousness is existentially primary and not [[thoughts/ontology|ontologically]] secondary to matter. Sartre: \"consciousness is never merely possible apart from existing; it is no possible instantiation of a definition apart from being actual\"\n\n\u003e They have forgotten that objective knowledge is 'made possible' by carving the lacuna of first person experience within it... scientists who believe that solving many such \"easy problems\" about consciousness will finally clear up the harder problem of its physical origin, look like somebody who believes one can finally reach the horizon by walking far enough\n\nIn the same way as the walker ignores the category gap between a line *in* space and an apparent line seen *through* space, these scientists ignore the category gap between the exclusively structural connections provided by science and the absolute and the absolute of experience analyzed through a structured framework\n\nTwo approaches to overcome the [[thoughts/Hard problem of consciousness#Explanatory Gap|explanatory gap]] both fail\n1. Absolutizing some properties of matter\n\t- If anything can be called \"absolute\", it is conscious experience\n\t\t- Lived experience is immediately and completely given from a self-evidential standpoint\n\t\t- Future experience can by no means *disconfirm* its existence here and now, but only take its place -- it is absolute in the sense that it is indubitable whenever it is present\n\t- Searle: \"Consciousness is the very fact that there is appearance; appearance is the reality of consciousness\"\n\t- Something like \"it appears red\" instead of \"it *is* red\". The subjective statement is admittedly indisputable, but the fact is not. This is a *functional absolutization* of the statement\n2. Relativizing/structuralizing experience\n\t- Karl Mannheim: coordinating the variety of individual or collective perspectives entails an ever increasing formalization of knowledge\n\t- Cassirer: history of science as a whole tends towards relinquishment of substantial and toward research of \"invariant relations\" instead\n\t\t- If properties are referred to, it is only after the concept of property has been redefined in such a way that it includes in itself the concept of relation\n\t- The problem: accounting for the self-evidentially *absolute* conscious experience in terms of the *relational* concepts of objective science\n\t\t- Chalmers and Strawson both attempt to overcome this conflict in naturalist terms, seeking to explain it in terms of some hidden *nonrelational* property\n\t\t- Leibnizian *Monadology*: \"we can attribute to substances no other intrinsic state than that whereby we ourselves inwardly determine our sense\"\n\nPotential solutions\n1. Instead of absorbing or reducing contents of experience or phenomenological reports into the structural network of objective science, strive towards *embedding* these experiences within a broader relational network of which the law-like relations of the objective domain is only a fraction\n2. Varela's notion of \"mutually generative constraints\" towards reciprocal alteration and enrichment of experiential and objective concepts\n\t1. Phenomenological reports may help to pick out and ascribe meaning to previously unnoticed neural configurations\n\t2. Neurological findings may become an incentive for re-categorization and further development in phenomenological research\n\nThese are not 'solutions' to the [[thoughts/Hard problem of consciousness|hard problem]] per-se but rather dissolves it. It does not arise because the physical world is no longer the standard for being, and objectivity is no longer the ultimate standard of method.","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Projects":{"title":"Projects","content":"\nThis is a list of notable projects that I've finished and or currently maintaining. My (considerably longer) list of unfinished ideas can be found [here](thoughts/idea%20list.md).\n\n## bft-json-crdt\n\nThe first public implementation of a JSON-like Byzantine Fault Tolerant CRDT. The project implements a simplified Automerge-like CRDT as well as the ideas in Martin Kleppmann's 2022 paper on _Making CRDTs Byzantine Fault Tolerant_. The blog post also [hit #3 on Hacker News](https://news.ycombinator.com/item?id=33694568) the day it was released and has been [featured in go-to resources for CRDTs](https://crdt.tech/).\n\nGitHub, [[posts/bft-json-crdt|blog post]]\n\n## Tabspace - a scratchspace for your new tab page\nA beautiful new tab replacement that gives you your very own scratch space to help you stay organized and focused. Wanted to experiment with [[thoughts/formality considered harmful|low-friction]] note taking and integrating [[thoughts/game design|game design]] principles of 'juiciness' into UI/UX.\n\n[GitHub](https://github.com/jackyzha0/tabspace), [Chrome Webstore](https://chrome.google.com/webstore/detail/tabspace/kcinhoikngobhiikicnpahoanenlnlha)\n\n## miniraft - \u003c1kloc Raft consensus algorithm implementation\nA minimal implementation of the [[thoughts/Raft Consensus Algorithm|raft Consensus Algorithm]] with a focus on readability/understandability.\n\nThis project was created as an exercise in implementing and learning about distributed systems. Do NOT use this in production.\n\n[GitHub](https://github.com/jackyzha0/miniraft), [Documentation](https://jzhao.xyz/miniraft/miniraft/)\n\n## Cursor Chat -- open source library for digital presence\n\n[GitHub](https://github.com/jackyzha0/cursor-chat), [Demo](https://jzhao.xyz/cursor-chat/)\n\nA lightweight (31.8kB) cursor chat à la Figma for digital co-existing + presence. An experiment in spatial software, [interaction design](thoughts/interaction%20design.md), and [digital commons](thoughts/digital%20commons.md).\n\nBuilt on top of [yjs](https://github.com/yjs/yjs) and [perfect-cursors](https://github.com/steveruizok/perfect-cursors).\n\n## Telescopic Text -- open source library for expandable text\n\n[GitHub](https://github.com/jackyzha0/telescopic-text), [Demo](https://jzhao.xyz/telescopic-text/demo/)\n\nAn open-source library to help with creating expandable text, inspired by [StretchText](https://en.wikipedia.org/wiki/StretchText) and [TelescopicText](https://www.telescopictext.org/text/KPx0nlXlKTciC).\n\nI've been thinking a lot about creating a browsable store of knowledge that provides something useful at all distance scales (e.g. viewing the entire library, just a subcategory, a single file, etc.) and concepts like Telescopic Text are a first step in creating more information scales than just a single document level.\n\n## Portal -- zero-config [P2P](thoughts/peer-to-peer.md) encrypted folder syncing\n\n[Producthunt](https://www.producthunt.com/posts/portal-11), [GitHub](https://github.com/jackyzha0/portal)\n\nPortal is a command line tool that syncs folders between multiple devices. Perfect for syncing photos/videos/code between many devices without using a 3P tool like GitHub, Email, or Google Photos. Built on top of the Hypercore protocol with Ink for the CLI.\n\nBuilt with: [[thoughts/Hypercore|Hypercore]], React, Ink, and Typescript\n\n## Quartz -- create and publish digital gardens for free\n\n[Site](https://quartz.jzhao.xyz/), [GitHub](https://github.com/jackyzha0/quartz)\n\nQuartz is a tool and workflow to make maintaining and publishing a digital garden and second brain extremely easy. Think Obsidian Publish but free. Links are scraped and processed using a GitHub action written in Go and dumped into a JSON file to be rendered by Hugo.\n\nOver 1.2k monthly users and 300+ forks on GitHub.\n\nBuild with: Hugo, Obsidian, Github Pages, Go, SCSS, and JavaScript.\n\n## Legist -- a platform to summarize policy for [democracy](thoughts/democracy.md)\n\n[DevPost (Finalists at HTN 2020++)](https://devpost.com/software/legist), [GitHub](https://github.com/htn2020plusplus)\n\nLegist is a web platform that allows users to digest policies in an efficient and accessible manner. Legist allows users view automagically summarize pieces of policy + legislation while still maintaining the key takeaways, view and filter policies by category, and subscribe to periodic rollups on updates. Frontend was built with React + Typescript + Chakra UI. Text summarization was done using DistilBART, Named-entity recognition with BERT, and zero-shot text categorization using BART. All models were served with BentoML. Built at Hack the North 2020++, winning the Founder Institute Fellowship Prize and finalist among over 3000+ participants\n\nBuilt with: React, Firebase, GraphQL, CockroachDB, Node.js, Flask, Docker, MailGun, BentoML, HuggingFace, TypeScript, Python, JavaScript\n\n## ctrl-v -- a modern, open-source pastebin\n\n[App](https://ctrl-v.app/), [GitHub](https://github.com/jackyzha0/ctrl-v)\n\nctrl-v is a modern, open-source pastebin with LaTeX and Markdown rendering support. Any user can create a paste without an account, with the ability to protect it with a password and set an expiry date. Additionally, ctrl-v does code highlighting as well as LaTeX and Markdown rendering. Pastes are stored in a MongoDB Atlas instance. Backend is a containerized Go service deployed on Google Cloud Run. Frontend is a SSR Next.js app hosted on Vercel.\n\nBuilt with: React, Next.js, Vercel, styled-components, MongoDB, Cloud Run, GCR, JavaScript, Go, Docker\n\n## reflect -- a mindful website blocker for the productive\n\n[Site](https://getreflect.app/), [GitHub](https://github.com/jackyzha0/reflect-chrome)\n\nreflect is a browser extension with 800+ active users focused around asking users to reflect before visiting distracting sites, helping to reduce mindless scrolling while still being able to get work done. During closed-beta, we created a Go service that logged user intents to a Cloud SQL database and did intent classification by serving a basic Flask API. We then trained an LSTM network in Keras on the closed-beta data and augmented it using [[thoughts/NLP|NLP]] data augmentation techniques, reaching ~86% classification accuracy. Finally, the model was ported to Tensorflow.js where it runs in-browser within the extension which is written in Typescript.\n\nBuilt with: Kubernetes, Docker, GKE, Cloud SQL, Keras, Tensorflow.js, Flask, CircleCI, TypeScript, Python, Go\n\n## nanoDB -- a simple, easy, and debuggable document database\n\n[GoDoc](https://godoc.org/github.com/jackyzha0/nanoDB), [GitHub](https://github.com/jackyzha0/nanodb)\n\nnanoDB arose out of many frustrations I've personally come across while prototyping, namely 1) difficulty of debugging data 2) faffing around with language specific drivers and 3) reference resolution. As a result, nanoDB stores everything on disk as a JSON document, has built-in reference resolution, and can be used fully through a REST API. Think of it like Redis but with MongoDB style documents — all of which is on-disk, human-readable, and through a REST API. The project is fully written in Go and is thoroughly unit-tested. It features a standalone server binary which creates a nanoDB server, as well as a shell which allows you to do some basic document inspection.\n\nBuilt with: Docker, Go\n\n## readAR -- an AR app to help those with learning disabilities\n\n[DevPost (TreeHacks 2020, Microsoft Azure Champ Prize - Hack for Good)](https://devpost.com/software/readar-twh41m), [GitHub](https://github.com/jackyzha0/treehacks2020-backend)\n\nreadAR is a mobile AR app re-renders text to be more dyslexic-friendly, and adds context-dependent word definitions and images. A custom BERT model was created and trained for word sense disambiguation (WSD), achieving a 76.6% F1% score on the test dataset which is only ~5% away from state-of-the-art. This model is served through Flask on an Oracle VM Instance. The API is also responsible for our image processing pipeline, which is a conglomerate of different Azure APIs (OCR, Text Analytics, Bing Search).\n\nBuilt with: PyTorch, Flask, Docker, Azure, Oracle Cloud, Python, Bash\n\n## Impostor -- group pomodoro timer with a twist\n\n[Devpost (Finalist at DubHacks 2020, Disney Prize)](https://devpost.com/software/impostor), [GitHub](https://github.com/h4ckh0use)\n\nImposter is a productivity timer designed to keep friends on task together even when working remotely. The Chrome extension monitors your browser tabs, checking against a blocklist of unproductive sites. If one of those websites is visited, the backend will be notified via Firebase and will notify all users in the room through a WebSocket connection. Chat and character customization is also supported.\n\nBuilt with: Firestore, WebSockets, Node.js, Heroku, JavaScript\n\n## Speech2Braille -- a wearable device to transcribe speech\n\n[Paper (Silver + 10k in awards at Canada Wide Science Fair)](res/gvrsf_report.pdf), [GitHub](https://github.com/jackyzha0/Speech2Braille)\n\nSpeech2Braille was created to help the over 360 million people in the world who have debilitating hearing loss. This project entailed creating an end-to-end speech recognition system using an Deep LSTM and a portable device to display braille. The device is able to recognize audio and transcribe it into Braille through the haptic feedback device via a novel neural network architecture. The feedback device is a self-made GPIO hat, consisting of 6 solenoids. The neural network itself is 2 layered LSTM-CTC network with 256 hidden cells in each layer, achieving 92% state-of-the-art word error rate on the TIMIT dataset.\n\nBuilt with: Tensorflow, numpy, Raspberry Pi, Python, Bash\n\n## PacketBook -- blockchain banking without [Internet](thoughts/Internet.md)\n\n[Devpost (nwHacks 2018 SAP Prize, Top 30)](https://devpost.com/software/packetbook), [GitHub](https://github.com/jackyzha0/PacketBook)\n\nPacketBook is a financial accessibility chatbot, fully accessible through the SMS (text messaging) protocol. Users are able to issue simple commands to register, check their balance, deposit, withdraw, and send money. These commands are secured with two-factor authentication through a Flask server on Heroku with Twilio. The backend that handles transaction is written with Node and Express and deployed on stdlib. PacketBook is unique in that it leverages the Stellar blockchain and tokens (XLM) for its transactions which greatly reduces operating overhead with its minimal transaction costs (around 1/100 of a cent per transaction).\n\nBuilt with: MongoDB, Node.js, Express, Flask, Stellar, Heroku, JavaScript, Python","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Prolly-Trees":{"title":"Prolly Trees","content":"\n## Why not just B-Trees?\nData structures with hysteresis have path dependency, in the case of B-trees the actual tree structure depends on the order of inserts and removes.\n\n## Merkle Search Trees\n[Source](https://0fps.net/2020/12/19/peer-to-peer-ordered-search-indexes/)\n\nMerkle Search Trees are an incremental method for constructing determinstic B-trees. Their idea is to first hash all content which is inserted into the tree, and then to place items at a level proportional to the number of 0’s in the prefix of their hash written in base B.\n\nUnder the assumption that all hashes are uniformly distributed, a Merkle search tree has the following properties:\n\n1. Every internal node has on average B children\n2. All leaves are on average the same distance from the root\n3. The tree is deterministic\n\nHowever, these are not Sybil resistant\n\n## Prolly Trees\n[Source](https://github.com/attic-labs/noms/blob/master/doc/intro.md#prolly-trees-probabilistic-b-trees)\n\nA Prolly Tree is a search tree where the number of values stored in each node is determined probabilistically, based on the data which is stored in the tree.\n\nWithin each hash, we look for a pattern that has a known probability of occuring. If the pattern is found, that position is a boundary. We slide the window forward to the end of the containing item, and write a new chunk containing the bytes between this boundary and the previous, if any. The resulting chunk is stored in a [[thoughts/content addressed storage]] system\n\nIn Noms, the pattern we look for is the 12 high bits being 1. Since this has a probability of 1/2^12, the average chunk size in Noms is 4kb.","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Protocol":{"title":"Protocols","content":"\nDefines:  \n- Roles of communicating entities  \n- Format of messages  \n- Order of messages  \n- Actions taken on the transmission, receipt of a message, or other event\n\n## Protocols as State Machines\nA fully-defined protocol must provide a proper action for any event in any state. Most protocols can be modelled in terms of state machines.\n\nEach interaction can have its own state machine.\n\n## Open vs Closed Protocols\n- Open Protocols\n\t- Examples: HTTP, SMTP, SSH\n\t- Usually defined in RFC documents\n\t- Different implementations\n\t- Allows a community, generally good!\n- Proprietary Protocols\n\t- Examples: Skype, iCloud, Zoom\n\t- Only one implementation\n\n## Building a Reliable Protocol\n- Generally includes a few states\n\t- Idle - waiting for something to be initiated\n\t- Waiting - waiting for a response\n- Edges are actions (e.g. receives a response of a certain type) or timeouts\n- Edge cases\n\t- Timeout too soon! (may result in getting two ACKs)\n- Timeout formulas\n\t- Assuming measured round trip time (RTT) of $t$\n\t- Estimated RTT\n\t\t- $ERTT_i = (1-\\alpha) ERTT_{i-1} + \\alpha t$\n\t- Deviation of RTT (captures jitter):\n\t\t- $\\Delta RTT_i = (1 - \\beta)\\Delta RTT_{i-1} + \\beta |t - ERTT_{i-1}|$\n\t- Timeout:\n\t\t- $ERTT_i + 4 \\Delta RTT_{i}$\n\t- Suggested: $\\alpha = 0.125$, $\\beta = 0.25$","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Public-key-Infrastructure":{"title":"Public-key Infrastructure","content":"\nPublic key infrastructure (PKI) is a catch-all term for everything used to establish and manage [[thoughts/Asymmetric Key Cryptography|public key cryptography]]. Related is the [[thoughts/Key Sharing Problem|key sharing problem]].\n\nFor example, it can help ensure that all peers in the network know each other's public keys (i.e. that public keys are... public knowledge)\n\n|Private Key|Public Key|\n|--|--|\n|Stays secret on your device|Shared with all your peers on the network|\n|Acts like a password -- only you have it, and it's necessary for proving ownership of your public key|Acts like a User ID -- people publicly know about this to identity you|\n|Can create signatures -- unforgeable, tamper-evident certifications that *you* created that data|Allows others to verify the integrity of your signature|\n|A mailbox key -- allows you to open messages that only you can see|A mail slot -- allows others to send you data only you can see|\n\n## PGP\nPretty Good Privacy\n\nA sort of web of [[thoughts/trust|trust]] protocol where you determine whether to trust another party based on who else you know has trusted that party.\n\n\u003e As time goes on, you will accumulate keys from other people that you may want to designate as trusted introducers. Everyone else will each choose their own trusted introducers. And everyone will gradually accumulate and distribute with their key a collection of certifying signatures from other people, with the expectation that anyone receiving it will trust at least one or two of the signatures. This will cause the emergence of a decentralized fault-tolerant web of confidence for all public keys.\n\nThe web of trust mechanism has advantages over a centrally managed public key infrastructure scheme","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Putnams-Ant-Argument":{"title":"Putnam's Ant Argument","content":"\n-   The ant who traces a line that ends up looking like a caricature of Winston Churchill. Is it a picture or representation of him?\n-   resemblance is not necessary nor sufficient for representation\n\t-   not sufficient → A can resemble B even if it fails to represent B\n\t-   not necessary → A can represent B even if A fails to resemble B\n-   do we need intention?\n-   how do you have a thought _about_ something?\n    -   the problem of intentionality\n    -   \"No physical object can, in itself, refer to one thing rather than to another; nevertheless, thoughts in the mind obviously do succeed in referring to one thing rather than another. So thoughts (and hence the mind) are of an essentially different nature than physical objects\"\n-   words and pictures aren't inherently _about_ something, that meaning is added via our own attitudes\n    -   if so, what do our attitudes depend on?\n-   what does matter for representation is some sort of causal link back to the [original thing](thoughts/originality.md)\n    -   X caused Y to do Z","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/RDF":{"title":"RDF","content":"\n\u003e RDF is a standard model for data interchange on the Web\n\nRDF can be understood as a linking structure which forms a directed, labeled graph, where the edges represent the named link between two resources, represented by the graph nodes.\n\nSee also: [[thoughts/LDP|LDP]]\n\n## RDF Triple\nRDF extends the linking structure of the Web to use URIs to name the relationship between things as well as the two ends of the link (this is usually referred to as a “triple”). Much like a relational database, information in a triplestore is stored and retrieved via a query language.\n\nA store of RDF Triples is called a triplestore.\n\n## Search\nFrom [Intertwingle](https://www.jwz.org/doc/intertwingle.html)\n\nFollowing a link only gives you one dimension of mobility. A [[thoughts/search|search]] can be seen as following multiple links, and finding the intersection (or union) of the results of those links.\n\nAny link-relationship should be searchable. For example:\n-   All messages from _person_ between _date_ and _date_ that have _pattern_ in the body.\n-   All messages from _person_ which contain a message from _person_.\n-   All messages to _mailing-list_ which refer to _URL_.\n-   All messages containing _text_ in the main body, but not in an attachment.\n-   All messages with an attachment whose file name contains _string_.\n\n## Turtle\n[Source: W3](https://www.w3.org/TR/turtle/)\n\nA textual syntax for RDF called Turtle that allows an RDF graph to be completely written in a compact and natural text form, with shorthands for common usage patterns and datatypes\n\n```xml\n@base \u003chttp://example.org/\u003e .\n@prefix rdf: \u003chttp://www.w3.org/1999/02/22-rdf-syntax-ns#\u003e .\n@prefix rdfs: \u003chttp://www.w3.org/2000/01/rdf-schema#\u003e .\n@prefix foaf: \u003chttp://xmlns.com/foaf/0.1/\u003e .\n@prefix rel: \u003chttp://www.perceive.net/schemas/relationship/\u003e .\n\n\u003c#green-goblin\u003e\n    rel:enemyOf \u003c#spiderman\u003e ;\n    a foaf:Person ;    # in the context of the Marvel universe\n    foaf:name \"Green Goblin\" .\n\n\u003c#spiderman\u003e\n    rel:enemyOf \u003c#green-goblin\u003e ;\n    a foaf:Person ;\n    foaf:name \"Spiderman\", \"Человек-паук\"@ru .\n```\n\n## JSON-LD\nA **JSON-LD document is both an RDF document and a JSON document** and correspondingly represents an instance of an RDF data model\n\n```json\n{\n  \"@context\": \"[https://json-ld.org/contexts/person.jsonld](https://json-ld.org/contexts/person.jsonld)\",\n  \"@id\": \"[http://dbpedia.org/resource/John_Lennon](http://dbpedia.org/resource/John_Lennon)\",\n  \"name\": \"John Lennon\",\n  \"born\": \"1940-10-09\",\n  \"spouse\": \"[http://dbpedia.org/resource/Cynthia_Lennon](http://dbpedia.org/resource/Cynthia_Lennon)\"\n}\n```","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/RPC":{"title":"RPC","content":"\nRPC: Remote Procedure Call\n\nSometimes called a remote function call, it is a call to a function whose implementation is on another node.\n\nRPCs needs an RPC client/server to mediate the call.\n- Client marshals (encode) arguments and passes it to the server\n- Server unmarshals (decodes) arguments and runs the implementation\n- ... same in reverse for response\n\nGenerally an HTTP request but other types of RPCs exists as well (e.g. gRPC)","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/RSA":{"title":"RSA","content":"\nA form of [[thoughts/Asymmetric Key Cryptography|asymmetric cryptography]].\n\nFull name is the Rivest, Shamir, Adelson Algorithm\n\n- Relies on modular arithmetic\n\t- Unfortunately, also really slow :((\n\t- Encryption/decryption are computation-heavy. Ok for occasional communication but too slow for extensive data transfer\n\t- Good for establishing initial secure connection\n- Hard to crack because to determine $d$ from $(n, e)$ requires computing factors of $n$ which is a hard problem\n- Choose two large primes $p$ and $q$ (1024-bits each)\n- Compute $n = pq, z = (p-1)(q-1)$\n- Choose $e \u003c n$ that has no common factors with $z$ (commonly 3)\n- Choose $d \u003c n$ such that $ed \\mod z = 1$\n- Public key: $K^+_B=(n,e)$\n- Private key: $K^-_B = (n,d)$\n- Encrypting is then $encrypt(m) = m^e \\mod n$\n- Decrypting is then $decrypt(c) = c^d\\mod n$\n\n[[thoughts/Key Sharing Problem|Key exchange]] can also be performed using RSA\n- If Alice and Bob both know the other's public key, how can they agree on a shared \"session\" key?\n- Alice chooses key $K_S$ and encrypts it with Bob's public key and Alice's private key $K_A^-(K_B^+(K_S))$\n- Bob decrypt's the message using his private key and Alice's public key $K_B^-(K_A^+(K_A^-(K_B^+(K_S)))) = K_S$\n\nSee also: [[thoughts/Elliptic-curve Cryptography (ECC)|elliptic curve cryptography]]\n\n","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Raft-Consensus-Algorithm":{"title":"Raft Consensus Algorithm","content":"\n\u003e An understandable [[thoughts/consensus|consensus]] algorithm\n\nA distilled version of the [Raft paper](https://raft.github.io/raft.pdf). For a more graphic version, see this [visualization of Raft by The Secret Lives of Data](http://thesecretlivesofdata.com/raft/).\n\nA really good [video review of the algorithm by Martin Kleppmann](https://www.youtube.com/watch?v=uXEYuDwm7e4\u0026list=PLeKd45zvjcDFUEv_ohr_HdUFe97RItdiB\u0026index=18)\n\nFor a [[thoughts/Byzantine Faults|BFT]]-resilient version of Raft, see [[thoughts/Tangaroa|Tangaroa]].\n\n## Distributed Consensus\nWhen you only have one machine, it is easy to figure out what the state of that machine is in. But what happens when you have multiple machines that need to agree on some value or state?\n\nHow do we arrive at a shared set of state across multiple machines that can be as far as opposite sides of the world? How do we handle machines crashing and become unable to respond to incoming requests?\n\nThis is the problem of *distributed consensus*\n\n## Replicated State Machines\nGenerally, this is done using a log of actions that are *replicated* across all machines. Keeping this replicated log consistent between all the machines is the job of the *consensus algorithm*. They allow a collection of machines to agree on some shared state which still make sense even when there is latency or unavailability.\n\nIn more formal language, consensus algorithms should typically have the following properties:\n1. [[thoughts/safety|Safety]] in the face of network delays, partitions, packet loss, duplication, and reordering (except under certain cases where there are no known solutions, e.g. [[thoughts/Byzantine Faults|Byzantine Fault Tolerance]])\n2. Functional (available) as long as the majority of servers are operational and can communicate\n3. Latency resilient and does not depend on timing of messages to ensure consistency\n\nRaft is one such consensus algorithm for managing a replicated log. It is an alternative to [Paxos](\u003chttps://en.wikipedia.org/wiki/Paxos_(computer_science)\u003e) which is the main consensus algorithm in use over the last decade. The main aim is to make it *understandable* to builders and students alike.\n\nIt is important to note that Raft assumes that all messages have been authenticated/authourized. It hands this responsibility to the [[thoughts/Transport Layer|transport layer]] to deal with. As such, Raft *does not have any protection against malicious actors*. More discussion in this [Google Groups conversation](https://groups.google.com/g/raft-dev/c/8WIrWfzIkvM).\n\n## Consensus\nRaft implements consensus by first electing a *leader*, then giving that leader temporary but complete responsibility for managing the replicated log. When a leader fails or becomes disconnected, a new leader is elected.\n\nGiven this approach, Raft decomposes this consensus into 3 independent subproblems\n1. Leader election: how do we choose a new leader when an existing leader fails?\n2. Log replication: how does the leader accept new log entries from clients and replicate them across all the other machines?\n3. [[thoughts/safety|Safety]]: when is it safe to consider log entries as 'agreed upon' and fully replicated across all machines?\n\nA server can only be in one of 3 states:\n1. Leader: handles all client requests\n2. Follower: issues no requests but respond to requests from leaders and candidates \n3. Candidate: used to elect a new leader\n\nState transitions follow the state diagram below:\n![[thoughts/images/raft-state-diagram.png]]\n\nAll Raft servers communicate using remote procedure calls (RPCs) that happen over the network. The basis consensus algorithm only requires 2 types of RPCs, RequestVote and Append-Entries. These are retried if a request times out and are issued in parallel for best performance.\n\n## Leader Election\nLeaders are active for *terms* of arbitrary length (this is randomly determined as we will see later). These are numbered with consecutive and monotonically increasing integers.\n\nEach term begins with an election in which one or more candidates attempt to become leader. If a candidate wins the election, then it serves as leader for the rest of the term.\n\n![[thoughts/images/raft-elections.png]]\n\n### Initiate State\nServers start up in the follower state.\n\nA server remains in the follower state as long as it receives valid RPCs from a leader or candidate (this is usually in the form of a 'heartbeat' from a leader which is an empty AppendEntries [[thoughts/RPC|RPC]] with no log entries).\n\nIf a follower receives no communication over a period of time called the *election timeout* (randomized between 150ms and 300ms), then it assumes there is no viable leader and begins an election to choose a new leader.\n\n### Beginning an Election\nA follower increments its current term and transitions to candidate state. It then votes for itself and issues RequestVote RPCs in parallel to each of the other servers in the cluster.\n\nIt is important to note that a server can only vote once per election. *It will give its vote to the first server that asks for it and meets the requirements for election.* A server should *only* vote for a candidate if the candidate's log is more up-to-date than its own. If the logs have different terms, the one with the larger term is more up to date. If the logs have the same term, the longer log is more up-to-date.\n\nA candidate remains a candidate until one of 3 events happens:\n1. It wins the election. It received votes from a majority of servers in the cluster. Majority rule ensures that at most one candidate can win the election for a particular term. It then sends heartbeat messages to all other servers to establish authority and prevent new elections.\n2. Another server establishes itself as leader. Received an AppendEntries [[thoughts/RPC|RPC]] from another server claiming to be leader. This claim is legitimate if the leader's term is at least as large as the candidate's current term.\n3. A period of time goes by with no winner. Possible if many followers become candidates at the same time, votes can be split so no candidate wins majority. When this happens, each candidate times out and starts a new election by incrementing its term and initiating another election. Raft uses randomized election timeouts to ensure split votes are rare.\n\nAfter a leader has been elected, it beings servicing client requests.\n\n### Properties\nGenerally, Raft will be able to elect and maintain a steady leader as long as the system roughly follows the timing requirement: `broadcastTime \u003c 10 * electionTimeout \u003c 100 * MTBF` where `broadcastTime` is amount of time for a server to send an [[thoughts/RPC|RPC]] to every server in the cluster and `MTBF` is the mean time between failure for a server.\n\nBroadcast time should be roughly an order of magnitude less than the election timeout so that leaders can reliably send heartbeat messages required to keep followers from starting elections (similar to having RTT be roughly a magnitude smaller than request timeout). \n\nThe election timeout should be a few orders of magnitude less than MTBF so that the system makes steady progress. When a system crashes, it will be down for roughly the period of the election timeout.\n\n## Log Replication\nEach client request is a command to be executed by the replicated state machines. The leader appends the command to its own log as a new entry, then issues AppendEntries RPCs in parallel to each of the other servers to replicate the entry.\n\nA single log entry contains the state machine command from the client request along with the term number when the entry was received by the leader. A log entry is considered 'safely replicated' or *committed* once it is replicated on a majority of servers.\n\nAfter an entry is committed, it applies the entry to its own state machine and returns the result of that execution to the client. When a follower learns a log entry is committed, it too applies the entry to its own state machine.\n\nThe *Log Matching Property* is maintained by Raft which guarantees\n1. Log entries with same index and term number store the same command\n2. Log entries with same index and term number mean that all preceding entries must identical (all log entries prior to that index are correctly replicated)\n\nWhen a leader comes to power, it just begins normal operation, and the logs automatically converge in response to failures of the AppendEntries consistency check.\n\nTo bring a follower's log into consistency with its own, the leader must find the latest log entry where the two logs agree. To do this, the leader keeps a value `nextIndex` for each follower which is the number of the *next log entry the leader will send to that follower*. The leader pings each follower with a AppendEntries [[thoughts/RPC|RPC]] call with that `nextIndex` value. If this call is successful, the leader knows that this follower is up to date. If it fails, then the leader decrements `nextIndex` again until it reaches a log entry that does succeed.  At this point, the follower's logs will be removed (as anything between `nextIndex` and what the follower currently has is conflicting) and the follower's log is now consistent with the leader's and will remain that way for the rest of the term.\n\n## Unbounded Logs (Log Compaction)\nIn a practical system, a log cannot grow without bounds. The simplest solution is to use snapshotting where the entire current system state is written to a snapshot on stable storage, then the entire log up until that point is discarded.\n\nAll snapshots are taken independently by each server. Each snapshot contains data like last included index, last included term, and the state machine state.\n\nSometimes, snapshots need to be sent from leader to followers if the followers lag behind using the InstallSnapshot [[thoughts/RPC|RPC]]. This can happen when the leader has discarded the next log entry that needs to be send to a follower (e.g. new server joining cluster).\n\nWhen a server receives a InstallSnapshot [[thoughts/RPC|RPC]] call, it usually discard its entire log. In the odd case where the server receiving the [[thoughts/RPC|RPC]] call has *more* entries in its log than the snapshot, it deletes all log entries covered by the snapshot but entries following the snapshot are still valid and must be kept.\n\nOther options like log cleaning and log-structured merge trees are also possible.\n\n## RPCs\nAll Raft RPCs are idempotent so sending multiple RPCs causes no harms (e.g. telling a follower to AppendEntries it already has does nothing). \n\n## Liveness Guarantees\nAdditionally, note that Raft (in its current specification) is *not resilient to omission faults*. This can be resolved with two additional RPCs however:\n1. PreVote: requires potential candidates to run a trial election to test if they can win an election before incrementing their term and running a normal election using RequestVote\n2. QuorumCheck: requiring leaders to actively step down if they do not receive AppendEntries responses from a majority of servers\n\n## Implementation\nYou can find a reference implementation on GitHub\n\n- [Miniraft Github Repository](https://github.com/jackyzha0/miniraft)\n- [Miniraft Crate Documentation](https://jzhao.xyz/miniraft/miniraft/)\n\n","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Random-Forest":{"title":"Random Forest","content":"\nExample of an [[thoughts/Ensemble method|Ensemble method]]. They are non-parametric\n\nThey work by taking a vote from a set of deep [[thoughts/decision tree|decision trees]]. Two key ingredients to help ensure the deep decision trees make independent errors\n1. Bootstrap sampling: generate different \"versions\" of your dataset\n\t- Usually done by sampling with replacement $n$ times, this creates a bootstrap sample\n\t- On average, this maintains roughly the same distribution as the original\n2. Random Trees: grow decision trees that incorporates some randomness\n\t- Randomly sample a small number of possible features (typically $\\sqrt d$)\n\t- Only consider these random features when searching for the optimal rule so splits will tend to use different features in different trees","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Reductionism":{"title":"Reductionism","content":"\nReduction is a relationship between theories.\n\n## Microreduction\nMicroreduction is a specific subset of reduction that focuses on explaining the macro using the micro ([emergent behaviour](thoughts/emergent%20behaviour.md))\n\n### Mind-brain Reductionism\nA successful neuroscience would show how to reduce statements about mental properties ([qualia](thoughts/qualia.md)) to statements about neural properties (actual neural activity).\n\n### Functionalism\nAn alternate to this is functionalism, wherein a successful neuroscience would show how to reduce statements about mental properties to statements about functional properties (an abstraction to apply this to other potentially non-human conscious minds -- e.g. AI)","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Rhizome-Philosophy":{"title":"Rhizome Philosophy","content":"\nSee the main [[thoughts/Rhizome Proposal|Rhizome Proposal]]\n\n### Interoperable\nData on the web today is mostly treated as second-class to applications. In this form, data is contextual -- it only makes sense in the context of what you can do in an application. At its best, developers and companies expose this data in the form of an API, not allowing you to actually access the underlying data but rather only giving you a limited range of actions or verbs that you can perform on it.\n\nThis is known as *verb-based interoperability* and it [creates a form of n-to-n problem](https://twitter.com/andy_matuschak/status/1452438198668328960) where every app needs to know what the APIs of another app are to even begin to interoperate. Data exported in this form rarely makes sense on its own outside of the application and often requires a lot of glue code in order to make the data the right format so that you can pass it off to the next application. In fact, companies are *incentivized* to not provide an easily understandable format that users can easily export. Why would they make it easier for people to leave their product?\n\nUsers shouldn't have to keep using platforms they don't like just because it's impossible to move all the data they have to another. Instead, users should *want* to use platforms because it fits the needs they have.\n\nThis might be possible if we treat data like a **noun**. How do we create sources of truth that are *legible outside of the application*, possibly in ways that the application developer never anticipated? Data-based interoperability can use the shared data directly. Once an app knows how to read a data format, it can read that data regardless of which app produced it.\n\nThis enables users to escape the iron-clad grasp of corporations which hold your data hostage in exchange for usage of their application. Users shouldn't have to sign away all rights to their data when they agree to use app -- they should control what applications have access to their data and how.\n\n### Modular\nWhen users choose to use an application, they generally have no choice but to use the whole stack that application uses.\n\nIn choosing an application, you are ceding agency to the application to decide how it stores the data, how it transforms that data, and how it displays that data. Don't like the way an application looks and the app doesn't give you an option to customize it? Better find a new app or deal with it.\n\nCan we give agency back to users by create modular layers so users can pick and choose what layers they want? Can we make it so these layers are available to others to reuse and adapt to their own needs?\n\n### Local-first\nThe cloud gives us collaboration, but old-fashioned apps give us ownership. Can’t we have the best of both worlds?\n\nWe should be able to use our applications without needing to be connected to an internet to load a 4MB web page. Many modern 'desktop' applications are simply Electron wrappers around a web application, providing no such thing as 'offline-support'.\n\nYour apps shouldn't break as soon as you reach an area with spotty internet connection or when some company's server goes down. When you work with local-first software, your work should continue to be accessible indefinitely, even after the company that produces the software has died. You shouldn't need to worry about companies selling your data to advertisers or using it to train large language models without your permission because you control exactly who has access and permission to your data.\n\nThe internet should be used to synchronize, update, and collaborate, not be a requirement for basic function. Your data should stay on your device unless you say otherwise.\n\n### Collaborative\nOf course, local-first doesn't mean local-only.\n\nIt was a dream of the early internet to be able to make spaces anyone can inhabit and enjoy, little pockets of [[thoughts/digital commons|digital commons]] that are tended to by many. \n\nApps should have the freedom to create new mediums of being digitally present with others. Apps should easily be able to have a digital indication that a space is lived in and occupied.\n\nAs of now, most platforms keep a primative chat log or history but thats it. What if there was a way to create digital [gardens](https://twitter.com/samihusseni/status/1329499588982575104) to foster and maintain existing relationships? A commonspace you could both take care of, share, and contribute to. Completely private common spaces often allow users to put whatever and allow people can construct their own digital nooks and cozy spaces. Places where people can consume the firehose of information through a feed or slowly and lazily through dialogue (see: [friction](thoughts/friction.md), [pace layers](thoughts/pace%20layers.md)).\n\nA collaborative application doesn't necessarily need completely open to the public either. It could just be among your family or close friends. It could just be permeable enough to be discovered by those curious enough to add their own drawings and words and details just hidden enough to be carefully unearthed by the intentional visitor. An app can be a [[thoughts/cozy software#An app can be a home-cooked meal|home-cooked meal]].\n\n### Simple Developer Experience\nLast but not least, the experience should feel pleasant to both build and use.\n\nThere are clearly social problems when it comes to making collaborative apps (e.g. [[thoughts/tragedy of the commons|tragedy of the commons]], [[thoughts/evaporative cooling|evaporative cooling]]), but even *enabling* this collaboration on a technical level to happen in the first place is already really difficult.\n\nThe reason why client-server is so much easier to develop is because of ACID properties. Everything is atomic, things are easy to reason about. P2P and distributed technologies generally are much more difficult to reason about with things like eventual consistency making it hard to understand what is *actually* happening in the code. Networking quirks like [[thoughts/NAT|NAT]] traversal make direct connections \n\nPeople tend to lean towards client-server models because nobody has made it easy to make P2P software. Almost everything today requires users to still setup their own signalling servers, STUN servers, ICE servers, and a bunch of other infrastructure that makes client-server applications seem like child play.\n\nBut what if developers didn't have to worry about server hosting *or* complexities of eventual consistency? Can we make the tech really easy to build so even hobbyists can quickly spin up a chat app for their own friends that suits their own needs?\n\nThe libraries that enable this form of P2P software should be able to plug and play into existing applications. The experience should be simple enough that your average CS student should be able to write a simple P2P chat app just as easily (if not easier) as if they wrote it as a client-server application.","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Rhizome-Proposal":{"title":"Rhizome Proposal","content":"\n\u003e Companies of the future should derive value from the intelligence they provide on top of existing data rather than have the value be just the data.\n\n![[thoughts/images/Rhizome.png]]*How can we imagine more rhizomatic structures instead of arborescent systems?*\n\n*DISCLAIMER: To borrow words from [Robin Sloan](https://www.robinsloan.com/lab/specifying-spring-83/): While it is okay to share this link, I want to underscore that I am sending it specifically to you with the hope that you will really think about it! At such a primordial stage, a proposal like this doesn’t need diffuse, drive-by attention. It needs, instead, close consideration and generous imagination.*\n\nThe competitive advantage of the vast majority of today’s centralized platforms are in their data moats and network effects. The major reason why these platforms remain so dominant is because of their data and users, not because of how good the service quality is.\n\nAs a result, apps have become inseparable from data. In an ideal world, there is data-neutrality. Much like how net neutrality strives to maintain separation of provider and content markets, data neutrality strives to maintain the separation of data and application markets.\n\nIn an ideal world, we focus on local-first software that works independently of large platforms – at the end of the day platforms should be used to support efficiency of collaboration at scale, not to gate users from moving their data for the sake of retention.\n\nI've spent a lot of time looking at the retrospectives of peer-to-peer protocols and distributed applications and there are 3 common themes I've found in all of them:\n\n1. Running your own infrastructure is hard. We need to think about the average non-technical user.\n2. Data availability and durability is largely unsolved. In most p2p systems, offline collaboration isn't possible.\n3. Lack of thought behind off-ramping off of existing systems. We have shiny new systems, how do we get people to switch to it?\n\nWhile blockchain can be used in creative ways to overcome most of these, it currently comes with a large set of downsides that make it hard to build on top of it (e.g. expensive to store things completely on chain, slow confirmation times).\n\nWhile I hope these will be mitigated in the future, I wanted to spend time exploring alternative and potentially more general-purpose means of addressing these main problems without blockchains.\n\n**My main research question is about how we can enable data-neutrality on a web dominated by data moats.** A few consequences of this work:\n\n1. Single purpose apps backed by general purpose data. If two apps are views on the same data, any change to the underlying data will instantly update both apps\n2. Applications ask for access rather than store their own data. You give apps permission to read or write specific parts of your data\n3. As there are separate markets for data and applications, it creates competition based on service quality rather than on data ownership\n4. We can get the convenience of a single centralized platform without the lack of agency that typically comes with it.\n\nI’m tentatively calling this project Rhizome. It aims to be a data-persistence and identity layer for the distributed web.\n\n1. A personal data pod that *you* own. Think iCloud or Dropbox but you have agency over how much storage you want, who has access to it, and what you want to do with it.\n2. A framework for easily developing cohesive peer-to-peer applications on top of data from the prev layer\n\nAs a whole, it forms the basis for a new model of the internet where first and foremost, people own their own data.\n\n*This is a summarized version of the full vision of Rhizome. Read the full essay on [[posts/towards-data-neutrality|data neutrality]].*\n\n## Technical Details\nRhizome is a set of abstractions on top of [[thoughts/DID|DIDs]], [[thoughts/UCAN|UCANs]], [[posts/bft-json-crdt|BFT CRDTs]], and a [[thoughts/RDF|tuple store]]. It is a local-first data replication and synchronization service much like iCloud/Dropbox.\n\n- All application data is stored in the form of an EAV Tuple store. This is fully replicated between devices.\n\t- Data availability is achieved with an always-available *cloud peer*, a companion add-on to the sometimes-available personal devices we have. A cloud peer is not a hosting provider, it is rather a different type of a personal device. It does not have a screen, but it is capable in a different way, it complements our personal devices with its high availability, storage, and compute.\n\t- A public marketplace where people can buy and sell compute/storage. Reliability of service is ensured using a modified version of [[thoughts/Filecoin|FileCoin]]'s [Proof of Replication](https://filecoin.io/blog/posts/what-sets-us-apart-filecoin-s-proof-system/)and providers can advertise storage/compute specification so purchasers can choose whether to optimize for space or performance.\n- Users can collaborate with others by creating a [[thoughts/UCAN]] which gives another user permission to read/write a portion of their data\n\t- For example, if I were to share a photo album with a friend, I might create a UCAN that allows read/write access to any tuple that matches the following: `is-photo: true \u0026\u0026 photo-album: garibaldi-camping-trip`\n\t- This allows live collaboration both in asynchronous and synchronous modes (more notes on this in [[thoughts/collaborative software]])\n- All of this will be exposed in the form an SDK in general programming languages like JavaScript, Python, and Rust so that developers can easily build collaborative and interoperable apps without needing to relearn everything from scratch\n\nRhizome's properties handily solve or avert the three problems listed above:\n1. Data replication is considered solved as devices under a single DID sync with each other. Data availability is solved with a cloud peer which can be bought from a distributed and decentralized network of providers.\n2. Users no longer need to run their own server infrastructure as compute happens natively on a users device rather than on some remote sever. When a user needs more compute, they can utilize a cloud peer which is like renting compute from a neutral provider.\n3. As all apps have a public schema which describe what types of tuple attributes they use (e.g. `friend` and `chat-message` attributes for a social media application). To interoperate with outside apps, anyone can publish a schema file for the output of a data export of API call for example.\n\n![[thoughts/images/rhizome-dec-6.jpg]]\n*Rough architecture diagram as of Dec 1st*\n\n### Differentiation from existing work\n- [Urbit](https://urbit.org/)\n\t- Claims to be an overlay OS and networking layer\n\t- A bad case of [NIH](https://en.wikipedia.org/wiki/Not_invented_here), pretty much reinvented everything from scratch in a language that nobody really understands. Very vaporwavy, not much of their tech lives up to their promises. Good summary [here](https://wejn.org/2021/02/urbit-good-bad-insane/) but TLDR; good in principle, didn't work out in practice.\n\t- No real applications built on top of it.\n\t- Modular collaborative yes, no on everything else.\n- [Ceramic](https://blog.ceramic.network/what-is-ceramic/)\n\t- Provides a universal document graph (Ceramic Documents) which by default are interoperable, scalable, and permissionless.\n\t- Seems to require a blockchain to anchor storage and provide strict ordering which in turn makes real-time data read/write infeasible (e.g. games, chat).\n\t- Use of DIDs is incredibly smart, potentially enabling [[thoughts/Self-sovereign Identity (SSI)|self-sovereign identity]] down the line.\n\t- Doesn't seem to support multi-writer documents right out of the box, seems to be an ongoing area of work/research.\n\t- Great principles and solid work already. Seems to have gained some adoption from people in [[thoughts/web3|web3]] already.\n- [[thoughts/Hypercore|Hypercore/Dat Protocol]]:\n\t- Extremely values aligned! Streaming based append-only log that aims to be the lego-block of distributed applications.\n\t- Great developer experience.\n\t- Use of [[thoughts/DHT|DHT]] means that it doesn't need a signalling server for peer discovery.\n\t- Not amazing availability, no incentive system for people to run nodes (though Dat is working on this using a blockchain-based reward system).\n\t- Not exactly great local first support. Continues working locally without an internet connection but new users cannot connect or get an up-to-date version of your data. If the user wants to send data to someone else, both devices need to be online simultaneously.\n\t- [[thoughts/Hypercore|Hypercore]] also does not guarantee long-term write-once storage.\n\t- Multi-writer support is still being worked on.\n\n## Output\n### Research artifacts\nBlog posts explaining distributed systems concepts as I learn and become more familiar with them\n\n- [[thoughts/Raft Consensus Algorithm|Explainer on the Raft Consensus Algorithm]]\n- Explainer on [[posts/bft-json-crdt|BFT CRDTs]]\n- Modelling distributed systems\n\t- [\u003c1kloc Raft Implementation](https://github.com/jackyzha0/miniraft)\n- [[posts/digital-identity|From legibility to identity]]\n- [[posts/communal-computing|LAN the Internet Again]]\n- ...more to come\n\n---\n\nYou can find the ongoing [[thoughts/Rhizome Research Log|research log here]].\n\n## Acknowledgements\nThank you to Anson Yu, Spencer Chang, Sebastien Zany, Jamie Wang, Raymond Zhong, Vincent Huang, Justin Glibert, Morgan Gallant, Ryan Johnson, David Zhou, Aadil Ali, JZ, Nishant Medicharla, Anh Pham, Farzaa Majeed, Amir Bolous, Aaron Pham, Rishi Kothari, Jasmine Sun, and Athena Leong for your continued support. This project wouldn't be possible without all of you.\n\n","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Rhizome-Research-Log":{"title":"Rhizome Research Log","content":"\nI think research logs tend to generally focus too much on what one did rather than what one felt. This log aspires to have a healthy mix of both.\n\n## February\n### February 11th\n- I really like how both Matrix and Email allow for people to host separately and still interop with each other\n- [De-premeterizing](https://en.wikipedia.org/wiki/De-perimeterisation) the walled gardens of the web\n- Lots of reading about networks today...\n- I feel like each of the components of this project on their own could be full-fledged companies on their own. I can easily see how I could sink my entire life into this line of work\n\n### February 10th\n- How do we make a [[thoughts/DHT]] that works in a sparsely connected world?\n- Things to tie together (how do these pieces fit together?)\n\t- [[thoughts/Overlay Network|Overlay Network]] Layer\n\t\t- Make it easy to address each other on the open web by creating a virtual private network\n\t- Identity and Permissions Layer\n\t\t- Basically key management software\n\t\t- OAuth / wallet / `did:key`\n\t\t- User friendly interface on top of persistence and data layer which embeds the persistence and data layer\n\t\t- Manage which applications have access to your data/indices\n\t\t- Like most other databases, includes role/access information in the underlying persistence layer\n\t- Persistence and Data Layer\n\t\t- Make it easy to spin up personal databases\n\t\t- Ingestion endpoint? Converting objects to tuples\n\t\t\t- Namespaced subscription to remote databases\n\t\t\t- [Efficient set reconciliation](https://arxiv.org/abs/2212.13567)\n\t\t\t- Logically monotonic\n\t\t- Merge semantics and CRDTs\n\t\t\t- Trivial merge for fact tuples is the set union operator (maybe use [[thoughts/clocks#Hybrid Logical Clocks]] here too)\n\t\t- Blob storage like `git` LFS\n\t\t- User-managed garbage collection, mark fact as retracted to update dependent indices\n\t\t- Once all index nodes have ack'd the deletion, we can actually delete it (similar to [[thoughts/Antimatter]])\n\t- Index Layer\n\t\t- Query over fact store (data layer) with materialized view maintenance\n\t\t- Prolly Tree data structure\n\t\t- Peers are incentivized to 'pin' and help index data for indices they are interested in\n\t- Application\n\t\t- Folk programming\n\t\t- Enables programming 'agents' and crawlers (like geists)\n\t\t- Reads from index layer through subscriptions\n\t\t- Write to persistence layer easily\n\t- Hosting\n\t\t- Network: hosted Wireguard or [Headscale](https://github.com/juanfont/headscale)\n\t\t- Data: On providers of the user's choice (also managed option)\n\t\t- Identity and Permissions: self-hosted application run on a user's devices\n\t\t\t- Each of these maintains a shallow clone of the indexes it's interested in\n\t\t- Applications: run on user's devices\n\t\t- Communal Clusters: an organizational unit, co-owning data and compute (think : a single Mastodon server)\n\t\t\t- Index: On providers of the user's choice (also managed option)\n- I feel like there is a large common ground between `git`, [[thoughts/CRDT|CRDTs]] and room for cross-pollination across both\n\t- Both basically focus on version control and collaboration\n\t- However, both aren't perfect\n\t\t- The railroad metaphor for `git` is powerful but the affordances of how to manipulate it aren't made clear to the end-user. CRDTs don't explicitly expose version control to the end-user\n\t\t- CRDTs have great conflict-free merge semantics that `git` (relatively) sucks at\n\t- Both are also pretty bad in terms of operation efficiency\n- Found out about [Ditto](https://www.ditto.live/), I guess local-first/offline-first applications make a lot of sense for aviation LOL\n\n### February 8th\n- [Types, not tables](https://github.com/edgedb/edgedb): I agree! What if we had a similar format for types as a sequence of map, filter, and reduce statements?\n- Fact stores with schemas as queries\n- Product : Product Market Fit :: Protocol : Protocol Platform Fit\n\t- Products derive value from benefiting end-users directly\n\t- Protocols derive value by expanding the horizons for what can be build\n\t\t- That is, the value is not reified into people build on top of it\n\t\t- Thus, part of the work of the protocol is figuring out the right platforms/applications that can be built on top of it and providing the right incentives for those to exist\n\t\t- I suspect this is partially why so much of [[thoughts/web3]] seems like vaporware: you necessarily need to promise things to attract people to build\n\t\t\t- But anyone who treats a protocol like a product is bound to find it suspect\n- Had a chat with Spencer and Raymond about the future of data / folk forums which was really energizing\n\t- Everything is pub-sub\n\t\t- What does a protocol level inbox/outbox system for the web look like?\n\t- Now, directly addressing people or applications is super hard because of [[thoughts/distributed systems]], [[thoughts/NAT]], and a bunch of other nasty things\n\t- See also: [[posts/communal-computing|communal computing]]\n\t- What if we had Docker-namespace- or [val.town](http://val.town)-style application network addressing?\n- Notes on Braid research\n\t- [[thoughts/Antimatter|Antimatter]]\n\t- RhizomeDB (Fission renamed WebnativeDB)\n\n### February 5th\n- Why continually *doing* matters\n\t- People talk about 'momentum' when it comes to projects a lot\n\t- I get told by people looking to do more projects/research that they *think* about it a lot but rarely spend much time actually *doing it*\n\t- [Robin Sloan captures this well](https://www.robinsloan.com/newsletters/sunshine-skyway/):\n\t\t- \"When you start a creative project but don’t finish, the experience drags you down. Worst of all is when you never decisively abandon a project, instead allowing it to fade into forgetfulness. The fades add up; they become a gloomy haze that whispers, *you’re not the kind of person who DOES things.*\"\n\t\t- \"When you start and finish, by contrast — and it can be a project of any scope: a 24-hour comic, a one-page short story, truly anything — it is powerful fuel that goes straight back into the tank.\"\n\t\t- \"Unfinished work drags and depresses; finished work redoubles and accelerates.\"\n\t- Truly doing something that is creative and agentic *gives* you energy. It doesn't drain it\n- A* path search for DHTs? Locality mapping?\n\t- This [video explainer of Meridian](https://www.youtube.com/watch?v=O7dyCDE-lw0) is really cool too! Taking account earth curvature when working with distance estimations\n\t\t- Essentially, the idea is for each node-to-node query hand-off to \"zoom in\" to the solution space, reducing the necessary state requirement on each node to only logarithmic of the system size\n\t- Optimizing geographical coverage through hypervolumes\n\t\t- Say you have a set of K servers in your cluster\n\t\t- And a set of L servers that are candidates\n\t\t- Iteratively sub out servers in K for servers in L to find the set that maximizes the hypervolume to maximize the geographical coverage\n\t\t\t- The ring members are diverse within the enclosed space by looking at the three dimensional case, which selects the three nodes from each ring that form the largest triangle\n\t- This of course assumes laying wires that follow the curvature of the earth. Does this assumption hold for interplanetary systems? Probably not but eh we'll think about it when we get there\n- [Rewind in Braid](https://www.youtube.com/watch?v=8dinUbg2h70), a talk by Jonathan Blow\n\t- Implementation options\n\t\t- Deterministic Simulation; record and play back user input. However, things break and it's not robust across revisions\n\t\t- Reversible sim. `tick()` and also `reversetick()`. However, this makes gameplay code really complex\n\t\t- Record full world state; drop frames and interpolate. However, this isn't exact and can lead to exploits.\n\t- 40MB rewind data gives 30-60m of recording time\n\n### February 4th\n- [Delightful apps](https://stopa.io/post/296)\n\t- What makes an app feel delightful? Optimistic Updates, Multiplayer, and Offline-Mode\n\t- Optimistic Updates\n\t\t- \"Interaction time changes how you use an application. Get fast enough, and your fingertips become your primary constraint. I think this is the key to unlocking flow\"\n\t\t- To do this well, we need to support undo. We need to maintain order, and we need to be able to cancel dependent mutations.\n\t- Offline-mode\n\t\t- \"When we know that an app will work no _matter what,_ we use it differently.\"\n\t- Good permissions models\n\t\t- User-defined functions for whether a user can modify a resource\n\t- Why not SQL? \"The frontend’s common case is SQL’s advanced case. We shouldn’t need advanced features for common cases.\"\n\t\t- Facebook runs on a graph database! So does Bytedance (so all of TikTok)! \n\n### February 3rd\n- In response to Spencer's [creative seeing](https://spencerchang.substack.com/p/creative-seeing) and provocation \"what does the internet look like in 5 years?\"\n\t- On developing taste\n\t- Agentic software and how current software makes it hard for people to make their own things\n\n![[thoughts/images/spencer-internet-provocation.png|400]]\n\n## January\n### January 30th\n- [Alan Kay on \"Should web browsers have stuck to being document viewers\"](https://donhopkins.medium.com/alan-kay-on-should-web-browsers-have-stuck-to-being-document-viewers-and-a-discussion-of-news-5cb92c7b3445)\n\t- This led to a “sad realization” that sending a data structure to a server is a terrible idea if the degrees of freedom needed on the sending side are large.\n\t- And eventually, this led to a “happy realization”, that sending a program to a server is a very good idea if the degrees of freedom needed on the sending side are large.\n\n### January 29th\n- I hosted a session in Andy Matuschak's unconference! It turns out a lot of people are thinking about collaborative software. It was super causal and we just chatted about ideas for 30 minutes but wow I felt so energized afterwards.\n\t- [Full FigJam file](https://www.figma.com/file/fHnlhboanqVVE4IOp7zqR0/New-interfaces-for-new-thoughts-in-the-new-year?node-id=0%3A1\u0026t=PBIeeb2LlMLj9ySZ-0)\n- Some ideas I found particularly insightful:\n\t- \"What is the *handwriting* for digital spaces? Something that passively conveys ownership for a particular unit of work\" (Gus Rasch)\n\t\t- \"Someone just surfaced the idea of personal fonts and some other avenues are 1. color, and 2. hand-drawn image\" (Spencer)\n\t\t- \"Imbuing digital spaces with personality feels more powerful than you might expect. Makes it easier to remember where things live because they’re “emotionally” different.\" (Amelia Wattenberger)\n\t- Effective diff interfaces: \"one of the most important factors here is being able to quickly understand the difference between versions.\" (Amelia Wattenberger)\n\t\t- Domain-specific merge flows: \"How do you enable people to manage many copies and forks of the same document and recombine? Is this going to be the same for prose and digital gardening as it will be for coding? Could we use LLMs to describe differences semantically?\" (Rob Haisfield)\n\n![[thoughts/images/beyond-cursors-gather-town.png]]\n\n![[thoughts/images/beyond-cursors-screenshot.png]]\n\n### January 28th\n- Started thinking about this Git for writing idea which I think will be a good vehicle for thinking about version control systems in general\n- Prototype Sketch\n\t- Question: what feels good about a collaborative medium?\n\t- Objects that have affordances we can interact with and manipulate in intuitive ways\n\t\t- Documents are made up of paragraphs which are made up of characters\n\t\t\t- Block-based editing allows us to manipulate at the paragraph level in addition to the character level editing we get in normal text editors\n\t\t\t- Networked note taking apps allow us to transclude text which is a very primitive form of document level editing\n\t\t\t\t- But what about manipulating documents through time?\n\t\t\t\t- Time as an object we can interact with and control? Similar to what Bret Victor says in *[Up and Down the Ladder of Abstraction](http://worrydream.com/LadderOfAbstraction/)*: A designer needs direct, interactive control over the independent variables of the system. \n\t\t\t\t- See notes below on version control\n\t- Supports a spectrum of collaboration\n\t\t- When we're collaborating with others, there's a natural human tendency to desire some privacy while working through something, the freedom to take a piece of the creative work and play out different ideas, move things around, edit and refactor, without fear of judgement or the burden of having to explain or communicate our thinking or concern for overhauling sections where another is actively reading or working. ([Jess Martin on Collaboration](https://publish.obsidian.md/jessmartin/Collaboration+is+a+spectrum+from+asynchronous+to+fully+synchronous))\n\t\t\t- Also sometimes called the fish-bowl effect. Some studies have found that real-time collaboration like in Google Docs creates stress as writers feel watched by their co-authors\n\t\t- It's not just a binary of either *working on your own* or *working with others*\n\t\t\t- Normally binded together on a single document (fully sync editing)\n\t\t\t\t- This is the typical Google Docs or Figma editing experience\n\t\t\t- Obvious button to “make a new version of this document” (async branching)\n\t\t\t\t- What if we did 'implicit' branching where any change makes a new branch?\n\t\t\t\t\t- Open question: Could we utilize LLMs to bundle these into “commits”?\n\t\t\t\t- Each copy has an obvious flow of “merge back into original document”\n\t\t- Presence (peripheral awareness of others)\n\t\t\t- Important so people don't step on each others toes when working across versions\n\t\t\t- Useful information at every scale\n\t\t\t\t- Coin this the *Engelbart Zoom* which Engelbart explored in [HyperScope](https://dougengelbart.org/content/view/154/86/)\n\t\t\t\t- TKTK: what type of peripheral information is actually useful?\n\t\t\t\t\t- e.g. see what paragraphs other people are editing with a scroll bar minimap?\n\t- Version control\n\t\t- Not only across time (edits to the same document) but also managing parallel versions by different authors\n\t\t- Version *control* implies agency over how merge and conflict resolution processes occur\n\t\t\t- 'Best-effort' merge using traditional merge techniques (borrowing from CRDTs or `git` merge strategies)\n\t\t- When working with physical objects, holding areas are very normal\n\t\t\t- `git stash` is a really handy tool, but using it through a CLI makes it confusing\n\t\t\t- Imagine the railroad track metaphor that `git` uses but each individual commit is an object you can manipulate (iirc GitKraken does this in their GUI but haven't had the chance to play with it yet)\n\t\t\t\t- Drag the tips of branches together to merge\n\t\t\t\t- Select multiple commits and drag them off of a branch\n\t\t\t\t\t- This 'detaches' them into free space\n\t\t\t\t\t- You can then 're-attach' these commits anywhere\n\t\t\t\t\t\t- This is effectively what `git stash` does\n\t- Flexible [[thoughts/access control|Access Control]]\n\t\t- It feels important to know who has access to your work (and what kind of access?)\n\t\t\t- Users should feel empowered to have agency over whether their work is public- or private-facing\n\t\t\t- These should also be flexible and dynamic\n\t\t\t- Open questions: what are good ways to deal with derivative works where the permissions over the source material changes\n\t\t\t\t- e.g. Say I make a private document public by accident\n\t\t\t\t- If someone makes a copy of the public document before I make it private it again, what should happen? Should the user no longer be able to access the document because the source document is no longer public? Should the user still be able to access the document because the fact that it *was* public at the time it was copied mean they should still have access to it? \n\t\t\t\t- Is this something that should even be reinforced at a technical level? Or social level (e.g. bump the responsibility up to users)? \n\t- Modular and customizable workspaces\n\t\t- It is important for people to customize the spaces they work in\n\t\t\t- Why force everyone to use the same interface and tools?\n\t\t\t- We all have differing needs for knowledge and collaborative workspaces\n\t\t- End-user scripting like Smalltalk for HyperCard\n\t\t- Subconscious calls this concept 'geist': programs that may work in concert with users\n\t\t\t- Little agents that crawl over your notes and help suggest things\n\t\t\t- Each one specialized for its own thing, e.g. a geist that fixes grammar, a geist to suggest common themes between notes that you may have missed\n\n### January 15th\n- *[Declarative Programming over Eventually Consistent Data Stores](https://www.cs.purdue.edu/homes/suresh/papers/pldi15.pdf)*\n\t- \"geo-distribution does not come for free; application developers have to contend with weak consistency behaviors, and the lack of abstractions to composably construct high-level replicated data types, necessitating the need for complex application logic and invariably exposing inconsistencies to the user\"\n\n### January 14th\n- Ladder of Abstraction\n\t- A designer needs direct, interactive control over the independent variables of the system. We must not be slaves to real time.\n- Query Guarantees in *[Keep CALM and CRDT On](https://www.vldb.org/pvldb/vol16/p856-power.pdf)*\n\t- \"The soundness of state convergence does not translate to predictable guarantees for computations that examine them. One might say that CRDTs provide Schrodinger consistency guarantees: they are guaranteed to be consistent only if they are not viewed\"\n\t- \"Can we develop a query model that makes it possible to precisely define when execution on a single replica yields consistent results?\"\n\t- Querying over something monotonic would be nice but computer time is non-monotonic? What about entropy?\n\t- \"The space of monotone queries is quite large; for example, four of the five operators of relational algebra are monotone: selection, projection, union, and intersection. Only set difference is non-monotone.\"\n\t\t- \"A pipeline composing monotone functions will always give a monotone function end-to-end, but if the pipeline contains any non-monotone function then the end-to-end-computation will be non-monotone\"\n\t\t- ^ this is quite similar to earlier observations about RedBlue consistency\n\t- \"With apologies, potentially-inconsistent observations are accompanied by compensating actions, which are intended to clean up any negative effects of weak consistency. By leveraging lineage tracing, a CRDT-enabled database could automatically determine when such apologies are necessary, prompting the application accordingly\"\n\t\t- How does this compare with netcode rollback techniques?\n- Upwelling pre-print\n\t- Fishbowl effect of real-time collaboration\n\t\t- Real-time collaboration like in Google Docs creates stress as writers feel watched by their co-authors\n\t\t\t- “Writers don’t want first drafts visible to the editor.” — Journalist\n\t\t- Writers often need to initially ideate or experiment with new ideas in private, and then share the new material with their collaborators when they are ready to do so.\n\t\t\t- Support diverge-converge workflows\n\t\t- See also: [[thoughts/collaborative software#A spectrum]]\n\t- File-based collaboration creates problems of versioning and merging edits from different co-authors.\n\t- Reviewing changes\n\t\t- Carefully reviewing a document is important in many professional contexts, but existing software makes it difficult to visualize and review the changes that have been made to a document.\n- Presence affordance that is not intrusive? (“I’m working on the introduction today, please don’t touch that section”)\n- Making cherry picking easy\n- I want to prototype a collaborative writing tool as a testing ground for the version control stuff\n\t- Also had the change to give feedback to a few friends on writing and one big pain point is just finding the best way to comment/give feedback. We always just paste in Google Docs and pepper the document with comments and suggestions but there needs to be a better way than this\n\n### January 13th\n- Had a lovely chat with Quinn from Fission and wow that was amazing\n\t- For more context, Quinn has been working on Dialog which has recently been renamed to Rhizome (!!!)\n\t- Feel like its a case of convergent evolution that we are separately coming to roughly the same conclusions about what a 'post-modern' database should look like\n\t- We talked about pvh's thoughts on RDFs and realized that actually, we don't necessarily need to expose this complexity to the user! We can have *Datalog as a compilation target*\n- Also caught up with Kleppmann for the first time in a while. He seemed really excited by the interface stuff I'm thinking about for CRDTs and version control in a collaborative setting!\n\n\n### January 12th\n- More on Datomic!\n\t- Why immutability actually makes sense when representing real-world things:\n\t- \"Facts don't go away. If the princess's tastes change so that she prefers sriracha, it's still useful to know that in the past she preferred mustard. More importantly, new facts don't obliterate old facts.\"\n\t- That's because time only works in one direction in the universe (that we know of): forward\n\t\t- So by encoding causal dependencies, we get this for free\n- Merging reallly old changes ([localfirst/auth discussion](https://github.com/local-first-web/auth/discussions/35))\n\t- Big usability problem for distributed apps. If a long-dormant device can come online and introduce a single operation that overturns months' worth of activity, people will perceive the app as unstable — even if there's no malice and no security issues involved.\n\t- Can we set limit `L` on how far out of date a device can be before we require it to catch up before submitting changes? The idea would be that you couldn't base a change on a head that's older than that. Instead you'd have to catch up with the latest information, and then rebase your change onto the current head.\n\t\t- `L` is a wall-clock timestamp\n\t\t- `L` is a logical timestamp\n\n### January 11th\n- [Deconstructing the Database](https://www.youtube.com/watch?v=Cym4TZwTCNU), talk by Rich Hickey, author of Clojure, and designer of Datomic\n\t- \"I think one of the questions we have in revisiting the architecture of a database is, what's possible? How much of the value propositions of databases can we retain while tapping into some of the new value propositions of distributed systems, in particular, their arbitrary scalability and elasticity?\"\n\t- \"Other problems we have in general when we talk about traditional databases are flexibility problems. Everyone knows the rigidity of relational databases and the big rectangles. We also have the artifice of having to form intersection record tables and things like that\"\n\t- I love (and strongly agree with) Datomics approach to thinking about databases\n- Had a brief chat with [pvh](https://twitter.com/pvh) about this same topic and he interestingly disagreed. Speaking from empirical evidence, [[thoughts/RDF]] and tuples have never really worked. It's *hard* for people to wrap their heads around\n- [Disk-locality considered irrelevant](https://people.eecs.berkeley.edu/~alig/papers/disk-locality-irrelevant.pdf)\n\t- Reading from local disk is only about 8% faster than reading from the disk of another node in the same rack\n\n### January 3rd\n- Rollback-based mode more thoughts\n\t- Attaching an epoch to each non-commutative operation (this is effectively making the implicit causal dependency explicit)\n\t\t- Separates non-commutative and commutative sequence numbers\n\t- Ordered so epoch numbers are treated as *earlier* (opposite to sequence numbers)\n\t\t- Then, if we add rules to deal with conflicting actions add a query/view level\n\t\t- e.g. how to deal with an insert op by author A if author A's access to the document is revoked\n- I think the research direction I want to explore further is expressing CRDTs as queries over an ever-growing fact-base (Represented as a )\n\t- Commutativity is trivial using the set union operator\n\t- Fact-base is a 6-tuple\n\t\t- Entity ID (E)\n\t\t- Attribute (A)\n\t\t\t- Cardinality of one or many\n\t\t- Value (V)\n\t\t- OpID (Id)\n\t\t- CausalOrigin (Origin)\n\t\t- Retracted (Del)\n\t\t\t- This is equivalent to a delete operation\n\t- Incremental View Maintenance\n\t\t- [DRed](https://www.researchgate.net/publication/213883593_Maintaining_views_incrementally)\n\t- Building indexes using [[thoughts/Prolly Trees]] for optimized lookups\n\t- Questions\n\t\t- How might capabilities be modelled? And private data?\n\t\t- Autocodec for translating attributes between applications?\n- Another possible route.... exploring UI/UX of CRDTs as time travel\n\t- More suited as a short, term-long project (and potentially a project I can do with Ink \u0026 Switch)\n\t- Visual drag-and-drop interface\n\n### January 2nd\n- An idea: Hashgraphs + safety-certificates for non-commutative operations\n- Eager mode (similar to Delta-CRDTs)\n\t- Flood communication\n\t- Assumes unique ID for each operation\n\t- We track a list of all peers who we have received messages from (a list of `AuthorID` for each neighbour)\n\t- Each time we receive an operation with ID `OpId` we haven't seen before and successfully apply it, we broadcast an `ACK(OpId)` message to all neighbouring peers\n\t- For each op `OpId`, we locally track the set of all peers who have acknowledged `OpId`\n\t- Once we have received an acknowledgement from each of our neighbours for a single operation (call this the safety-certificate), it is safe to apply a non-commutative operation on it (we can now delete it or deliver any causal dependents)\n\t\t- This works for applications with explicit causal dependencies (e.g. text editing)\n\t\t- However, it is a bit more difficult to reason about for implicit causal dependencies (e.g. access control) \n\t\t- Consider two admins A and B who are accessing the same document.\n\t\t\t- Concurrently:\n\t\t\t\t- `op1`: Admin A types the letter 'a' in the document\n\t\t\t\t- `op2`: Admin B revokes A's access to the document\n\t\t\t- The problem is that the algorithm treats these as operations that commute when the clearly don't! Some peers may see 'a' (if they receive `op1` ahead of `op2`) and others will not (`op2` ahead of `op1` so `op1` becomes invalidated)\n\t\t- This is solved with the epoch-based approach below\n\t- However this requires fixed membership as it seems to completely mishandle cases where members leave the group (can no longer get a whole safety-certificate)\n\t\t- This is potentially solved by signalling departure and setting an inactivity timeout for nodes\n\t\t\t- Though using heartbeats to refresh inactivity timeout feels counter to the whole CRDT ethos of offline support\n- Rollback-based mode\n\t- Attaching an epoch to each non-commutative operation (this is effectively making the implicit causal dependency explicit)\n\t- This implies that each CRDT requires the ability to undo and redo operations between non-commutative operations\n\t\t- Not all computation is reversible though (e.g. entropy increasing operations like blurring), how do we reconcile this?\n\t\t- Can we utilize the hashgraph to do git-like rebasing to avoid having to implement a redo?\n\n### January 1st\n- More thoughts on access control\n- *[Distributed Access Control for Collaborative Applications using CRDTs](https://hal.inria.fr/hal-03584553/file/papoc.pdf)* uses a total ordering of roles in order to resolve access conflicts\n\t- However, in the case of two top-level administrators revoking access, the same problem occurs\n\t- Additionally, it is not not always possible to totally order a set of permissions. Consider one person with access to file 1 but not file 2 and another person with access to file 2 but not file 1.\n\t- \"Combining CRDTs for data with CRDTs for policies raises several challenges. Conflicts between two concurrent operations based on diverging policies cannot be safely resolved.\"\n\t\t- They resolve this by attaching an epoch to each policy change \n\t\t\t- The epoch doesn’t grow in size, but merely refers to a parent operation that last changed the policy.\n\t\t- This implies that each CRDT requires the ability to undo and redo operations between epochs\n\t\t- Undo-redo may be expensive if it happens a lot! The assumption here is that policy changes are rare so this doesn't happen very often\n- Garbage Collection\n\t- Two part series ([pt1](http://web.archive.org/web/20200621012528/http://composition.al/CMPS290S-2018-09/2018/11/12/implementing-a-garbage-collected-graph-crdt-part-1-of-2.html) and [pt2](http://web.archive.org/web/20200214095630/http://composition.al/CMPS290S-2018-09/2018/12/08/implementing-a-garbage-collected-graph-crdt-part-2-of-2.html))\n\t- Why GC is hard:\n\t\t- First, establishing the stability of an update as described in the paper assumes that the set of all replicas is known and that they do not crash permanently.\n\t- Inspiration from Delta-CRDTs\n\t\t- In the causal-consistency-ensuring anti-entropy algorithm. When a node sends a delta-interval to another, the receiving node replies with an acknowledgment after merging the interval into its local state. A delta that has been acknowledged by all of a node’s neighbours is then garbage-collected\n\t- Synchronized GC\n\t\t- Under two-phase commit, each replica will vote on whether each tombstone is still necessary.\n\t- QCs for GC?\n- Type-level consistency guarantees?\n\t- [Source](http://web.archive.org/web/20200225212322/http://composition.al/CMPS290S-2018-09/2018/11/21/mixing-consistency-in-a-programmable-storage-system.html)\n\t- Just as 'function colouring' exists as a way of distinguishing async and non-async functions, what if we could colour other sorts of [[thoughts/system model|system models]]?\n\t\t- [IPA](http://web.archive.org/web/20220121204308/https://homes.cs.washington.edu/~luisceze/publications/ipa-socc16.pdf) does this\n\t\t- [RedBlue](http://web.archive.org/web/20200910163620/https://www.usenix.org/system/files/conference/osdi12/osdi12-final-162.pdf) consistency?\n- CockroachDB Layers\n\t- SQL Layer: translates high-level SQL statements to low-level read and write requests to the underlying key-value store\n\t- Transactional KV: Requests from the SQL layer are passed to the Transactional KV layer that ensures atomicity of changes spanning multiple KV pairs\n\t- Distribution: monolithic key space. Range-partitioning on the keys to divide the data into contiguous ordered chunks of size ~64 MiB, that are stored across the cluster. We call these chunks Ranges\n\t- Replication: consensus replication using [[thoughts/Raft Consensus Algorithm|Raft]] across replicas\n\t- Storage: KV-store, use RocksDB\n\n## December\n### December 30th\n- Reading about [[thoughts/Datalog]] as a way of expressing CRDTs... some promising work in this direction\n\t- I think there's a pretty clear articulation of this over SQL as this allows us to separate data representation from data views in a more clear way\n\t- This also means we can do away (?) with SQL migrations\n\n### December 28th\n- Finally finished up my blog post on [[posts/communal-computing|Communal Computing]]! It turns out, sharp feedback leads to better writing, who would have ever thought :')\n- Did a bit more thinking about Kleppmann's *Recovering from key compromise in decentralised access control systems*\n\t- I feel like there is a close connection to be made with [[thoughts/Arrow's Impossibility Theorem]] but haven't been able to formally show it\n\t- Perhaps using Quorum Certificates for group membership voting?\n\t\t- These can be built offline (and even allows for receiving updates offline) and sent when a user is back online.\n\t\t- A membership change is then considered stable when it receives 2 unique supporting QCs. Of course, this only works with $f\u003c\\frac n 3$.\n\t\t- Voting members: all members of the group which were members prior to the membership change\n\t\t- Mutual removal: going with something that is intent-preserving feels important here. One potential way to resolve this is to restrict membership changes to at most one removal per round. Requiring 2 QCs would mean that we have consensus on which group member to remove and removing a single member cannot possibly cause a conflict. (this may not be ideal for situations where a large number of group members are removed but I suspect these cases are very rare)\n- Found out that [Beaker Browser](https://github.com/beakerbrowser/beaker/blob/master/archive-notice.md) is now archived :(( A really interesting retro that has a lot of good reflections and learnings for anyone working on p2p tech\n\t- Major challenges:\n\t\t- Without some logically centralized repository of data or router of messages, you struggle with discovery and delivery.\n\t\t- Users don't stay consistently online and connections will randomly fail, so you stuggle with availability and performance.\n\t\t- Initial connections and thus time-to-first-paints are slow, which is very bad news for web browsing.\n\t\t- Debugging is quite hard.\n\t\t- Managing resource usage on the device is hard.\n\t\t- Scaling a user's view of the network past (say) 100k users is pretty much out the window because you're not sharing indexes; rather, you're having each device build the indexes locally.\n\t\t\t- Is this fixable with [[thoughts/Prolly Trees]]?\n\t- \"As decentralizers we may be pursuing a mission, but our work only wins in the market, and to win in the market we need to think like entrepreneurs. Ultimately, my lesson learned is that mission needs PMF.\"\n- Coordination in CRDTs? Inspiration from the [TreeDoc paper](https://pages.lip6.fr/Marc.Shapiro/papers/RR-6956.pdf)\n\t- TreeDoc is occasionally flattened from a tree into an array to cleanup tombstones and balancing issues\n\t- However, this is *not* commutative. TreeDoc solves this by using an update-wins approach in a two-phase commit protocol\n\t\t- The site that initiates a flatten acts as the coordinator and collects the votes of all other sites. Any site that detects a concurrent update to the flatten votes \"no\". The coordinator aborts the flatten if any site voted \"no\" or it never received a response\n\t- Supporting large groups of replicas\n\t\t- Uses hubs to help scale -- see [[thoughts/Network Theory]]\n\t\t- Core: well-known nodes that are well-connected\n\t\t- Nebula: all other nodes\n\t- Epoch-based flattens\n\t\t- Each flatten – each change of epoch – changes the frame of reference for TID\n\t\t- A core site maintains a buffer of updates messages it needs to send to the nebula, some in old epoch some in the new one\n\t\t- A nebula site maintains a buffer of update messages to be sent to the core; these are all in the old epoch\n\t\t- The nebula must first bring the out of date messages into the new epoch to replay them\n\n### December 14th\n- Had a wonderful chat with Brooklyn from Fission. We nerded out a lot about capabilities, lot's more reading for me to go through:\n\t- *[Capability Myths Demolished](https://srl.cs.jhu.edu/pubs/SRL2003-02.pdf)* \n\t- *Recovering from key compromise in decentralised access control systems* by Kleppmann and Bieniusa\n\t- *[Robust Composition: Towards a Unified Approach to Access Control and Concurrency Control](http://erights.org/talks/thesis/markm-thesis.pdf)*\n- More research direction refinement!!\n- Released some unfinished work and asked people close to me to read it\n\t- A lot of feelings stewing around feeling not confident in my own work after the average sentiment was lukewarm at best\n\t- I think it stems around sharing inherently incomplete/vague/in-progress work. It's a very weird frustration that comes from mismatches between my mental model, the work itself, and the readers mental model\n\t- But this is the great part of feedback!! Even though emotional brain says that \"oh no, harsh feedback scary\", it is actually really constructive and helps me articulate my thoughts better. I'm going to try to make a piece of writing I'm fully proud of when I finish exams (soon!)\n\n### December 1st\n- Well would you look at that... it's December\n- It's been a week but the hype from [[posts/bft-json-crdt|my BFT JSON CRDT project]] has finally started to cool\n\t- Over 10k people viewed the blog post for meaningful length of time and HN was surprisingly nice about it :'))\n\t- A bunch of people reached out asking to chat more about CRDTs (some even asked if I was open to contracting!) Super cool to find more people working in this space and who are as equally excited about it as I am\n\t- Most importantly, Kleppmann reached out! I had messaged him to schedule a call at some point but we never found the time. But he saw (and even retweeted!) my blog post and really thought it was solid work. \n\t\t- He asked if I would be interested in doing a PhD with him at Munich University. Unfortunately, visa problems combined with the requirement that I get a Masters first mean that I probably won't be taking him up on this offer.\n\t\t- However, we *are* still going to be formally collaborating on some papers regardless which I am still kind of in shock over. This felt so full circle for me! I quite literally started this summer with *zero* distributed systems knowledge and now I get the chance to collaborate with one of the people on the bleeding edge of distributed systems knowledge and research. Bonkers!!\n- Today, I spent a lot of time thinking about the technical architecture of Rhizome now that I have the experience of the project behind me. Updated some diagrams in [[thoughts/Rhizome Proposal]] but TLDR;\n\t- EAV tuple store not append-only log\n\t- [[thoughts/UCAN]] good\n\t- [[thoughts/CRDT|CRDTs]] instead of Raft for most things, [[thoughts/CALM Theorem]] may be useful to figure out when coordination is necessary\n- Open questions\n\t- How will we mark state as requiring coordination?\n\t- How do we efficiently reconcile big tuple stores?\n\n## November\n### November 18th\n- I know I've been neglecting this research log a little bit...\n- I've been squeezing time wherever I can to work on this silly little project. As of 11:59pm tonight, I have finished the project and fully written out a 6.2k word blog post ([[posts/bft-json-crdt|read it here]]) on it to pair\n\t- This project realllyyy pushed me to my limits in terms of my engineering ability\n\t- So many times I doubted if something was even possible or not and many late nights of pushing off other responsibilities to get more hours on this silly little thing\n\t- I always knew I'd finish but to be honest, I can't really believe its over\n\t- There's still more projects I want to work on but in the meanwhile... time to take a small break : )\n\n## October\n### October 27th\n- Adding JSON support is harder than I expected!\n\t- Mostly taking inspiration from yet another [Kleppmann paper](https://arxiv.org/pdf/1608.03960.pdf)\n\t- Insert\n\t\t- Ignore if we have it already\n\t\t- Create new entry in table with hashed `OpID` with `is_deleted = false` \n\t- Update\n\t\t- All the steps of delete and insert\n\t- Delete\n\t\t- Lookup prev `OpID` and mark it as deleted\n- Probabilistic decay mechanism for CRDTs\n\t- 'Remind me...' mechanism\n\n### October 24th\n- Privacy preserving CRDTs??\n- Turns out Automerge is actually fast now\n\t- They've refactored their codebase significantly and use a b-tree similar to Diamond Types\n\t- Ed25519 should be able to sign + verify upwards of 100k signatures/s on a 1 GHz processor so I need to make some improvements here\n\n### October 23rd\n- [Another great talk on WNFS](https://www.youtube.com/watch?v=-f4cH_HQU4U) by Brooklyn Zelenka\n\t- The whole 'ask for permission' thing isn't actually new!\n\t- Our phones already do this: \"Google Photos is asking permission to access your camera roll\"\n- [New Directions in Cloud Programming](https://www.cidrdb.org/cidr2021/papers/cidr2021_paper16.pdf)\n\t- The way we write distributed systems today is like writing assembly by hand -- incredibly error prone\n\t\t- Creative programmers are held back by the need to account for these complexities using legacy sequential programming models originally designed for single-processor machines.\n\t- We need projects like Bloom/Hydro that help with 'compiling away' those concurrency semantics\n\n### October 22nd\n- Had a random question about a paper that Kleppmann wrote and just straight up messaged him on Twitter LOL totally not expecting him to respond\n\t- He did! Within just a few hours and helped to confirm that I did in fact need to sign messages using [[thoughts/Asymmetric Key Cryptography|asymmetric cryptography]] to prevent forgery\n- Also, Nalin helped to clarify a lot of my understanding for cryptography which was super nice of him :))\n- Finally finished implementing tests for BFT and... it seems to work?? Kinda bonkers that I've been working on this project for almost 2 months now. Probably the most technically involved project I've done that integrates so much stuff I've learned in the past few months in systems design, networking, cryptography, and information theory\n\t- Just need to finish up hashgraph reconciliation and the JSON aspect of the CRDT and should be good to go\n- Thinking about a potential sharded/partitioned design for a triple store DB\n\t- Using distance metrics like [[thoughts/Kademlia DHT]] does?\n\n### October 20th\n- Started writing post on [[posts/bft-json-crdt|a BFT JSON CRDT]]\n- Ran into a potential problem with message forgery...\n\t- Seems like [Kleppmanns's Paper](https://martin.kleppmann.com/papers/bft-crdt-papoc22.pdf) doesn't address cases where, say a Byzantine node tries to send a message *on behalf* of another node (as it knows the unique IDs of other nodes) and forges an update.\n\t- This is possible as the unique ID doesn't have any other properties that guarantee that only that the node with the ID can send that message.\n\t- We would potentially need some sort of [[thoughts/Public-key Infrastructure|PKI]] assumption where the unique ID of a node is its public key and the ID is the signed digest of the message\n- This is (sort of) confirmed in [Kleppmann's 2020 paper](https://arxiv.org/pdf/2012.00472.pdf)\n\t- \"We assume that each replica has a distinct private key that can be used for digital signatures, and that the corresponding public key is known to all replicas. We assume that no replica knows the private key of another replica, and thus signatures cannot be forged\"\n\n### October 19th\n- Picked up *[[thoughts/Seeing like a State|Seeing Like A State]]* again, it feels a lot more relevant to my research now for some reason\n\t-  We can think of a [[thoughts/RDF|triple store]] as a distributed and fragmented SQL database, where instead of tables with rows and value, we have entities with attributes and values.\n\t\t- Any application can declare new attributes or alias an attribute to a more common one\n\t\t- The most important part is that applications that share attributes can automatically interoperate their data\n\t\t\t- The harder question is how to build good indices so that when the number of triples grows really large, we still get fast queries\n\t\t\t- I suspect there's a lot to learn from decades of SQL index/query optimizations\n\t\t\t- Would like the syntax to borrow from GraphQL\n\t\t- This type of 'decentralized' database means there is no canonical schema. You can't mistake the map for the territory because everyone has their own map and can't force others to view the 'truth' of the world through your map\n\t- Forcing ourselves into schemas make it hard to innovate\n\t\t- To make new things requires us to provide migration paths forward or just accept stagnation\n\t\t- It inadvertently shapes what people build -- leads to easily legible/classifiable applications (see: [[posts/digital-identity|post on digital identity and legibility]])\n\t\t- It is treading outside the map that gives us innovation\n\t- This would give us contextual data for app specific data\n\t\t- We can see this as analogous to context dependent personalities (again, [[posts/context-collapse|context collapse]] bad)\n- Spent a lot of time trying to optimize `bft-json-crdt` to squeeze more performance out of the base list CRDT but to no avail\n\t- Realizing this was kind of a waste of time as I was just using this is a proof-of-concept\n\t- Especially if I want to focus on something that's more like a [[thoughts/RDF|triple store]], a list is kind of useless lol\n\t- Going to focus more on the [[thoughts/Byzantine Faults|BFT]] and JSON-aspects of this project\n\n### October 12th\n- Ok well... it's been 3 weeks since I last wrote an update. School has been busy!\n- I got really stuck with Rhizome work so I took a week and a bit off to work on [Tabspace](https://github.com/jackyzha0/tabspace) and launched it. It felt good to launch something and 'unstick myself'\n- Got more motivation to work on `bft-json-crdt` and started a more methodical approach to debugging (rather than just changing index offsets and rerunning LOL).\n\t- Eventually pinpointed two bugs:\n\t\t- Not accounting for repeated delete elements\n\t\t- Not properly updating the internal sequence number\n\t- Once these were fixed, it kind of just worked! Of course, the performance isn't great but it still happens to be ~4x faster than the base Automerge implementation B))\n\n## September\n### September 30th\n- I think decision is that going down splay tree route is not worth and I'll just do this using a simple vector LOL\n- Been slowly but surely working away at this BFT CRDT implementation in Rust\n\t- Figuring out some tradeoffs, I already rewrote the crate from using doubly-linked lists to using a splay tree but maybe this isn't the right data structure either\n\t- Desired attributes\n\t\t1. Fast insert at arbitrary location\n\t\t\t- A decent chunk of edits happen in places that are not the start or end of edits!\n\t\t\t- Ideally less than $O(n)$\n\t\t2. Ordering in list is a local property\n\t\t\t- It should be easy to figure out location of a node given its ID\n\t\t3. Insert time for integrate\n\t\t\t1. Find right position to insert\n\t\t\t\t- Comparison involves looking up position of parent\n\t\t\t2. Insert\n\t\t5. Update should be considerably faster than render (which realistically doesn't need to happen that often)\n    - Candidates\n\t\t- B-Tree (Diamond Types uses this)\n\t\t\t- Node location is **not** local (worst case $O(\\log n)$ indirections)\n\t\t\t- Insert time for integrate\n\t\t\t\t1. Find right position: $O(\\log n)$ amortized\n\t\t\t\t\t1. Finding parent is $O(\\log n)$ amortized\n\t\t\t\t\t2. Overall is $O(\\log(n \\log n))$ amortized\n\t\t\t\t3. Insert: $O(\\log n)$ (need to recount up the tree)\n\t\t\t- Note: has pretty good cache locality because you can read entire lines of nodes into memory\n\t\t\t- Requires indexing by character position which is not ideal\n\t\t- SplayTree\n\t\t\t- Node location is **not** local (average case $O(\\log n)$ levels of indirection and potentially $O(n)$ worst case)\n\t\t\t- Insert time for integrate\n\t\t\t\t1. Find right position: $O(\\log n)$ amortized\n\t\t\t\t\t1. Find parent is $O(\\log n)$ amortized (we can use a binary encoding of the search path as an index)\n\t\t\t\t\t2. Overall is $O(\\log(n \\log n))$ amortized\n\t\t\t\t2. Insert: $O(\\log n)$ (need to rebalance up the tree)\n\t\t\t- Note: rebalancing may not be bad in terms of time complexity but sucks because of memory locality\n\t\t\t\t- SplayTrees are binary search trees which can lead to some deep trees which require many pointer dereferences\n\t\t\t\t- Are there $m$-ary SplayTrees??\n\t\t- Doubly Linked List (Yjs uses this)\n\t\t\t- Node location is not local\n\t\t\t- Insert time for integrate\n\t\t\t\t1. Find right position: $O(n)$\n\t\t\t\t\t1. Find parent is $O(n)$\n\t\t\t\t\t2. Overall is $O(n^2)$ which is slow on many concurrent inserts\n\t\t\t\t2. Insert: $O(1)$\n\t\t- Vector\n\t\t\t- Node location is local\n\t\t\t- Insert time for integrate\n\t\t\t\t1. Find right position: $O(n)$\n\t\t\t\t\t1. Find parent is $O(n)$\n\t\t\t\t\t2. Overall is $O(n^2)$ which is slow on many concurrent inserts\n\t\t\t\t2. Insert: $O(n)$\n- Catching up today on a bunch of talks + reading\n\t- Wonderful [talk by Brooklyn Zelenka](https://www.youtube.com/watch?v=mxkAAtTvcEE\u0026t=10656s) (CTO of Fission)\n\t\t- \"The limitation of local knowledge is the fundamental fact about the setting in which we work, and it is a very powerful limitation\" -- Nancy Lynch, A Hundred Impossibility Proofs for Distributed Computing\n\t\t- [[thoughts/CID|CIDs]] give us **global pointers** that we can all agree on (these are hard links, unbreakable)\n\t\t\t- Compared to URLs (soft links, kind of like symlinks, can break). Point to a latest something\n\n### September 3rd\n- Bunch of weird Rust things today\n\t- Generally, use `.take()` on `Option\u003cBox\u003cT\u003e\u003e` and `.clone()` on `Option\u003cRc\u003cT\u003e\u003e`\n\t- `.as_ref()` is like `\u0026` but generally acts on the internal reference (i.e. on an `Option\u003cT\u003e`, `\u0026` gives you `\u0026Option\u003cT\u003e` whereas `.as_ref()` gives you `Option\u003c\u0026T\u003e`)\n\t\t- Additionally, `.as_deref()` basically is just `.as_ref()` with an additional `.deref()` on the unboxed value (effectively performing deref coercion)\n\t\t- `\u003coption\u003e.map(|node| \u0026**node)` is equivalent to `\u003coption\u003e.as_deref():`\n\t- `Rc::try_unwrap` which moves out the contents of an `Rc` if its ref count is 1\n\n### September 1st\n- [[thoughts/CAP Theorem|CAP Theorem Tradeoffs]] and [[thoughts/A Certain Tendency Of The Database Community]]\n- Rhizome Architecture: now with triple-stores :))\n\t- Root: identity + persistence layer\n\t\t- Standalone app to manage identity + storage\n\t\t- Support multiple identities\n\t\t- essentially a managed `DID:key` that controls a set of [[thoughts/IPFS|IPFS]] nodes to pin certain things\n\t\t- 'open [app] on your computer' type authorization for web applications\n\t- Trunk: application layer\n\t\t- Data framework layer: distributed triple store\n\t\t\t- rust → compiled to WASM for web\n\t\t\t- each node has its own [[thoughts/RDF|triple store]] that is created from an append-only data log\n\t\t\t- each triple contains ID, relation, and value\n\t\t\t\t- how do we do realllyyy fast triple search? on multiple relations?\n\t\t\t\t- how do we pack memory efficiently for this?\n\t\t\t\t- we can 'subdomain' relations (e.g. it belongs to a certain set of schemas or application) using a trie\n\t\t\t- optional `author_id` field to link to Root\n\t\t- Query layer: turns the triple store into live views that are interpolated\n\t\t- Display layer: uses the views to perform calculations and display things\n\t\t- Bring your own data: an application has a specific fingerprint\n\t\t\t- Defines exactly which types of triples it reads/writes\n\t\t\t- Enables you to invite another user to 'bind' to your current application state (similar to 'invite' to collaborate on a document or something)\n\t- Ditto: publicly contributable schema and API definitions\n\n## August\n### August 31st\n- What would it be like to build in interpolation into the state replication level?\n\t- e.g. similar to [Quake 3's Networking](https://www.jfedor.org/quake3/) or [perfect-cursors](https://github.com/steveruizok/perfect-cursors/) both do 3 types of smoothing:\n\t1. **Interpolation**: If it knows the state of the world at time _t_ and at time _t+50 ms_ and it needs to render additional frames between those points in time, it interpolates the positions of all visible objects between their known two states.\n\t\t- That means that when the client is rendering the frame at _t+16 ms_, it already needs to have received the information about the server frame from _t+50 ms_!\n\t\t- The only way that is possible is if the client intentionally delays its view of the world in relation to what it’s receiving from the server.\n\t2. **Extrapolation**: What happens when the network packet containing the next snapshot is delayed or lost and the client runs out of states to interpolate between? Then it’s forced to do what it normally tries to avoid: extrapolate or guess where the objects will be if they keep moving the same way they’re currently moving.\n\t3. **Prediction**: The only exception here is player input. Instead of waiting for the server to do that and send back a snapshot containing that information, the client also immediately performs the same player movement locally. In this case there’s no interpolation - the move commands are applied onto the latest snapshot received from the server and the results can be seen on the screen immediately. In a way this means that each player lives in the future on their own machine, when compared to the rest of the world, which is behind because of the network latency and the delay needed for interpolation.\n- See also: [GGPO](https://en.wikipedia.org/wiki/GGPO) which is heavily used in real-time fighting games\n\n### August 30th\n- [A Graph-Based Firebase](https://stopa.io/post/296)\n\t- Turns out most modern real-time applications look something like this:![[thoughts/images/modern-app-architecture.png]]\n\t- SQL seems to be too complex. The common request for data in front end is a complex case to express to SQL. \"We shouldn’t need advanced features for common cases.\"\n\t\t- The most common query is our “fetch nested relations”. This should be supported first class\n\t- We can potentially emulate this using triple stores built on top of an append-only CRDT. [[thoughts/Datalog|Datalog]] and triple stores have been around for decades. This also means that people have built reactive implementations.\n\t- Unsure if we can leverage [[thoughts/CALM Theorem|CALM]] as its Datalog but *not* monotonic (facts can be retracted)\n- DAG instead of append-only log\n\t- \"Both of these abilities follow directly from the explicit embedding of causality into a DAG, with time travel being analogous to a traversal over that graph\" [Dialog](https://fission.codes/blog/fission-reactor-dialog-first-look/)\n\n### August 23rd\n- Phillip Wang's talk -- related to [[posts/the-fools-who-dream|reflection post]]\n\t- tldr; We should leave space in our lives for finding conviction in things we work on\n\t- How do we enable the \"other\" path for high achievers? Not the one where they can just work at a big company, get paid lots of money, life a cozy life, but the harder path in which they truly question the *why* and ask themselves what they find truly fulfilling\n\t- Fully commit to one thing -- deep beauty in choosing, against [[thoughts/optionality|optionality]]\n\t\t- How does this fit into the [[thoughts/exploit explore|exploit-explore]] tradeoff?\n\t\t- Feels like there's a necessary balance between\n\t\t\t1. being deeply invested in something to be able to have a level of almost unwavering conviction\n\t\t\t2. not being so deeply invested that you are oblivious to exploring better potential options\n\t- Leaving space to have conviction is inherently a privilege, how might we enable local spaces of abundance (places for [[posts/play#A re-worked definition|play]]) so that more people have that privilege?\n\t\t- This also feels like a generational thing. My parents first immigrated to Canada when I was around 3. They've spent a big chunk of their lives worrying about how to meet basic survival needs\n\t\t- I grew up with enough resources around me that I've begun looking for what I have conviction in; what I feel invigorated by \n\n### August 22nd\n- Justin Glibert's talk\n\t- tldr; composability + permissionlessness enable novel affordances we haven't seen before in digital systems\n\t- What if... [[thoughts/Kademlia DHT|Kademlia-like]] XOR distance metric but for [[thoughts/State Machine Replication (SMR)|SMR]]\n\t- Permissionlessness is an important characteristic to enable innovation and [[thoughts/emergent behaviour|emergent behaviour]]\n\t\t- See also: [Simon Harris on the same topic](https://simonsarris.substack.com/p/welcome-ghosts)\n\t\t- \"Many tales exist of [the origin of the bistro]. Some say it was working-class landlords opening their kitchens for extra income. Others say it was the Auvergnats, immigrating to Paris from what is today central-south France, who first worked as rag-pickers, then wood and coal sellers, then metalworkers, who created small working-class restaurants to supplement their income. Either way, it was not planned or engineered, but simply not-disallowed. There were no rules in place to stop this invention.\"\n\t\t- Same with YouTube which started out as a dating app but then let people upload anything. The _users_, not the website creators, found its real uses\n\t\t- Does this conflict with the fact that good DX/UX comes with strongly opinionated use cases?\n\n### August 19th\n- Packing and flying back to NY for Hack Lodge! Will be posting an ongoing thought stream :))\n\n### August 18th\n- Preparing workshop notes to talk about [[thoughts/computer networking|computer networking + P2P]]\n- Feelings rant -- I feel an odd and unusually heavy sense of impostor syndrome today. Going to write out more stuff in [[posts/the-fools-who-dream|this blog post]] I'm going to flesh out\n- Frustrated by [this video by one of the founders of the Browser Company](https://www.youtube.com/watch?v=v0160IirdL4)\n\t- Their vision is that the 'next generation' of computers -- after the mainframes and personal computers -- is the *internet computer*, where everything we do happens in the cloud and our machines are just dumb portals to access these\n\t\t- We can't be going back to time-sharing! Time-sharing was only a thing because we didn't have access to powerful enough consumer hardware -- this is no longer the case\n\t\t- Not only do you need to always be connected to the internet to use it, it is also incredibly Orwellian except with all-powerful companies instead of states which have detailed metrics into how you conduct every moment of your digital lives\n\t- Josh seems to be conflating [[thoughts/local-first software|local-first software]] with software that is not connected to the internet\n\t\t- Just because our data lives locally on our device, does not mean your work is trapped on one device\n\t\t- I think the future is a happy middle between completely offline and completely online -- we've pendulum-ed to both sides of the spectrum and are perhaps settling on the reasonable option\n\t\t\t- Servers have a role to play in the local-first world — not as central authorities, but as “cloud peers” that support client applications without being on the critical path. For example, a cloud peer that stores a copy of the document, and forwards it to other peers when they come online, could solve the closed-laptop problem.\n\t- \"Nobody makes native apps anymore\"\n\t\t- People want the *performance* of native apps without having to maintain many codebases across them.\n\t\t- As more and more apps become 'internet-first', libraries for storing things locally and reconciling them with remote copies of that data have not made nearly enough progress.\n\t\t- As a result, many 'native apps' are just wrappers for a single source of truth that lives on a remote server. This is not ideal in terms of many things but mostly performance and data ownership.\n\t- In a million years time when they dig back down in the archive history of our digital footprint, they won't see vibrant replicas of the web but rather a digital dark age.\n\t\t- The documents created in cloud apps are destined to disappear when the creators of those services cease to maintain them.\n\t\t- Cloud services defy long-term preservation.\n\t\t- No Wayback Machine can restore a sunsetted web application.\n\t\t- The Internet Archive cannot preserve your Google Docs.\n\n### August 17th\n- Really diving into whether a dual optimistic replication (CRDT) + transactional replication (Raft SMR) approach is needed or if one will do\n\t- Optimistic replication\n\t\t- Best for global collaboration. Local nodes can still be speedy even with collaborators from across the world\n\t\t- Can lead to inconsistent states if not careful (again, can use a DSL to help catch these types of errors but it just becomes difficult to write and will require extra research time)\n\t\t\t- Alternatively, have no global invariants. JSON-style data structure\n\t\t- Strong eventual consistency data stores (e.g. CRDTs) will hit a few million TPS per second locally for sticky writes with actual TPS being roughly $\\frac 1 {RTT}$ (where RTT is ~500ms at worst, ~150ms usually)\n\t\t- Bandwidth use is $n$ (just send to all nodes)\n\t\t- Latency is $\\frac 1 2 RTT$ (don't need to wait for reply)\n\t- Transactional replication\n\t\t- Easier to reason about for application developers\n\t\t- Atomic commit-type data stores (e.g. SQL, CockroachDB) still achieve upwards of 28k TPS in a single-region zone. In a global environment, TPS will be roughly $\\frac 1 {2RTT}$. This means that if you have a very global team working on something, synchronously collaborating something will still be quite laggy (~1TPS). Doesn't work on an 'inter-planetary scale'!\n\t\t- Bandwidth use is $r n^2 + 1$ where $r$ is number of rounds of the consensus mechanism\n\t\t\t- $1$ for initial request and $r$ rounds of $n^2$ communication between all nodes (overhead can be reduced to $rn + 1$ if normal state is $O(n)$)\n\t\t- Latency is \n\t- Hybrid\n\t\t- Best of both worlds, but the most complex to reason about and write programs for\n\t\t- Alternatively... what if we expose a simple KV store using CRDTs to exchange routing info? This would open it to easily layering real-time applications on top (e.g. video calls, WebRTC). This eliminates the need for a signalling server\n\t\t\t- This can technically be done already by the user in transactional replication model if they want\n- Addendum: the [[thoughts/CALM Theorem|CALM Theorem]] conjectures that if program state can be expressed in monotonic Datalog, it can safely use optimistic replication. If we can always express something using an immutable Merkle-DAG with occasional consensus for GC, shouldn't this work? \n- Have one SMR instantiation of the SMR algorithm per application\n- How do we do live reconfiguration of cluster quorum size?\n\t- https://users.ece.cmu.edu/~reiter/papers/2000/DSN.pdf\n\t- https://www.alibabacloud.com/blog/raft-engineering-practices-and-the-cluster-membership-change_597742\n\n### August 16th\n- Finally made my way through all my research papers. There's a weird peace to have no open browser tabs, down from around ~75 open\n- Thinking about [[thoughts/access control|access control]] and revocation. Especially for add-only data structures, how can we prove data has been deleted or removed?\n- What is the base metaphor we should use when building applications?\n\t- A chat except the base unit is not text but structured data. Call this the 'event history'\n\t- This implies a certain causal history and a partial ordering\n- Trunk\n\t- User defines\n\t\t- `data Op = ...`: All possible operations of the app\n\t\t- `data State = ...`: Application state\n\t\t- `r :: State -\u003e Op -\u003e State `: The reducer function\n\t\t- `s0 :: State`: The initial state\n\t- How is state persisted?\n- Root\n\t- Identity\n\t\t- A `did:key` is generated for every history\n\t\t- One root IPFS document tracks all active `did:key`s associated with a root DID\n\t- The [[thoughts/Merkle-DAG|Merkle-DAG]] will be anchored using IPLD, this means that hopping cloud providers is easy as everything is [[thoughts/content addressed storage|content-addressed]]\n\t- Storage Providers\n\t\t- Providers should pass a suite of unit tests for correctness in terms of satisfying certain behaviour.\n\t\t- With this model, all a storage provider needs to do is pin a few CIDs\n\t- This takes care of data availability... but what about liveness? This is where SMR comes in\n- Ideal [[thoughts/State Machine Replication (SMR)|SMR]] algorithm properties\n\t- Favour liveness over consistency when potentially majority replicas are offline (i.e. handle all cases $f \u003c n$ in asynchronous crash-stop model)\n\t- Should scale well with number of participants\n\t- Synchronization should *not* be on the critical path (read: CRDTs where possible, consensus otherwise)\n\t- Collaboration over consensus (i.e. try to preserve user intent where possible)\n\t- Things to figure out\n\t\t- When is it safe to GC?\n\t\t- Is it worth writing a DSL that compiles down to different host languages? This could be really useful to provide helpful compile-time checks\n\t\t\t- Basically to adhere to [[thoughts/CALM Theorem|CALM]], we want to make it easy to write synchronization free code (similar to Rust and how it makes it easy to write GC-free code)\n\t\t\t- Generate the appropriate boilerplate for code that requires synchronization\n\t\t\t- Have a good standard library of data structures that are primarily synchronization-free\n- Potential demo apps\n\t- Basic chat app\n\t- Google drive/Dropbox clone (testing large op/diff sizes)\n\t\t- Tool for thought, Google Docs-like writing primitive (testing permissioned access and collaboration)\n\t- Semantic diffing, live `git`\n\t- Minecraft or other real-time game (testing latency)\n\t- EVM (testing expressiveness)\n\t- Synced file system.. with editing and hosting of local-files baked in\n\t\t- co-creating w ebsites live, similar to [Beaker Browser](https://docs.beakerbrowser.com/)\n\n### August 14th - 15th\n- Organized The SF Commons: Hack Day #0 with Athena! A non-zero number of people were like \"Hey! I've read your blog before\" or \"I love the work you do\" and it was a little surreal\n\n### August 13th\n- Visited the Computer History Museum today! Lots of interesting tidbits on how we got to where we are today\n\t- If economies of scale favoured large consolidated computer systems how did the personal computing revolution happen?\n\t\t- One reason is that the main bottleneck to adoption back then was the price. But as Moore's Law continued to hold, hardware became exponentially cheaper due to innovations in chip design, manufacturing, storage, etc.\n\t\t- People started buying it because companies like Apple started branding personal computing devices not as something reserved for only programmers and geeks:\n\t\t\t- \"Since computers are so smart, wouldn't it make sense to teach computers about people, instead of teaching people about computers?\"\n\t\t- There were magnitude level improvements over existing technology. The census for example, took 10x-100x less time using computers\n\t- How can this be applied to the moving away from large, consolidated, monolithic applications to the personal application era?\n\t\t- \"Why is it so hard to own my own hardware?\" roughly translates today to \"Why is it so hard to own my own data?\"\n\t- Explaining data availability like the differences between calling versus texting someone\n\t\t- Calling means that the other person needs to pickup\n\t\t- Texting means that you can still communicate without both being on a call\n\n### August 12th\n- [[thoughts/CALM Theorem|CALM Theorem]] and [[thoughts/CRON Theorem|CRON Theorem]]: Basically, avoid coordination where possible, it makes things slow. When we can avoid or reduce the need for coordination things tend to get simpler and faster. This theorem tell us when it is safe to avoid coordination.\n\t- I wonder if there's possibility here to write a DSL (perhaps similar to BLOOM) that compiles to JS/Rust/etc. but also checks for monotonicity properties.\n\t- Similar to that Quilt piece on why hiding network complexity in APIs is bad, perhaps baking in these inefficiency warnings (i.e. warning on 'accidental' coordination, is there a way to refactor this program to use a different set of data structures which don't require coordination) into the language\n\n### August 11th\n- Notes on [[thoughts/Braid HTTP|Braid HTTP]], [[thoughts/Yjs|Yjs]], [[thoughts/Secure Scuttlebutt|SSB]], [[thoughts/OrbitDB|OrbitDB]]\n- Quilt has a [great piece](https://writings.quilt.org/2014/05/12/distributed-systems-and-the-end-of-the-api/) arguing for more CRDTs and why APIs are lacking and what the next logical step is\n\t- Put more simply, going back to picking on APIs, what will complete this analogy? `assembly/C : Java/Python/Clojure :: APIs : ???`\n\t- To quote Leslie Lamport: \"Most people view concurrency as a programming problem or a language problem. I regard it as a physics problem.\"\n\t- Sadly, looks like the project is no longer maintained\n\n### August 10th\n- Notes on [[thoughts/HotStuff|HotStuff]], [[thoughts/HoneyBadgerBFT|HoneyBadgerBFT]]. HotStuff seems to be a really useful lens to analyze future protocols as it is a general framework for expressing [[thoughts/Byzantine Faults|byzantine fault-tolerant]] [[thoughts/State Machine Replication (SMR)|SMR]].\n- Lots of paper reading... I feel a little burnt out. I've been spending almost 15h days just trying to mental sponge as much as this as I can.\n\t- I think I'm getting enough sleep and my eating habits aren't terrible but my body seems to disagree. My eye sometimes just twitches randomly and my stomach has a certain tightness to it that I can't really describe well.\n- A bit of a slump day. Really spent the last month just reading about consensus protocols in *partially synchronous system models* only to discovery that what I was really looking for was consensus protocols in *completely asynchronous system models* (which handle cases where potentially majority replicas are offline).\n\t- I realized this as I was digging into the very last PDF I had in my browser tab on consensus algorithms -- the last of 50 or 60 odd papers I made my way through.\n\t- In this last paper, I found out about the [[thoughts/LR Permissionless Result|LR Permissionless Result]] which was derived earlier this year in February. It rules out the possibility for deterministic consensus in a Byzantine, permissionless model, which voids my current assumptions about the right type of consensus model for Rhizome.\n\t- I don't think the research and learning went to waste per-se, I feel like I really learned a lot, but it sure feels like that whole month went to waste -- none of the protocols are of any direct use to the project. I just feel incredibly frustrated.\n- A summer retrospective. Anson encouraged me to write a more in-depth reflection on my research processes. I mentioned on a call that I felt unhappy with my progress this summer. I think the bulk of it comes down to doing way too much reading and not enough building and producing things.\n\t- A large part of this I think comes down to underestimating just how much I didn't know about the space to begin with\n\t\t- Every paper I read opened 2-4 new ones. An unknown concept or definition meant another day or two to get familiar with the literature surrounding it. It wasn't until a month ago that the number of tabs I had open started to go down.\n\t- It feels like the attitude I'm taking towards research is one of bumping around in the dark. For the most part its enjoyable and exhilarating, finding things out for the first time.\n\t\t- There's a certain joy to putting yourself in an environment where you can discover things for yourself. I can ask for help when I need it, but most of the time I'm puttering along at my own pace.\n\t\t- This is roughly what my self-satisfaction curve looks like for self-motivated exploration:  ![[thoughts/images/self-exploration-satisfaction.jpeg|400]]\n\t\t- This is usually fine, but when I look at it *instrumentally*, just from a perspective of how much I've actually got done, I'm a little disappointed in myself.\n\t\t- I've decided that I'm okay with it. I'm not trying to any% speedrun my work. I want to be able to enjoy research for what it is, to visit unexpected results and learn what I find intriguing about it.\n\n### August 9th\n- Finished reading [[thoughts/Weaving the Web|Weaving the Web]]! Probably my favourite non-fiction read so far this year. Was supposed to just write up quotes but instead wrote a 1.2k word History of the Web piece instead :')\n\t- It gives me hope!! Trying to change deeply intrenched habits is hard. Getting people to see the potential is hard. But there are so many people working on this and putting their whole hearts and souls into the projects they believe in that I can't help but believe it'll work out.\n\t- To quote from Tim Berners-Lee: \"When I try to explain the architecture now, I get the same distant look in people's eyes as I did in 1989, when I tried to explain how global hypertext would work. But I've found a few individuals who share the vision; I can see it from the way they gesticulate and talk rapidly.\"\n- Rough notes on [[thoughts/Casper FFG|Casper FFG]], [[thoughts/SBFT|SBFT]]. Revising notes on [[thoughts/PBFT|PBFT]]\n\n### August 8th\n- I want to target 60 updates per second (~16ms budget) for local and 10 updates per second (~100ms budget) for global updates\n\t- This is a good target to aim for but also wary of premature optimization\n\t- Will likely need to just build stuff out first and experiment to see if it is usable\n- Spent some time restructuring all my notes around [[thoughts/cryptography|cryptography]] to have better note and concept separation\n- Reading more about [[thoughts/IPFS|IPFS]], their BitSwap protocol for block exchange is a super cool case study on how to do incentive design.\n\n### August 5th - 7th\n- Went to [Hackclub Assemble](https://assemble.hackclub.com/) and was just inspired by the magnitude of talent of the next generation of hackers and builders. Zach (+ Sam and rest of the HC team) really blew it out of the park this time. The theme was to build something completely useless and the kids went wild with it. I still strongly believe that one of the best signals for someone who *deeply* and intrinsically cares about technology is one who can still play and tinker for the hell of it.\n\t- In a similar vain, I'm organizing a Hack Day at [The SF Commons](https://www.thesfcommons.com/) on August 14th! A little callback to my hackathon organizing days :)) Really hoping to bring this new space to life with this event\n- Reading **Weaving the Web** by Tim Berners-Lee. More thoughts on this coming soon, but tldr; it is reassuring to hear that it took almost 13 years to combine the Internet and [[thoughts/hypertext|hypertext]] together to conceptually create the Web. Even then, it took a lot of trying over many years to bring adoption for something that many didn't really see as potentially revolutionary\n- Reading through [[thoughts/PBFT|PBFT]] paper, really trying to understand the correctness and [[thoughts/liveness|liveness]] proofs\n\n### August 4th\n- Random thoughts:\n\t- What if messages were doubly-signed with the hash of application source? This would mean that all events are specific to application version.\n\t\t- Holochain cites that this may be a problem: \"unfortunately anyone can modify their own source chain, regenerate the hashes and signatures, and create a perfectly valid, but wrong, alternate history for themselves.\"\n\t\t- However, this is actually a non-issue, given we split this into two cases:\n\t\t\t1. Single-player App: whatever the user does is 'correct' behaviour anyways, what does it mean to have a wrong alternate history when you are the only person dictating it? All actions will still need to be in the domain of valid actions as dictated by the app (otherwise, message signature would not add up as we sign messages with the hash of application source).\n\t\t\t2. Multi-player App: peers will have a hash of the last known action of a user. If the action history is completely rewritten, the probability of arriving at the same hash is negligible, meaning that the peers will reject any further actions as invalid.\n\t\t- This brings up a new question of what migration paths look like between old and new versions of applications. If we go by hash of application source, then each update to the source code will seem like a completely new application!\n\t\t\t- Each application perhaps can be signed by an author. If a newer application by the same author claims to be an update for the existing application, it can propose an upgrade path to interpret the older data in a usable format for a new one, essentially 'importing' the data in\n\t- Good furniture and architectural choices respect user agency, allowing those in the space the ability to move around at will. How might we analogize this to software? [[thoughts/digital commons|Digital commons]]?\n- Read through [[thoughts/Holochain|Holochain]] docs which are actually quite similar to what I have in mind for Rhizome.\n\t- Really liked\n\t\t- Using [[thoughts/RDF|RDF]] triples in a [[thoughts/DHT|DHT]] to create a distributed graph database is a smart way to network the data -- feels like what semweb was supposed to be\n\t\t- Everything is self-owned and consistency of application state is maintained by storing hashes of actions to a global [[thoughts/DHT|DHT]] which allows for peer accountability\n\t- Things that I think are unaddressed\n\t\t- Documentation was well-written but the terminology was confusing at times. Was not immediately obvious what part each piece played\n\t\t- How important is global data-witnessing? Why do we need social pressures for this when we can do this using [[thoughts/cryptography|cryptography]]?\n\t\t\t- This also means that progress cannot be made until a node is back online (otherwise, actions remain unvalidated)\n\t\t- Problem of getting people to migrate off of existing platforms remains unsolved\n\t\t- Developer experience is difficult to set up and get started (see [HApp setup docs](https://developer.holochain.org/happ-setup/)) -- heavy use of technical terminology\n\n### August 2nd - August 3rd\n- Learned a lot about [[thoughts/Network Theory|Network theory]]\n\t- Expanded more on thoughts about the inevitability of centralization with more insights from advantages and disadvantages of scale-free networks compared with random ones\n\t- Also notes on [[thoughts/cascading failures|cascading failures]], interesting to note that sometimes the most effective way to stop a failure is to prematurely kill edges and nodes (e.g. burning parts of the forest ahead of a forest fire to clear debris in a controlled manner)\n- Stressed about what to do for the upcoming gap term/year!! \n\t- Things that are weighing on my mind:\n\t\t- I want to graduate. Most visas other than the O-1 visa require at minimum a Bachelor's degree so this is definitely something I'm thinking about. Also, a lot of highly technical jobs are (unfortunately) still gated by degrees so having at least a Bachelors is useful in that regard.\n\t\t- I want to be able to spend the *at least 3-6 hours per day* thinking about this research project. I really think that given I have the financial means to pursue research full-time I should. A younger version of me once said that if they found an idea that excites them when they wake up every morning, they would pursue it without fail.\n\t- School Situation: I need 2 more 4xx+ Computer Science Courses and 5 more 3xx+ Electives to graduate. Problem is that it is wayyy past course registration time to jig things around so either:\n\t\t- I keep my current course schedule (stay on track to graduate next May)\n\t\t- Unregister from all my courses (push back graduation date to next fall or 2024 May)\n\t- Research Situation: Although the research grant is no-strings attached, I really want to be able to output good work that I am proud of. Plus, the people at Protocol Labs are super cool and I want to be on good working terms with them for potential future collaboration.\n\t\t- I think summer research has been literature review era and once next semester starts, it will mostly be building things out.\n\t- Other thoughts: in my [[posts/2021|Letter to my Future Self]], I mentioned I wanted to reach deep focus in whatever work I do and have the resources to be able to choose the work I find enjoyable. I'm not going to half-ass do whatever, so it will either be full-send research or full-send finishing school.\n\t- Options\n\t\t- Keep current class schedule and try to move research to after graduation\n\t\t\t- Not nearly as interesting as working on research\n\t\t\t- Will graduate on-time in May!!\n\t\t\t- Less long-term stress about returning to school to finish things\n\t\t\t- **I think I'm going to choose this option!!**\n\t\t- Gap year to purely focus on research\n\t\t\t- Output research work I am proud of, keep good relations with Protocol Labs\n\t\t\t- Keeps research momentum going, will be more effective than picking up the project a year from now\n\t\t\t- Will need to go back to school which will feel like I'm set back a year\n\n### August 1st\n- Gordon Brander deep-dive today... more thoughts on the [[thoughts/inevitability of centralization|inevitability of centralization]] and [[thoughts/credible exit|credible exit]]\n- It seems we are reaching that 'recentralization' step of the decentralization-recentralization cycle, with power concentrating in the infrastructure and application level.\n\t- Gordon proposes abolishing the `same-origin` policy. His thesis is that this forces resources on the web to be centralized around the ownership of domains. Everything -- security, privacy, identity, data, and scripting -- needs to be provided by the same origin, unless explicitly set otherwise. The 'hub' here that everything goes through is the domain. We've arrived back at the original centralized hub model of the internet.\n\t- How we can learn from the leap that Baran made going from circuit switching to packet switching and apply it to this new layer of the web? In the words of Gordon: \"Can we imagine a new weblike thing that is to the web as packet switching is to circuit switching?\"\n- Content-addressing feels like a viable alternative to how loading resources works on the internet today.\n\t- Address-based addressing relies on a central registry to figure out where things are. [[thoughts/content addressed storage|Content addressed storage]] (e.g. [[thoughts/CID|CIDs]]) *decouples* the data from the origin. If you know what the hash is, you can request the original file, irrespective of where the file actually lives.\n\t\t- There is no single domain hosting your file.\n\t\t- Many copies of your file exist across the network. This redundancy keeps things safe in case of failure.\n\n## July\n### July 30th\n- I think I'm going to take a gap semester from September to December to give myself the time to finish the research to a level I'd be happy presenting to Protocol Labs at the end of the year.\n\t- Never thought I'd *actually* take a gap semester but here I am... looks like I might graduate late now LOL\n- I want to spend some time thinking about how to create effective learning and research communities. I know that since I started working in the public hackerspace at Incepto, my productivity has gone up something like 5x. How do I *geographically* surround myself with people that constantly inspire me to work on ambitious things?\n- On a whim, read this awesome [Patreon post](https://www.patreon.com/posts/ratcheting-in-47976114) by Andy Matuschak\n\t- *Ben Shneiderman, a pioneering human-computer interaction researcher, offers this charming schematic for research project design in The New ABCs of Research. He calls it the “two parents, three children” pattern.*\n\t  ![[thoughts/images/research project pattern.png|500]]\n\t  - I've been thinking more about how research seems to come in two layers\n\t\t  1. The ideas\n\t\t  2. The language in which it is expressed\n\t  - Majority of my time has been on refining 1. so that 2. may come easier, but perhaps both should be worked on in concert. \n\n### July 24th - 29th\n- Roadtrip! Had a really fun roadtrip with Anson, Joss, and Jaclyn from SF to LA. Stopped at a million beaches, observed some stunning sunsets, surfed for the first time, ate great food, and sang lots of songs. Learned about 'Surfboard' by Cody Simpson which was the trip themesong.\n- On July 25th, I heard back from Protocol Labs and got my first large grant for 20k for the next 4 months!!! \n\t- I think this support will mean a lot for the project. Protocol Labs is incredibly values aligned and they have some of the brightest minds thinking about similar problems. Even just being in an environment where I know I can expect feedback from these people (not to mention financial support) feels like a major milestone\n\t- I really loved how they have an RFP-000 which is an 'open-call' for research that may not fall any other current category\n\t- They are strongly encourage I have more 'traditional' research outputs, which I think makes a lot of sense! This will give me more exposure to the more 'academic' side of research as\n\t\t- An open-access paper or brief technical report (e.g. submitted to arXiv)\n\t    - An open-source code library with good documentation\n\t    - A recorded, shareable presentation of the work, preferably as part of our research talk series (!! this is really exciting).\n\t    - A blog post describing the impact of your work to be featured it their [research blog](https://research.protocol.ai/posts/).\n\t- I especially love how the grant is 'no-strings attached'. I think this really incentivizes honest behaviour and reporting of *true outcomes* rather than encouraging fabricated results or demos to get funding.\n\t\t- \"**Unsuccessful projects**. Our interest is in accelerating science for the benefit of all. Naturally, over time we will be more likely to fund proposals from active and effective members of our community.  However, we understand the complexities of research and do not revoke payment if the work changes course, is unsuccessful, or reaches a dead end. We value great results but also understand the value of exploration and impossibility results.\"\n- My passport is about to expire so I will need to be in Canada for fall :(\n\n### July 22nd - 23rd\n- Finished up the [[posts/digital-identity|identity piece]]! Cent and B from Metagov gave some very good advice and clarifying feedback on the piece.\n\t- I think the essay was trying to do too much so I'm going to split out the content and keep all the stuff about agency and legibility in this one.\n\t- I want to write another piece eventually about different ways of being online (specifically, collective inter-being vs individualism)\n\t\t- The new atom of identity is not a single entity but a set of relationships. A group chat. A chat that isn’t just a text messaging history but can embed applications and rich worlds on top of it.\n\t\t- Elaborate more on groupchat as an entity\n- I have a bunch of reading piled up this week since I've been doing a lot of writing so I'll focus on getting through some more stuff today and tomorrow.\n\n### July 21st \n- Polishing up [[posts/digital-identity|identity piece]]. I've worked on it enough that I'm starting to feel ick just touching it but I'm happy that I've thought about this deeply. Implications for Rhizome as a whole:\n\t- Self-sovereignty seems useful for agency *if implemented in ways that don't force legibility*\n\t\t- e.g. be careful about [[thoughts/Verifiable Credential|VCs]] without zkSNARKS\n\t- Probably will need to think more heavily about how to model a relation history on the dev side of things as people are used to modelling individual users. Perhaps phrasing the basic item as a *group chat* makes sense?\n\n### July 20th\n- Finally got the piece to a place where it is ready for feedback. B, Shrey, and Saffron took a look and left a bunch of comments which identified plenty of spots where either my reasoning was flawed or just wasn't good.\n\t- Revision time !! 🙃\n- Feel like I haven't been very proactive in thinking about funder relations.\n\t- Found out today that GitHub has a very handy feature to email all of your sponsors!\n\t- Will probably draft up a short update email and include a link to the identity piece as soon as it's done.\n\n### July 19th\n- Slowly reaching a place where I'm happy with the direction of this piece on identity, framing it more around 3 modes of thinking about [[posts/digital-identity|identity]].\n- Got a comment from Zoë Ruha Bell on my essay in Reboot that asked about \"the complexities of how moving data between contexts changes its meaning and that individual control over data may not match up well with the relational information encoded in data\"\n\t- Incidentally, this is exactly what I've been thinking more about! My response:\n\t- This is a great question and I'm still grappling with (and in the midst of writing a whole other piece about!). Data in context is incredibly important. Like identity, when taken out of context, it can be incredibly harmful and misused. Pursuing interoperability without considering the intention behind the actions that data encodes can easily turn dangerous very quickly.\n\t- One way I'm thinking about this is analogizing the multiple facets and contexts of data as people. Just as people behave differently in different contexts, so can data. The same reason we have so many 'alts' or 'finstas' is that this multifaceted-ness isn't accommodated by existing media platforms. Data platforms similarly treat data as single faceted. What does a multi-faceted encoding of data look like? What does communal ownership of data look like?\n\n### July 18th\n- I've been trying to write down some more cohesive thoughts around [[thoughts/identity|identity]] for the past two days and running into a block where I'm struggling to articulate why and how real world identity and digital identity differ\n- Just read this blog post on [Going Doorless](https://rosano.hmm.garden/01evv3hq1ak4b6ng1jzppx5n2j) that really resonated and gave new language to ideas and concepts that have been floating around in my head for a while\n\t- Public commons like parks and libraries feel public because moving around in them is effortless\n\t\t- We don't have commons because the space between digital spaces have the viscosity of honey. Movement becomes heavily disincentivized.\n\t\t- To be clear: I mean that *people* should be able to move freely. Data should have access control switches exposed to users. They should decide whether it moves freely or not. \"after voluntary communication to others, free as the air to common use\"\n\t- You shouldn't need to pay or set up and account to walk through the gates, commons just let you show up and start using it\n\t- Software is the principles of an experience, your data is just the details\n\n### July 16th - 17th\n- Currently on a two-day writing retreat with Belinda, Athena, and Vincent. It's been such a good mix of sight-seeing and focused writing.\n\t- The other choice of spending this weekend was to go to an Art Book Fair and assemble furniture with friends. In all honesty, I'm very glad I chose to focus and write over just socializing.\n\t- Some good time away from purely technical reading meant I had time to think more about identity. More thoughts around [[posts/digital-identity|verb based identity]]\n\n### July 15th\n- Part of the nail of my left pinkie ripped off today argH it is now painful to type :((\n- Realized that when doing site redesign, I lost a commit's worth of notes (sad) but also Obsidian Sync which I normally use for backup *also* expired today (double sad). Not as bad as it could have been though! Thankfully I commit often :)\n- Spent a lot of time just reading today, a lot of different scattered blogs that I've been meaning to get to. [One link that was sent](https://generative-identity.org/human-identity-the-number-one-challenge-in-computer-science/?curius=1294) in the Metagov Slack particularly stood out to me though. It was on human identity and, more specifically, a critique of specifically [[thoughts/Self-sovereign Identity (SSI)|SSI]]\n\t- Long read but I think it captures a lot of my thinking around why I think [[thoughts/digital permanence|digital permanence]] is scary (and why I've been thinking about relational notions of identity!) TLDR;\n\t\t- The concept of identity is very noun-like (i.e. tied to physical traits and current state) in Computer Science + software systems\n\t\t- Contrasts with identity as verb-like (i.e. incredibly contextual, based on who you are with, how you are feeling, what experiences you have)\n\t\t\t- \"The joins are the pathways for information exchange and transformation, for organising, and the expansion of organisational identity. Joins give the dots their meaning, their contextual relevance, their identity, just as dots give the information exchange direction and potency.\"\n\n### July 14th\n- Reboot published my research proposal / manifesto / essay on Rhizome and data-neutrality today!\n\t- [Check it out on Substack](https://reboothq.substack.com/p/rhizome)\n\t- Ben Tarnoff, the guy who cofounded Logic, actually read and [tweeted about it](https://twitter.com/bentarnoff/status/1547619611796914179) and readers seemed to resonate a lot with the post!\n\t- Two general sentiments:\n\t\t1. This project seems really exciting and I appreciate it recognizes existing work. What will get people to use this though? The social difficulty with \"apps as a view over data\" is that it requires users to understand data models and this consensus over data models has proven difficult\n\t\t\t- I agree with this evaluation and so far, feels unsolved. I think a promising solution is to think about it like how community-sourced types for TypeScript work. There's a whole open-source project that wildly popular that provides TypeScript definitions for plain JS libraries called [DefinitelyTyped](https://github.com/DefinitelyTyped/DefinitelyTyped) (with over 12.6 million usages!). I think there's a potential for this to work with data schemas as well\n\t\t2. Well.. crypto/existing-thing actually solves this! Blockchain scaling techniques are getting pretty good, don't see why this work is necessary.\n\t\t\t- Again, true. I think these new technologies all seem really promising and I definitely try to keep up with all the developments in the space but my main concern comes from how convoluted these solutions are slowly getting.\n\t\t\t- A lott of smart people in crypto have been working on these problems for a while, I'm starting to think it might be easier to tackle it from the other side. Plurality of approaches y'know :))\n- nobody: ...\n   youtube: https://www.youtube.com/watch?v=g7MSfHEdxXs\n- Going to read more about [[thoughts/causal tree|causal trees]] as a way of understanding more basic forms of [[thoughts/CRDT|CRDTs]] that value readability over correctness\n\n### July 13th\n- Feeling a little tired of just reading papers and coding\n- Going to do a mental reset and just play piano for a while and then doing that person website redesign that I've been thinking about for a while now...\n\t- Update: this is so fun gah\n\t- Realized that the typography on the old site was kind of garbage and hard to read. Spent a bit of time reading up on good typography practices and it looks soooo much better\n\n### July 12th\n- Ok, a bit of a wrench in the system : ' )))) CRDTs are incredibly hard to reason with for the average dev and *cannot guarantee global invariants* without requiring consensus.\n- Finished up CRDT implementation collection over at [[thoughts/CRDT Implementations|CRDT Implementations]].. I feel like I'm getting a better grasp at how to write op-based CRDTs but less so for state-based\n\n### July 11th\n- Seems like there are a lot of open research questions in CRDTs that I could plausibly spend *years* working on (e.g. undo operations in CRDTs, encrypted CRDTs using homomorphic [[thoughts/encryption|encryption]])\n- I need to read more about this but it seems like most traditional consensus algorithms require synchronicity from all nodes for them to be considered honest. I wonder how we can reconcile this methods like CRDTs that allow for more asynchronous forms of consistency\n\t- Is it possible to take advantage of the partially synchronous [[thoughts/system model|system model]] and having CRDT-like behaviour in async modes and Raft/Paxos-like behaviour during synchronous periods for compaction\n\t- This is especially important as users will rarely have all (or even supermajority) of their nodes online at any given time. Will need to look into variations on Raft that tolerate live membership changes\n\t\t- \"The network can partition and recover, and nodes can operate in disconnected mode for some time.\"\n\n### July 10th\n- A lot of good meditations on adoption of tech that gives agency to users at a Hack Night that Rishi hosted :))\n- Currently at another session of the writing circle. Good to probably zoom out from a lot of the technical in-the-weeds work and re-orient about what this means for the average consumer\n- Do people care about data ownership and data agency?\n\t- The average user probably doesn't. They want convenience and are comfortable with current options.\n\t- But as a counterpoint, if you ask anyone on the street whether they would be comfortable sharing their entire browsing history right there on the spot, my bet is that ~95% of people will say no\n\t\t- This could be a really fun social experiment: incrementally increase the amount you offer strangers to look at their browsing history\n\t\t- How much does the average person value their [[thoughts/privacy|privacy]]?\n\t\t\t- Yes, companies and the government have a lot of data/info on us\n\t\t\t- But what has come out of it? For the average consumer, nothing! There is a definitely anxiety of *but what if* with no real bad cases (that we know of)\n\t- Another question is why having a *real person* snoop on your data feels so different than large companies snooping and *profiting* off of your data\n\t\t- I suspect a large part of this is due to learned helplessness\n\t\t- We haven't ever really known what it is like for companies *not* to be doing that\n\t\t- It feels abstract! A company remotely snooping on your data is something that a user could remain fully blissfully ignorant from\n\t- I think people don't care because they haven't known what a possible future could look like\n\t\t- People don't ask for cars because all they've known in their lives are horses. They can only think of faster horses\n- How do we convince the average consumer that this is something worth caring about?\n\t- Near zero-friction doesn't necessarily people will want to switch to this new paradigm. It is still a non-neglible activation energy to move platforms\n\t- This probably won't happen unless there is both 1) a radical *push away* from existing centralized platforms and 2) a strong and convincing *pull towards* new decentralized platforms like Rhizome\n\t\t1. This is where I think regulation, anti-trust, and legal requirements for data usage transparency are incredibly important! There are institutions just as powerful as these large tech companies that can serve as a counterbalancing force too\n\t\t\t- This still feels incredibly difficult as these tech companies have started invading these regulatory bodies and holding immense lobbying power\n\t\t2. We do so by providing tangible and real improvements over existing products (that matter to the average consumer)\n\t\t\t- Never need to manage a million different accounts again\n\t\t\t- Local-first feels lighter and faster\n\t\t\t- Easily understandable ToS (people know what access are giving away)\n\t\t\t- End-user programming should be trivial and non-technical (i.e. making integrations like Zapier useless)\n- Why would companies care about this model of computing?\n\t- tldr; building and maintaining a data moat is hard\n\t- Computation happens almost entirely on end-user devices, need to host massive infrastructure goes way down (unless you are doing heavy ML and info processing, which most companies are not)\n\t- New markets for lending compute to the masses rather than just to programmers and tech companies\n\t- Almost all the grunt work of data transformations is eliminated so companies can focus on business logic\n\t- [[thoughts/GDPR|GDPR]] compliance built-in, users have freedom to manage their own data\n- Meta-meditations: this was incredibly helpful to iron out philosophy a bit more. I think this is starting to make more sense from both a user and company perspective, but only for people who *care* about these sorts of things. I think end-game is getting my Mom to understand why this is important.\n\n### July 9th\n- Various notes on CRDTs\n\t- Seem to require [[thoughts/consensus|consensus]] for state compaction\n\t- Learning about [[thoughts/clocks#Hybrid Logical Clocks|HLCs]] and maintaining [[thoughts/causality#Causal Order|causal order]] in CRDTs\n\n### July 8th\n- Learning more about [[thoughts/CRDT|CRDTs]], [[thoughts/Order theory|Order Theory]]\n- I got my first email from a mutual which was along the lines of \"help, I'm stuck in leetcode hell, how do I escape and do other things?\"\n\t- I feel like I barely know what I'm doing, let alone ready to help another person along on their journey! I sent along a few questions that were really helpful for me when convincing myself to do this project and I hope it's useful.\n\t- Here was the email response I sent: ![[thoughts/images/Screenshot 2022-07-08 at 4.08.41 PM.png]]\n- Had a great chat with Saffron today about some of the really cool research she's thinking about doing re: online identity and data agency.\n\t- This really would not have happened if Spencer hadn't pushed me to write a thread briefly summarizing what I was working on this summer. I've had a lot of super cool folks reach out and say that they are really excited by the work I'm doing! This is both reassuring but also extremely nerve-wracking. Expectations!!!! A concept\n\t- One point we talked about that I'm still ruminating on is the idea that selling data requires a baseline level of interoperability between two parties\n\t\t- How do current data markets work? If Facebook for example sells their data to another company, is it literally a raw export? How does that handoff happen and how do they ensure the format of the data they are using is understandable by both parties?\n\t\t- I think inspiring more thoughts on what potential business models could exist on a platform like this\n\n### July 7th\n- Finished up Tim Roughgarden's lectures on the foundations of blockchain which had some really useful theoretical details on traditional [[thoughts/consensus|consensus]] mechanisms which definitely solidified my understanding\n- Currently at ~$900/mo in terms of sponsors and I'm just blown away by the volume of support people have expressed. This is more than halfway to monthly living expenses and it feels so close?\n\t- At first I was a little nervous because, y'know, that's a lot of expectation of producing something meaningful\n\t- But I think this is exactly the forcing function I need to be active in doing as much as I feasibly can and share as much as possible. Even if someone steals my idea and runs with it, so what? The future is pluralistic. If it's interoperable, it doesn't matter how many implementations there are!\n- Read a really good paper on [[thoughts/neutrality|neutrality]] and learned about the [Data Transfer Project](https://datatransferproject.dev/)\n\n### July 6th\n- Holy shit [Morgan](https://twitter.com/morgallant), [Aadil](https://twitter.com/aadillpickle), [David](https://twitter.com/TheDavidZhou), and [JZ](https://twitter.com/jzlegion) just sponsored me for ~$400/mo for this research project and ... I am genuinely just speechless??\n\t- It's just so wild to me that this little project that I’ve just felt so strongly about because of reasons that still seem to evade words is something that other people are interested in seeing come to life too.\n\t- It feels like this project is a mountain I've set my sights on hiking for the longest time. And for a while I was hiking it alone, appreciating the scenery and the path but the path was lonely. But now I can hear the singing and laughing of my friends as people cheer and join along for the journey and it feels just a bit more manageable.\n\t- The generosity of these friends (shoutout to MFC and Anson) means that paying the next two months of rent and food isn't something constantly nagging at the back of my mind :')\n- There were many points this summer I was fully ready to give up (see: plenty of mental breakdowns below) and stop trying because I questioned whether this was worth doing -- if I should just stop and get an actual job\n\t- I felt really silly for asking people to help financially on a project that I sometimes had trouble believing in too.\n\t- So thank you for your trust, thank you for dreaming with me\n\t- Today's soundtrack is from [La La Land -- Audition (The Fools Who Dream)](https://open.spotify.com/track/6j0wBBAP3hMe4t1Ymj7GIe?si=ef50241abfe04ac2)\n\n![[thoughts/images/IMG_1805.png|???]]\n\n### July 5th\n- Finalizing notes on [[thoughts/Tendermint|Tendermint]] and wondering if I should switch out [[thoughts/Raft Consensus Algorithm|Raft]] for it. How valuable is [[thoughts/Byzantine Faults|BFT]] anyways? Do we assume nodes are prone to potentially malicious takeover?\n\n### July 2-4th\n- An 'aha' moment caught in 4k... watch me try to figure out why asynchronous and partially synchronous [[thoughts/system model|system models]] aren't the same thing (s/o Sebastien for being so kind and patient). This was super satisfying!\n\n![[thoughts/images/on-async-partially-sync-models.png]]\n\n### July 1st\n- Internet went out today halfway through watching lectures :(( \n\t- Spent a bunch of time just reading books + thinking\n- More notes from Tim Roughgarden's foundation course on [[thoughts/Public-key Infrastructure|PKI]], [[thoughts/Byzantine Broadcast|BB]], impossibility theorems, etc.\n\n## June\n### June 30th\n- Settling into a better work rhythm I think.\n\t- Food here is surprisingly expensive but groceries is still miles cheaper than just getting Uber Eats everyday. \n- Have a sudden urge to work on my personal site but I will ignore that for the time being...\n- Sebastien sent a [YouTube playlist](https://www.youtube.com/watch?v=KNJGPI0fuFA\u0026list=PLEGCF-WLh2RLOHv_xUGLqRts_9JxrckiA\u0026index=1) on the foundations of [[thoughts/blockchain|blockchains]] that have some sections which seem highly relevant. Slowly making my way through these\n\n### June 29th\n- Finally wrapped up school! Anson is headed back to Arizona today too :((\n\t- Living together has been a fun dance of trying to balance our energy levels, but felt very much like a team throughout. I'm really glad I chose to prioritize relationship, truly some moments over the past month where I was like \"wow, is this real.\" It feels like I'm selectively giving deep attention in-turn to the things I care most about.\n\t- Now is the era to just fully focus my attention on research and this project though\n- I think this finally means that the vast majority of my waking hours will be on research. Uninstalled a game I was spending way too much time playing :')' it is grind time\n\n### June 27-28th\n- Nearing the end of my literature review era. Still need to go through Braid/Redwood, SSB, Yjs, and Hypercore inner-workings.\n- Thinking it might be good to do a general overview of [[thoughts/CRDT|CRDTs]] before delving any further\n\n### June 26th\n- Belinda and Athena from Incepto told me about an SF writer event which happens every week and I'm currently at it right now. So many people here are just working on such really cool things and I'm excited to potentially have this space as incredibly condensed resesarch + thinking time. I think this is a great forcing function every Sunday to just... orient myself for the week and get shit done.\n- Talked with some really really cool people at a birthday party in SF which were surprisingly receptive and interested in my work. Will definitely follow up on these conversations.\n- More research on [[thoughts/CouchDB|CouchDB]] and other database replication mechanisms to see what I can learn from it\n\n### June 25th\n- HackLodge meetup today, also met up with Spencer and Liam. Talked lots about the project then realized I haven't spent much time just... sitting down and grinding out work.\n- A decent chunk of it is 1) summer courses taking up much more time than I expected them to and 2) wanting to meet people in SF and spend time with Anson while she is still in SF... priorities priorities\n- To borrow words from Anson, it's \"hermit time\". I feel like I am definitely behind schedule in terms of what I wanted to get done by this point of summer and I need to put in some serious work and thinking into this project.\n\n### June 24th \n- Reading about [[thoughts/Hyper Hyper Space|Hyper Hyper Space]], doesn't seem to place a big deal of emphasis on finality which seems important for a large chunk of applications.\n- Open questions:\n\t- Append-only log or append-only [[thoughts/Merkle-DAG|Merkle-DAG]]? Leaning more towards log still for easy understandability + debug even though Merkle-DAGs are more expressive (and battletested in [[thoughts/blockchain|blockchains]] and `git`)\n\n### June 20th - 23rd\n- Reading about [[thoughts/file system#Virtual Distributed File System|VDFS's]] (specifically Alluxio) and \n- Open Questions\n\t- Handling cases where data \u003e storage availability\n\t- Checkpoint heuristics: when to checkpoint? especially important if Rhizome is to run indefinitely\n\t\t- \"Lineage chains can grow very long in a long-running system like Alluxio, therefore the checkpointing algorithm should provide a bound on how long it takes to recompute data in the case of failures\"\n- Settling into new place, we cleaned out the garage (which is where I am staying) and made it somewhat liveable?? Took a lot of work, the previous tenant didn't even properly move out which was a stressor for a little while\n\t- Because there is no proper heating/cooling, sometimes I literally work with the garage door open for good circulation which gets me weird looks from the neighbours but it's fun\n\t- Incepto people have all been super nice and they are all working on/exploring cool things. I get a little distracted sometimes just working in the garage so it's really nice I can just hop over to the hackerspace in the house to get some more focused work done.\n\n### June 16 - 19th\n- Interact Retreat! Lots of good conversations about the work I'm doing which has been super clarifying for what type of explanation gets through to certain types of people\n- Generally find framing it in terms of net neutrality but applied to data gets a lot of people excited about it, as well as meaningfully explaining + differentiating from Tim Berners-Lee's [[thoughts/Solid|Solid]] project and how Rhizome focuses on addressing main retro points from major p2p protocols.\n\n### June 14 - 15th\n- Mostly trying to answer questions around how [[thoughts/decentralized marketplace|decentralized marketplaces]] for demand work, looking at Golem and Orchid\n- Lots of moving around (moved from Tempe to SF, about to head to Interact retreat!)\n\n### June 13th\n- Rough research notes and open questions on [[thoughts/DID#DWN|DWNs]]\n- DID document needs to specify the service\n\t- Resolve a DID to web node URI\n\t- `did:example:123` -\u003e resolve to Decentralized Web Node endpoint(s) -\u003e `https://dwn.example.com`\n- Raw vs Signed Data\n\t- Raw → only data + descriptor\n\t- Signed → data + descriptor + attestation (JSON web signature/JWS)\n\t- more details: https://identity.foundation/decentralized-web-node/spec/#message-descriptors\n- Storing data relative to a schema\n\t- https://identity.foundation/decentralized-web-node/spec/#query\n\t- schema field in descriptor\n\t- JSON-LD + https://schema.org ?\n\t- or... openzepellin style, vetted schemas\n\t- data lensing should fit into this\n- Permissions request\n\t- https://identity.foundation/decentralized-web-node/spec/#request\n\t- signed message\n\t- define scope\n\t- based on DAG commit range perhaps?\n\t- Potentially using [[thoughts/UCAN|UCANs]]\n- Open questions\n\t- How does DID ownership work? what is it pinned to? is IPFS sufficient?\n\t\t- TLDR; DID needs to be generally anchored to something. Notes on [[thoughts/Sidetree|Sidetree]], a backend agnostic DID persistence mechanism\n\t- How do we make ownership/data management easy for non-technical people?\n\n### June 11-12th\n- Roadtrip with Anson! Much needed break to get a mental break and reset\n\n### June 10th\n- Spicy day today... Jack Dorsey just announced TBD working on Web5, supposedly an extra decentralized web platform (https://twitter.com/jack/status/1535314738078486533)\n\t- web5 seems to focus on the philosophy side a lot more than actual usability\n\t- Very similar to [[thoughts/WebID|WebID]] except anchored on bitcoin (lots of interesting stuff using [[thoughts/Sidetree|Sidetree]])\n- Feel like a little boat in a big ocean where huge battleships drift by every now and then\n\t- Makes me doubt what I can really do as this small little boat\n\t- But reminded that steering my own little boat gives me agency as to what I can explore and do\n\t- The little boat that could\n\n### June 9th\n- Lots of research, mostly around [[thoughts/FOAF|FOAF]], [[thoughts/LDP|LDP]], [[thoughts/RDF|RDF]]\n- Looked more into [[thoughts/decentralized marketplace|decentralized marketplaces]] like Raiden and Orchid to see how they handle payments\n- Mostly just reading articles and specifications, your average day of research\n\n### June 8th\n- Got my first grant rejection from Emergent Ventures today :((\n\t- Feeling.. kinda numb? I feel like grand scheme of things it doesn't matter but this is the first *hard* no that I've gotten\n\t- Spent some time looking for some other grants but my conclusion is that I should spend more time getting shit done before asking for more funding.\n\t- I have enough in savings to last me until end of summer but it means I'll have to start contracting during the school year which isn't ideal, but gives me pure focused time this summer to just do research.\n\t- Onwards!\n- Lots of really great bits from Browser Co's piece on Optimizing for Feelings\n\t- \"Anything new is by nature without precedent — meaning, without data to know whether it will work or not. So when we approach building new things, we don’t optimize for metrics. We optimize for feelings\"\n\t- \"How do you feel when you finally step foot in your own living room, after weeks away from home? When you plop down on your own bed, or whip up a meal in your own kitchen? It conjures up a specific feeling, doesn’t it? That’s because these spaces are a reflection of you — created by you, for you. Software can feel the same way if individuals have agency and sovereignty over what is on their screens.\"\n\n### June 4th - June 7th\n- Getting back into a working groove after moving again, Arizona is ridiculously hot. Made the dumb mistake of walking to the grocery instead of taking transit lol\n- Learned more about underlying datastructures of [[thoughts/IPFS|IPFS]] including [[thoughts/CID|CIDs]]\n\t- Potential for interop between IPFS and [[thoughts/DID#Creating DIDs using IPLD|DID Documents]]?\n- More notes on [[thoughts/DHT|DHTs]] and [[thoughts/Kademlia DHT|Kademlia]] in particular\n\n### June 1st - June 3rd\n- Had a call with a few others folks working adjacent to decentralized infrastructure and people seemed pretty excited about the proposal! It was the first time in the past month that I felt pretty confident about the project when talking about this with others, definitely a personal milestone :)\n\n## May\n### May 28th - May 29th\n- Attending friends' graduation for the past few days, crazy to think that this will be the last time I see some of these friends for a long time.\n- Worked on thinking about and polishing my grant proposal, finally getting to some phrasings that resonate and sound good\n\n### May 27th\n- Finishing up `miniraft`, added tests for voting and fixed up some workflow stuff to auto-test and publish documentation!!! It's [published now on GitHub :))](https://github.com/jackyzha0/miniraft)\n- Notes on [[thoughts/DID|DID]] which seems particularly applicable to the notion of identity + identity documents\n- Once again had a breakdown :)) Constantly feel like I'm not doing enough and that time is slipping between my fingertips...\n\n### May 23rd - May 26th\n- Catching up on school work\n- More reading + notes in [[thoughts/decentralization|decentralization]], [[thoughts/authorization|authorization]], and [[thoughts/federation|federation]]. Notable readings:\n\t- [IETF Draft on Centralization and Internet Standards](https://www.ietf.org/archive/id/draft-nottingham-avoiding-internet-centralization-03.html?curius=1294)\n\t- Gordon Brander on [Modularity](https://subconscious.substack.com/p/modularity?s=r\u0026curius=1294), [weblike things](https://subconscious.substack.com/p/weblike-things?s=r\u0026curius=1294), and [feudal metaphors for the web](https://subconscious.substack.com/p/web3?s=r\u0026curius=1294)\n\t- [Fission on UCAN for serverless authorization](https://fission.codes/blog/auth-without-backend/?curius=1294)\n\n### May 21st - May 22nd\n- Packing + flights! I am now in Vancouver for the next week :))\n- Hectic flying experience... didn't get much done\n\n### May 20th\n- Chatted with Justin Glibert who gave some very piercing advice\n\t- What is the most you can cut from your current proposal and have it still be meaningful?\n\t\t- *via negativa*: essentially the study of what not to do\n\t\t\t- In action, it is a recipe for what to avoid, what not to do—subtraction, not addition.\n\t\t- You can't know what is going to work but also you know there are things that are obviously not.\n\t\t- Don't try to think you are a god and reinvent everything from scratch. Don't catch NIH syndrome.\n\t- You only have 10 beautiful idea tokens in your life you want to do it so you should just do it\n\t\t- Don't just do the plumbing and make stuff you already are good at if you're trying to learn\n\t\t- If this is something you just want to work on (true in this case) then work on it with your full heart\n\t- Not being harsh because it's a bad idea\n\t\t- But rather I don't want you to waste your time. This is your last summer without 'real-world' responsibilities. I would trade so much to be in your position right now.\n\t\t- I am being harsh so that you spend your time wisely and don't do something stupid.\n- Technical thoughts\n\t- Is Rhizome actually a generalized form of state channels?\n\t\t- EVM + Solidity on top of little chains between people\n\t\t- Minecraft on top of this to build engines like https://www.worldql.com/\n\n### May 19th\n- Proposal re-writes + more research today, got a lot done in office today and still had time to head to Central Park to read... a great day all things considered.\n- Open questions from today's reading + writing:\n\t- How do identity 'clusters' or organizations/groups of people work? How are they represented?\n\t\t- Perhaps instead of having separate instantiation of your identity on fixed set of apps, we can have the same identity with separate instantiations of the app?\n\t- Who runs cloud peers?\n\t\t- Have a global marketplace where people can list/sell spare compute and storage\n\t- Who does the compute?\n\t\t- Most apps are lightweight to run on people's own devices\n\t\t- The main reason we've needed massive datastores and compute centers in the first place is because large companies have centralized billions of people's data into their own servers\n\t\t- Cloud peers can offload and perform heavy lifting if necessary\n- More meditations on identity and data\n\t- Thinking about how data exists only as *relations* between things... how do we preserve this?\n\t- 'Data' is data in the context of that user (or group of users) using that specific application\n\t- Learned about the concept of [[thoughts/petname|petnames]] in more depth today and there's a really cool way of thinking about identity here perhaps\n\t\t- Almost all of the contexts in which we collaborate are not global. The *you* I know is likely different from the you your family knows. Identity should be relational rather than standalone?\n\n### May 18th\n- Grant writing + Verses proposal wrangling\n- Had Anson tear apart my proposal today\n\t- It was so incredibly helpful to get that level of honest feedback but I just feel in the dumps right now LOL I need to figure out how to untie my own self-worth from my work\n\t- I expect something similar will happen when I meet with Justin.. and many more times this summer\n- Good feedback is equal parts bitter and sweet\n\t- Bitter in that it tells you the harsh truths that few have the courage to\n\t- Sweet in that they truly care enough and have enough faith to point harsh truths out\n\t- \"When you’re screwing up and nobody says anything to you anymore that means they’ve given up on you…you may not want to hear it but your critics are often the ones telling you they still love you and care about you and want to make you better.\" ― Randy Pausch, The Last Lecture\n\n### May 17th\n- Went to NYC to work at the Thrive Capital office with some Interact folks and wow... the difference being outside and in a good working environment makes is ridiculous.\n- Migrated all the tracing stuff out of `server.rs` and `log.rs` into its own file. Makes the code a lot cleaner to work with.\n- Deleted `transport.rs` (and moved the contents into `tests/common.rs`) now that it is no longer a part of the server. Realizing now I'll probably need to do another refactor of the transport layer to support simulating network partitions, dropping packets, etc. so I have more surface area to test with.\n- Talked with Sebastien who has been doing independent research for almost a decade now. Mentioned that I was really feeling like I was in the depths of the Valley of Despair and he just laughed and said \"that was me 10 years ago and I still feel that way.\" Horrifying but also weirdly comforting? He gave me some advice and thoughts (mostly with regards to independent research but honestly a lot of sage life advice too):\n\t- In independent research, one often pendulums between two brains that drive your day-to-day\n\t\t1. Brain 1: I want to make change in the world, I want to ship and build\n\t\t2. Brain 2: I want to *understand* why this works the way it does\n\t\t- It is almost always Brain 2 thinking that leads to incredibly high payoffs in clarity and increased conviction.\n\t- Still, breaking things into legible pieces is important. If not for other people, for yourself to have small wins.\n\t\t- Don't build for the sake of building, build as a by-product of understanding\n\t\t- Don't get trapped in the mindset of having every little thing you do fit perfectly in your grand master plan.\n\t\t- It is sufficient to do things to learn and to understand (even if just about yourself)\n\t- Don't have conviction that you are right because that will lead to disappointment. Have conviction that you will learn regardless.\n\t\t- He flew out every weekend from SF to San Diego just to attend a lecture from a professor he really liked and he said it was worth every flight.\n\t- Often times, it is one core principle that if followed to its natural conclusion/end will result in a fundamental perspective shift (e.g. quantum mechanics).\n\t\t- What is that core principle that sits at the heart of everything you find interesting? The connection between the dots is only evident in hindsight so don't spend too long thinking about it. But just follow your gut, it right more often than not.\n- To be honest, I don't really understand all of this advice yet and I don't pretend to but at the moment, it gives me comfort that even if there isn't light at the end of the tunnel, the darkness will still be enjoyable\n\n### May 16th\n- Grant writing again... Finished rough draft for Protocol Labs RFP 000 and writing EV grant proposal + getting feedback\n- Had a mini-breakdown today after realizing I am just not enjoying this as much as I thought I would be. I'm often spending 12+ hour days writing code or grants and I just feel so behind. And I don't get why!!!! I've been looking forward to this summer for so long.\n\t- I think financial uncertainty is becoming more real day after day... really hoping that one of these goes through and is successful\n\t- It's too early to quit. There's still so much more to build/learn/do/write and I'm not ready to throw in the towel just yet.\n\n### May 15th\n- Family roadtrip, no work today :)\n\n### May 14th\n- Finish testing harness - it looks so pretty!\n- Finally updating research proposals after putting it off for 3 days. I suspect I'm using `miniraft` as an excuse to avoid the grant writing because making things legible is hard!! I'd much rather write code and look at pretty command line outputs instead but this is important work that needs to be done.\n\n### May 12th - May 13th\n- Reaffirming myself that a lot of this is necessary learning and this is a worthwhile project\n\t- Not sure if this is actually true\n\t- But more so convincing myself of it so that I have the energy/motivation to go through with it\n- A lot of technical refactoring going on to accommodate unit testing\n\t- Removed a lot of unnecessary lifetimes while changing `RaftServer` functions to return a vector of sendable messages rather than directly having each server hold a mutable reference to the transport layer (Rust doesn't allow multiple mutable references without a `RefCell`!)\n\n\u003e Let's say you want to become good at [x].\n\u003e \n\u003e It's almost impossible to do it because every day on Twitter you have friends who’ve raised 6 million to do crazy stuff. And so every single day, you open your books, and you take your notes and you start writing stuff, and you have to solve those equations.\n\u003e \n\u003e And every single day you tell yourself, why am I doing this?\n\u003e \n\u003e I could just go out and bullshit investors and build a company. And I think too many people actually do that. Myself included. I managed to resist for a while and I spent a lot of time learning different, difficult things, but it's very hard not to have ADD in this world. It's very hard to stay focused on important things that take a while to be learned.\n\u003e \n\u003e - [Justin Glibert on doing hard things](https://masterplan.substack.com/p/master-plan-justin-glibert-foundation?curius=1294\u0026s=r)\n\n### May 11th\n- Finished the first pass of implementation of `miniraft`! In the midst of adding test infrastructure and verifying correctness of the implementation.\n\t- Probably spent tooo long making it look nice but hey, if I'm going to be spending hours looking at this it might as well be good to look at\n- Also spent an hour trying to debug a test only before realizing `cargo test` runs in parallel so debug messages were out of whack\n- Feeling quite demotivated regarding overall self-belief in the project even though I'm only 11 days in! Been trying to explain Rhizome to a few folks who have experience in the space and it is often so intimidating.\n\t- Like yeah, I know this probably isn't the best way to go about it. Maybe they'll tell me what I'm working on is a long solved problem and I'm wasting my time. Or \"couldn't you just use x and y to achieve the same effect\"? I can't help but sometimes feel like I'm wasting my time -- there are so many smart people working on the same problem, what makes me feel like I can be the one to make a meaningful contribution to it?\n\t- I know that regardless of whether this project succeeds a lot, I'm already learning a lot in terms of technical skills and also about myself in the face of uncertainty and more independent work so I will take that as a win regardless.\n\n### May 10th\n- Discussing grant proposals with Verses folks, doing a lot more grant/proposal writing than I'd like these days\n- Finished most of `miniraft` logic up until `commit_log_entries`. Still need to add tests though :')\n- Tech bear market isn't promising for raising funding, esp for more experimental/greenfield work like this :((\n\n### May 9th\n- Literally just wrestling with Rust's borrow checker because `dyn` traits are funky :((\n\t- Ran into a really weird design problem where I wasn't sure how to order the lifetimes of the log or the state machine (should the app own the log which owns the state machine? should the log hold a reference to the app)? \n\t- I opted to construct the application first then pass a pointer to the log so that when appending entries to the log, it can just call `self.entries.iter().for_each(|entry| self.app.transition_fn(entry))`\n- Finally caved and watched an hour long video on closures, `Fn`, `FnOnce`, `FnMut`, boxed closures, and function pointers ([Jon Gjengset, I owe you my life](https://www.youtube.com/watch?v=dHkzSZnYXmk\u0026t=3005s))\n\t- Feels really stupid but it was literally a change from `\u0026's mut dyn App\u003c's, T, S\u003e` to `Box\u003cdyn App\u003cT, S\u003e`\n\t- When lifetimes get as messy as they did, there's probably a cleaner way to do it with a heap allocated value :)) Use `Box` more often!\n\n### May 8th\n- Sketching out grant proposals to Emergent Ventures + Protocol Labs\n- Had a chat with Sebastien about research institutes and what long-term support for work like this could look like in the context of Verses\n- More implementation work for `miniraft`, about halfway done I think?\n- More of a slower day to spend time with family for Mothers Day :)\n\n### May 7th\n- Does not seem promising that my research work will be support by Verses this summer...\n- Looking for other places to apply for funding but ugh this is unfortunate\n- Lots of coding today for `miniraft`! Finally feeling like I'm becoming more fluent in Rust. Figured out some nasty named lifetime stuff today by drawing a few diagrams and kinda feel like a wizard!!! Small wins\n\n### May 6th\n- Mostly writing up recent learnings and incorporating them into the [[thoughts/Rhizome Proposal|research proposal]]... lots of words today\n\t- Sometimes I feel like I'm doing research to be able to do more research...\n- I think I am finally getting to a point where Rhizome is making more and more sense and obvious why it is necessary\n\t- I started this project/research very much like \"oh wow, this is a cool set of technologies and here are some vague words and feelings about what I think is inadequate in the space\" and it has sort of refined itself into a clear use case!\n\t- Came across the concept of a \"cloud peer\" today in Hypercore documentation and it was like \"WOW I had this exact same idea and they already have a name for it\" and it was so cool\n\t- Really excited about this future of 'personal cloud computing'\n\t- I think this summer will be mostly focused on the data replication / identity aspect of Rhizome, realizing that I think I was way too ambitious with my first proposal\n- More implementation on `miniraft`. Rust feels so slow to get back into a 'de-rusted state' (hah) where code just 'flows'. It feels fun though! Type system reminds me a lot of Haskell.\n\n![[thoughts/images/rhizome-may-6.jpeg]]\n\n### May 5th\n- Finishing up [[thoughts/distributed systems#Martin Kleppmann's Course|Martin Kleppmann's Course on Distributed Systems]]\n\t- Cleaning up notes into atomic concepts that I can reference\n- Continuing implementation of `miniraft`\n- What if... Rhizome had built in mechanisms for managing 'branches'\n\t- Default branches are single stream\n\t- To make a collaborative doc you can 'fuse' or 'join' branches together temporarily to sync them with each other\n\t\t- What if we made something on top of `git` like this that actually functions on a syntax level rather than a character level... one for the [[thoughts/idea list|idea list]]\n\t- Pace layers for collaboration\n\t\t- Real-time (keystroke-by-keystroke)\n\t\t- On-click (manually click refresh)\n\t\t- Suggest changes (like Google Docs, accept/reject)\n- Agreeing on what operations a [[thoughts/CRDT|CRDT]] can perform still seems to be difficult ([see 1hr into this talk](https://youtu.be/Qytg0Ibet2E?t=3665))\n\t- Possible room for data lensing on public schemas to be useful here\n\n### May 4th\n- Skimming [[thoughts/distributed systems#Martin Kleppmann's Course|Martin Kleppmann's Course on Distributed Systems]]\n\t- Really good foundation to work off of\n\t- Learned about differences between physical and logical [[thoughts/clocks|clocks]] and realizing that `miniraft` should probably use some sort of [[thoughts/clocks|logical clock]] rate\n\n### May 3rd\n- Read about more [[thoughts/NAT#Efficacy|NAT traversal and holepunching efficacy]], turns out hole punching is just not as reliable as I thought it was\n- Compared more traditional consensus algorithms like [[thoughts/Raft Consensus Algorithm|Raft]] to [[thoughts/Solana|Solana]].\n- First formal architecture sketch?\n\t- Need to read more about DID and IPFS but this seems like a promising start?\n\t- Each user is essentially a DID that is associated with an IPFS document that references a bunch of other things\n\t\t- Each device in the devices array runs a Rhizome Node which is essentially a wrapped IPFS node that pins the user IPFS object and can edit it\n\t\t- Right now, this means that if all a user's devices are offline, those files are unreachable. For people who still want their stuff to be replicated online, perhaps can integrate FileCoin to incentivize other nodes to pin their document?\n\t- The devices array is also used by Raft to coordinate what devices should be included in the cluster\n\t\t- Modifications in the devices array leads to a Raft configuration update\n\t\t- All devices that are reachable sync via Raft to keep an `appState` object up to date for the user\n\t\t- When any `appState` log gets too long, it is snapshotted by the leader and persisted in IPFS.\n\t- All the questions that are unanswered right now are in red. Lots of unanswered questions :))\n\t\t- How does auth work for applications?\n\t\t- How will schemas be published? Is there an app store?\n\t\t- Who runs the web host? Is it self-hosted?\n\t\t\t- What about non-technical people?\n\t\t- How is a user created?\n\n![[thoughts/images/rhizome-may-3.jpeg]]\n\n### May 2nd\n- Mostly reading about [[thoughts/Raft Consensus Algorithm|Raft]] consensus algorithm today and understanding how it works\n\t- Always wondered how these consensus algorithms deal with bad actors -- turn out they don't! That's where [[thoughts/Byzantine Faults|BFT]] comes in\n\t- Seems to be promising for replicating between trusted peers (potentially applicable)\n- Starting a very minimal stripped down implementation of [[thoughts/Raft Consensus Algorithm|Raft]] in Rust I am nicknaming `miniraft`. Code [here](https://github.com/jackyzha0/miniraft) (but will most likely be private until it is done).\n\n### May 1st\n- Settling back into home, general research reading + writing [[thoughts/Rhizome Proposal|the proposal]]\n- Read various papers\n\t- [[thoughts/internet computing#Changing an entrenched internet|Changing an entrenched Internet]]\n\t- [[thoughts/mechanism design|Mechanism Design]]\n\t- [[thoughts/Raft Consensus Algorithm|Raft]]\n- Learned about the basic premise of [[thoughts/Self-sovereign Identity (SSI)|SSI]]","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Rhizome-Specification":{"title":"Rhizome Specification","content":"\n\u003e See also: [[thoughts/Rhizome Research Log|Research Log]]\n\n... tbd\n\nscraping the page for now as my idea for what Rhizome even is is still evolving rapidly","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Risk-Homeostasis":{"title":"Risk Homeostasis","content":"\n\u003e Did you know that when seatbelts were made mandatory, the number of deaths on the road actually didn't decrease, they stayed roughly the same! Similarly, it has been observed that motorists drove closer to the vehicle in front when the vehicles were fitted with anti-lock brakes.\n\nRisk compensation is a theory which suggests that people typically adjust their behavior in response to perceived levels of risk, becoming more careful where they sense greater risk and less careful if they feel more protected\n","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Rokos-Basilisk":{"title":"Roko's Basilisk","content":"\nA form of arithmetical [[thoughts/Utilitarianism|utilitarianism]] (see: [effective altruism](thoughts/effective%20altruism.md)), assuming that one can meaningfully calculate the [[thoughts/utility|utility]] of actions as a numerical value.\n\nYou could then \"shut up and multiply\" utterly negligible probabilities by hypothetical huge outcomes, and take the resulting number seriously — there exists scenarios in which you should torture one person for 50 years if it would prevent dust specks in the eyes of a sufficiently large number of people — resulting in claims like eight lives being saved per dollar donated (a claim made using a calculation of this sort, very popular arguments in EA circles).","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Root-Verses-on-the-Middle-Way-MMK":{"title":"Root Verses on the Middle Way or the MMK","content":"\n*by Nāgārjuna*\n\nA key text in [Buddhist](thoughts/Buddhism.md) religious texts. Use of reductio ad absurdum (proof by contradiction) to show how all phenomena exhibit [emptiness](thoughts/emptiness.md).\n\nNāgārjuna is a [phenomenologist](thoughts/phenomenology.md).\n\nWithin it, heavy use of the tetralemma form of argument that is composed of 4 forks\n1. Affirmation: $X$\n2. Negation: $\\lnot X$\n3. Both: $X \\land \\lnot X$\n4. Neither: $\\varnothing$\n\nObjection posed that [emptiness](thoughts/emptiness.md) is nihilistic and would lead to the non-existend of the Four Noble Truths, Three Jewels, and Buddha. Yet, Nāgārjuna shows this not to be the case.\n\n\u003e \"Like a poisonous snake when held incorrectly or a magic spell when improperly used, emptiness, when incorrectly understood, devastates the simple minded\"\n\nEmptiness is not nothingness. Emptiness is form.","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/SBFT":{"title":"SBFT","content":"\nA [[thoughts/Byzantine Faults|Byzantine fault-tolerant]] [[thoughts/State Machine Replication (SMR)|state machine replication]] system that improves upon the scalability of [[thoughts/PBFT|PBFT]].\n\nTo achieve this performance improvement, SBFT uses a combination of four ingredients: using collectors and threshold [[thoughts/digital signatures|signatures]] to reduce communication to linear, using an optimistic fast path, reducing client communication and utilizing redundant servers for the fast path","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/SVM":{"title":"Support Vector Machine","content":"\nAn SVM is just Hinge loss with L2-regularization\n\n$$f(w) = \\sum_{i=1}^n \\max\\{0, 1-y_iw^Tx_i\\}$$\n\nThey can also be viewed as 'maximizing the margin':\n\n![[thoughts/images/maximizing margin.png]]\n","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Sandglass":{"title":"Sandglass","content":"\nA *permissionless* [[thoughts/consensus|consensus]] algorithm that guarantees deterministic agreement and termination under a crash-stop [[thoughts/system model|system model]].\n\n[Source Writeup](https://decentralizedthoughts.github.io/2022-06-21-sandglass/)\n\nSandglass proceeds in virtual rounds.\nEvery round, nodes propose a value $v$ by broadcasting it. Values come with an associated priority.\n1. In the first round, each node proposes its initial value $v_0$ with priority initialized to 0.\n2. In subsequent rounds, nodes propose a value $v_i$ chosen among those received in the previous round.\n\t1. The priority of $v_i$ depends on the number of consecutive rounds during which $v$ was the only value received by the node proposing $v_i$.\n\t2. Whenever a node receives a value other than _v_, it resets $v$’s priority back to 0. When proposing a value in a given round, node $p$ selects the highest priority value received in the previous round; if multiple values have the same priority, then it selects randomly among them.\n3. A node can safely decide a value $v$ after $v$'s priority is sufficiently high. Termination follows from the non-zero probability that the necessary sequence of unanimous, consecutive rounds will actually eventually occur.","lastmodified":"2023-02-15T01:38:21.229820855Z","tags":null},"/thoughts/Search-Diary":{"title":"Search Diary","content":"\n# Entry 1\n**Day, Time, and Location:** February 6th, ~4:01pm EST, Montreal\n\n**How long did the search take?** ~10 seconds\n\n**Photo showing setting of the search:** No photo, but was sitting at a desk with a couple of friends! Casual co-working time.\n\n**Motivation for the search**: A group of us were chatting and one of my friends mentioned her undergraduate thesis on the concept of vibes as applied to fundamental essences of objects. I was curious if she had heard of the term 'qualia' before as the concepts seemed related. I keep a personal online archive of notes on my website and wanted to surface a relevant link that I read but couldn't remember off of the top of my head. Specifically, looking for this article from [Real Life Mag](https://reallifemag.com/nameless-feeling/?curius=1294).\n\n**Details of the search**: Search term: *qualia*, result was in the first three surfaced\n\n**Device type and Search Engine**: Mobile, site-specific search on my personal site (jzhao.xyz)\n\n**Was the search successful?** Finished within one session! Found the note I was looking for with the first query.\n\n**Reflection on the search:** This is a pretty good representation of the average use-case for searching through my own website. If done well, I have a **shareable representation of my thoughts** that I can send out into the world and access easily from any device anywhere.\n\nSearch is a pretty default entry point for me into my 'second-brain' (more on why in my post on [networked thought](posts/networked-thought.md)). I use search as an entry-point into a single node, then recall by associativity rather than by indexing. But having a good entry-point can make or break my flow into finding what I’m looking for. In this case, I had already known that this note existed in my garden so I just searched by the title of the note.\n\nBecause this search system is still rather brittle, I've learned to start splitting notes into atomic concepts with short, simple nouns like \"[qualia](thoughts/qualia.md)\" and \"[Chesterton's Fence](thoughts/Chesterton's%20Fence.md)\" rather than long winding descriptions, which helps me find and organize notes more easily. The engine operates on an extended version of the bag of words model and as such, I have adapted to mostly searching off of keywords rather than more \"natural language\".\n\n# Entry 2\n**Day, Time, and Location:** February 5th, 10:23pm EST, Montreal\n\n**How long did the search take?** ~30 minutes\n\n**Photo showing setting of the search:** No photo. Sitting at desk with a laptop, slightly groggy.\n\n**Motivation for the search**: I am currently working on a digital version of an essay that a collective of technologists I'm a part of is publishing soon. We are doing last minute polish around performance for lower-end devices that may not be able to handle a lot of the more performance-intensive graphics we have. \n\n**Details of the search**: A collection of searches with queries like \"three js gradient skybox\", \"ScissorCanvas effectcomposer\", and a huge string of other searches. Most results led me to issues on GitHub like https://github.com/mrdoob/three.js/issues/6022 and https://github.com/mrdoob/three.js/issues/5979.\n\n**Device type and Search Engine**: Laptop, Google + GitHub code search.\n\n**Was the search successful?** None of the search results were able to give me an exact answer but helped provide context into the history of the issue. For example, the second search result let me know that shaderpasses will use the wrong viewport/scissor for rendering if used in conjunction. I ended up using a slightly hacky workaround to achieve the same effect.\n\n**Reflection on the search:** I have had a decent amount of experience making technical searches in the past. A lot of programming *is* just knowing what combination of search terms will make Google spit out the most relevant search results. Most times, Google surfaces relevant and helpful pages and this was no exception. \n\nI tend to use search engines like Google very frequently. As a fast typer, my approach is to just stream words that surface from my head and iteratively refine and re-type queries as I visit and park pages (in the terminology of [information foraging](thoughts/information%20foraging.md), I rely heavily on behaviour enrichments and have a tight goal, forage, refine loop).\n\n# Entry 3\n**Day, Time, and Location:** February 4th, 2:56pm PST, Vancouver\n\n**How long did the search take?** ~5 minutes\n\n**Photo showing setting of the search:** No photo. At desk while on a Discord call with cool folks!\n\n**Motivation for the search**: We were trying to find a fitting banner image for our community Discord we were setting up! I had remembered seeing a very nice solarpunk-themed video commercial on YouTube somewhere but couldn't quite remember the right combination of search times to find it. I *did* remember that it was somehow a yoghurt commercial.\n\n**Details of the search**: Initial search was for \"yoghurt commercial\". After immediately realizing this was not specific enough, I asked in the Discord call if people remember the name of the company and then modified it to \"Chobani commercial solarpunk\" and finally \"Chobani commercial solarpunk but no product placement\" to remove all the product placement.\n\n**Was the search successful?** Eventually found the \"Dear Alice\" video that I was looking for! [Video here](https://www.youtube.com/watch?v=UqJJktxCY9U)\n\n**Reflection on the search**: This was a really interesting example of search in a more 'collaborative' fashion. A lot of my information recall happens via association and the more people to help fill in gaps in memory, the faster I am able to find the thing I am looking for. This search in particular took two 'hops' of refinement.\n\n# Entry 4\n**Day, Time, and Location:** January 28th, 2:58pm PST, Vancouver\n\n**How long did the search take?** ~1 minute\n\n**Photo showing setting of the search:** No photo. At desk, messaging people on Facebook while eating a meal.\n\n**Motivation for the search**: One of my close friends has been experimenting with the concept of telescopic text (an example: https://www.telescopictext.org/text/KPx0nlXlKTciC). There was a really interesting interaction design experiment that one of my mutual friends on Twitter has been experimenting with that I wanted to share (this one in particular: https://twitter.com/azlenelza/status/1487153246531579905)\n\n**Details of the search**: I had remembered that I bookmarked this tweet reply at some point so the first place I looked was my Bookmarks tab in Twitter. Twitter's search is notoriously bad so I just scrolled chronologically and used cmd+f liberally until I found the tweet.\n\n**Was the search successful?** Yes! I found what I was looking for relatively quickly. It also 'mentally' refreshed a few ideas I had forgotten I had bookmarked like this really cool scoping interaction (https://twitter.com/wcrichton/status/1487223891751694339).\n\n**Reflection on the search**: I think this interaction is really interesting because it is often representative of behaviour on sites where the search system is either non-existent or poorly designed. In these cases, I rely heavily on interaction enrichments like using in-browser search and F-scanning (more on F-scanning: https://www.nngroup.com/articles/f-shaped-pattern-reading-web-content/) of the tweet profile pictures to quickly comb through content. Of course, if this was much further back in time than a few weeks, this would have been a monumentally more difficult search to make.","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Secure-Scuttlebutt":{"title":"Secure Scuttlebutt (SSB)","content":"\n## SSB\nSecure Scuttlebutt is a database protocol for unforgeable (read: [[thoughts/digital signatures|digitally signed]]) append-only message feeds.\n\n## Scuttlebot\nScuttlebot forms a global cryptographic social network with its peers. Each user is identified by a public key, and publishes a log of signed messages, which other users follow socially.\n\n### Identity\nWeb-of-Trust style (see: [[thoughts/Public-key Infrastructure#PGP|PGP]]). There is no global registry of usernames. Instead, users name themselves, and share [[thoughts/petname|petnames]] for each other.\n\nIdentities are ed25519 key pairs.\n\n### Pub Servers\nTo get over the data availability problem and because Scuttlebot has no DHT or NAT-traversal utilities, users must \"join\" a Pub to distribute their messages on the WAN.\n\nPubs are bots that follow users and rehost the messages to other peers, ensuring good uptime and no firewall blockage.\n\n## Secret Handshake\nAn encrypted channel protocol based on a mutually authenticating key agreement handshake, with forward secure identity metadata. It's used by Scuttlebot to authenticate and encrypt peer connections.","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Seeing-like-a-State":{"title":"Seeing like a State","content":"\nBook by James C. Scott\n\n*An account of the logic behind the failure of some of the great utopian social engineering schemes of the twentieth century.*\n\nLessons:\n1. Take small steps: In an experimental approach to social change, presume that we cannot know the consequences of our interventions in advance. Given this postulate of ignorance, prefer wherever possible to take a small step back, observe, and then plan the next small move (see also: [[thoughts/Collingridge dilemma]])\n2. Favour reversibility: prefer interventions that can easily be undone if they turn out to be mistakes. Irreversible interventions have irreversible consequences. Interventions into ecosystems require particular care in this respect, given our great ignorance about how they interact. Aldo Leopold captured the spirit of caution required: \"The first rule of intelligent tinkering is to keep all the parts\" (see also: [[thoughts/Chesterton's Fence]])\n3. Plan on surprises: in agricultural schemes, this may mean choosing and preparing land so that it can grow any of several crops. In planning housing, it would mean \"designing in\" flexibility for accommodating changes in family structures or living styles.\n4. Plan on human inventiveness: always plan under the assumption that those who become involved in the project later will have or will develop the experience and insight to improve on the design\n\nThese, unsurprisingly, have heavy overlap with the design of [[thoughts/software principles|software]]\n\n## Simplification\n- Legibility: certain forms of knowledge and control require a narrowing of vision.\n\t- \"Legibility is a condition of manipulation. Any substantial state intervention in society -- to vaccinate a population, produce goods, mobilize labour, tax people and their property, conduct literacy campaigns, conscript soldiers, enforce sanitation standards, catch criminals start universal schooling -- requires the invention of units that are visible\"\n\t- \"The great advantage of such tunnel vision is that it brings into sharp focus certain limited aspects of an otherwise far more complex and unwieldy reality.\"\n\t- \"This very simplification, in turn, makes the phenomenon at the centre of the field of vision more legible and hence more susceptible to careful measurement and calculation.\"\n- Standards\n\t- \"Large-scale commercial exchange and long-distance trade tend to promote common standards of measurement.\"\n\t- But yet, most complexities of human life fail to be marshalled into a single regulatory code.\n\t- \"Even in a particular locality, practices varied greatly from farm to farm and over time; any codification would be partly arbitrary and artificially static. To codify local practices was thus a profoundly political act.\"\n\t- \"At the limit, there would be at least as many legal codes as there were communities\"\n- Cities\n\t- \"For Jacobs, the city as a social organism is a living structure that is constantly changing and springing surprises. Its connections are so complex and dimly understood that planning always risks unknowingly cutting into its living tissue, thereby damaging or killing vital social processes.\"\n\t- See also: [[thoughts/Chesterton's Fence]]\n- Why schemes have failed, a tldr;\n\t- \"I would say that the progenitors of such plans regarded themselves as far smarter and farseeing than they really were and, at the same time, regarded their subjects as far more stupid and incompetent than *they* really were.\"\n## Monocultures and centralization are fragile\n- Scientific, \"fiscal forestry\", and monocultures\n\t- In which the actual tree with its vast number of uses was replaced by an abstract tree representing a volume of lumber or firewood.\n\t- Purely, the state wanted to optimize the greatest possible constant volume of wood\n\t- \"In the short run, this experiment in the radical simplification of the forest to a single commodity was a resounding success.\"\n\t\t- \"It is apparent that centralized high-modernist solutions can be the most efficient, equitable, and satisfactory for many tasks. Space exploration, the planning of transportation networks, flood control, airplane manufacturing , and other endeavours may require huge organizations minutely coordinated by a few experts.\"\n\t- \"But it was the whole world that lied 'outside the brackets' which returned to haunt this technical vision.\"\n\t\t- \"The narrowness in turn means that production agronomy is occasionally blindsided by factors outside its analytical focus and is forced, by the resulting crisis, to take a broader perspective\"\n\t- \"The monoculture meant that the whole nutrient cycle got out of order and eventually was nearly stopped, representing a production loss of 20 to 30 percent. A new term, *Waldsterben* (forest death), entered the German vocabulary. An exceptionally complex process involving soil building, nutrient uptake, and symbiotic relations among fungi, insects, mammals, and flora was apparently disrupted with serious consequence.\"\n\t- \"Monocultures are, as a rule, more fragile and hence more vulnerable to the stress of disease and weather than polycultures are\"\n- Leo Tolstoy, *War and Peace*\n\t- \"While the sea of history remains calm the ruler-administrator in his frail bark, holding it with a boat hook to the ship of the people and himself moving, naturally imagines that his efforts move the ship he is holding on to. But as soon as a storm arises and the sea begins to heave and the ship begins to move, such a delusion is no longer possible. The ship moves independently with its own enormous motion, the boat hook no longer reaches the moving vessel, and suddenly the administrator, instead of appearing a rule and a source of power, becomes an insignificant, useless, feeble man.\"\n- \"Perspective makes the single eye the centre of the visible world. Everything converges on the eye as to the vanishing point of infinity, The visible world is arranged for the spectator as the universe was once thought to be arrange for God.\" (see also: *The Unflattening*)\n## Diversity is Good, actually\n- Explaining the Western appeal for 'order'\n\t- \"The diversity of species naturally occurring in a tropical setting is, other things being equal, consistently greater than the diversity of species in a temperate setting. An acre of tropical forest will have far more species of plants, although fewer individuals of each species, than will an acre of temperate woodland. Thus unmanaged nature in temperate climates *looks* more orderly because it is less diverse, and this may play a role in the visual culture of Westerners.\"\n- Jacobs and parallels with cities\n\t- \"A highly specialized neighborhood, by contrast, is like a gambler placing all his bets on one turn of the roulette wheel. If he wins, he wins big; if he loses, he may lose everything. For Jacobs, of course, a key point about the diversity of a neighborhood is the *human* ecology it fosters. The variety of locally available goods and services and the complex human networks that it makes possible, the foot traffic that promotes safety, the visual interest than animated and convenient neighborhood provides -- all interact to make such a location's advantages cumulative. The diversity and complexity that cause systems of flora to become more durable and resilient work, at another level apparently, to cause human communities to become more nimble and satisfactory.\"\n## Flexibility for the unexpected\n- Cities and Design\n\t- Whereas Le Corbusier's planner is concerned with the overall form of the cityscape and its efficiency in moving people from point to point, Jacob' planner consciously makes room for the unexpected, small, informal, and even nonproductive human activities that constitute the vitality of the \"lived city\"\n- \"[imperial pretensions of agronomic science's] inability to recognize or incorporate knowledge created outside its paradigm sharply limited its utility to many cultivators. Whereas farmers, as we shall see, seem pragmatically alert to knowledge coming from *any* quarter should it serve their purposes\"\n\t- \"Farmers, being polytheists when it comes to agricultural practice, are quick to seize whatever seems useful from the epistemic work of formal science\"\n- Erosion Control\n\t- \"Erosion control in Japan is like a game of chess. The forest engineer, after studying his eroding valley, makes his first move, locating and building one or more check dams. He waits to see what Nature's response is. This determines the forest engineer's next move, which may be another dam or two, an increase in the former dam, or the construction of side retaining walls. Another pause for observation, the next move is made, and so on, until the erosion is checkmated.\"\n## Informal Order\n- Jane Jacobs' Sidewalk Terms\n\t- \"Jacobs explains that when a friend used their apartment while she and her husband were away or when they didn't want to wait up for a late-arriving visitor, they would leave the key to their apartment with the deli owner, who had a special drawer for such keys and who held them for friends. She noted that every nearby mixed-used street had someone who played the same role: a grocer, candy-store owner, barber, butcher, dry cleaner, or bookshop owner/ This is one of the many public functions of private business. These services, Jacobs notes, are not the outgrowth of any deep friendship; they are the result of people being on what she calls 'sidewalk terms' with others... The city relies on the density of people who are on sidewalk terms with one another to maintain a modicum of public order... A person didn't think twice about asking someone to hold one's seat at the theatre, to watch a child while one goes to the restroom, or to keep an eye on a bike while one ducks into a deli to buy a sandwich\"\n- \"The planned city, the planned village, and the planned language are, we have emphasized, likely to be thin cities, villages, and languages. They are thin in the sense that they cannot reasonably plan for anything more than a few schematic aspects of the inexhaustibly complex activities that characterize 'thick' cities and villages. One all-but-guaranteed consequence of such thin planning is that the planned institution generates an unofficial reality -- a 'dark twin' that arises to perform many of the needs that the planned institutions fails to fulfil... Nearly every new, exemplary capital city has, as the inevitable accompaniment of its official structures, given rise to another, far more 'disorderly' and complex city *that makes the official city work* -- that is virtually a condition of its existence. That is, the dark twin is not just an anomaly, an 'outlaw reality'; it represents the activity and life without which the official city would cease to function.\"\n- \"It is helpful to imagine two different maps of activity [in a city]. In the case of a planned urban neighbourhood, the first map consists of a representation of the streets and buildings, tracing the routes that the planners have provided for the movements between work places and residences, the delivery of goods, access to shopping, and so on. The second map consists of tracings, as in time-lapse photograph, of all the *unplanned* movements -- pushing a baby carriage, window shopping, strolling, going to see a friend, playing hopscotch on the sidewalk, walking the dog, watching the passing scene, taking shortcuts between work and home, and so on. This second map, far more complex than the first, reveals very different patterns of circulation. The older the neighbourhood, the more likely that the second map will have nearly supeseded the first, in roughly the same way that planned suburban Levittowns have, after fifty years, become thoroughly different settings from what their designers envisioned.\"\n\t- \"If our inquiry has taught us anything, it is that the first map, taken alone, is misrepresentative and indeed nonsustainable... As with industrial agriculture and its dependency on landraces, the first map is possible only because of processes lying outside its parameters, which is ignores at its peril.\"\n## Metis and Local Knowledge\n- See also: [[thoughts/traditional knowledge]]\n- \"One powerful indication that [a skill requires] metis is that they are exceptionally difficult to teach apart from engaging in the activity itself. One might imagine trying to write down explicit instructions on how to ride a bicycle, but one can scarcely imagine that such instructions would enable a novice to ride a bicycle on the first try\"\n- \"We might reasonably think of situated, local knowledge as being *partisan* knowledge as opposed to generic knowledge... An insurer of commercial shipping for a large, highly capitalized maritime firm can afford to rely on probability distributions for accidents. But for a sailor or captain hoping for a safe voyage, it is the outcome of the single event, a single trip, that matters. Metis is the ability and experience necessary to influence the outcome -- to improve the odds -- in a particular instance.\"\n- \"The big mistake of the rationalist -- though it is not inherent in the method -- is to assume that 'tradition' or what is better called 'practical knowledge' is rigid fixed and unchanging -- in fact it is 'preeminently fluid'. Tradition, in part because of its local variation, is pliable and dynamic. No traditional way of behaviour. no traditional skill ever remains fixed. Its history is one of continual change.\"","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Self-sovereign-Identity-SSI":{"title":"Self-sovereign Identity (SSI)","content":"\nSelf-sovereign identity (SSI) is an approach to digital identity that gives individuals control of their digital identities\n\n\u003e \"Identity is a uniquely human concept; however modern society view this concept of identity as state-issued credentials as driver's license and social security cards, which suggests a person can lose his very identity if a state revokes his credentials or even if he just crosses state borders.\" (Christopher Allen)\n\nIdentities are required for trust to be established (Party A needs to ensure Party B is actually who they claim to be and vice versa).\n\nIn centralized identity paradigms, this is usually done through authorities (e.g. [[thoughts/security#Certification Authorities CA|Certification Authorities]]) who are trusted by both parties.\n\nIn SSI systems, holders have control over unique identifiers (decentralized identifiers). These can be verified using [[thoughts/encryption|encryption]] and anchored on some sort of distributed ledger (e.g. [[thoughts/blockchain|blockchain]])\n\n## Why SSI matters to the average citizen\n- Avoid a million accounts to log into\n\t- SSI federates logins to various services and applications\n- Granular access permissions for content\n- Data provenance through signatures, can request takedowns as proving ownership is trivial\n\n## Critiques of SSI\n[Source: Molly White](https://blog.mollywhite.net/is-acceptably-non-dystopian-self-sovereign-identity-even-possible/)\n\nMostly critiques about certain implementations of [[thoughts/soulbound|SBTs]] or [[thoughts/Verifiable Credential|VCs]] (which she refers to as Verifiable attestations)\n- people are able to send soulbound tokens without the consent of the recipient—given that it is unlikely people would consent to police departments recording their crimes for others to later use against them if they had the choice\n- against a world where relationships are front-run by a deluge of data rather than formed more organically between individuals\n\t- \"An acquaintance now quits those ‘old-fashioned’ relationship-building niceties and gets straight to the SSI point. Where do you work? Which college did you go to? Which college did your parents go to? Republican or Democrat? What’s your gender? Your ethnic origins? Do you have this gene or the other one? If you fail to offer up the requisite verifiable claims then you fail to get to ‘trust building’ first base in the SSI century.\"\n\t- similar to Black Mirror's Nosedive Episode (S3E1)\n- people suck at security: the average person is shit at securing their data\n\t- though, is this just bad ui/ux or is it just fundamentally hard (tm) to make it easy for people to be secure? i feel like VPNs for example have made 'good security' practice pretty easy for the average consumer","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Sidetree":{"title":"Sidetree","content":"\n[Source Spec](https://identity.foundation/sidetree/spec)\n\nA 'meta'/Layer 2 protocol that can be applied to any target trust layer to create a scalable DID method (batteries *almost* included)\n\nA bunch of DID methods work fine at lab scales (~100 DIDs) but how do we scale to billions?\n\n- Doesn't require any additional consensus, relies on the consensus of the underlying trust layer\n- Strict deterministic ruleset means no conflicting states are allowed\n- IDs are *not* transferable\n\nBatches a bunch of operations as content-addressable storage references (read: [[thoughts/IPFS|IPFS]]) and anchors them to underlying trust layer.\n\n[ION](https://identity.foundation/ion/) takes roughly 20 minutes for commitment finality","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Sloppy-Hashing-DHT":{"title":"Coral: Sloppy Hashing DHT","content":"\n[Source](https://www.cs.princeton.edu/~mfreed/docs/coral-iptps03.pdf)\n\nMain problems with [[thoughts/Kademlia DHT]] is that it has poor locality. A peer could make requests that hop all the way around the globe when the information they are looking for is in their local network!\n\n\u003e Though some DHTs make an effort to route requests through nodes with low network latency, the last few hops in any lookup request are essentially random. Thus, a node might need to send a query half way around the world to learn that its neighbor is caching a particular web page.\n\nChoral achieves locality through clustering! It creates self-organizing clusters of nodes that fetch information from each other to avoid communicating with more distant or heavily-loaded servers.\n\nNotes\n- 'Sloppiness' comes from the fact that a `set(key, nodeaddr)` operation doesn't just store the pointer `nodeaddr` on one node\n\t- It stores pointers along the lookup path for popular keys (this is called \"spilling-over\")\n\t- Helps to balance load while inserting pointers, retrieving pointers, and downloading data\n- Generally set a TTL for records to expire quickly enough to keep the fraction of stale pointers below 50%\n\n## Network Layers\nIn order to restrict queries to nearby machines, each Coral node is a member of several DSHTs, which we call clusters, of increasing network diameter.\n\nThe diameter of a cluster is the maximum desired round-trip time between any two nodes it contains.\n\nFor example, a node can be a part of 3 clusters, and L0, L1, and L2.\n- L0 is the 'lowest' level and widest network diameter, having a maximum desired round-trip of $\\infty$ so the network spans every node in the DHST\n- L2 is 'highest' level and narrowest network diameter, having a small maximum desired round-trip time to restrict it to local nodes\n\nSimilar concept to isochrone maps\n\n![[thoughts/images/isochrone.png|500]]\n\n## Downsides\n- The privacy sucks sucks: nodes publish not only their [[thoughts/IP Addresses]] but the path to get there too!\n- Requires network size estimation which is hard to do if the number of nodes are small (i.e. requires a large deployment to be effective)\n\t- Can be done using [[thoughts/Network Theory]] as lookups are on average $O(\\log n)$ hops\n- Not [[thoughts/Byzantine Faults|BFT]]: a malicious actor could pollute the DHT and cause really poor routing\n","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Social-Bias-in-Information-Retrieval":{"title":"Social Bias in Information Retrieval","content":"\n\n## Social Bias in Information Retrieval\nSource: Addressing Social Bias in Information Retrieval in *In Experimental IR Meets Multilinguality, Multimodality, and Interaction*\n\n\"Many algorithmic processes are opaque and that the reasons for this may vary. For instance, it is more often than not difficult to interpret results from models induced by new machine learning techniques such as deep learning\" (especially why we need to work on [explainability](thoughts/explainability.md))\n\nAs a counter argument, there are social and economic challenges for achieving algorithmic [transparency](thoughts/transparency.md), such as the need for developers/owners of such processes to protect trade secrets, or even the [[thoughts/privacy|privacy]] concerns of users.\n\nFriedman and Nissenbaum's definition of [bias](thoughts/bias.md):\n1. its results are slanted in unfair discrimination against particular persons or groups\n2. the observed discrimination is systematic within the system\n\n\u003e Indeed, over the past years, many researchers have found that search engines, through the result sets they present to users, tend to reinforce a view of the social world that aligns with the status quo.\n\nRelated: [To Live in their Utopia](thoughts/To%20Live%20in%20their%20Utopia.md), [Data Distributions](thoughts/data%20distributions.md), [Algorithms of Oppression](thoughts/Algorithms%20of%20Oppression.md)","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Social-Choice-Problem":{"title":"Social Choice Problem","content":"\n1. How to aggregate many individual preference orderings into a single group or social preference ordering; or,\n2. How to have rational individuals make rational choices as a group\n\nWe can define a Social welfare function (SWF) combining individual preference orderings (over social states) into a social preference ordering (over those same states).\n\nSuggestions\n1. Use majority rule to aggregate individual preferences into group preferences.\n\t1. Problem: The voting paradox. Individual preferences may be transitive but the group preference *can* be cyclic when we do a majority vote. The violates [[thoughts/probability#Kolmogorov Axioms|a Klmogorov Axiom]] about ordering\n2. Use maximum total utility to determine group preference\n\t1. Different scales (equivalent vNM scales) yield a different social preference ordering\n3. Just use ordinal rankings\n\t1. [[thoughts/Arrow's Impossibility Theorem]]\n\nDefinitions:\n1. A group $D \\in G$ is decisive with respect to some pair of social states $(a,b)$ iff $a \\succ b$ by the whole group $G$ whenever everyone in $D$ prefers $a \\succ b$\n2. A group is decisive if it is decisive over all pairs of social states\n\nSee: [[thoughts/Arrow's Impossibility Theorem]]","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Social-Contract-Theory":{"title":"Social Contract Theory","content":"\n**Social contract theory is the view that persons’ moral and/or political obligations are dependent upon a contract or agreement among them to form the society in which they live.** It focuses on the individual and collective benefits of protecting certain human rights, such as the right to life, liberty, and property\n\nIn his book *Leviathan*, Thomas Hobbes argues that without rules and a means of enforcing them, people would not bother to create anything of value, because nobody could be sure of keeping what they created. Collaboration (and thus society) is possible only when people mutually agree to follow certain guidelines\n\nHobbes argues that everybody living in a civilized society has implicitly agreed to two things (collectively known as the **social contract**):\n1. the establishment of a set of moral rules to govern relations among citizens (necessary if we are to gain the benefits of social living)\n2. a government capable of enforcing these rules.\n\nWhat prevents the community from enacting bad rules is that no one is above the rules. Since everyone is in the same situation, no community members will want to put unfair burdens on others because that would mean putting unfair burdens on themselves.\n\nClose correspondence between rights and duties. If one has a right, others have a duty not to take that right away. For example, moral obligation to not take away the right to life of another.\n\nTypes of rights:\n- A negative right is a right that another can guarantee by leaving you alone to exercise your right. For example, the right of free expression. In order for you to have that right, all others have to do is not interfere with you when you express yourself.\n- A positive right is a right that obligates others to do something on your behalf. The right to a free education is a positive right\n- An absolute right is on that is guaranteed without exception\n- A limited right is one that may be restricted based on the circumstances\n\n## Rawl's Theory of Justice\nTo be well ordered, a society must establish the rights and duties of its members and also determine a just way of distributing “the benefits and burdens of social cooperation”\n\n### The Veil of Ignorance\nRawls proposes a thought experiment: the principles are determined from an original position in which each person is hidden behind a veil of ignorance. People must agree to the principles before they know what place they will hold in society; they are ignorant of their sex, race, ethnicity, wealth, intellectual capacity, physical abilities or disabilities, and so on. Thus, Rawls claims that agreements reached from this initial condition would be fair because they could turn out to be in a disadvantaged position in society relative to others\n\nRawl proposes that rational people behind the veil of ignorance would decide on two principles of justice (Rawl's Difference Principle)\n1. Each person has a fully adequate number of basic rights as long as these are consistent with everyone else having these same rights\n2. If social and economic inequalities exist, it is for one of two reasons:\n\t1. Associated with societal positions anyone has a fair opportunity to assume\n\t2. They benefit the least-advantaged members of society the most\n\n## Counterarguments\n- Social contract implies agreement. None of us agreed to it when we were born!\n-  Social contract theory does not explain how to solve a moral problem when the analysis reveals conflicting rights\n- Classifying those who deliberately break moral rules and those who cannot understand a rule can be difficult\n\n","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Solana":{"title":"Solana","content":"\nSolana is a [[thoughts/blockchain|blockchain]] that claims to be fast, secure, scalable, affordable, and resistant to [[thoughts/censorship|censorship]]\n\nMain technical innovations\n\n## Proof of History\nFor a blockchain to work, participant nodes need to reach an agreement on time. Traditional blockchains like [[thoughts/bitcoin|Bitcoin]] function by [[thoughts/proof of work|proof of work]].\n\nThe whole philosophy behind it is:\n\n-   Running the function takes some time\n-   Running the function is the only way to produce the output\n-   With the known input and output of the function, the only way of evaluating the output is to re-execute the function with the provided input\n\nThis guarantees that when an output is valid for an input, some time has passed for producing that output.\n\n## Tower BFT\n[[thoughts/PBFT|PBFT]] which uses proof of history as a reliable source of time.\n\nFrom [Solana Documentation](https://docs.solana.com/implemented-proposals/tower-bft)\n\n\u003e The basic idea to this approach is to stack consensus votes and double lockouts. Each vote in the stack is a confirmation of a fork. Each confirmed fork is an ancestor of the fork above it. Each vote has a `lockout` in units of slots before the validator can submit a vote that does not contain the confirmed fork as an ancestor.\n\u003e \n\u003e When a vote is added to the stack, the lockouts of all the previous votes in the stack are doubled (more on this in [Rollback](https://docs.solana.com/implemented-proposals/tower-bft#Rollback)). With each new vote, a validator commits the previous votes to an ever-increasing lockout. At 32 votes we can consider the vote to be at `max lockout` any votes with a lockout equal to or above `1\u003c\u003c32` are dequeued (FIFO). Dequeuing a vote is the trigger for a reward. If a vote expires before it is dequeued, it and all the votes above it are popped (LIFO) from the vote stack. The validator needs to start rebuilding the stack from that point.\n\n## Turbine\nSimilar to data sharing approaches in [[thoughts/peer-to-peer|p2p]], seed chunks to peers that can then share amongst themselves.\n\n## Gulf Stream\n\u003e Each Validator knows the order of upcoming Leaders due to Solana's architecture. So clients and Validators forward transactions to upcoming Leaders before they act as a Leader in the network. This allows Validators to start processing transactions ahead of time. This results in fewer transactions cached in Validators’ memory and faster confirmations.\n\nIsn't this potentially problematic? If all nodes know what the upcoming leader is, couldn't they just DDoS the next leader?\n\n## Archiver Nodes\nIf each node in the network was required to store that much data, a limited group of participants who could afford and manage that kind of storage, could join the network and this makes the network centralized.\n\nPoRep stands for proof of replication and it’s a system introduced by [[thoughts/Filecoin|Filecoin]] initially in which a prover defends a publicly verifiable claim that it is dedicating unique resources to storing one or more retrievable replicas of a data file.\n\nOccasionally, the network will ask/challenge the archivers to prove they’re doing their job of storing data and at this point, archivers should complete PoRep.","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Solid":{"title":"Solid","content":"\n\u003e **Solid** is a [specification](https://solidproject.org/TR/protocol) that lets people store their data securely in decentralized data stores called **Pods**. Pods are like secure personal web servers for data. When data is stored in someone's Pod, they control which people and applications can access it.\n\nPushing for universalization at the data level: just as any website can be viewed on any browser and any internet provider, any data should be accessible by any application under people's control.\n\nExisting large owners of data wont innovate because they have monopoly over data, new innovators cant enter because they lack data\n\n[[thoughts/GDPR|GDPR]] technically does all of this, Solid is just technology that ensure it actually happens.\n\nSolid is essentially a glue between HTTP, [[thoughts/LDP|LDP]], and LDN\n\n## Pods\n- Pods are like secure personal web servers for your data. You can think of it like a website with data.\n- You can get a Pod from a Pod Provider, or you may choose to self-host your Pod.\n- Users can own multiple pods\n- Linked Data means that different applications can work with the same data\n\n![[thoughts/images/Solid pod Linked Data.png]]\n## Details\n*Summarized from specs*\n\n- Exchanges data between clients using [[thoughts/HTTP|HTTP]] + TLS\n- A storage (`pim:Storage`) is a space of URIs in which data can be accessed; it is the root container for all of its contained resources\n- Seems to just be a fancy HTTP file server (operated on [[thoughts/RDF|RDF]] Documents)\n\t- Applications can 'patch' pods with new data, given that they have the correct access to it\n- Real-time collaborative communication between pod and application uses WebSockets\n- CORS by default prevents apps that run on one origin from accessing data on other origins\n\t- Get around this by having servers waive the cross-origin protection as Solid handles this [[thoughts/access control|access control]] themselves\n- Identity is done through [[thoughts/WebID|WebID]]\n- Servers are strongly discouraged from exposing information beyond the minimum amount necessary to enable a feature.\n\n## Opinions\n- Feels completely unopinionated, see this as a negative. Should shepherd and guide the average user down the happy path but still make it easy to customize for those who wish to.\n- Still seems to try to emulate client-server interactions heavily\n- Providers are not distributed\n- DX seems pretty poor, comment section on [this video](https://www.youtube.com/watch?v=-C-hSqcU4k8) which has a lot of laypeople seem to dislike","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/State-Machine-Replication-SMR":{"title":"State Machine Replication (SMR)","content":"\nA subset of the algorithmic [[thoughts/consensus|consensus]] problem about agreeing on the same state\n\n1. [[thoughts/consistency|Consistency]]: all notes agree on the same history\n2. [[thoughts/liveness|Liveness]]: every transaction submitted eventually added to all node's histories\n\nSMR can be reduced to [[thoughts/Byzantine Broadcast|Byzantine Broadcast]]","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Stream-of-Consciousness":{"title":"Stream of Consciousness","content":"\nQuotes from *The Principles of Psychology* by William James\n\n\u003e “Consciousness, then, does not appear to itself chopped up in bits. Such words as ‘chain’ or ‘train’ do not describe it fitly as it presents itself in the first instance. It is nothing jointed; it flows. A ‘river’ or a ‘stream’ are the metaphors by which it is most naturally described. In talking of it hereafter, let us call it the stream of thought, of consciousness, or of subjective life.” – William James, Principles of Psychology\n\n- Gaps and changes in quality that we do notice don't undermine the feeling that our consciousness is continuous (we bridge the gap between pre-gap consciousness easily)\n- Gaps and changes in quality that we don't notice aren't felt as interruptions because we're not aware of them\n- The stream of consciousness is really both a stream of perception and a stream of thought and attention shifts dynamically back and forth between them\n\n\u003e \"When we take a general view of the wonderful stream of our consciousness, what strikes us first is the different [pace](thoughts/pace%20layers.md) of its parts. Like a bird's life, it seems to be an alternation of flights and perchings... Let us call the resting places the 'substantive parts' and the places of flight the 'transitive parts' of the stream of thought\"\n\nSee also: [Mangrove Theory of the Internet](thoughts/Mangrove%20Theory%20of%20the%20Internet.md)\n\n## Types of thought[^1]\n- Spontaneous thought\n\t- Weak automatic and deliberate constraints\n\t- $\\textrm{DN}_\\textrm{MTL}$ (default network medial temporal lobe) exerts relatively strong diversifying influence on the stream of thought\n- Rumination and obsessive thought (internally oriented thought)\n\t- Strong automatic constraints from $\\textrm{DN}_\\textrm{CORE}$\n- Goal-directed thought\n\t- Strong deliberate constraints from the frontoparietal control network ($\\textrm{FPCN}$)\n\n### Spontaneous thought\n- Unplanned, much like mind-wandering\n- Contrast is between planned/deliberate thought versus unplanned or spontaneous thought\n\nGuided Thought\n- Counterfactual Aspect\n\t- One could alter their behaviour to bring things back on course\n- Normative Aspect\n\t- Implies the monitoring and correcting of behaviour in relation to some norms\n- Both goal-directed thinking and rumination fall under this category\n\n## Abhidharma Buddhist Philosophy[^1]\n- Abhidharmikas agree that the mental stream is always changing\n- Appears to flow continuously only to the untrained observer. Deeper examination indicates that the stream of consciousness is made up of very short-lived and discrete moments of awareness\n- Consciousness is reckoned by the particular condition dependent upon which it arises\n\t- Just as fire is reckoned by the particular condition dependent on which it burns -- when fire depends on logs, it is reckoned as a log fire\n\t- When consciousness arises dependent on eye and the forms it perceives, it is reckoned as eye consciousness (related: [epistemic instruments](thoughts/epistemology.md))\n- **Mind** is a term for a collection of impersonal mental factors in constant flux\n- **Person** is a term for a collection of impersonal psychophysical factors in constant flux\n\n|External Bases|Internal Bases|Consciousness|\n|---|---|---|\n|Visual Forms|Eye|Eye-consciousness|\n|Sounds|Ear|Ear-consciousness|\n|Smells|Nose|Nose-consciousness|\n|Tastes|Tongue|Tongue-consciousness|\n|Mental phenomena|Mind|Mind-consciousness|\n\n- In this philosophy, the mind is a series of mind moments, each with a consciousness and a collection of mental factors (*dharmas*)\n- Breakdown of a mind-moment, there are various factors. Some occur in each moment of the mental stream, others are variable and come and go according to certain conditions.\n\t1. Contact/Sense Impression\n\t\t1. Something has an impact on the senses (e.g. light striking the eye)\n\t\t2. Initial impact\n\t2. Feeling/Sensation/Experience\n\t\t1. How does it feel? Pleasant, unpleasant, or neutral?\n\t\t2. Experiencing the object\n\t3. Perception/Recognition\n\t\t1. With that contact and sensation, what is it? What 'marks' this as distinct?\n\t\t2. Recognizing what distinguishes the object\n\t4. Volition/Intention/Will\n\t\t1. There is a direction in the mindstream either towards or away from something\n\t\t2. Gathering of other factors (Contact, Feeling, Perception, One-pointedness, Attention)\n\t\t3. Accumulating kamma\n\t5. One-pointedness/Concentration\n\t\t1. Way in which the awareness is centered around mental content or object\n\t\t2. Uniting mental factors\n\t6. Attention/Reflection\n\t\t1. Orienting towards something\n\t\t2. Joining mental factors to object\n\t7. Life Faculty/Vitality\n\t\t1. Basic aliveness, vitality of being\n\t\t2. Supports Volition\n\n![Mind-moments](thoughts/images/Mind-moments.png)\n\n## Waves of Consciousness[^1]\n*Waves of consciousness: ongoing cortical patterns during binocular rivalry*\n\nAn example of an [NCC](thoughts/Neural%20Correlates%20of%20Consciousness%20(NCC).md)\n\nThey measure brain activity using EEGs and they are seeing the expanding/contracting checkerboard ring\n- Build-up in phase-synchronicity when the brain reports seeing the checkerboard ring (uninhibited)\n- Motion can be perceived as either simultaneous or sequential depending *not on the delay between flashes or the stimulus* but at when you present the flash in relationship to the phase of the alpha rhythm\n- There is very strong evidence for the content of perception being influenced by endogenous (intrinsic) neural rhythms at various spatiotemporal scales\n\t- What you perceive is a function of how your brain rhythmically parses the ongoing stream of sensory stimulation\n\n[^1]: This content is sourced from Professor [Evan Thompson](https://evanthompson.me/)'s course materials for PHIL451A at UBC. All rights to this content is retained by Evan Thompson.","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Sybil-Attack":{"title":"Sybil Attack","content":"\n[Source: Sybil attack on *Wikipedia*](https://en.wikipedia.org/wiki/Sybil_attack)\n\nSybil attacks are also called sock puppetry\n\nCreating a large number of pseudonymous identities and uses them to gain a disproportionately large influence (e.g. control of \u003e50% nodes allows you to 'override' the consensus)\n\n**3E's of Preventing Sybil Attacks**\n1. Entry Cost\n2. Existence Cost\n3. Exit Penalty\n","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Symmetric-Key-Cryptography":{"title":"","content":"## Symmetric Key Cryptography\n- Bob and Alice share same key $K_S$\n- Method/algorithm maybe be different (opposite) for decryption but same key is used","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Syndication":{"title":"Syndication","content":"\n## POSSE\n[Source](https://indieweb.org/POSSE)\n\n**POSSE** is an abbreviation for **Publish (on your) Own Site, [Syndicate](https://indieweb.org/Category:syndication \"Category:syndication\") Elsewhere**, the practice of posting content on your own site first, then publishing copies or sharing links to third parties (like [social media](https://indieweb.org/social_media \"social media\") silos) with [original post links](https://indieweb.org/original_post_link \"original post link\") to provide viewers a path to directly interacting with your content.\n\n","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/TCP":{"title":"TCP","content":"\n[[thoughts/Transport Layer|Transport layer protocol]]\n\nWhen a host requires assurance that the remote end has actually received the data it sends. But instead of requesting a signature at the remote end, TCP requires an acknowledgement be returned\n\n## Overview\n1. Point-to-point: one sender, one receiver\n2. Reliable, in-order byte stream: no message boundaries\n3. Pipelined: TCP congestion and flow control set window size\n4. Send and receive buffers (similar to GBN and SR)\n5. Full duplex data: bi-directional data flow in same connection\n\t1. MSS: maximum segment size\n6. Connection-oriented: handshaking initializes both sender and receiver state before data exchange\n7. Flow controlled: sender will not overwhelm receiver\n\n## Flags\n- SYN (sychronize): packets used to initiate a connection\n- ACK (acknowledgement): packets that are used to confirm that the data packets have been received, also used to confirm the initiation request and tear down requests\n- RST (reset): signify the connection is down or maybe the service is not accepting the requests\n- FIN (finish): indicate that the connection is being torn down. Both sender and receiver send the FIN packets to gracefully terminate the connection\n\n## Connection Establishment\n- Three-way handshake\n- To solve single initial sequence number problem, we randomly choose the initial sequence number\n1. Client sends initial SYN message\n\t1. Sequence number for client to server is specified\n2. Server responds with a SYN/ACK (flip both bits) message\n\t1. Client to server sequence number is confirmed in ACK\n\t2. Server to client initial sequence number is specified\n3. Client sends an ACK message\n\t1. Server to client sequence number is confirmed in ACK\n\n## Window Management\n- Size is selected by the application (if not the default)\n- Both sender and receiver have congestion windows\n\t- Measured with segments of maximum segment size (MSS)\n\t- Size is determined by the presence of absence of congestion\n\t- Actual send window is the min of the flow control window (receiver) and the scaled congestion window (computed by sender)\n- Retransmission strategy\n\t- ACKs correspond to first sequence number not yet received (similar to GBN)\n\t- Receiver stores packets in its own window (like SR)\n\t- Four or more ACKs with same number triggers a retransmission without a timeout\n\t- Retransmit just one segment instead of whole window (like SR)\n\n## Congestion Management\n- Very conservative, at first sign of congestion, cuts congestion window in half\n- When it appears that congestion has eased, it increases slowly (1 segment to congestion window each time)\n- TCP uses bandwidth in a fair way\n- Slow start: always start with a congestion window of 1 segment\n\t- Increase by 1 each time a segment is ACKed (this is exponential, equivalent to doubling each time we send a window full of data)\n\t- Stop doubling when we detect congestion\n\n## Flow Control\nDifference between a sender's sequence number and the remote host's acknowledgement number represents any outstanding, unacknowledged data\n\nACK flag is offset 107\n\nSequence and acknowledgement number are both 32 bit fields so the range is from $0$ to $2^{32}-1$. After all the $2^{32}$ sequence numbers are used up and more data is to be sent, the sequence numbers can be wrapped around and used again from the starting.\n\n## Sequence Number\nOffset 32\n\nTracks number of bytes sent outward by a host. If a TCP packet contains 1400 bytes of data, then the sequence number will be increased by 1400 after the packet is transmitted.\n\n## Acknowledgement Number\nOffset 64\n\nTracks number of bytes **received**. If 1000 bytes are received by a host, it increases the acknowledgement number by 1000 when it sends out a packet in response.\n\nThe flag is set **if the acknowledgement number field contains a valid acknowledgement number**.","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Tangaroa":{"title":"Tangaroa","content":"\n\u003e A [[thoughts/Byzantine Faults|Byzantine fault-tolerant]] [[thoughts/Raft Consensus Algorithm|Raft]] algorithm inspired by [[thoughts/PBFT|PBFT]]\n\n[Source Paper](https://www.scs.stanford.edu/14au-cs244b/labs/projects/copeland_zhong.pdf)\n\nByzantine nodes are problematic for Raft:\n- Node can keep calling for elections to terminate the current term. As Raft cannot progress until a leader is elected, this makes Raft unavailable (breaking [[thoughts/liveness|liveness]])\n- Byzantine leader could modify a client's request and violate correctness\n\nDifferences from Raft\n- Message Signatures: Uses [[thoughts/digital signatures|digital signatures]] to authenticate messages and verify integrity. This prevents a Byzantine leader from modifying the message contents or forging messages\n- Client Intervention: Clients can force interrupt leadership if the cluster fails to make progress. This prevents a Byzantine leader from continuously calling elections\n- Incremental Hashing: each entry has a [[thoughts/hash function|hash]] that is computed over the previous hash and the newly appended log entry, preventing Byzantine nodes from reorganizing the event log\n- Election Certificates: on a successful leader election, its first heartbeat will contain a quorum certificate with all the RequestVoteResponse RPCs it received to become leader. Nodes can individually verify this is the case (all public keys are known ahead of time)\n- Commit Verification: rather than having leader be responsible for incrementing the commit index, it keeps track of this itself by broadcasting AppendEntriesResponse RPC to every node (not just the leader). That way, when a node receives quorum on the number of AppendEntriesResponses, it will increment the commit index (similar to the prepare phase in [[thoughts/PBFT|PBFT]])\n- Lazy Voters: a node does not grant a vote to a candidate unless it believes the current leader is faulty. This prevents unnecessary elections from being started in attempts to starve the system","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Tendermint":{"title":"Tendermint","content":"\n\u003e Tendermint is most useful as an analog of Paxos/[[thoughts/Raft Consensus Algorithm|Raft]] but in a multi-stakeholder, or otherwise more adversarial, setting. However, the performance may not be as high due to the overhead of cryptographic operations\n\n[Source Paper](https://tendermint.com/static/docs/tendermint.pdf), authored by Buchman, Kwon, Milosevic in 2018, stabilized in 2019.\n\nA [[thoughts/consensus#State Machine Replication|state machine replication]] protocol with a partially synchronous [[thoughts/system model|system model]] that, when $f \u003c \\frac n 3$, satisfies always [[thoughts/consistency|consistency]] and eventually satisfies [[thoughts/liveness|liveness]] (under the presence of an attack). However, the time to obtain a supermajority increases linearly with the number of nodes in the network.[^1]\n\n[^1]: \"There is a practical limit to how decentralized a blockchain with [[thoughts/PBFT|PBFT]]-based consensus can be. For instance, most Tendermint based blockchains only have 100-150 validators; this is done to strike a balance between time to finality and decentralization\" (from Scott's *[Guide to Finality](https://www.smsunarto.com/blog/guide-to-finality)*)\n\nHigh-level ideas:\n1. Iterated single-shot consensus (something that looks like [[thoughts/consensus#Byzantine Agreement|Byzantine Agreement]]) where the output of each single-shot consensus instance outputs a block (ordered list of transactions)\n2. For a fixed height, keep proposing + voting until agreement is reached\n3. Two stages of voting as different nodes may see different voting schemes\n\nWe assume [[thoughts/Public-key Infrastructure|PKI]] and a shared global [[thoughts/clocks|clock]]. A round is $4 \\Delta$ timesteps, leaders are rotated once per round.\n\n## Properties\n### Quorum Certificate (QC) Lemma\nA collection of a supermajority ($\\geq \\frac 2 3$) of votes for a block $B$ in a particular round at some height $h$ and some stage $s$. Any two QCs overlap in at least one honest node as $overlap \\geq n - \\frac 1 3 n - \\frac 1 3 n \u003e f$ and thus any two QCs must support the same block $B$.\n\n![[thoughts/images/tendermint proof of consistency.png]]\n\n### State\n- Each node maintains a ($B_i$, $QC_i$) and periodically updates these variables block-QC pair it's heard about\n- Each node also keeps a local append-only data structure for blocks considered 'delivered'\n- Each node maintains it's own height (which block it is currently working on) and ignores all messages about other heights\n\n## Pseudocode\nAssume a specific height $h$ and round $r$ with leader $l$. We split each round into 4 phases ($t = 4 \\Delta r$).\n\n1. $t = 4 \\Delta r$: \n\t1. $l$ updates $(B_l,QC_l)$ to most recent QC known\n\t2. broadcast $(B_l, Q_l)$ signed by $l$ to all other nodes\n2. $t = 4\\Delta r + \\Delta$:\n\t1. honest node $i$ will ignore the proposal if it seems out of date ($QC_l$ seems behind $QC_i$)\n\t2. if node $i$ receives $(B_l, QC_l)$ from $l$ and it is up to date\n\t\t1. broadcast first-stage vote for $vote_1(B_l)$\n\t\t2. update $(B_i, Q_i) := (B_l, Q_l)$\n\t\t3. broadcast $(B_l, Q_l)$ signed by $i$\n\t3. else, do nothing\n3. $t = 4 \\Delta r + 2\\Delta$:\n\t1. if node $i$ receives $\\geq \\frac 2 3 n$ round-$r$ stage-1 votes (supermajority) for block $B$,\n\t\t1. if this occurs, all possible QCs must all support the same block (by QC overlap property)\n\t\t2. assemble QC from supermajority of votes\n\t\t3. set $QC_i := QC_\\textrm{assembed}$, $B_i := B$\n\t\t4. after witnessing a conclusive winner to the first stage, we broadcast second stage vote for $vote_2(B_i)$\n\t\t5. broadcast $(B_i, QC_i)$ signed by $i$\n\t2. else, do nothing\n4. $t = 4\\Delta r + 3 \\Delta$:\n\t1. if node $i$ receives $\\geq \\frac 2 3 n$ round-$r$ stage-2 votes for block $B$,\n\t\t1. set $QC_i := QC_\\textrm{assembed}$, $B_i := B$\n\t\t2. commit $B$ to local history\n\t\t3. broadcast $(B_i, QC_i)$ signed by $i$\n\t\t4. increment $h_i$, re-initialize $B_i$ and $QC_i$ to null\n\t2. else, do nothing\n5. $t = 4 \\Delta r + 4 \\Delta$ (just before round $r + 1$):\n\t1. If we have heard of a stage-2 QC for block $h_i$ supporting block B\n\t\t1. commit $B$ to local history\n\t2. else, do nothing\n\nIn the background,\n- All honest nodes store all QCs received for future blocks $h_i + 1, h_i + 2, \\dots$\n\n## Proof of consistency\nDefinition of [[thoughts/consistency|consistency]]: For a given block number, all honest nodes commit the same block $B^*$.\n\nThis seems pretty obvious from the QC lemma but we can formalize this through proof by induction:\n\nAssumptions\n1. Fix a height $h$.\n2. Let $r$ be the first round in which $\u003e \\frac n 3$ honest nodes (set $S$) cast stage-2 votes for some block $B^*$. $r$ is the first round in which a stage-2 QC could have been created.\n\nInduction: at the end of round $r$\n- we know $B_i = B^*$, $\\forall i \\in S$ \n- current $QC_i$ is from round-$r$ stage-1 or later\n- all QCs for other blocks are from round $r - 1$ or earlier\n\nThese properties remain to be held in round $r + 1$ given they hold in round $r$ as no nodes of $S$ change their mind.\n\n## Proof of liveness\nDefinition of [[thoughts/liveness|liveness]]: if a transaction $T$ is known by all honest nodes, then it will get added to all of their local histories.\n\nNote: this is a weaker definition of liveness than usual for [[thoughts/State Machine Replication (SMR)|SMR]] which states that if a single honest node knows about a transaction, then all honest nodes will eventually add that transaction to their local histories.\n\nWe define a **clean** round when\n1. we are post-GST\n2. there is an honest leader\n3. all honest nodes are working on the same block number\n\nProofs:\n- Fast forward to pair of $r_1$, $r_2$ consecutive rounds after $GST + \\Delta$ with honest leaders $l_1$, $l_2$ (this must be true for $f \u003c \\frac n 3$)\n- Lemma: at the start of round $r_1$, every honest node is working on either block $h$ or $h+1$\n\t- True because of the broadcast of a stage-2 QC at the end of $t = 4\\Delta (r - 1) + 3 \\Delta$, and all nodes should pick this up by $t = 4 \\Delta r + 3 \\Delta$ and be working on at least $h$\n\t- Nodes could possibly be split between working on $h$ and $h + 1$ if a Byzantine node keeps secret a stage-2 QC for $h$ and selectively forward it to honest nodes.\n- Lemma: if there is a clean round, all honest nodes commit the block proposed by the leader\n\t- By part 2 in assumption of clean round, after the update in the first phase, the leader's QC is at least as recent as any other honest nodes.\n\t- As we are post-GST, vote request will arrive at each node for $4 \\Delta r + \\Delta$ where they all broadcast stage-1 votes for $B_l$ and have their local variable updated.\n\t- Nodes assemble super majority for $B_l$ and can create a QC... same argument for stage-2 votes\n\t- All nodes then commit $B_l$ to their local history\n\n","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/The-Dragon-and-the-bridge":{"title":"The Dragon and the Bridge","content":"\n*Paper #1 for PHIL240A at UBC*\n\n\u003e It's been three weeks now since you woke up deep in a forest. You've managed to survive; the forest itself isn't that bad. But, there's a pack of wolves that keeps trying to hunt you down, and every few days you have to run away from where you've set up camp. This is one of those days. You hear the howling of the wolves and run run run for it... until you break through the tree line and find yourself facing a massive ravine. There's clearly no way to jump, go around, or scale down it. Scanning frantically, you see a rope bridge about half a kilometer away, and you dash toward it. There seems to be some large boulder blocking the entrance, but you'll deal with that when you get there. As you approach, a long neck raises an elegant reptilian head, and two golden eyes turn to regard you. The boulder was a sleeping dragon! You slow down and approach with caution. Dragons are known to be intelligent and mostly benevolent; maybe you can just talk to them and ask them to move. \"Great dragon!,\" you call out. \"Please let me past you onto the bridge. There's a group of wolves coming after me, and I don't want to be eaten.\" The dragon looks askance at you, turns its long neck to look across the ravine, and turns back to you again. \"Bridge? What bridge?,\" they ask. \"The one right behind you,\" you reply, surprised. \"There's a bridge here?,\" the dragon queries, feigning (or not?) confusion. You're stunned. \"Yes, the bridge, it's right there!,\" you say. \"Aha!,\" says the dragon. \"But how do you know there's a bridge here? How can you be certain of what you see, that it's not an illusion, or that all of this isn't a dream? Death approaches you from behind, death looms before you if you fall unsupported into this ravine. Why would you trust that the world has provided you with a bridge?\"\n\u003e \n\u003e Respond from the perspective of Uddyotakara, assuming that he endorses Gautama's verses and Vātsyāyana's comments (see: [epistemology](thoughts/epistemology.md))\n\n---\n\n- **D:** the dragon guarding the bridge\n- **U:** Uddyotakara, a philosopher in the [Nyāya](thoughts/Nyāya.md) school of philosophy, running for their life from wolves. A proponent of [philosophical realism](thoughts/philosophical%20realism.md)\n\n**U:** Great dragon! Please let me pass you so I can cross the bridge.\n\n**D:** But how do you know there's a bridge here? What if your senses deceive you?\n\n**U:** Turn around and see for yourself! Can you not see clearly? There is clearly a rope bridge right behind you.\n\n**[The Dragon turns around.]**\n\n**D:** Hm.. there does not appear to be a bridge. How can you be sure you are not hallucinating a bridge?\n\n**U:** I have trust in my vision -- it is a reliable epistemic instrument. Why doubt my sight now when it has served me faithfully so many times before? I trust that my eyes see I bridge so I believe there is a bridge for me to cross the ravine.\n\nRational inquiry requires purpose. We do not doubt everything, lest we not [trust](thoughts/trust.md) the ground beneath us. (Nyāyasūtra 4.2.33).\n\n**D:** You seem to rely heavily on inductive principles in your reasoning. One cannot infer that \"my vision will always be faithful\" given that it has been faithful in the past. How do you convince yourself that this bridge is not a [black swan](https://en.wikipedia.org/wiki/Black_swan_theory)? Or that bridges exist at all? Perhaps nothing exists at all.\n\n**U:** Vision is a subset of perception, which is a *pramāna*. It is a means of knowing that is gained through \"close examination of objects through cognition\" (Nyāyasūtra 4.2.29). With the existence of *pramānas* the thesis \"Nothing exists\" cannot possibly be true.\n\nLet us suppose the claim were true and it was supported by a *pramāna*. In which that case, that very *pramāna* would contradict that claim. If there were no *pramāna* to support this claim, then the thesis could not be proved (Nyāyasūtra 4.2.30). Thus, the claim is false. *Pramānas* must exist and *some* things must be real.\n\n**D:** Yet, you cannot be sure that the bridge is real. Your vision can deceive you. Have you not seen a simple magic trick? How do you know the bridge is not a visual illusion or dream?\n\n**U:** Well, first I must get close enough to examine the bridge closely. If it was a visual illusion, I can consult another sense like touch to reinforce my trust in it. But even if it was, say a dream, then I could wake up from it! Both dream wolf and dream bridge would cease to matter.\n\nThe concept of being chased by wolves and the concept of a rope bridge may have been real, but the *physical* risk associated with them would be dissolved. In a dream, things are still *real* in the conceptual sense. For something to have been in a dream, I must have had the *essence* of the object as a prior. There is no concept 'dream wolf' if there is no concept of 'wolf' (Nyāyasūtra 4.2.34-35).\n\n**D:** I concede then that *conceptually* the bridge must exist. Yet, how do you reconcile that with the real and the physical? What if that bridge is actually broken? What if you mistook the bridge for a fallen log?\n\n**U:** That is to say that my cognition of the bridge is erroneous? Do you believe there to be nothing in its place? I cannot make a mistake about what it is unless there is something there that I could be wrong about. What do you see instead?\n\n**[The Dragon takes another glance at the ravine.]**\n\n**D:** I see a log. There is no concept of 'bridge' behind me.\n\n**U:** This is quite the anti-realist argument -- that because you and I see two different things when referring to the same object (due to [[thoughts/language|language]] understanding, presupposed knowledge, etc.) then the object must therefore have no 'true nature' (Nyāyasūtra 4.2.37).\n\nYet, to even be wrong about something, one needs to mistake something $\\lnot F$ for something $F$ (to see a post as a person). This, of course, happens when the differences between $\\lnot F$ and $F$ are ignored while their similarities are grasped.\n\nWhile either one of us could be wrong about the *true* nature of the thing in the ravine, it is undoubtable that there is something there which has the essence of 'bridge' and 'log' and should be usable to cross the ravine.\n\n**D:** Well, seeing as there is *something* for you to cross the ravine with, you must get going now. The wolves are getting close, I shall let you cross.\n\n**[The Dragon steps aside.]**","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/The-Grasshopper-Games-Life-and-Utopia":{"title":"The Grasshopper: Games, Life and Utopia","content":"\n\"It is the attempt to discover and formulate a definition, and to follow the implications of that discovery even when they lead in surprisingly, and sometimes disconcerting, directions.\"\n\n## The Grasshopper\nA fun Platonic dialogue poised as a tale between insects. The grasshopper, about to die for winter, leaves his disciples with a few riddles. Within these tales, the grasshopper details his philosophy of \"refusing to work and insisting upon devoting himself exclusively to play\". Of course, his disciples challenge him about this, leading to a journey of defining what [games](thoughts/games.md) are, attitudes toward playing games, and the role of games in utopias. \n\n(When talking about why the author chose to write the book as a Platonic dialogue) \"His refusal to express himself in a plain expository style is perhaps no different in principle from someone's setting out to write an entire book without using the letter *e*\"\n\n## [Utopia](thoughts/utopia.md) and Scarcity\n\"For one cannot help reflecting that if there were no winters to guard against, then the Grasshopper would not get his come-uppance nor the ant his shabby victory. The life of the grasshopper would be vindicated and that of the ant absurd\"\n\n\"Thus, although time is a finite quantity for everyone, it is not a limited resource for everyone. For a bored person time is a burden; for a person on the rack it is agony. And when time *is* a resource for someone it is not always a limited resource. For a person with very few goals there is always enough time to accomplish all of them.\"\n\n\"[Play](thoughts/play.md) is necessary but not sufficient adequately to account for the ideal of existence\"\n\n## A post-work society\nLet us imagine that all of the instrumental activities of human beings have been eliminated. All of the things ordinarily called work are now done by wholly automated machines which are activated solely by mental telepathy, so that not even a minimum staff is necessary for the housekeeping chores of society.\n\n\"You talk as though there were but two possible alternatives: either a life devoted exclusively to play or a life devoted exclusively to work. But most of us realize that our labour is valuable because it permits us to play, and we are presumably seeking to achieve some kind of balance between work input and play output. People are not, and do not want to be, wholly grasshoppers or wholly ants, but a combination of the two; people are and want to be (if you will forgive a regrettably vulgar but spooneristically inevitable construction) asshoppers or grants. We can, of course, all cease to work, but if we do then we cannot play for long either, for we will shortly die.\"\n\n### Art and Pursuit of Knowledge\nArt has a subject matter which consists in the actions and passions of humanity: with human aspirations and frustrations, hopes and fears, triumphs and tragedies, with flaws of character, moral dilemmas, joy and sorrow. But it would seem that none of these necessary ingredients of art could exist in Utopia, thus there are no artists of any sort in Utopia.\n\nThe acquisition of knowledge, just like the acquisition of anything else, is an instrumental process; that is acquisition is instrumental to possession, no matter what it is. We must therefore assume that all Utopians have acquired all the knowledge there is. Thus, there are no scientists, philosophers, or any other intellectual investigators.\n\nWe can call this state of affairs the **Alexandrian Condition of Man**, after Alexander the Great. When there are no more worlds to conquer, we are not filled with satisfaction but with despair.\n\nThus in Utopia, we need therefore is some activity in which what is instrumental is inseparably combined with what is intrinsically valuable, and where the activity is not itself is not itself an instrument for some further end: games. Games have obstacles which we can strive to overcome *just so that* we can possess the activity as a whole (playing the game).\n\nThe counter-argument though, is the existence of individuals value the means as much as the ends themselves, if not more. Once a scientist or philosopher after great effort solves a major problem he is very let down, and far from rejoicing in the possession of his solution or discovery, he cannot wait to be engaged once more in the quest. **Success is something to shoot at, not to live with**. This seems to dismantle the previous argument dismissing art and pursuit of knowledge as important in a post-work society.\n\nThe resolution to this appears to be the fact that activities which from one point of view be seen as instrumentally valuable can, from another point of view, be intrinsically valuable. For example, we can agree that carpentry is an instrumental activity; that is, instrumental to the existence of houses. But to a person who enjoys building for its own sake, that otherwise instrumental activity has intrinsic value as well. The same could be true of anyone who really enjoys their work, whatever that work might be. I then posit this type of work *as game playing* so thus can exist in Utopia.\n\nEven in a purely abundant world, one can *create* scarcity for themselves through imposing constraints [constitutive rules]. The dedicated puzzle solver will say, \"Don't tell me the answer; let me work it out for myself.\" Even if other means for coming to know the answer are readily available, he voluntarily rejects these means so that he will have something to do. This is definition of game playing.\n\nWhereas our own culture is based on various kinds of scarcity -- economic, moral, scientific, erotic -- the culture of Utopia will be based on plentitude and abundance. A utopic society would not study economics but rather [agalmics](thoughts/positive%20sum.md).\n\n## Games\nDefinitions:\n1. \"Let us say that games are goal-directed activities in which inefficient means are intentionally chosen.\"\n2. \"A game is an activity in which observance of rules is part of the end of the activity, and where such rules are non-ultimate; that is, where other rules can always supersede. the game rules; that is, where the player can always stop playing the game\"\n\nThen, to play a game is to attempt to achieve a specific state of affairs [prelusory goals], using only means permitted by rules [lusory means], where the rules prohibit the use of more efficient in favour of less efficient means [constitutive rules], and where the rules are accepted just because they make possible such activity possible [lusory attitude] (this is to say that rules are sufficient to make possible a game but not required). Simplified, **playing a game is the voluntary attempt to overcome unnecessary obstacles.**\n\n\"Rules in games thus seem to be in some sense inseparable from ends, for to break a game rule (a means) is to render impossible the attainment of an end.\"\n\n\"In anything but a game the gratuitous introduction of unnecessary obstacles to the achievement of an end is regarded as a decidedly irrational thing to do, whereas in games it appears to be an absolutely essential thing to do.\"\n\nGames which are competitive (read: telic) involve winning and losing -- that is the aim or end of the game in the first place. The win of one implies the loss of another, a [zero sum](thoughts/zero%20sum.md) world. Playing, though, are the means which are ends themselves; the act of playing is enough and paratelic in nature. Thus, someone who plays games as an end is autotelic.\n\n\u003e Do you like the act of climbing the mountain or just being at the top? Because the latter doesn't require the first.\n\nGames, simply put, reverse the ends and means of other activities. In Kant's *Critique of Aesthetic Judgment*, he likens aesthetic experience to play as a kind of 'purposiveness without purpose' \n\n### Open and Closed Games\n- **Open games**: system of reciprocally enabling moves whose purpose is the continued operation of the system.\n- **Closed games**: games which have an inherent goal whose achievement ends the game. e.g. crossing a finish line, mating a king, etc.\n\nDisagreement in games then, usually comes from the disagreement over whether a certain game is open or closed.\n\n\"We might expect societies which place a high value on success through co-operation to be more inclined to emphasize open games\"\n\n### Distinction between rules and goals\nIt is possible to follow the rules of chess [the institution] without playing chess [the game]. On the contrary, one cannot play chess without following the rules (to do so is to be a cheat).\n\n### Terminology\n- Prelusory goals: specific achievable state of affairs. They can be described before, or independently of, any game of which it may be, or come to be, a part.\n- Lusory goals: winning the game. Game specific.\n- Lusory means: means which are permitted (legal or legitimate) in the attempt to achieve prelusory goals.\n- Constitutive rules: rules which prohibit use of the most efficient means for reaching a prelusory goal.\n- Lusory attitude: the acceptance of constitutive rules just so the activity made possible by such acceptance can occur.\n\n### Lusory Attitude -- the game attitude\nThe element which unifies the other elements into a single formula which successfully states the necessary and sufficient conditions for any activity to be an instance of game playing. The elements of game are\n1. The goal\n2. The means of achieving the goal\n3. The rules\n4. The lusory attitude\n","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/The-Midnight-Library":{"title":"The Midnight Library","content":"\n*by Matthew Haig*\n\nA really good fiction read on [optionality](thoughts/optionality.md), the meaning of [life](thoughts/life.md) and what it means to be a truly happy with your life.\n\n\u003e \"I think it is easy to imagine there are easier paths,\" she said, realising something for the first time. \"But maybe there are no easy paths. There are just paths. In one life, I might be married. In another, I might be working in a shop. I might have said yes to this cute guy who asked me out for a coffee. In another I might be researching glaciers in the Arctic Circle... Who knows? Every second of every day we are entering a new universes. And we spend so much time wishing our lives were different, comparing ourselves to other people and to other versions of ourselves, when really most lives contain degrees of good and degrees of bad.\"\n\n\u003e \"There are patterns to life... Rhythms. It is so easy, while trapped in just one life, to imagine that times of sadness or tragedy or failure or fear are a result of that particular existence. That it is a by-product of living a certain way, rather than simply *living*... sadness is intrinsically part of the fabric of happiness.\"\n\n\u003e \"She realized that you could be as honest as possible in life, but people only see the truth if it is close enough to their reality.\" As Thoreau wrote, \"It's not what you look at that matters, it's what you see.\"","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/The-Psychopathology-of-Everyday-Things":{"title":"The Psychopathology of Everyday Things","content":"\n\u003e \"The design of the door should indicate how to work it without any need for signs, certainly without any need for trial and error.\"\n\nTwo of the most important characteristics of good design:\n1. Discoverability: is it possible to even figure out what actions are possible and where and how to perform them?\n2. Understanding: what does it all mean? How is the end product supposed to be used?\n\nCovers three major areas of design\n1. Industrial Design: creating/developing concepts and specs that optimize function, value, and appearance of products and systems for the mutual benefit of both user and manufacturer\n2. Interaction Design: enhance people's understanding of what can be done, what is happening, and what has just occurred\n3. Experience Design: practice of designing products, processes, services, events, and environments with a focus placed on the quality and enjoyment of the total experience\n\nThe machine does what it is told, no matter how insensible and illogical. Humans, on the other hand, are imaginative and creative, filled with common sense. Yet, to interact with machines, they require us to be precise and accurate, things we are not very good at.\n\nThe problem with the designs of most engineers is that they are too logical. We have to accept human behaviour the way it is, not the way we would wish it to be.\n\n**TL;DR**\n1. Most failures of human-machine systems are due to poor designs rather than human error itself. \n2. Good design accounts of human limitations.\n\nRelevant for [human computer interaction](thoughts/human%20computer%20interaction.md) and [interaction design](thoughts/interaction%20design.md)","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/The-Secret-Life-of-Books":{"title":"The Secret Life of Books","content":"\nBooks have rich inner lives of their own, unbeknownst to many. They babble and talk amonst each other, gossip about what they saw in the homes of the people that took them home, and whisper about who had the chance to be read and seen that week.\n\nThis book always sat in the back shelves of the library, one row over from all the 'popular' kid's books like Geronimo Stilton and the Magic Schoolbus. Kids always flocked to the first aisle, books always vying to be placed on display and on feature to be seen.\n\nMost books got their turn in this row, a beautifully lit shelf under the skylight. It was here that most books had their first 'take-home' experience -- something akin to a coming of age.\n\nYet as the years came and went, this book left unread and unfeatured, sitting.\n\nThere was a sharp piercing laughter that rang through the halls, a sharp contrast to the usually hushed and muted sounds library. A young girl, no older than 8, ran through the halls waving books in her two small hands.\n\nHushed whispers spread amongst the books. \"Look at her! She's so special!\"\n\nA seemingly frazzled women stumbled after her, trying immensely to summon up the energy to even keep up with the child.\n\n\"Look ma!! This one starts with W too!\" she squealed, pointing at \"Wonders of the World\". An excited hush fell over the shelf as we all watched to see who she would pick next.\n\n\"Do you think she's going to pick one of the new bestsellers?\"\n\n\"No, those haven't been hot with the kids lately. She's going to want something of _substance_ something that intrigues her inner world.\"\n\n\"Don't be stupid, she's like 8. She's probably going to pick one of us with a nice cover.\"\n\nAll the other books chattered constantly as she sat and gazed at the rows and rows of shelves. Honestly, the chatter never really bothered me. I had my own little spot in the world -- the end of 573.001. Sometimes I felt unworthy, a book no one wanted to read or reference. This little book society of ours, always praising being the popular book; the book that is 'critically acclaimed' or 'insightful'. But I had become content living in my own little world for the past few years. A sort of internal beauty that I can't really explain to anyone but myself.\n\n\"Ma, look at this one! It's got pretty flowers on it! And it has two Ws!\"\n\nA sudden hush fell over the books; one had been chosen! I hadn't cared to look, nor did I really intend to. At least until I felt the grasp of a childs hand on my spine. A grasp that has grasped crayons, carrots with might but also knew the tenderness and respect that one needs to have when holding a book.\n\nIn a haze, I had forgotten that was me! _Wonderful Wildflowers of British Columbia._ An identity outside of that inner world of mine.\n\nAnd so I was taken home that evening. Under the blankets in the beam of a flashlight, I felt the fingers of a child's hand trace the letters in my pages.\n\nShe murmered under her breath, feeling and voicing the shape of each new word. Words that I had skimmed over and thought unimportant proved to provide hours of entertainment and excitement. Pictures that seemed to show the mundane petals and stems of flowers were the muses for countless artworks and storytimes.\n\nWhen it came time to return, the book couldn't actually be returned -- the pages had been too torn, too coloured on, too roughed up.\n\nBut that's just another way to say it's been loved.","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/The-Upanisads":{"title":"The Upanisads","content":"\nA collection of texts composed over several centuries (the oldest from ca. 700-300 BCE) and in various regions (northern India, ranging from the upper Indus valley to the lower Ganges).\n\nTwo interpretations\n1. Upa(near)+ ni(down) + sad(sit): \"to sit close beside\" The secret teaching passed orally from teacher to disciple\n2. \"Connection\" or \"equivalence\" secret knowledge or hidden connections (the Upanisads being the texts containing those doctrines)\n\n## Bṛhadāraṇyaka Upaniṣad 4.3-4.4\nA dialogue between\n- (Y) Yājñavalkya: a great teacher of secret doctrines. Learned, sarcastic, and irreverent\n- (K) King Janaka: a great and learned King from Videha\n\nK asks Y \"What light does a person have?\" and Y responds. K keeps asking \"What light does a person have when that is gone?\"\n\nThe order of Y's responses is as follows:\n- The sun\n- The moon\n- Fire\n- Speech\n- [The Self](thoughts/the%20Self.md) (see: [Cartesian Realism](thoughts/Descartes'%20Meditations.md))\n\nInteresting to note that this moves from far away to closeby in terms of spatial distance (astronomically far to the intimate self)\n\nThen K asks, \"What is [the Self](thoughts/the%20Self.md)?\". Y answers \"the inner light that is the person\" (puruṣa) or consciousness as it travels through 3 states. (Map of [consciousness](thoughts/consciousness.md), four aspects/\"quarters\" of the self)\n1. Waking: person in its physical nature, awareness of external objects, perception and thought, identification with the body\n2. [Dreaming](thoughts/Dreams.md): person in its mental nature, awareness of dream images (mental impressions, memories), identification with the dream ego\n3. Deep and dreamless sleep: person beyond desire, peace and bliss, absence of identification\n4. Pure Awareness (Māṇḍūkya Upaniṣad) (added in a latter Upaniṣad): ground state of consciousness\n\nThis is where the OM/AUM sound comes from. A from waking, U from dreaming, M from deep sleep, and pure awareness as a combination of all 3\n\n[Death](thoughts/death.md) is described as the dissolution of vital functions (prāna) of the mind and body which then culminates in pure awareness and transitioning to rebirth\n\nLife, then, is impelled by desire which leads to rebirth according to karma. Death is liberation for those who have freed themselves from desire (and achieve nothing but *brahman* or pure light)","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/The-Writing-Life":{"title":"The Writing Life","content":"\nBy Annie Dillard\n\n## Quotes\nOn throwing away early work:\n\n\u003e A painting covers its tracks. Painters work from the ground up. The latest version of a painting overlays earlier versions, and obliterates them. Writers, on the other hand, work from left to right. The discardable chapters are on the left. The latest version of a literary work begins somewhere in the work's middle, and hardens toward the end. The earlier version remains lumpishly on the left; the work's beginning greets the reader with the wrong hand. In those early pages and chapters anyone may find bold leaps to nowhere, read the brave beginnings of dropped themes, hear a tone since abandoned, discover blind alleys, track red herrings, and laboriously learn a setting now false.\n\n\u003e The work is not the vision itself, certainly. It is not the vision filled in, as if it had been a colouring book. It is not the vision reproduced in time; that were impossible. It is rather a simulacrum and a replacement. It is a golem. \n\nOn rest:\n\n\u003e Octavio Paz cites the example of \"Saint-Pol Roux, who used to hang the inscription 'The poet is working' from his door while he slept\"\n\nOn spending time wisely:\n\n\u003e How we spend our days is, of course, how we spend our lives. What we do with this hour, and that one, is what we are doing. A schedule defends from chaos and whim.\n\nOn learning to write:\n\n\u003e Who will teach me to write? a reader wanted to know.\n\u003e \n\u003e The page, the page, that eternal blankness, the blankness of eternity which you cover slowly, affirming time's scrawl as a right and your daring as necessity; the page, which you cover woodenly, ruining it, but asserting your freedom and power to act, acknowledging that you ruin everything you touch but touching it nevertheless, because acting is better than being here in mere opacity; the page, which you cover slowly with the crabbed thread of your gut; the page in the purity of its possibilities; the page of your death, against which you pit such flawed excellences as you can muster with all your life's strength: that page will teach you to write.\n\n\u003e A well-known writer got collared by a university student who asked, \"Do you think I could be a writer?\"\n\u003e \n\u003e \"Well,\" the writer said, \"I don't know... Do you like sentences?\"\n\u003e \n\u003e The writer could see the student's amazement. Sentences? Do I liked sentences? I am twenty years old and do I like sentences? If he had liked sentences, of course, he could begin, like a joyful painter I knew. I asked him how he came to be a painter. He said, \"I liked the smell of paint\"\n\nOn being in the rut:\n\n\u003e \"You asked how my work is going.\" he said. \"That's how it's going. The current's got me. Feels like I'm about in the middle of the channel now. I just keep at it. I just keep hoping the tide will turn and bring me in.\"\n\nJust beautiful:\n\n\u003e Each sentence hung over an abyssal ocean of sky which held all possibilities, as well as the possibility of nothing.","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/The-ones-who-walk-away-from-Omelas":{"title":"The Ones Who Walk Away From Omelas","content":"\n[Source: The Ones Who Walk Away From Omelas by *Ursula Le Guin*](https://learning.hccs.edu/faculty/emily.klotz/engl1302-6/readings/the-ones-who-walk-away-from-omelas-ursula-le-guin/view)\n\nThere is no happiness without suffering. The story presents a classic utilitarian problem: is it morally justifiable to inflict suffering on one person in the service of others’ happiness (and a potential [utopia](thoughts/utopia.md))?\n\nThinking about it in terms of technology as a multiplicative tool. Is it then morally just to develop technology to benefit others knowing that it will exacerbate the suffering of marginalized groups?\n\nFollow up: is there any way we can use tech as a [running shoe instead of a crutch](thoughts/crutch%20and%20shoe%20metaphor.md)?\n\nDid the agricultural revolution make us generally less happy? \"We didn’t domesticate wheat, we domesticated ourselves\"\n\n## What does it mean to walk away from Omelas?\nJoining the counterculture rather than feeding into the status quo: [From Counterculture to Cyberculture](thoughts/From%20Counterculture%20to%20Cyberculture.md). Rejecting the capitalist society and 'returning to the land'\n\nImmersion in the [virtual worlds](thoughts/virtual%20worlds.md) rather than reality?\n\n## Quotes\n\"The trouble is that we have a bad habit, encouraged by pedants and sophisticates, of considering happiness as something rather stupid. Only [pain](thoughts/pain.md) is intellectual, only evil interesting.\"\n\n Some of them understand why, and some do not, but they all understand that their happiness, the beauty of their city, the tenderness of their friendships, the health of their children, the wisdom of their scholars, the skill of their makers, even the abundance of their harvest and the kindly weathers of their skies, depend wholly on this child’s abominable misery.\n \n \"To exchange all the goodness and grace of every life in Omelas for that single, small improvement: to throw away the happiness of thousands for the chance of the happiness of one: that would be to let guilt within the walls indeed.\"\n \n ","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Theory-of-Niche-Construction":{"title":"Theory of Niche Construction","content":"\n## Theory of Niche Construction\n-   many animals intervene in their environment, shaping it in ways that improve the adaptive fit between the agent and its world\n-   such animals in part adapt to their niche, in part construct their own\n-   the niche construction perspective focuses our attention on the common features of this whole range of cases whereas the extended mind model does not\n    -   human capacities, cognitive and non-cognitive alike, turn out to depend on the fact that humans engineer their environment to support their activities\n-   extended digestion example\n    -   some animals do the hard digestion stuff on-board, powerful jaws, large mouths, lots of time chewing\n    -   we cook lmao\n    -   also, we selectively breed livestock which improves the food value of domestic stock\n\n## Extended Phenotypes Concept\n-   things animals build are part of their phenotype (physical exhibited traits that are determined genetically)\n\t-   developmentally stable, as heritable and predictable in their ecological effects as other traits\n-   e.g. wasp nests, beaver dams, spider webs\n- arguably, language and [terminology](thoughts/terminology.md) are extended phenotypes\n\t- language as a phenotypical trait -\u003e [language of thought](thoughts/language%20of%20thought.md) and [terminology](thoughts/terminology.md)\n\t- like beaver dams, these technologies have evolved by cumulative trail and error but the mechanism of inheritance is cultural rather than genetic\n\t- inheritance is not strictly vertical, it can be oblique and many-to-one (information flow from many members of the parental generation — and from each other)\n\t- the cognitive competence of generation N+1 individually and collectively depends on cognitive provisioning by generation N","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/To-Live-in-their-Utopia":{"title":"To Live in their Utopia","content":"\n[Paper](https://ali-alkhatib.com/papers/chi/utopia/utopia.pdf) and [Video Essay](https://www.youtube.com/watch?v=ClGIosevT0Y)\n\n## Design and Development of Systems\n[Creation vs Maintenance](thoughts/creation%20vs%20maintenance.md) view of developing AI:\n1. Creation: \"focus on finding new places and ways to use technologies and new insights that AI might yield when ML is applied to massive datasets to find relationships in the data\"\n2. Maintenance: \"surfaces problems with existing systems and attempts to mitigate those harms (for instance, by making them more fair, accountable, and transparent)\"\n\n\"When designers of these algorithmic systems train computational models that ignore transgender identity, these systems demand that trans people somehow shed an identity they can't; identities that cisgender people hardly ever bother to regard.\"\n\n\"Designers of sociotechnical systems have repeatedly built computational systems and models rendering decisions that exacerbate and reinforce historical prejudices, oppression, and marginalization\"\n\nFor those of us who can just *not* deal with race, or gender, or sexuality, we get to pass through these systems relatively unscathed. But for those of us who can't ignore those dimensions of who we are, those aspects of ourselves make us stick out. More examples in [Design Justice](thoughts/Design%20Justice.md).\n\n## [Utopia](thoughts/utopia.md)\nA utopia implies perfection and thus no feedback. ML models think they live in a perfect world unless told otherwise.\n\nRelated: [The ones who walk away from Omelas](thoughts/The%20ones%20who%20walk%20away%20from%20Omelas.md)\n\n## '[Truth](thoughts/truth.md)' and [Feedback loops](thoughts/feedback%20loops.md)\n\"Absurdity follows when algorithmic systems deny the people they mistreat the status to lodge complaints, let alone the power to repair, resist, or escape the world that these systems create.\" How do [feedback loops](thoughts/feedback%20loops.md) play into these systems? Is it possible to create good human-in-the-loop ML?\n\n\"Absurdity and tragedy tend to manifest when bureaucratic imaginations diverge from reality and when people can't override the delusions baked into those imaginations\" It's dangerous when a single source dictates the truth.\n\nBut when the institution *does* wield power and people can't just leave anymore, these institutions can (and do) get more and more detached from the lives and needs of people. Those bureaucracies construct their own worlds where everything gets \"rationalized\" in simplified, reductive language.\n\n\"People talk about \"debiasing\" data and reviewing code before a model is trained and deployed. What I'm saying is that even if you've done everything right, if you don't pay attention to the power dynamics as they unfold and play out, the system out in the world is going to drift further and further away from reality.\"\n\nSystemized classification and quantification of the world acts as an interpretive and transformational force. In other words, [quantization](thoughts/quantization.md) changes the world.\n\nWhy monopolies (over data and power) are bad: bureaucracies with no power self-correct (or be corrected) -\u003e they have no place in a world where people can freely walk away or reject the bureaucracy's nonsense (give feedback)\n\n## Abridged Maps\nAbridged maps as [potemkin villages](thoughts/potemkin%20village.md), producing a simplified yet inaccurate view of the world. It's not necessarily wrong to create 'abridged maps', the problem comes when projecting the map onto the world to try and create change.\n\n\"When modelers and designers of influential systems use these maps as guides to substantially transform the world, the abridgements and the omissions they make become targets of erasure.\"\n\n\"In the process of training a model, the algorithm creates its own world -- it generates its own sort of utopia where things are clear and calculable. That system imposes its model upon the world, judging and punishing people who don't fit the model that the algorithm produced in the interest of some ostensibily objective goal that designers insist is better than decisions humans make in some or many ways.\"\n\nThese systems become more actively dangerous when they go from \"making sense of the world\" to \"making the world make sense\"\n\nThere's no dataset in the world that adequately conveys white supremacy, or slavery, or colonialism. (see: [data distributions](thoughts/data%20distributions.md))\n\nSo at best these systems generate a facsimile of a world with the shadows of history cast on the ground skewed, flattened, and always lacking depth that only living these experiences can bring. Once again, creating a potemkin village of what the true problem is: an incredibly reductionist view on complex problems.\n\n## Metis\nJames C. Scott in [[thoughts/Seeing like a State|Seeing like a State]] desribes *metis*, which he translates substantively as the intelligence required to adapt to new and changing circumstances.\n\nMetis is more than constructing any number of \"rules of thumb\". Rather, knowing how and when to apply those rules in a concrete situtation is the essense of *metis*. Isn't *metis* then just the [frame problem](thoughts/frame%20problem.md)?\n\n\"A person without the lived experience of disabilities can never truly understand what it means to be 'like' someone who experiences it.\" [Disability simulation](thoughts/Design%20Justice.md) doesn't work; why do we let ML systems do it then, let alone systems without *metis*? \n\nImportant in the context of [traditional knowledge (TK)](thoughts/traditional%20knowledge.md)","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Tomorrow-and-Tomorrow-and-Tomorrow":{"title":"Tomorrow, and Tomorrow, and Tomorrow","content":"\nOn [[thoughts/games]], [[thoughts/friendship]], grief, and the creative process.\n\n*by Gabrielle Zevin*\n\n- \"You're incredibly gifted, Sam. But it is worth noting that to be good at something is not quite the same as loving it.\"\n- \"'Life is very long, unless it is not.' Sadie knew this to be a tautology, but it also happened to be true.\"\n- \"One of Sam's eventual strengths as an artist and as a businessman was that he knew the importance of drama, of setting the scene. He wanted to ask her to work with him at a special place -- the occasion of their prospective creative union should be memorable.\"\n- \"There is a time for any fledgling artist where one's taste exceeds one's abilities. The only way to get through this period is to make things anyway.\"\n- \"Sometimes, I would be in so much pain. The only thing that kept me from wanting to die was the fact that I could leave my body and be in a body that worked perfectly for a while -- better than perfectly, actually -- with a set of problems that were not my own.\"\n  - \"Sam's grandfather had two core beliefs: (1) all things were knowable by anyone, and (2) anything was fixable if you took the time to figure out what was broken\"\n  - \"She was intelligent, but her intelligence didn't get in her way of her enthusiasm\"\n  - \"Computers are great for experimentation, but they're bad for deep thinking\"\n  - \"Though you cannot see him, you become aware of the fact that your father is sitting on the floor. He is folding cranes so that your mother can string them. This is marriage.\"\n  - \"What is a game? It's tomorrow, and tomorrow, and tomorrow. It's the possibility of infinite rebirth, infinite redemption. The idea that if you keep playing, you could win, No loss is permanent, because nothing is permanent, even.\"\n\t  - On Unfair Games almost being called Tomorrow Games\n  - \"To make a game is to imagine the person playing it\"\n  - \"She had once read in a book about consciousness that over the years, the human brain makes an AI version of your loved ones. The brain collects data, and within your brain, you host a virtual version of that person. Upon the person's death, your brain still believes the virtual person exists, because, in a sense, the person still does. After a while, though, the memory fades, and each year, you are left with an increasingly diminished version of the AI you had made when the person was alive.\"\n  - \"Maybe it was the willingness to play that hinted at a tender, eternally newborn part in all humans. Maybe it was the willingness to play that kept one from despair.\"\n\nParts that I loved that are too long to directly quote\n- The chapter on Marx as a bird being shot in a game juxtaposed with him actually being shot in real life and how it tied back to an earlier flashback where there is a man-sized thrush, stealing a strawberry.\n- How *real* all the games felt. It must have taken so long to not only write the book, but to write the games in a way that made them feel natural and not potemkin constructions","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Tools-for-Conviviality":{"title":"Tools for Conviviality","content":"\nIvan Illich on the proper use of technology to reclaim agency and practical knowledge for the average citizen.\n\n---\n\nThe main TLDR; science and technology with their panoply of elite controlled knowledge and procedures have brought us so far, but cannot take us much further. They are, in fact, damaging as we approach crisis.\n\nThese tools suppress other ideas and systems of knowledge and concentrate control of knowledge and power in the few and the elite. As such, these tools can only provide a limited and very unsatisfactory set of answers to how we may live meaningful lives. Illich argues that these tools alienate humans from each other, moving away from communal notions of [[thoughts/interdependence|interdependence]] and towards increasing dependence on systems of production, killing our ability to work together and towards a better world.\n\nThis dependence on production creates a treadmill, encouraging the average citizen to consume more and forever be unsatisfied. The only way out, Illich posits, is through giving people convivial tools. 'Convivial' is used as by Illich as a technical term to designate a modern society of responsibly limited tools. Often times, this is used interchangeably with a notion of agency or autonomous discourse.\n\nIllich seems to advocate for a world where we consume less, depend less on systems which depend on us consuming more to survive, and depend more on each other. \n\n\u003e People will suddenly find obvious what is now evident to only a few: that the organization of the entire economy toward the “better” life has become the major enemy of the _good_ life.\n\n## Quotes\n### Acceleration and law\n\"Speed is one of the means by which an efficiency-oriented society is stratified... Fostered addiction to speed is also a means of social control.\"\n\n\"Society can be destroyed when ... cancerous acceleration enforces social change at a rate that rules out legal, cultural, and political precedents as formal guidelines to pres**ent behaviour.\"\n\n\"Convivial reconstruction requires limits on the rate of compulsory change. An unlimited rate of change makes lawful community meaningless. Law is based on the retrospective judgement of peers about circumstances that occur ordinarily and are likely to occur again. If the rate of change which affects all circumstances accelerates beyond some point, such judgements cease to be valid. Lawful society breaks down. Social control does not accommodate community participation and becomes the function of experts and the elite.\"\n\n\"Judges, governments, and voters abdicate their own evidence about the necessity of resolving conflicts in a situation of defined and permanent scarcity and opt for further growth on the basis of data which they admittedly cannot fully understand\"\n\n### Watershed Moments\nOn the two watershed moments of institutions: \"At first, new knowledge is applied to the solution of a clearly stated problem and scientific measuring sticks are applied to account for the new efficiency. But at the second point, the progress demonstrated in a previous achievement is used as a rationale for the exploitation of society as a whole in the service of a value which is determined and constantly revised by an element of society, by one of its self-certifying professional elites.\"\n\n**Transportation**\n\nIt has taken almost a century to pass from an era served by motorized vehicles to the era in which society has been reduced to virtual enslavement to the car. Cars have ceased to be effective tools for mass transportation.\n\n1. During the American Civil War steam power on wheels became effective. The new economy in transportation enabled many people to travel by rail at the speed of a royal coach, and to do so with a comfort kings had no dared dream of.\n2. When transportation had passed through its second watershed, vehicles had created more distances than they helped to bridge; more time was used by the entire society for the sake of traffic than was \"saved\"\n\n**Medicine**\n\n1. 1913, we reached the point in Western medicine where a patient had a better than 50-50 chance that trained doctors would provide better treatment than anyone else. Medicine and our expanding knowledge grew in leaps and bounds, and improvements resulted in corresponding improvements in health.\n2. The point at which we shifted to keeping people alive longer, without worrying about quality. Treatment has become further and further professionalised, removed from the control of patients and their families and communities. Multiple studies in health argue this exact point — that medical knowledge can solve only a portion of health issues, the others are interconnected with society, environment, employment, housing, inequality, etc.\n\n### Agency and Conviviality\n\"I choose the term 'conviviality' to designate the opposite of industrial productivity ... I consider conviviality to be individual freedom realized in personal interdependence and, as such, an intrinsic ethical value. I believe that, in any society, as conviviality is reduced below a certain level, no amount of industrial productivity can effectively satisfy the needs it creates among society's members\" (Illich seems to be very against of a 'utopia' like the one imagine in B.F. Skinner's *Walden Two*)\n\n\"A convivial society would be the result of social arrangements that guarantee for each member the most ample and free access to the tools of the community and limit this freedom only in favour of another member's equal freedom\"\n\n\"What is fundamental to a convivial society is not the total absence of manipulative institutions and addictive goods and services, but the balance between those tools which create the specific demands they are specialized to satisfy and those complementary, enabling tools which foster self-realization\"\n\nTools foster conviviality to the extent that \n- they can be easily used, by anybody, as often or as seldom as desired\n- they allow the user to express their meaning into action (i.e. for a purpose chosen by the user)\n- the use of such tools by one person does not restrain another from using them equally (non-rivalrous)\n- their existence does not impose any obligation to use them\n\n### Radical monopoly\n\"By 'radical monopoly' I mean the dominance of one type of product rather than the dominance of one brand... Cars can thus monopolize traffic. They can shape a city into their image--practically ruling out locomotion on foot or by bicycle in Los Angeles. That motor traffic curtails the right to walk... constitutes radical monopoly.\"\n\n\"People will face a danger that threatens their own self-interest but not one that threatens society as a whole. Many more people are against cars than are against driving them. They are against cars because they pollute and because they monopolize traffic. They drive cars because they consider the pollution created by one car insignificant, and because they do not feel personally deprived of freedom when they drive. It is also difficult to be protected against monopoly when a society is already littered with roads, schools, or hospitals, when independent action has been paralyzed for so long that the ability for it seems to have atrophied, and when simple alternatives seem beyond the reach of the imagination. Monopoly is hard to get rid of when it has frozen not only the shape of the physical world but also the range of behaviour and of imagination.\"\n\n\"The attempt to make a better environment has turned out to be a presumptuous as the attempt to create better health, education, or communication .As a result there are now more people, most of them less at home in the world. This large population can survive because of new tools. In turn, it spurs the search for even more powerful tools, and thereby demands more radical monopoly; this monopoly, in its turn, calls for more and more education.\"\n\n### Degrowth\nSee also: [[thoughts/degrowth|thoughts on degrowth]]\n\n\"Most of the present laws and present legislators, most of the present courts and their decisions, most of the claimants and their demands are deeply corrupted by an overarching industrial consensus: that more is better, and that corporations serve the public interest better than men\"\n\n\"If within the very near future man cannot set limits to the interference of his tools with the environment and practice effective birth control, the next generations will experience the gruesome apocalypse predicted by many ecologists.\"\n\n\"This expansion is maintained by the illusion that careful systems engineering can stabilize and harmonize present growth, while in fact it pushes all institutions simultaneously toward their second watershed\"","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Transformative-Technology-Trilemma":{"title":"Transformative Technology Trilemma","content":"\n[Source](https://cip.org/whitepaper)\n\nTransformative technologies (TTs) refer to technological advances with a high likelihood of significantly altering society. Specifically, among TTs, there are significant trade-offs between\n\n1. **progress**: advancing technological capabilities\n2. **participation**: enabling public input and self-determination\n3. **safety**: avoiding disproportionate risks\n\nThis reliably leads to a set of three failure modes.\n\n1. Capitalist Acceleration: sacrificing safety for progress while maintaining basic participation.\n\t- Participation comes in the form of consumer choice and investor agency\n\t- The downsides include proliferating risk and lack of public oversight (minimal regulation, auditing, or provision of public goods)\n2. Authoritarian Technocracy: sacrificing participation for safety while maintaining basic progress.\n\t- Built on the belief that ensuring safety requires entrusting only a few entities (individuals, companies, nation-states) with the ability to develop advanced technologies\n\t- The downsides include the risks of illegitimacy, the well-documented failures (see: [[thoughts/Seeing like a State]]) of central planning (e.g. the [economic calculation problem](https://en.wikipedia.org/wiki/Economic_calculation_problem) and the challenges of gathering representative information for centralized decision-making), and the basic injustice of autocracy\n3. Shared Stagnation: sacrificing progress for participation while maintaining basic safety.\n\t- Combines anti-technology inclinations with concerns about worsening global conditions (such as climate change, inequality, bias and discrimination) due to current trajectories of progress (see: [[thoughts/degrowth]])\n\t- The downsides include a lack of investment in necessary economic or technological development, and undervaluing the need for large-scale coordination, e.g. via international bodies or large-scale production.","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Transport-Layer":{"title":"Transport Layer","content":"\nLayer 2, the layer below the [Application Layer](thoughts/Application%20Layer.md) and layer above the [Network Layer](thoughts/Network%20Layer.md)\n\n1. Unit: Segment\n2. Responsibilities: Ensures data arrives in order (if required), Recovers lost data (if required), Identifies process on machine, flow control\n3. Adds an additional addressing space at the port level (historically a 16 bit uint from 0 to 65535)\n4. Can be either be either packet or stream based\n\t1. Packet - best effort, no established connection, no transport level delay/waiting (e.g. video, games, etc.)\n\t2. Stream - pipe model, established connection, flow/congestion control, possible delays (e.g. HTTP, email, etc.)","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Trust-as-Unquestioning-Attitude":{"title":"Trust as Unquestioning Attitude","content":"\nPHIL240A Essay 1\n\nExplain how Nguyen's account of trust as an unquestioning attitude entails that we integrate objects into our own agency.\n\nA good answer to this question will include an explanation of what it means for trust to be an unquestioning attitude, a clarification of why we trust objects given this account, and a statement of what it means to integrate objects into our own agency.\n\n---\n\nNguyen's theory of the form of trust is the unquestioning attitude. Let us break down this meaning-laden phrase.\n\nUnquestioning implies an absence of \"deliberation over [something's] reliability\". To trust unquestioningly is to accept it as a basic axiom of your world and to take it for granted. It is invisible until it is gone or reconsidered.\n\nAttitude implies some semblance of consistent mental state or stability. Trust, then, as an attitude, must exhibit \"cognitive inertia\". To rephrase, this means that trust is more easily maintained than reconsidered.\n\nThis account, unlike the goodwill and responsiveness theories, does not presume intentionality or agent-directedness. In fact, by this account, any object can be trusted and thus be integrated into our own agency.\n\nTo integrate an object into our agency involves not just a reliance but an almost blind trust of that object to be load-bearing in our lives. This is clearly obvious with our readiness to extend smartphones and search engines into our lives which we do not fully understand as parts of our cognition.\n\nWe then turn to Clark and Chalmer's Extended Mind Hypothesis. Specifically, the parity principle: if an external resource plays the same functional role in supporting action as an action-supporting internal resource that is uncontroversially cognitive, then the external resource is part of the cognitive system of the agent.\n\nOne trusts their digital photo albums like they would their own memory -- often treating it like a part of our extended mind. When we lose our saved photos, it almost feels as if we've lost a part of our experience. When this object fails to function in an expected way, we not only feel disappointed but betrayed. To lose trust then, is to shift from the unquestioning state to the endlessly skeptical and suspicious mood.\n\nFootnote: It is interesting to consider differences between what we are trusting when we trust designed objects (e.g. search engines, devices, websites, etc.) versus non-designed objects (the ground, physics, etc.). I'm curious if there are properties of derived trust especially in regards to trusting the object really being a trust in its designer (trusting the engineers at Apple versus the iPhone itself). Does this have relation to non-designed objects like the Earth? Does this lead to the religious attempts to describe everything to ever exist as designed by God?","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Turing-Test":{"title":"Turing Test","content":"\n-   dialogic test of competence\n-   exploring the notion of reference\n-   are the things the machine refers to the same things we refer to?\n\t-   e.g. when talking about steak, are we talking about the same steak?\n\t-   the machine doesn't have any real input into the world, no sense organs\n\t\t-   It is true that the machine can discourse beautifully about, say, the scenery in New England. But it could not recognize an apple tree or an apple, a mountain or a cow, a field or a steeple, if it were in front of one","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Twin-Earth-Argument":{"title":"Twin Earth Argument","content":"\nRelated to [semantics](thoughts/semantics.md) and [terminology](thoughts/terminology.md)\n\n-   my twin is thinking of XYZ and I am thinking of H2O\n-   XYZ ≠ H2O\n-   content determines object (frege: the sense of a term determines its referent)\n-   if t1 and t2 have different objects, then they must also have different content\n-   twin and I have thoughts with different content\n-   thoughts are individuated by their content\n-   twin and I have different thoughts even though we are molecule-for-molecule duplicates\n- \"the fact that an English speaker in 1750 might have called XYZ \"water,\" whereas she or his successors would not have called XYZ water in 1800 or 1850 does not mean that the \"meaning\" of 'water' changed for the average speaker in the interval","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/UCAN":{"title":"UCAN","content":"\nAt a high level, User Controlled Authorization Networks (UCANs) are a way of doing [[thoughts/authorization|authorization]] (\"what you can do\") where users are fully in control. There's no all-powerful authorization server, or server of any kind required. Everything that a users is allowed to do is captured directly in a key or token, and can be sent to anyone that knows how to interpret this format.\n\n\u003e UCANs work more like [movie tickets](http://www.erights.org/elib/capability/duals/myths.html#caps-as-keys) or a festival pass between multiple venues. No one needs to check your ID; who you are is irrelevant. For example, if you have a ticket to see Citizen Kane, you are admitted to Theater 3. If you cannot attend an event, you can hand this ticket to a friend who wants to see the film instead, and there is no coordination required with the theater ahead of time.\n\u003e \n\u003e from the *[UCAN working group spec](https://github.com/ucan-wg/spec/)*\n\n![[thoughts/images/UCAN hierarchy.png]]\n\u003e \n\u003e The master keypair requires strong security and should not be duplicated to multiple locations or enter low-security environments such as the browser. This makes it difficult to access every time a new repository commit needs to be produced. Therefore we issue child keypairs from the master keypair in the form of [UCANs](https://fission.codes/blog/auth-without-backend/), a JWT-style token that contains a permission description. UCANs can prove the authority of some key to undertake a given action, _or_ produce new UCANs with a subset of their authority. Through this mechanism, a user is actually associated with _many_ (likely hundreds) of keys, each belonging to a given context (a device or an application). These keys are granted only the authority they require from the root signing key.\n\u003e \n\u003e from [[thoughts/Bluesky|Bluesky's ADX]]\n\nSee [source 1](https://fission.codes/blog/auth-without-backend/) and [source 2](https://fission.codes/blog/verifying-ucans/)\n","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/UDP":{"title":"UDP","content":"\n## User Datagram [Protocol](thoughts/Protocol.md) (UDP)\n1. Source Port\n2. Destination Port\n3. Length\n4. Checksum\n5. Payload\n\n68 is usually client, 67 is usually server\n\nFor reliable networks (like local) where out-of-order protections of [TCP](thoughts/TCP.md) are unnecessary, or for time sensitive applications (e.g. streams or calls) where lossy transmission at high speed is better than quality transmission at choppy speed.\n\nSegment Format\n- Source Port (16 bits)\n- Destination Port (16 bits)\n- Length in bytes, including header (16 bits)\n- Checksum (16 bits)\n- Application Data","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Unrepeatable-Miracle-of-Silicon-Valley":{"title":"Silicon Valley: An unrepeatable miracle?","content":"\n[Source: Silicon Valley: An unrepeatable miracle? with *Margaret O’Mara*](https://www.aei.org/economics/silicon-valley-an-unrepeatable-miracle-a-long-read-qa-with-margaret-omara/)\n\nPodcast Interview with Margaret O’Mara, the author of _[The Code: Silicon Valley and the Remaking of America](https://www.amazon.com/Code-Silicon-Valley-Remaking-America/dp/0399562184)_\n\nTouches on a lot of similar topics to [*From Counterculture to Cyberculture*](thoughts/From%20Counterculture%20to%20Cyberculture.md)\n\nWhat caused the big influx of extraordinary opportunity in Northern California, despite mostly being another sleepy fruit-growing region? Mostly the result of the Cold War and the military-industrial complex and the power of Stanford -- these two were not completely separate.\n\nA lot of military funding went to the west (and to California and thus Stanford). Big result of Fred Terman (Dean of Engineering at the time): \"let’s remake Stanford so that it’s a perfect receptacle for this new money. We are a true Cold War university.\"\n\nThe military-industrial complex rose as a result of the Cold War, showing how a capitalist democracy can be 'triumphant' over more socialist policies. As a result, a lot of government money went to private defense contractors (think Lockheed). When the Space Race came along, a lot of that money went to places specializing in small, light, powerful devices (microchips, integrated circuirts), and this happened to be Silicon Valley.\n\nGovernment wasn't the sole reason this explosion happened, rather more of \"a customer, as a catalyst, as a kind of de facto venture capitalist at an early stage, when there was no commercial market for this stuff.\"\n\n\u003e To have such mobilization around this massive effort, you do probably need some sort of geopolitical catalyst. It’s hard for it to be purely commercial...  **That’s the thing that can catalyze people, government, and resources into doing these big things.**\n\nProblem is that this 'urgency' needs to be bipartisan -- this was very difficult when the Soviet Union was widely feared. As a result, anything even mildly centrist is perceived as socialist -\u003e https://www.youtube.com/watch?v=ULYWIDcUOY4\n\nAbstraction of the problem\n\nAntipathy that the Valley has had towards the government is kind of like, \"Well it doesn’t have anything to do with us, if they could stay as far away as possible it would be good.\" -- tech is political\n\n## Democratic Capitalism\nDemocratic capitalism and the ability for people to protest what their government is doing.\n\nHistorically, white-collar tech workers in industry have been very OK with whatever their companies are doing as long is it gives them a comfy lifestyle -- yet now people are starting to question it.\n\nSo much of the technical expertise that used to be distributed across industry and government is now just in industry. This inbalance means that government agencies like the Pentagon and CIA need to go to these big tech companies to build good tech.\n\n## Blue-sky Operations\n\"Spending money on moonshots, whether metaphorical or real, is kind of something only the government can do.\"\n\nExamples like DARPA, investing in technology that is at least a few decades away from being commercializable or being something the military could possibly use.\n\nPersonal Computing? Moving away from establishments having all the computing power and giving power back to the individual user. \"We’re going to create these devices, take them, and build computers of our own that are apart from this corporate military-industrial business.\"\n\nTo tell a company that is accountable to shareholders and quarterly earnings calls, “Okay, the moonshot’s on you guys,” is not so great.\n\n### Sandbox Model\n\"Throw a lot of money in its direction and get out of the way\" Create the sandbox, an incredible container with lots of resources in it, and allow creative people to play around in the sand and see what they develop. Naturally very incompatible with political traditions in other places.\n\n### Moonshot People and Immigration\nPeople like Andy Grove who later becomes the CEO of Intel, come into the country as teenage refugees from places like Hungary where the immigration officers probably thought he would be a 'drain on the system'.\n\nBut then you have winners of one generation picking the winners of the next, creating a very self-reinforcing [feedback loop](thoughts/feedback%20loops.md). This as a result causes huge [diversity problems](thoughts/Design%20Justice.md) where it works really well for elite college students in the US but less so for the housewives in Myanmar.\n\n","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Urbit":{"title":"Urbit","content":"\n## Terminology\n- Arvo: OS\n- Hoon: language\n- Tlon: company\n- Azimuth: ID\n- Ames: Network\n\n\u003e imo, falls into the category of vaporwave tech that never manifested itself into anything useful\n\n## OS\nIn 1974 a computer was a mainframe the size of a room and was shared by hundreds of people. By 1984 a computer was the size of a desk and everyone had their own PC. The PC was more flexible and more fun, so it won by a wide margin. Then, with the rise of the internet, the PC’s flexibility slowly became irrelevant -- we’re more or less back to the timesharing model of the 1970s.\n\nUrbit OS is the PC to MEGACORP’s mainframe.\n\n![](https://media.urbit.org/site/understanding-urbit/technical-overview/technical-overview-kernel@2x.png)\n\n## ID\nUrbit ID is a decentralized addressing and public key infrastructure designed for Urbit OS.\n\nThe Urbit ID registry is live and deployed to the Ethereum blockchain. Urbit ID isn’t specifically wedded to Ethereum – someday we’d like it to be hosted by Urbit OS itself.\n\nRelated: [internet computing](thoughts/internet%20computing.md)\n\n- 256 (2^8) Galaxies\n\t- Web analogue: DNS Root Servers\n\t- The senate that can upgrade the logic of the Urbit ID system by majority vote\n- 65,280 (2^16) Stars\n\t- Web analogue: ISP, for routing packets\n- 4,294,901,760 (2^32) Planets\n\t- Individual ID\n- 2^64 Moons\n\nIn a way, upgraded version of ENS?\n\nUses [Kelvin Versioning](https://jtobin.io/kelvin-versioning) which is an interesting exercise in [digital permanence](thoughts/digital%20permanence.md)\n\nLibraries\n- Profile picture generation from Urbit: https://github.com/urbit/sigil-js\n- Phonetically pronounceable data: https://github.com/urbit/urbit-ob","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Utilitarianism":{"title":"Utilitarianism","content":"\n## Act Utilitarianism\nAlso called the Greatest Happiness Principle.\n\nAn action is good if its benefits exceed its harms, and an action is bad if its harms exceed its benefits. This is based on calculations of [[thoughts/utility|utility]].\n\n\u003e An important decision an act utilitarian must make is determining which beings are considered to be morally significant.\n\nIt is a consequentialist theory because it focuses on the consequences of an action rather than the intention.\n\nCalculating the utility to make a decision falls under [[thoughts/Decisions under risk|DUR]] (specifically, EU Max)\n\n## Rule Utilitarianism\nWe ought to adopt those moral rules that, if followed by everyone, lead to the greatest increase in total happiness over all affected parties\n\nDifference between rule utilitarianism and [[thoughts/Kant|Kantianism]]:\n- A rule utilitarian looks at the consequences of the action\n- A Kantian looks at the will motivating the action\n\n## Critique\n1. Utilitarianism forces us to use a single scale or measure to evaluate completely different kinds of consequences.\n\t- See also: [[thoughts/quantization|quantization]]\n2. Utilitarianism ignores the problem of an unjust distribution of good consequences.\n\t- One person receiving 100 units of good while 99 people receive nothing is treated the same as 100 people receiving 1 unit of good.\n\t- This doesn't sit right with most people.\n\t- See also, [[thoughts/The ones who walk away from Omelas|The ones who walk away from Omelas]]","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/VPN":{"title":"VPN","content":"\nVirtual Private Networks\n\nMotivation:\n1. Company with multiple locations wants everything to appear as one big network\n2. Workers want access to resources restricted to company internal network\n3. Users want to bypass regional blocks\n\n![](thoughts/images/VPN.jpeg)\n\nVPN Encapsulation\n- Virtual end points establish software association between them (e.g. [TCP](thoughts/TCP.md) connection) usually referred to as a tunnel\n- Routing rules on local machine send traffic to virtual interface\n- Virtual card encapsulates IP message and sends it through tunnel\n- Receiver receives message and sends it through its own network","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Valve-Handbook":{"title":"Valve Handbook","content":"\n[Source](https://steamcdn-a.akamaihd.net/apps/valve/Valve_NewEmployeeHandbook.pdf)\n\nValve is a company is one that I respect a lot for the agency they give their employees. Feels very much like a [[thoughts/metalabel|metalabel]] where you have a bunch of highly agentic people working on things they wanna work on rather than a company.\n\nTLDR; hire well\n\n\u003e This book is an abbreviated encapsulation of our guiding principles. As Valve continues to grow, we hope that these principles will serve each new person joining our ranks.\n\nSome highlights from their handbook:\n\n## Facts that matter\n1. Valve is self-funded: gives agency to the org to work on work they care about and that customers care about\n2. Valve owns all of their IP: agency to make their own decisions about what they do with their products\n\n## Hierarchy\nFlatness necessarily implies high responsibility for the individual\n\nAdding individuals then (hiring), is one of the most important things people have control over at the company:\n\n\u003e \"If you’re thinking to yourself, “Wow, that sounds like a lot of responsibility,” you’re right. And that’s why hiring is the single most important thing you will ever do at Valve\"\n\nFlatness also means more mobility. *Why does your desk have wheels? Think of those wheels as a symbolic reminder that you should always be considering where you could move yourself to be more valuable.*\n\nPeople move frequently; there is no organizational structure keeping you from being in close proximity to the people who you'd help or be helped by most\n\n## Projects\nFlatness implies anyone has the power to green-light projects. So how does Valve choose what projects to prioritize?\n\n1. Employees vote on projects with their feet (or desk wheels)\n2. Strong projects are ones in which people can see demonstrated value; they staff up easily.\n\nHow should I as an individual choose what to work on? A few good guiding questions:\n1. Of all the projects currently under way, what’s the most valuable thing I can be working on?\n2. Which project will have the highest direct impact on our customers? How much will the work I ship benefit them?\n3. Is Valve not doing something that it should be doing?\n4. What’s interesting? What’s rewarding? What leverages my individual strengths the most?\n\nHow do people discover new projects? There is no central 'board', but the best way to find out about projects is to just ask people. \n\n\u003e Lots of people at Valve want and need to know what you care about, what you’re good at, what you’re worried about, what you’ve got experience with, and so on. And the way to get the word out is to start telling people all of those things.\n\nPeople first [[thoughts/friction|friction-ful]] onboarding!\n\n\n### Structure\n1. Team leads\n\t1. This person’s role is not a traditional managerial one. Most often, they’re primarily a clearinghouse of information.\n\t2. They’re keeping the whole project in their head at once so that people can use them as a resource to check decisions against. The leads serve the team, while acting as centers for the teams.\n2. There is still structure\n\t1. Project teams often have an internal structure that forms temporarily to suit the group’s needs.\n\t2. This is dynamic on scales of months to years, but gives some semblance of expectation and stability on the day-to-day.\n3. Hours\n\t1. For the most part working overtime for extended periods indicates a fundamental failure in planning or communication. If this happens at Valve, it’s a sign that something needs to be reevaluated and corrected (of course, there are exceptions like when a project nears ship date)\n\n## Long-term thinking\n\u003e If we’re not careful, these traits can cause us to race back and forth between short-term opportunities and threats, being responsive rather than proactive. So our lack of a traditional structure comes with an important responsibility. It’s up to all of us to spend effort focusing on what we think the long-term goals of the com- pany should be.\n\n1. Someone told me to (or not to) work on X. And they’ve been here a long time!\n\t1. They aren't always right! *Hold on to your goals if you’re convinced they’re correct. Check your assumptions. Pull more people in. Listen. Don’t believe that anyone holds authority over the decision you’re trying to make.*\n2. I constantly feel behind with everything going on! How do I make my work feel sustainable?\n\t1. Trust us, this is normal. Nobody expects you to devote time to every opportunity that comes your way. Instead, we want you to learn how to choose the most important work to do.\n3. How does Valve as an organization decide what to work on?\n\t1. We believe in each other to make these decisions, and this faith has proven to be well-founded over and over again.\n\t2. We have learned that when we take nearly any action, it’s best to do so in a way that we can measure, predict outcomes, and analyze results.\n4. Can I be involved with X?\n\t1. Yes. You either\n\t\t1. Start working on it\n\t\t2. Start talking to all the people who you think might be working on it already and find out how to best be valuable\n\n## Risk\nProviding the freedom to fail is an important trait of the company— we couldn’t expect so much of individuals if we also penal- ized people for errors.\n\nThere are still some bad ways to fail.\n- Repeating the same mistake over and over is one.\n- Not listening to customers or peers before or after a failure is another.\n- Never ignore the evidence; particularly when it says you’re wrong.\n\n### Collective Risk\nWhen everyone is sharing the steering wheel, it seems natural to fear that one of us is going to veer Valve’s car off the road.\n\n\u003e Concepts discussed in this book sound like they might work well at a tiny start-up, but not at a hundreds-of-people-plus- billions-in-revenue company. The big question is: Does all this stuff scale?\n\nWell, so far, yes. And we believe that if we’re careful, it will work better and better the larger we get. This might seem counterintuitive, but it’s a direct consequence of hiring great, accomplished, capable people.\n\n## Hiring\nIn the mean- time, here are some questions we always ask ourselves when evaluating candidates:\n\n- Would I want this person to be my boss?  \n- Would I learn a significant amount from them?\n- What if this person went to work for our competition?\n\nWe want people who are integral to *high-bandwidth collaboration*. People who can\n- deconstruct problems on the fly\n- talk to others as they do so\n- simultaneously being inventive, iterative, creative, talkative, and reactive\n\n### T-Shaped People\nWe care about T-shaped people: people who are both generalists (highly skilled at  \na broad set of valuable things—the top of the T) and also experts (among the best in their field within a narrow discipline—the vertical leg of the T).\n\nAn expert who is too narrow has difficulty collaborating. A generalist who doesn’t go deep enough in a single area ends up on the margins, not really contributing as an individual.\n\n## Things to improve\nThings Valve wishes they were better at\n\n1. Helping new people find their way\n2. Mentoring people\n3. Disseminating information internally\n4. Finding and hiring people in completely new disciplines\n5. Making predictions longer than a few months out\n6. We miss out on hiring talented people who prefer to work within a more traditional structure (isn’t something we should change, but it’s worth recognizing as a self-imposed limitation)","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Vanilla-Ice-Cream-effect":{"title":"Vanilla Ice Cream effect","content":"\nAsk everyone to vote on their favourite ice cream, you'll most likely end up with vanilla.\n\nSimilar to design by committee → a project that has many designers involved but no unifying plan or vision\n\n## Coordination Headwind\n[Source: How Organizations are like Slime Molds by *Alex Komoroske*](https://komoroske.com/slime-mold/)\n\nIn small orgs, individuals matter a lot, but when the org gets larger the system (structure + dynamics) dominate. [Consensus](thoughts/consensus.md) is especially difficult in larger groups.\n\nBottom-up orgs (slime mold model)\n- unpredictable\n- uncontrollable (can influence via incentives)\n- individual autonomy\n- fluid\n- messy\n- resilient\n- exploratory\n\nTop-down orgs (military model)\n- predictable\n- controllable\n- cog in the machine\n- structured\n- efficient\n- fragile\n- exploitative\n\n## On avoiding Vanilla Ice Cream\nRelated to how to better [fund](thoughts/funding.md) moonshot things\n\nSetting an appropriate council size so that if one person proposes an idea and the others don't agree, they can still drive that decision. obviously based on high trust and should not dictate entire budget → have a [consensus](thoughts/consensus.md) (more publicly governed) budget and an aconsensus budget (core council budget)","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Verifiable-Credential":{"title":"Verifiable Credential","content":"\nVerifiable credentials can be issued by anyone, about anything, and can be presented to and verified by everyone\n\n- Issuer: the entity that generates the credential\n- Holder: entity that receives the credential\n- Verifier: entity that wants to check the credentials of the Holder\n\nFor this to work requires a triangle of trust:\n- The issuer trusts the holder\n- The holder trusts the verifier\n- The verifier trusts the issuer\n\nVerifiable Data Registry (VDR): can be used to maintain identifiers and schemas\n\nTo make a VC:\n1. Issuer registers a DID and its associated verification key (verkey) to the VDR\n2. Issuer writes a credential definition (a template) to the VDR\n3. (Optional) Issuer offers a credential to the holder\n4. Holder requests a credential from the Issuer\n5. Issuer creates a credential based on the definition for the holder\n6. Issuer signs the credential with their private part of the verification key, and gives it to the holder (offer)\n7. Verifier can then check the credential against the issuer's verkey\n\n![[thoughts/images/verifiable credential.png]]\n\nExample VC\n\n```json\n{\n    \"@context\": [\n        \"https://www.w3.org/2018/credentials/v1\",\n        \"https://www.w3.org/2018/credentials/examples/v1\"\n    ],\n    \"id\": \"0892f680-6aeb-11eb-9bcf-f10d8993fde7\",\n    \"type\": [\n        \"VerifiableCredential\",\n        \"UniversityDegreeCredential\"\n    ],\n    \"issuer\": {\n         \"id\": \"did:example:76e12ec712ebc6f1c221ebfeb1f\",\n         \"name\": \"Acme University\"\n    },\n    \"issuanceDate\": \"2021-05-11T23:09:06.803Z\",\n    \"credentialSubject\": {\n        \"id\": \"did:example:ebfeb1f712ebc6f1c276e12ec21\",\n        \"degree\": {\n            \"type\": \"BachelorDegree\",\n            \"name\": \"Bachelor of Science\"\n        }\n    },\n    \"proof\": {\n        \"type\": \"Ed25519Signature2018\",\n        \"created\": \"2021-05-17T15:25:26Z\",\n        \"jws\": \"eyJhbGciOiJFZERTQYjY0Il19..nlcAA\",\n        \"proofPurpose\": \"assertionMethod\",\n        \"verificationMethod\": \"https://pathToIssuerPublicKey\"\n    }\n}\n```","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Weaving-the-Web":{"title":"Weaving the Web","content":"\n\u003e The original design and ultimate destiny of the world wide web.\n\nBook, written by Tim Berners-Lee\n\n## A Brief History of the Web\n[[thoughts/hypertext|Hypertext]] was invented by Ted Nelson in 1965. The [[thoughts/Internet|Internet]], as worked on by Donald Davis, Paul Barran, Vint Cerf, and Bob Kahn, were already becoming pervasive by the 1970s. Tim Berners-Lee came at the right time to marry them together into the Web.\n\nThe Web was a slow process -- there was no \"Eureka!\" moment. He described the process like getting a bobsled down the hill -- something you needed to put a lot of upfront effort into getting moving, but once you did, you needed to get in and steer.\n\nHe first wrote a proposal for the Web at CERN in March of 1989 and began work on it with Robert Cailliau. On Christmas Day 1990, the first *WorldWideWeb* browser/editor was working, communicating with the info.cern.ch server, a full 20 years after the existence of both hypertext and the Internet. Not only was it able to view web pages, it could edit them collaboratively with others.\n\nEven still, people at CERN \"didn't seem to see how it would be useful.\" This created a lot of tension between Robert and Tim about how to deploy their resources effectively.\n\n\u003e Should we develop it further on the NeXT? Should we reprogram it for the Mac or the PC or Unix, because even though the NeXT was an efficient machine, few other people had them? After all, what good was a \"worldwide\" web if there were only a few users? Should we tailor the Web to the high-energy physics community, so they'd have a tool that was theirs and would support it, since CERN was paying our salaries? Or should we generalize the Web and really address the global community, at the risk of being personally disenfranchised by CERN? ... My gut told me I had to pursue my larger vision of creating a global system.\n\nAt the same time, several other Internet-based information systems were surfacing too, namely WAIS and Gopher. Both systems took off much more quickly and he was concerned that they would suffocate the Web. Nonetheless, they put their heads down and kept working at it.\n\nAs browsers started to spread, no one working on them really focused on writing or editing functions for the web. Browsers were just that -- things to browse the web. This was one of the first major divergences between the vision that Tim had for the web and what actually happened. He wanted the web to be collaborative, citing that \"without a hypertext editor, people would not have the tools to really use [it] as an intimate collaborative medium. Browsers would let them find and share information, but they could not work together intuitively.\" This was a concern that would come back to continuously haunt him.\n\nBut by the summer of 1992, the bobsled had started to move. The logs showed a dramatic exponential curve over the past twelve months, doubling every three to four. After a single year, the load had grown by a factor of ten.\n\nNow, companies and individuals were starting to eye the Web as a way to make profit. With the rise of Mosaic (which would later become Netscape), they tried to make the web 'theirs'. It wasn't \"on the Web\", it was \"on Mosaic.\" The media started to portray Mosaic as if it were equivalent to the Web.\n\nAs technologists and entrepreneurs were launching or merging companies to exploit the Web, they seemed fixated on one question: \"How can I make the Web mine?\" Tim was asking, \"How can I make the Web yours?\" Gopher, one of two most popular Internet information systems at the time, decided to charge an annual fee for access and just as quickly as people flocked to it, they dropped it like a hot potato. Many asked if the Web would suffer the same fate. His response? On April 30th, 1993, Tim and Robert signed a declaration saying that the Web protocol and code was free to use and anyone could create a server or a browser to give away or sell without royalty or other constraint.\n\nMore than ever, this experience convinced Tim that it was time to stop pushing the bobsled and instead to jump in and steer it. With yet another factor of 10 growth since the previous year, he decided to start the World Wide Web Consortium, the W3C. It wasn't a standards body, but rather an international organization to help developers of servers and browsers alike reach consensus on how the Web should operate. With everyone trying to pick up the Web and run with it in different directions, Tim thought the W3C would help unify their pursuits in creating a single, universal, accessible, hypertext medium for sharing information. It would develop open technical specifications and have a small full-time staff[^1] to design and develop the code wherever necessary. With members open to any organization, regardless of commercial, educational or governmental, for-profit or non-profit, W3C would represent the power and authority of millions of developers, researchers, and users.\n\n[^1]: This full time staff team was paid through the membership fee for the W3C, which was $50k for full-membership and 1/10 the price for non-profit or governmental entities. Members had to commit to a three-year term of membership, after which they could renew annually. Members were free to attend any meeting, and sit on any working group. They would also get exclusive access to in-depth information on all activities under way, much like how the Xerox Parc membership worked.\n\nOf course, the W3C was not meant to be a point of control. Tim made it clear that he had designed the Web so there should be no centralized place where someone would have to \"register\" a new server, or get approval of its contents. Anyone could build a server and put anything on it. Philosophically, if the Web was the be a universal resource, it had to be able to grow in an unlimited way.\n\nThe international telephone system offers a great analogy. It defines what it has to (i.e. the voltages and signals), but then leaves how it is used up to the devices. That's what we needed for computers on the web. Universality.\n\nQuietly, under the noise of all the companies trying to make a fortune off the web, the W3C has been steering the web and leading the web to its full potential. Today, Tim currently sits as Director of the W3C. He was knighted by Queen Elizabeth in 2007. Now, Sir Tim promotes open government data globally and spends time fighting for rights such as net neutrality, privacy and the openness of the Web.\n\nBut there is still work left to be done. A slow [[thoughts/inevitability of centralization|recentralization of the Web]] is happening, and users lack agency over their own privacy. Of course, there have been many proposals to address this, including Tim's own [[thoughts/Solid|Solid project]] as well as my research on [[thoughts/Rhizome Proposal|Rhizhome]]. We are still early.\n\n\u003e When I try to explain the architecture now, I get the same distant look in people's eyes as I did in 1989, when I tried to explain how global hypertext would work. But I've found a few individuals who share the vision; I can see it from the way they gesticulate and talk rapidly.\n\n## Quotes\n### Relational Theories of the World\nEnquire was a very early [[thoughts/RDF#RDF Triple|triple-store]] like [[posts/networked-thought|networked thought]] note-taking tool developed by Tim Berners-Lee. He made it to stored information without using structures like matrices or trees. After all, the human mind uses the organizing structures all the time, but can also break out of them and make intuitive leaps across the boundaries -- those coveted random associations.\n\nIn an extreme view, the world can be seen as only connections, nothing else. We think of a dictionary as the repository of meaning, but it defines words only in terms of other words.\n\n### Separation of layers of the Web\nThe web's infrastructure can be thought of as composed of four horizontal layers; from bottom to top they are the\n1. transmission medium: connecting computers together\n2. computer hardware\n3. software: runs web access\n4. content: the Web itself\n\nThe independence of these layers is important. From the software engineering point of view, this is the basic principle of modularity. From the point of view of economics, it is the separation of horizontal competitive markets from anticompetitive vertical integration. From the information point of view, think of editorial independence, the neutrality of the medium.\n\nI am more concern about companies trying to take a vertical slice through the layers than creating a monopoly in any one layer. Keeping the medium and the content separate is a good rule in most media. When I turn on the television, I don't expect it to deliberately jump to a particular channel, I expect my television to be an impartial box.\n\nI also expect the same neutrality of software. When I ask a search engine to find the information it can on a topic, I don't expect it to return just the sites of companies that happen to advertise with or make payments to the search company.\n\nIf a company claims to give access to the world of information, then presents a filtered view, the Web loses its credibility. That is why hardware, software, and transmission companies must remain unbiased toward content. I would like to keep the conduit separate from the content. I would like there always to be a choice of the unbiased way, combined carefully with the freedom to make commercial partnerships. And when other people are making a choice for me, I would like this to be made absolutely clear to me.\n\nSee also: [[thoughts/inevitability of centralization|inevitability of centralization]]\n\n### Privacy\nPeople should be able to surf the Web anonymously, or as a well-defined entity, and should be able to control the difference between the two. I would like to be able to decide who I will allow to use my personal information and for what.\n\nThe W3C is creating a technology that will allow automatic negotiation between a user's browser and store's server, leading to an agreement about privacy. The Platform for Privacy Preferences Project (P3P) will give a computer a way of describing its owner's privacy preferences and demands and give servers a way of describing their privacy policies.\n\n### Annotations\nI would like annotation servers to exist where groups could add links to documents they want to comment on. Annotation servers are third-party services allowing a group to share each others' comments on documents anywhere else on the Web. The browser gets the original page and then separately checks annotation servers for comments which are then superimposed on the page.\n\nImagine having servers for comments in different forums, perhaps family, school, and company. Again, the theme is human beings doing the thinking and machines helping it work on a larger scale, but nothing replacing wisdom in the end.\n\n### Technology and Policy\n[The W3C] defines mechanism, not policy. That said, it is essential that policy and technology be designed with a good understanding of each other. As I noted in closing the first International World Wide Web Conference at CERN in May 1994, technologists cannot simply leave the social and ethical questions to other people, because technology directly affects these matters. (see: [[thoughts/software and politics|software and politics]])\n\n### The Web's Achilles' Heel: DNS\nAt the top of the [[thoughts/DNS|DNS]] hierarchy sits 13 root servers. An operator error at this level can black out huge portions of the web. However, that technical weakness is itself less of a concern than the social centralization that parallels it.\n\nAll domain names are given out in a delegated fashion. To set up the name www.lcs.mit.edu, one registers it with the Lab for Computer Science, which is owner of the lcs.mit.edu domain, LCS got its domain in turn from MIT, which is the registered owner of mit.edu. MIT got its domain from the owner of edu. Control over these 'top-level' domains gives control over all domain names and so is something of great power. Who should exercise that power?\n\n### Semantic Web and Data Lensing\nTo build understanding, we need to be able to link terms. This will be made possible by *inference languages*, which work one level above the schema languages. Inference languages allow computers to explain to each other that two terms that may seem different are in some way the same -- a little like an English-French dictionary. Inference languages will allow computers to convert data from one format to another.\n\n### Social\nA person who's completely turned inward, who spends all his or her time alone, is someone who has trouble making balanced decisions and is unhappy. Someone who is completely turned outward, who's worried about the environment and international diplomacy and spends no time sitting at home or in their local community, also has trouble making balanced decisions and is also unhappy. It seems a person's happiness depends on having a balance of connections at different levels. We seem to have built into us what it takes in a person to be part of a fractal society.\n\n### Teaching\nHaving to work with someone else's definitions is difficult. An awe-inspiring talent of my physics tutor, Professor John Moffat, was that when I brought him a problem I had worked out incorrectly, using a strange technique and symbols different from the well-established ones, he not only would follow my weird reasoning to find out where it went wrong, but would then use my own strange notation to explain the right answer.\n\nThis great feat involved looking at the world using my definitions, comparing them with his, and translating his knowledge and experience into my language. It was a mathematical version of the art of listening.","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/WebID":{"title":"WebID","content":"\n[Content summarized from W3](https://www.w3.org/wiki/WebID)\n\nSimilar to [[thoughts/DID|DIDs]].\n\n\u003e A WebID is a way to uniquely identify a person, company, organisation, or other agent using a URI.\n\nPeople often publish data about themselves on the Web, such as:\n\n-   Who they know\n-   What they are interested in\n-   Photos they have taken\n-   Projects they work on\n-   Their curriculum vitae or employment history\n-   Their publications\n\nMost importantly of all, having a Web ID allows people to reference you and declare social relations on the web (such as that you are their friend, colleague, parent, etc.) even when their profile is hosted on a *different web server* than yours (emphasis added).\n\nCommonly uses [[thoughts/FOAF|FOAFs]] for profiles.\n\n## Proof of Ownership\nWebID protocol is just a technology that leverages X.509 Certificates, already in common (and largely invisible) use. By placing that same URL in the certificate that identifies the user, and then placing information at that URL about the public key of the certificate, a web server that receives a user request can verify that the user has write access to that URL\n\nSeems to be read-only (i.e. only user can write, can't tell apps to write to your own WebID)?\n","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/World-Building":{"title":"World Building","content":"\n## Emissaries Guide To Worlding\n[James Stuber's Blog](https://jamesstuber.com/emissaries/)\n\nWell-built worlds enable *new stories*. [Games](thoughts/games.md) and [fiction](thoughts/fiction.md) are forms of worldbuilding (or 'worlding' as Cheng says), but not the only ones\n\nInstitutions, religions, and life itself are Worlds unto their own–real Worlds where we can choose to play or shape the rules ourselves.\n\n\u003e “A World is a reality you can believe in: one that promises to bring about habitable structure from the potential of chaos, and aim toward a future transformative enough to metabolize the pain and pleasure of its dysfunction.”\n\nRelationships, [friendships, and love](thoughts/friendship.md) are all forms of Worlding\n\nFour different kinds of people (masks) required to World\n1. The Director: shapes the World's container and narrative, giving birth to an idea\n\t- The container must be bound enough to enable creation but surprising enough to encourage narrative\n\t- To be the Director requires good taste: knowing what you like and what you dislike gives rise to an opinionated view on what your World should look like\n2. The Cartoonist: reduces the complexity of the world by creating understandable characters and structures\n\t- Characters help make the Director’s ideas comprehensible.\n\t- \"A character is good when a child can pick out its features and draw their version of it.\"\n3. The [Hacker](thoughts/Hackers.md): pushes the boundaries of the World, using exploration and 'meaningless' [play](thoughts/play.md)\n\t- The Hacker’s job is to experiment, to play, and to create “New” art. Why? Because they can.\n4. The Emissary: serves the World by ensuring its continuation\n\t- “A world wants to emerge as an infinite game: one that keeps on going, invites new agents to keep it in play, is fertile with surprises, and continues to generate unexpected meanings”\n\nCrucially, each of these masks are worn by a single person: the Artist\n\n\u003e “It requires the Artist to abandon any sense of a coherent self and take on a different kind of psychology. One that moves between the artistic masks that already exist unevenly inside us, letting each contribute to the creation of a World.”\n\n\n\n## World Seed\n-  the world seed\n\t-  \"It is made so that the created new worlds do not require one large server, but can run on multiple smaller servers.\"\n\t-  \"All [games](thoughts/games.md) using The Seed as their game engine allow conversion of one account in a Seed-based world to another.\n-  infrastructure that operates at different [pace layers](thoughts/pace%20layers.md)","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/XGBoost":{"title":"XGBoost","content":"\nUses [[thoughts/regularization|regularized]] regression trees. These are like [[thoughts/decision tree|decision trees]] where each split is\n- based on a single feature\n- each leaf gives a real-valued prediction\n\n## Fitting a regression tree\n- Train: set each weight $w_L$ at leaf $L$ by minimizing squared error $\\sum_{i=1}^n (w_{L_i}-y_i)^2$\n\t- We use using greedy recursive splitting for growing the tree\n- Prediction: At each leaf, the prediction $\\hat y_i$ is the mean of all $y_i$ that fall under that leaf node\n\n## Ensemble and Boosting\nWe create a series of trees that are trained on the residual of the previous tree. That is, the first tree is trained on the actual dataset. The second tree is trained on the residuals of the prediction of the first tree, and so on.\n\n- `tree[0] = fit(X,y)`\n- `y_hat = tree[0].predict(X)`\n- `tree[1] = fit(X,y - y_hat)`\n- `y_hat = y_hat + tree[1].predict(X)\n- `tree[2] = fit(X,y - yhat)`\n- `y_hat = y_hat + tree[2].predict(X)\n- ...\n\n## Regularization\nAs long as not all $w_L = 0$, each tree decreases training error. However, it may overfit if trees are too deep or you have too many trees\n\nWe can apply L0-regularization (stop splitting if $w_L = 0$) and L2-regularization to discourage this.","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Yjs":{"title":"Yjs","content":"\n\u003e Yjs is a linked-list-based, network-agnostic [[thoughts/CRDT|CRDT]] implementation in Javascript.\n\nFrom [GitHub Documentation](https://github.com/yjs/yjs/blob/main/INTERNALS.md)\n\nYjs supports many different transport layers:\n1. WebRTC\n2. Websockets\n3. Libp2p + GossipSub\n4. [[thoughts/Hypercore|Dat]]\n5. [[thoughts/Matrix|Matrix]]\n\nAt its heart, Yjs is a list-based CRDT:\n- Arrays are easy - they're lists of arbitrary items\n- Text is a list of characters, optionally punctuated by formatting markers and embeds for rich text support\n- Maps are lists of entries. The last inserted entry for each key is used, and all other duplicates for each key are flagged as deleted\n\n## Syncing\nThe client can ask a remote client for missing document updates by sending their state vector (often referred to as _sync step 1_). The remote peer can compute the missing `Item` objects using the `clocks` of the respective clients and compute a minimal update message that reflects all missing updates (sync step 2).\n\n## YATA\nThe underlying conceptual framework that Yjs builds on top of.\n\n[Original paper](https://www.researchgate.net/publication/310212186_Near_Real-Time_Peer-to-Peer_Shared_Editing_on_Extensible_Data_Types)\n\n\u003e YATA, an approach for peer-to-peer shared editing applications that ensures convergence, preserves user intentions, allows offline editing and can be utilized for arbitrary data types in the Web browser\n\nOne frustration is that applications based on complex models must therefore map the underlying data to the data structure that is supported by the used collaboration framework. \n\nYATA works by defining all data structures in terms of a doubly-linked list. Insertions take the form of `insert(id, origin, left, right, isDeleted, content)`. `origin` is set at time of insertion and can't be changed, but `left` and `right` are references that  can change.\n\nThey use $\u003c_c$ to define a total ordering which depends only on the origin, where\n\n$$o_1 \u003c o_2 \\iff o_1 \\textrm{ is a predecessor of } o_2$$\nThis is quite similar to [[thoughts/CRDT Implementations#Replicated Growable Array RGA|RGA]]","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/Zookos-Triangle":{"title":"Zooko's Triangle","content":"\nPostulates that names of participants can have at most 2 of these 3 properties\n- Human-meaningful: Meaningful and memorable (low-entropy) names are provided to the users.\n- Unique: statistically impossible collisions\n- Global: names are globally scoped, correspondence between name and the entity behind the name does not depend on context\n\nSee also: [[thoughts/petname|petname system]]","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/academia":{"title":"Academia","content":"\n## The 'rat race' of Computer Science Academia\n\n\u003e There is no mechanism today, other than time, donations, and personal social platforms,  for researchers to support other researchers' work. Every act of support is out of selflessness and there is a lack of incentive for cross collaboration other than having your name on another paper. The reward system in this community is highly dependent on your ability to make your research well known and marketed. [Shrey Jain](https://twitter.com/shreydjain13)\n\n[Source: Just ask for Generalization](https://evjang.com/2021/10/23/generalization.html)\n\nMy guess is that the research community tends to reward narratives that increase intellectual complexity and argue that \"we need better algorithms\". People pay lip service to \"simple ideas\" but few are willing to truly pursue simplicity to its limit and simply scale up existing ideas. \n\n---\n\nThe typical research project might last 4 years at the longest because that is the max duration of a PhD and post-doc. An average PhD candidate wants their own unique project; they don’t want to continue someone else’s project. So the academic world is a rapid succession of short-lived projects[^1]\n\n[^1]: From [Stephen Fay](https://stephenfay.xyz/): \"I don't really understand where this claim comes from. In physics there are many huge international collaborations spanning decades (e.g. large radio arrays in poles+south africa+Canada, LIGO + LISA, CERN, James Webb, building quantum computers is going to take large collaborations even if research goes underground). I can't really speak to other fields but it would be nice to have a bit more context to this claim.\" I've now clarified this critique to mostly target computer science/theoretical fields. I think any research field with sufficient barrier entry/requirements for access to infrastructure/hardware/physical resources does necessarily require pooling of resources on an institutional and often multi-year/decade long timespan\n\n## Tunnel Vision\n[Source: Mimetic by *Brian Timar*](https://www.briantimar.com/notes/mimetic/mimetic/), see also [mimetic](thoughts/mimetic.md)\n\n\"Graduate programs select for intensely competitive individuals with highly specific skills, often with negligible market value outside of universities. A strong desire for publications on esoteric topics is inherited from senior postdocs and professors, making tunnel vision especially acute.\"\n\n## Incentive Structure\nAcademia feels more pure, more [playful](thoughts/play.md), than industry? More of a '[constructionist](thoughts/constructionist.md)' approach, freedom to ask your own questions\n\nCan we create the energy of DARPA outside of government [funding](thoughts/funding.md)? A modern day Xerox Parc or Bell Labs? A [research institutions](thoughts/research%20institutions.md) perhaps?\n\nMore on [incentives](thoughts/incentives.md)\n\n## Research at Microsoft\nSession w/ Jim Pinkelman, Ph.D. Been at MS for 19 years, 11 years in Microsoft Research\n\nMost of MS research is not necessarily driven by a technical challenge that a product group faces. Very driven by research interests of new hires.\n\nMissions\n1. Advance the state-of-the-art in CS\n2. Rapidly transfer technologies to Microsoft products and services\n3. Incubate disruptive technologies and new business\n\n95% of internal research is peer-reviewed + published\n\n1990 memo\n* \"We have some unique potential to productize research\"\n* \"We should still listen to external research, but in some areas there is a big benefit in owning the tech\"\n\nHorizons\n* Horizon 1: Near term, ~6mo-1yr, what technical challenges do we need to overcome?\n* Horizon 2: Medium term, 1-4yrs, idea of general challenge needed to be solved\n* Horizon 3: Long term, 5-10yrs, advancement in the field\n\nMSR sub-groups\n1. MSR Labs: Long term basic research\n2. MSR NExT: New experiences and technologies","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/access-control":{"title":"Access control","content":"\n\u003e Access control systems guarantee that every action performed adheres to a set of rules, which can be dynamically changed at runtime.\n\nIn traditional systems, this guarantee can be enforced by relying on a central server. But this becomes a lot more difficult for eventually [[thoughts/consistency|consistent]] systems (e.g. [[thoughts/CRDT|CRDTs]])\n\nThere is a  common perception of ACL systems and capability systems as merely alternative perspectives on Lampson’s access matrix\n\n| |Asset 1|Asset 2|File|Device|\n|-|-|-|-|-|\n|Role 1|read, write, execute, own|execute|read|write|\n|Role 2|read|read, write, execute, own|||\n\n![[thoughts/images/acl vs capability.png]]\n\n### Access Control Lists\nAn Access Control list (sometimes called ACL) is a data structure containing entries that specify an individual user or group’s rights to specific system objects. Generally good when the groups of individuals remains relatively static and objects change a lot.\n\nIn the Lampson's access matrix, they are normally seen as the columns.\n\n### Capabilities\nThe capability list (sometimes called C-list) of a user or a process or domain is a list of rights that it has on the various objects. Generally good when groups of individuals changes a lot and objects remain relatively static.\n\nIn the Lampson's access matrix, they are normally seen as the rows.\n\nCapabilities provide much better support for least-privilege operation and for avoiding confused deputy problems\n\nFrom *[Capability Myths Demolished](https://srl.cs.jhu.edu/pubs/SRL2003-02.pdf)*:\n1. Equivalence Myth: access control list systems and capability systems are formally equivalent\n\t- No description of any security mechanism is complete without a specification of how access relationships are allowed to evolve over time\n\t- False as shown in descriptions above\n2. Confinement Myth: capability systems cannot enforce confinement\n\t- The argument assumes that subjects can transmit capabilities anywhere they can transmit data, which is not the case in most capability systems.\n\t- We can get around this by limiting connections between objects\n\t\t- In partitioned or type-enforced capability systems such as KeyKOS, W7, EROS, or E, capabilities and data are distinguished by the kernel or runtime\n\t- No capability transfer can introduce a new connection between two objects that were not already connected by some path\n\t- Suppose, for example, we decide not to trust Bob. To prevent Alice from delegating to Bob, we simply refrain from giving Alice access to Bob.\n4. Irrevocability Myth: capability-based access cannot be revoked\n\t- It is true that capabilities themselves are not literally revocable.\n\t- Further, we know that the capability alone is sufficient to establish access to the resource.\n\t- However, we can create a pair of forwarders, F and R to get around this. Of this pair, we may call F the forwarding facet, and R the revoking facet. Any messages sent to F get forwarded through R to Carol, so Bob may use F as if it were Carol. This works as long as inter-object interactions are mediated by messages, and messages are handled generically, so that a reusable mechanism can forward any message.  ![[thoughts/images/capabilityrevokation.png]]\n\t- When Alice wants to revoke Bob’s access to Carol, she invokes R, telling it to stop forwarding. R then drops its pointer to Carol, and F becomes useless to Bob.\n\nAmbient Authority:\n- We will use the term ambient authority to describe authority that is exercised, but not selected, by its user.\n- The corresponding analogy is to imagine a world with doors but without keys. When a person walks up to a door, the door magically opens if it deems the person worthy.\n- For example, Unix filesystem permissions constitute an ambient authority mechanism, because the caller of a function such as open() does not choose any credentials to present with the request; the request merely succeeds or fails\n\nConfused Deputy Problems:\n- A deputy is a program that must manage authorities coming from multiple sources.\n- A confused deputy is a deputy that has been manipulated into wielding its authority inappropriately.\n- A big part of preventing confused deputy problems is by removing ambient authority\n\t- If the authority to write to BILL were not ambient, then the compiler could hold one key to BILL for the purpose of writing billing information, and accept another key from the user for the purpose of writing debugging information. Then, as long as the compiler uses each key for its intended purpose, the confused deputy problem cannot occur.","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/accountability":{"title":"Accountability","content":"\n-   reparations and reconciliation can only occur after both parties have acknowledged it\n\t-   how does this work if one party '[ghosts](https://static1.squarespace.com/static/557744ffe4b013bae3b7af63/t/557f2d6ce4b029eb4288a2f8/1434398060958/)' or otherwise leaves the conversation?\n-   emotional labour goes up in a democratic setting when more people are involved (rel: [group limits](thoughts/group%20limits.md))\n\t-   is there a point where it is almost always better to have an authoritarian/impersonal third party? (e.g. the state and the law)\n-   how do we keep people accountable in [digital spaces](thoughts/digital%20commons.md) and [virtual worlds](thoughts/virtual%20worlds.md)?\n\t-   especially with anonymous/[pseudonymous](thoughts/pseudonymity.md) users\n\t-   is it better to create better tools to help users manage digital boundaries or to shift the responsibility to the platforms? [moderation](thoughts/Moderation.md) in [infrastructure](thoughts/infrastructure.md)?\n\t-   digital boundaries and scale: being bigger will attract hate\n","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/algorithmic-decision-making":{"title":"Algorithmic decision making","content":"\nEU: significant decision making cannot be based solely on automatic information processing (though, what is to say that the human [consciousness](thoughts/consciousness.md) isn't just automatic information processing?)\n\nRelated: [bias](thoughts/bias.md), [bias-bug](posts/bias-bug.md), [Algorithms of Oppression](thoughts/Algorithms%20of%20Oppression.md)","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/aperture-problem":{"title":"Aperture Problem","content":"\n### Aperture Problem in [Computer Vision](thoughts/computer%20vision.md)\n- Without distinct features to track, the true visual motion is ambiguous\n- Locally, one can compute only the component of the visual motion in the direction perpendicular to the contour\n\nIn relation to the [Internet](thoughts/Internet.md): our browsing is also very static and in a small window. By default, you can only browse on a page-level scale. What about subdomains? Apex domains (see more in [DNS](thoughts/DNS.md))? How do we expand the aperture of the web browser to encompass more [information scales](thoughts/information%20scales.md)? (potential [idea](thoughts/idea%20list.md))","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/art":{"title":"Art","content":"\n\u003e An activity in which perfection can be pursued\n\n[Source: An artist in Crypto by *Wendi Yan*](https://reboothq.substack.com/p/crypto-artists) and in discussion with Wendi\n\nWhat makes something “art” comes from its _intention_. How did the artist create the work? What is the personal experience or historical question their art responds to? Or did they seek to evoke certain emotions through their work?\n\nIn this sense, art is a form of derivative [intentionality](thoughts/intentionality.md) where the artist imparts it into the work. Is generative art still art? I still think so. You just have a fancier paintbrush.\n\n\u003e True art doesn’t care to be appreciated, obsessed over with, or owned. It holds a certain self-respect that knows enough of its own value to not plea for attention.\n\nTrue art is like a gift. They should not be explicitly marked with a monetary value. They should not be used as holds of value to be predicted and sold. \"If art is important to you, you want to hold onto it, instead of trading it with others.\"\n\n## On Crypto Art\nHas a lot of money in it right now but most (keyword: most) of the 'value' derived is from speculation and not necessarily new ways of exploring the medium or good/interesting art.\n\nYet, this new form of 'art' still carries the burden of its past. Crypto art still has not solved the curation problem. There is so much art (just take a look at open sea). How does one ensure their art is discovered, other than pleading to the whims of Twitter and to constantly blast their work in hopes that someone will pay [attention](thoughts/attention%20economy.md)?\n\n### Art as entertainment\n\u003e Most of what the crypto world calls art is entertainment. They snatch your attention. They care more about making a tweet or a headline declaring they SOLD OUT, they set a HISTORICAL RECORD, and they tell you this is the art’s value.\n\nSituated at the top of the [pace layers](thoughts/pace%20layers.md), true art should be much lower.\n\n## On AI Art\n[Source](https://theconvivialsociety.substack.com/p/lonely-surfaces-on-ai-generated-images)\n\nHorning [observes](https://substack.com/app-link/post?publication_id=1073994\u0026post_id=89481239\u0026utm_source=post-email-title\u0026isFreemail=true\u0026token=eyJ1c2VyX2lkIjoxODEwNDM3LCJwb3N0X2lkIjo4OTQ4MTIzOSwiaWF0IjoxNjcwNjI2Njc4LCJleHAiOjE2NzMyMTg2NzgsImlzcyI6InB1Yi0xMDczOTk0Iiwic3ViIjoicG9zdC1yZWFjdGlvbiJ9.hI3UELLqNg32fmQndpVpsRKJuzSV8f_RUYpiPbfpVGU), \"presume that thought is entirely a matter of pattern recognition, and these patterns, already inscribed in the corpus of the internet, can [be] mapped once and for all, with human ‘thinkers’ always already trapped within them. The possibility that thought could consist of pattern breaking is eliminated.\"\n\n“The best art isn’t about pleasing or meeting expectations,” as Dan Cohen has put it in a recent [essay](https://buttondown.email/dancohen/archive/humane-ingenuity-45-what-ai-tells-us-about-art/) about generative AI. “Instead, it often confronts us with nuance, contradictions, and complexity.”\n\nOn the contrary, Cohen concluded, “The desire of AI tools to meet expectations, to align with genres and familiar usage as their machine-learning array informs pixels and characters, is in tension with the human ability to coax new perspectives and meaning from the unusual, unique lives we each live.”\n\nIn other words, AI produces what it *thinks we want to see*\n\nThis is one way of thinking about what it means for a work of art to have depth. You can press in, and it won’t dissolve under a more attentive gaze. AI art *does* dissolve under deep [[thoughts/attention economy|attention]]. Questions to ask:\n1. How will AI-generated images train our vision?\n2. What habit of attention does it encourage?\n3. What modes of engagement do they sustain?","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/ask-vs-guess-culture":{"title":"Ask vs Guess culture","content":"\n*phrasing from Jasmine*\n\n## Guess Culture\n- High social cost in asking for things\n\t- Often *guess* at the reaction of the other in order to mitigate potential social cost (e.g. will not ask for things if it could be seen as out of place)\n- Tend to ask for things less with the assumption that the other will most likely accept\n\n## Ask Culture\n- Low social cost in asking for things\n- Will just ask and expect to be rejected more often, generally more forward","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/attention-economy":{"title":"Attention Economy","content":"\nMichael Goldhaber, who, in a series of essays in the late 1990s, argued that a new “attention economy” was emerging alongside the traditional economy of goods and services. “Ours is not truly an information economy,”\n\n## As a commodity\nAttention as a commodity, it is increasingly competitive to compete for everyone's attention\n* shortening of attention spans? not sure if this is an actual thing\n* 'digital detox'\npeople not just as the products, but as the producers of the product (data)\n\nAttention is the main currency of production -- what limits you from doing everything at once. Attention, then, is a common pool resource. It is non-excludable (anyone can bid for their attention) and rivalrous (limited attention).\n\nMore in Odell's [*How to do Nothing*](thoughts/How%20to%20do%20Nothing.md), [designing for slowness](thoughts/digital%20mindfulness.md)\n\n## Information Scaling\n[Source](https://theconvivialsociety.substack.com/p/the-pathologies-of-the-attention)\n\nSee: [[thoughts/information scaling threshold]]\n\nThe wealth of information means a dearth of something else—a scarcity of whatever it is that information consumes. What information consumes is rather obvious: it consumes the attention of its recipients","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/authenticator-complexity":{"title":"Authenticator complexity","content":"\nA measure of complexity (lower is better) for distributed [[thoughts/consensus|consensus]] mechanisms in partially synchronous [[thoughts/system model|system model]].\n\nDefinition: The sum, over all replicas $i \\in [ n ]$, of the number of authenticators received by replica $i$ in the protocol to reach a consensus decision after GST.\n\nAn authenticator is either a partial signature or a [[thoughts/digital signatures|signature]].\n\n\n![[thoughts/images/authenticator-complexity-meme.png]]*Figure 2: Our Network Protocol (from [The Saddest Moment](https://scholar.harvard.edu/files/mickens/files/thesaddestmoment.pdf))*","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/authorization":{"title":"Authorization","content":"\nAuthorization is the process of verifying what a user has access to (whereas authentication is the process of verifying who someone is)\n\n## JWT\n\u003e  Each JWT contains encoded JSON objects, including a set of claims. JWTs are [[thoughts/digital signatures|signed]] using a cryptographic algorithm to ensure that the claims cannot be altered after the token is issued.\n**\nThree components (looks something like this: xxxxx.yyyyy.zzzzz.)\n1. Header: contains the type of token and signing algorithm\n2. Payload: contains the claims\n3. [[thoughts/digital signatures|Signature]]: ensures the token hasn't been altered\n\nThe party that creates the JWT signs the header and payload with\n- a secret that is known to both the issuer and receiver, or\n- a private key known only to the sender\n\nWhen the token is used, the receiving party verifies that the header and payload match the signature.\n\nSee also: [[thoughts/UCAN|UCAN]]","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/automatic-differentiation":{"title":"Automatic Differentiation (AD)","content":"\n- Input: code computing a function\n- Output: code to compute one or more derivatives of the function.\n\nAD writes functions as a sequence of simple compositions\n$$f_5(f_4(f_3(f_2(f_1(x)))))$$\n\nAnd  writes derivatives using chain rule:\n\n$$f'(x) = f_5'(f_4(f_3(f_2(f_1(x)))))*f_4'(f_3(f_2(f_1(x))))*f_3'(f_2(f1 (x)))*f_2'(f_1(x))f_1'(x)$$\n\nWe decompose code using the chain rule to make derivative code. This can lead to a lot of redundant computations. We can use dynamic programming to avoid redundant calculations.\n\n## Multi-variable AD\nWe define a computation graph as a DAG. \n- Root nodes are the parameters (and inputs).\n- Branch nodes are computed values (𝛼 values).\n- Leaf node is the function value.\n\nTwo stages (example of a function that takes $x$ and $y$ and calculates a $z$):\n1. Forward AD pass is called forward propagation:\n\t- Computes $z$ from $x$ and $y$ and passes it to its outputs\n\t- Storing intermediate calculations $\\frac{\\partial z}{\\partial x}$ and $\\frac{\\partial z}{\\partial y}$\n3. Backward AD pass is called backpropagation:\n\t- Starts from the end with $\\partial \\mathcal L / \\partial \\mathcal L$ which is just 1\n\t- Computes $\\frac{\\partial \\mathcal L}{\\partial x}$ and $\\frac{\\partial \\mathcal L}{\\partial y}$ from $\\frac{\\partial \\mathcal L}{\\partial z}$\n\t\t- Using intermediate calculations stored during forward pass\n\t\t- $\\frac{\\partial \\mathcal L}{\\partial x} = \\frac{\\partial \\mathcal L}{\\partial z} \\frac{\\partial z}{\\partial x}$\n\t\t- $\\frac{\\partial \\mathcal L}{\\partial y} = \\frac{\\partial \\mathcal L}{\\partial z} \\frac{\\partial z}{\\partial y}$","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/automation":{"title":"Automation","content":"\n[Source: What Tech Futurists Get Wrong About Human Autonomy by *Divya Siddarth and Kelsi Nabben*](https://www.noemamag.com/ai-blockchain-human-autonomy-future/)\n\n[AI systems](posts/ai-systems.md) and [blockchain](thoughts/blockchain.md) both means to achieve the same \"underlying desire: to implicitly or explicitly abstract away human fallibility in service of a fully automated vision of perfection.\"\n\nAI focuses on autonomy of **outcome**, blockchain focuses on autonomy of **process**.\n\nPrevalent in [post-work society thinking](posts/play.md), especially one of a [positive sum](thoughts/positive%20sum.md) sum, post-scarcity world\n\n\"However, the link between individual autonomy and the collective good has always been pernicious — and nowhere more so than in the visions of technology that promise to give us both in unparalleled measure.\"\n\nWe need to push not for technological **determinism** but for technological **pluralism**.","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/autopoiesis":{"title":"Autopoiesis","content":"\n\u003e A system capable of producing and maintaining itself by creating its own parts\n\nOften times, [emergent behaviour](thoughts/emergent%20behaviour.md) is a form of autopoiesis. Mostly refers to biological behaviour\n\n![Biologic as self-specifying](thoughts/images/biological%20autopoiesis.png)\n\nJoint Attention\n- Children coordinating attention between two things: object and the adult\n- But as the child monitors the attention of the adult to other entities, this entity is sometimes the child, and thus the child begins to see themselves from the outside (see: Kegan's Development stages in [In Over Our Heads](thoughts/In%20Over%20Our%20Heads.md))","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/awareness":{"title":"Awareness","content":"\nAn inverse is absence, particularly visual absence\n1. Absence by occlusion: parts are hidden\n2. Absence by vacancy: characterized by lack of visual information\n3. Pure visual absence: no visual information is provided\n\n## On Having No Head\n*D. E. Harding*\n\n\u003e What actually happened was something absurdly simple and unspectacular: just for the moment I stopped thinking. Reason and imagination and all mental chatter died down. For once, words really failed me. I forgot my name, my humanness, my thingness, all that could be called me or mine. Past and future dropped away. It was as if I had been born that instant, brand new, mindless, innocent of all  \nmemories. There existed only the Now, that present moment  \nand what was clearly given in it. To look was enough.\n\n\u003e And what I found was khaki trouserlegs terminating  \ndownwards in a pair of brown shoes, khaki sleeves  \nterminating sideways in a pair of pink hands, and a khaki  \nshirtfront terminating upwards in - absolutely nothing  \nwhatever! Certainly not in a head...\n\nFirst-person methods are central to the philosophical movement known as Phenomenology.","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/bandwidth":{"title":"Bandwidth","content":"\n\u003e When we talk together, we flatten our N-dimensional thoughts into 1D linear narratives, in order to fit them through the 1D bottleneck of words. When we draw or sketch, we flatten our N-dimensional thoughts into 2D images in order to fit them through the 2D bottleneck of sight.\n\n## Hypertext\n[Source: Hypertext Montage by *Gordon Brander*](https://subconscious.substack.com/p/hypertext-montage)\n\nWhat is the shape of [networked-thought](posts/networked-thought.md)?\n\n## Interpretation\nDoes moving closer to real-time mean less interpretation? Less expressive mediums like text mean that a lot of the emotion and meaning is left up to the reader to interpret and guess at. As we move to higher bandwidth mediums (e.g. calls and video), is there less room to interpret?\n\nWhat does this mean for art which inherently requires interpretation? Will we ever get to a communication medium so direct (e.g. mind-to-mind) that it doesn't require interpretation? What about [qualia](thoughts/qualia.md) and the subjective human experience?\n\n### Lossiness as Mutation\n[Source: Self-Organizing Ideas by *Gordon Brander*](https://subconscious.substack.com/p/self-organizing-ideas)\n\nMaybe chaos is necessary for [emergent behaviour](thoughts/emergent%20behaviour.md). Thus, lossy communication in low [bandwidth](thoughts/bandwidth.md) communication helps seed for selection/mutation of new ideas. Examples of this include [[thoughts/writing|writing]].\n\nWhen we write, **[we flatten the cloud of associated ideas in our head](https://subconscious.substack.com/p/hypertext-montage)** into a linearized subset (lossy). The reader then unflattens this linearized subset into their own cloud of associated ideas (lossy). Each lossy step is an opportunity for **mutations** in understanding to emerge.\n\n## Resources\n\"I have a theory, which has not let me down so far, that there is an inverse relationship between imagination and money. Because the more money and technology that is available to [create] a work, the less imagination there will be in it.\" Alan Moore","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/banking":{"title":"Banking","content":"\n[Source: Banking in the Shadows, *Kernel*](https://kernel.community/en/learn/module-2/banking)\n\nT account or balance sheet-style thinking is a banker's way of being able to hold complementary opposites and demand in mind.\n\n### Printing Money\nIt's often not correct to say that when the Fed is 'printing money' they are straight up just injecting into one side. Most times, it expands *both sides of the balance sheet*.\n\n### Prices of Money\n1. Interest Rate (future) -- price of money now in terms of price of money later\n2. Part (now) -- price of one money in terms of another money (e.g. between states, between private and central bank)\n3. Exchange Rate (foreign) -- price of domestic money in terms of foreign/world money\n4. Price level (commodities) -- price of money in terms of price level of commodities","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/beyond-chat-gpt":{"title":"Thoughts on ChatGPT","content":"\n- [[thoughts/teaching|pedagogy]] → how do we assess thinking?\n\t- I suspect ChatGPT will do to writing what calculators did to math\n\t- Made it much more accessible to the masses but in the process of doing so, lost the value in the actual *process* of doing math\n\t\t- We do math by hand to help internalize it in our minds, to naturalize and practice the mind to thinking in that manner\n\t\t- \"The hours spent choosing the right word and rearranging sentences to better follow one another are what teach you how meaning is conveyed by prose. Having students write essays isn’t merely a way to test their grasp of the material; it gives them experience in articulating their thoughts.\"\n- Will product an influx of AI generated content\n\t- Modern day automated content mills\n\t- Don't shit where you eat!!\n\t- *[Ted Chiang on ChatGPT](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web)*\n\t\t- \"the more that text generated by large language models gets published on the Web, the more the Web becomes a blurrier version of itself.\"\n\t\t- \"Repeatedly resaving a _jpeg_ creates more compression artifacts, because more information is lost every time\"\n- On replacing human interaction\n\t-  “I've been journaling as I code and it works pretty similarly. An interactive journal that asks really good questions, unprompted and when appropriate would be a d r e a m”\n\t\t-  [https://beta.openai.com/docs/guides/embeddings/what-are-embeddings](https://beta.openai.com/docs/guides/embeddings/what-are-embeddings)\n\t- Why we shouldnt use ai to replace people\n\t\t-   [https://www.kernelmag.io/2/all-the-better-to-see-you](https://www.kernelmag.io/2/all-the-better-to-see-you)\n- Confidently wrong hallucination\n\t- [[thoughts/search#Search Engine to Oracle|Search as oracle]] is bad actually\n- AI for ‘good enough’ code/art/writing\n\t-   [https://twitter.com/gordonbrander/status/1600469469419036675](https://twitter.com/gordonbrander/status/1600469469419036675)\n\t-   [https://twitter.com/jachiam0/status/1598448668537155586](https://twitter.com/jachiam0/status/1598448668537155586)\n-  Can we solve the problem data provenance?\n\t-   [https://openai.com/blog/webgpt/](https://openai.com/blog/webgpt/)","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/bias":{"title":"Bias","content":"\nMore detailed post on [Bias in AI](posts/bias-bug.md). Related readings: [Design Justice](thoughts/Design%20Justice.md), [To Live in their Utopia](thoughts/To%20Live%20in%20their%20Utopia.md), [Social Bias in Information Retrieval](thoughts/Social%20Bias%20in%20Information%20Retrieval.md), [Algorithms of Oppression](thoughts/Algorithms%20of%20Oppression.md)\n\nBias: a slant or preference\n\n## Captchas\nHow do you distinguish between human and non-human without discriminating against certain types of people (e.g. ethnicity, cultural background)? How does one prove their humanity without betraying anything else about them?\n\n\"What is the universal human quality that can be demonstrated to a machine, but that no machine can mimic? What is it to be human?\"\n\n\u003e \"You need something that’s easy for an average human, it shouldn’t be bound to a specific subgroup of people, and it should be hard for computers at the same time. That’s very limiting in what you can actually do. And it has to be something that a human can do fast, and isn’t too annoying.\"\n\nPossibility of reverse CAPTCHAs where you can only pass if you get it wrong in the 'right' way? (e.g. optical illusions)\n\n## Ethical Matrices\nWho cares about my algorithm? Who are the stakeholders? Why do they care? What are their goals?\n\n## Search Engine Bias\nFrom [Social Bias in Information Retrieval](thoughts/Social%20Bias%20in%20Information%20Retrieval.md)\n\nRelated: [data distributions](thoughts/data%20distributions.md)\n\n\u003e \"We use the term bias to refer to computer systems that systematically and unfairly discriminate against certain individuals or groups of individuals in favour of others... A system discriminates unfairly if it denies an opportunity or a good or if it assigns an undesirable outcome to an individual or group of individuals on grounds that are unreasonable or inappropriate\" (Friedman and Nissenbaum, 1996)\n\n## 3 groups of study\nfrom [Design Justice](thoughts/Design%20Justice.md) and Friedman\n\n1. Preexisting Bias: bias that exists in broader society, culture, and/or institutions is reproduced in the computer system, either intentionally or unintentionally, by systems developers.\n\t- e.g. Notions of quality and authority bias embedded in the web content itself\n2. Technical Bias: some underlying aspect of the technology reproduces bias\n\t- e.g. Design of crawlers/aggregate/surfacing algorithms for content, ranking features\n3. Emergent Bias: may not have been biased given its original [context](thoughts/context.md) of use or original user base but comes to exhibit bias when the context shifts or when new users arrive\n\t- e.g. Responses to spam, content moderation, search suggestions\n\nCathy O’Neil: algorithms are “opinions embedded in code” -- [artifacts do indeed have politics](thoughts/Do%20Artifacts%20Have%20Politics.md)\n\nBaeza-Yates\n1. Activity Bias: who contributes to the data? who is seen by these algorithms?\n2. Data Bias: is the underlying data biased/non-representative?\n3. Sampling Bias: what data is used by algorithms?\n4. Algorithmic Bias: what gets shown to users?\n5. Interaction Bias: how do people use the algorithms?\n6. Self-selection Bias: who uses these algorithms?\n7. Second-order Bias: digital trace data, how do our data-residues \n\n## Forbidden Rates\nCoined by Tamar Gendler\n\nWe do not live in perfectly egalitarian societies, and race, gender, class and other identities can significantly affect how our lives work out.\n\n\u003e Now suppose you’re at a reception for engineers and their spouses, and you’re introduced to a male–female couple about whom you know next to nothing. Odds are, he’s the engineer. But if you have anti-sexist instincts, you may feel pulled towards keeping an entirely open mind about which of these two strangers is the engineer, rather than allowing your statistical knowledge to incline you towards the man. If you do ‘slip’ into assuming the man to be the engineer, and this turns out to be a mistake, you’re likely to be more embarrassed than you would be had you wrongly assumed the couple to live in the local area, on the grounds that most guests at the reception live locally.","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/binary-classification":{"title":"Binary Classification","content":"\n- Set $y_i = +1$ for one class (“important”)\n- Set $y_i = -1$ for the other class (“not important”)\n- To predict, we look at whether $w^Tx_i$ is closer to +1 or -1\n\t- $\\hat y_i = \\textrm{sign} (w^Tx_i)$\n\nLeast squares error may overpenalize. Only thing we care about is the sign, not how far away it is from the decision boundary.\n\nCould we instead minimize number of classification errors? This is called the 0-1 loss function: you either get the classification wrong (1) or right (0).\n\n$$\\mathcal L(i,j) = \\begin{cases} \n  0 \u0026 i = j \\\\\n  1 \u0026 i \\neq j\n\\end{cases}\n$$\n\n![[thoughts/images/0-1-loss.png|500]]\n\nIllustration above is if $y_i = 1$. Flip for $y_i = -1$\n\nUnfortunately, 0-1 Loss is non-convex. We can, once again, use a convex approximation which is called the Hinge loss:\n\n$$\\mathcal L(i,j) = \\max(0, 1 - y_iw^Tx_i)$$\n\nSee also: [[thoughts/SVM]]\n\nThis is an upper bound on the 0-1 loss (as illustrated by the picture). For example, if the hinge loss is 18.3, then the number of training errors is at most 18.\n\nSimilarly, we can use the log-sum-exp trick to get the logistic loss which is convex *and* differentiable.\n\n$$\\mathcal L(i,j) \\approx \\log(1 + \\exp(-y_iw^Tx_i))$$\n\n### Perceptron\nOnly works for *linearly-separable* data\n\n- Searches for a $w$ such that $\\textrm{sign}(w^Tx_i ) = y_i, \\forall i$\n- Intuition is that you search for the ledge\n- Start with $w^0 = 0$\n- Classify each example until we reach a mistake\n\t- Then, update $w$ to $w^{t+1} = w^t + y_ix_i$\n- If a perfect classifier exists, this algorithm finds one in finite number of steps\n","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/bitcoin":{"title":"Bitcoin","content":"\n[Peer to peer](thoughts/peer-to-peer.md) electronic cash built using [blockchain](thoughts/blockchain.md). Capital 'B' Bitcoin is the network and [protocol](thoughts/Protocol.md), lower case 'b' bitcoin is the actual currency.\n\nHere, centralized intermediaries (banks) are replaced by a trustless network of 'miners' which use [proof of work](thoughts/proof%20of%20work.md) for consensus.\n\n## Mining\nCompeting to solve a cryptographic puzzle to earn rights to add a new block to the blockchain. Reward is new bitcoin.\n\nHashing then, is the process of guessing a 'nonce' (pseudo-random number once which is used to initialize communication) that when entered with the previous block information into SHA-256, generates an output deemed satisfactory by the Bitcoin protocol. If the nonce found can be verified by the other miners, then can add the new block to the network and earn bitcoin.\n\nTo prevent transaction data from being altered, Bitcoin employs an algorithm in which tampering of transaction details will result in large difficulty increases in the puzzle. As a result, it would be extremely difficult to achieve consensus around tampered data.","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/black-box":{"title":"Black boxes","content":"\nSee also: [[thoughts/paperclip optimizer|paperclip optimizer]]\n\n\u003e Scientific and technical work is made invisible by its own success. When a machine runs efficiently, one need only to focus on its inputs and outputs and not on its internal complexity. Thus, paradoxically, the more science and technology succeed, the more opaque and obscure they become\n\nIn the context of systems, actors are anyone, human or nonhuman, who engages in intentional action shaped by internalized expectations of how it will be perceived\n\nIf we start to disect the black box and understand that it\n- is made by people\n- substitutes their actions\n- is a permanent delegate of the work\n- shapes human action by prescribing what sorts of people can pass through it\n\nThen this is called \"opening the black box\" or \"infrastructural inversion\" for larger scale infrastructures\n\nJim Johnson: building and rebuilding walls everytime you use it is a waste, thats why we have doors as *[infrastructure](thoughts/infrastructure.md)* that saves a lot of this repetitive work.\n\n## Computational Reliabilism (CR)\n*Who is afraid of black box algorithms? On the epistemological and ethical basis of trust in medical AI* by Juan Manuel Durán, Karin Rolanda Jongsma\n\nOn [[thoughts/trust|trust]] in black box algorithmic decision making systems\n\nBlack boxes are algorithms that humans cannot survey: they are [[thoughts/epistemology|epistemically opaque]] systems that no human or group of humans can closely examine in order to determine its inner states. Physicians have a hard time offering accounts of how the algorithm came to its recommendation or diagnosis\n\nTerms:\n- [[thoughts/transparency|transparency]]: algorithmic procedures that make the inner workings of a block box algorithm interpretable to humans\n\t- transparency is an epistemic manoeuvre intended to offer reasons to believe that certain algorithmic procedures render a reliable output and that the output of the algorithm is interpretable by humans\n- opacity: inherent impossibility of humans to survey an algorithm both understood as a script as well as a computer process. Burrell proposes 3 types of opacity\n\t1. Intentional corporate or state secrecy\n\t2. Technical illiteracy\n\t3. Arising out of the scale of machine learning algorithms\n\nClaim: transparency will not provide solutions to opacity, and therefore having more transparent algorithms is not a guarantee for better explanations, predictions, and overall justification of our trust in the results of an algorithm\n\nComputational reliabilism (CR)\n- offers epistemic justification for the belief that the algorithm is reliable and its results are trustworthy\n- main claim: researchers are justified in believing the results of AI systems because there is a reliable process that yields, most of the time, trustworthy results. \n- formal definition \"the probability that the next set of results of a reliable (AI system) is trustworthy is greater than the probability that the next set of results is trustworthy given that the first set was produced by an unreliable process by mere luck\"\n\t- in regular language: given two results are the same, we should consider the one generated by a reliable system to be more trustworthy\n- reliability indicators\n\t1. verification and validation methods: building and measuring dev confidence in the computer system. Verification is assessment of accuracy with comparison to known solutions, validation is the assessment of accuracy with comparison to experimental data\n\t2. robustness analysis: figure out whether results of a given model are an artefact of the model or related to the core features of the model\n\t3. a history of (un)successful implementations: scientific and engineering methodologies and practices related to designing, coding, and running algorithms\n\t4. expert knowledge: experts' judgements, evaluations, and sanctioning\n\nResponsibility gaps\n- a physician cannot be held responsible for results of algorithms they don't understand\n\t- though, we do generally accept ex-post explanations and deem these sufficient of human actors in decision making\n\t- physicians typically operate other technologies and machinery which they do not fully understand or cannot fully explain the inner working of (e.g. MRI scans)\n\t\t- Debatable; because they are not making decisions, just presenting information. Additionally, these other technologies generally *can* be understood by an expert. This is not the case for AI systems\n\nCounterpoints raised:\n- automation complacency: tendency to overestimate the reliability of decision support systems\n- black box algorithms can hide normative assumptions\n\t- epistemic and normative considerations often blur into each other in the medical setting\n\t- we know nothing about the priors of the black box algorithm\n- model and data drift\n\t- computationally reliable black box algorithms can be reliable in one setting and time and not everywhere and forever","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/blockchain":{"title":"Blockchain","content":"\n[Source: A Primer to Web3](https://docs.google.com/presentation/d/1aIjYKKM64Eyp497-j6wkDjCsHBA3CbbWg25UQ9Why3g/mobilepresent?slide=id.gefbf959b67_0_58)\n\nThe universal message bus. An immutable, digital, distributed ledger that connects a decentralized network. Can be used to build cryptocurrencies like [Bitcoin](thoughts/bitcoin.md), [[thoughts/Solana|Solana]], and [Ethereum](thoughts/ethereum.md).\n\nA blockchain is a [[thoughts/State Machine Replication (SMR)|SMR]] protocol that has a 3-layer architecture.\n1. Consensus core: forms agreement over an immutable sequence of updates to a shared state: [[thoughts/Byzantine Faults|byzantine fault-tolerant]]. The consensus algorithm most commonly used are [[thoughts/longest-chain consensus|longest-chain consensus algorithms]] and solve BFT for a _permissionless_ [[thoughts/system model|system model]]\n2. State-machine API:  [[thoughts/bitcoin|Bitcoin]]’s state-machine and state-updates use a limited scripting language; [[thoughts/ethereum|Ethereum]] expands the state-machine and state-updates with a Turing complete abstraction (whose resources are bounded using gas).\n3. Application Layer: In Bitcoin is the shared provenance tracking of digital assets, and in Ethereum, could be anything decentralized.\n\nCharacteristics:\n1. Distributed: data is stored by and updates are broadcasted to everyone\n2. Smart Contracts: codified agreements. Once the predetermined conditions of the contract are met, the transaction and attached computation are completed and recorded on the blockchain.\n3. Immutable: A completed transaction can never be changed or hidden. This gives us **provenance of assets** (you can determine any asset's entire history as long as all transactions happen on-chain)\n4. [Decentralized](thoughts/decentralization.md): communal consensus rather than one party's decisions determines access/update to the chain\n\nOn a technical level, blockchain is just a linked list that is replicated.\n\nEach block contains the hash of the previous block header and the [Merkle root](https://www.investopedia.com/terms/m/merkle-tree.asp) representing the hash of all the transactions in that block.\n\nTransactions happen as follows:\n1. A transaction is initiated by a client\n2. Transactions are checked for validity to see if the state transition is legal (validation)\n3. Multiple transactions are packaged into a block and sent to members of the chain (block proposal)\n4. Consensus and approval by rest of network (either [proof of work](thoughts/proof%20of%20work.md) or [proof of stake](thoughts/proof%20of%20stake.md))\n5. Block is added to chain and distributed to members\n\n## Why it Matters\nIt feels like the level of change which blockchain impacts is huge but at the same time latent.\n\nAfter going through a bunch of Kernel modules, Austin came upon a name for the concept: \"blockchain changes what soil is\"\n\n\"The \"new world\" seems to look very similar to the old. i.e. *isn't a DAO just voting on how to donate money, which we could do today?*\"\n\nIn actuality, the *[[thoughts/pace layers|layer]]* at which change is happening is much deeper (more [infrastructure](thoughts/infrastructure.md) level than solution/product level)\n\n## Data\n[Source: Ethereal Dreamers by *Kernel*](https://kernel.community/en/learn/module-1/promise-blockchains)\n\n\"Back in early history, the databases were singular, existing in an atomic state with one DB per enterprise. The network existed in some relational sense between enterprises, but because DB's were so fragile they never spoke directly to the network because then they broke. Even if you did connect DBs somewhat directly, the DB encodes the worldview of the organization and different organizations have different worldviews, so the DBs can't speak to each other clearly.\"\n\n**There were no large-scale computer-to-computer connections that allowed us to create a shared world view between lots of different organizations**.\n\n\u003e This is the promise of blockchains -- to create a global 'distributed database'\n\nThe goal is to build a single, shared story of reality, spread across all the machines simultaneously. And when it changes in one place, it changes everywhere.\n\n### Thoughts\nThe part about no more 'storing stuff' and 'sending stuff' I always find interesting because 'storing' stuff still happens to be on the public ledger. The only difference now is that there is a distinction between sending metadata (which you tell someone to just refer to a piece of data on chain) and sending information (transferring ownership).\n\nWaiting for the day web3 projects get large enough to amortize and offset the gas fees that consumers pay now (much like centralized orgs nowadays front hosting costs for 'free' tier or the average consumer).\n\n### Act II -- Smart Contracts\n\"First we merged the network and the database in a blockchain. Then, we take computer software and put it into the shared database. That means everyone that is connected has a copy of exactly the same program: same data, same code, same result\"\n\n### Act III --- IOT\nThe 'scaled blockchain'\n\nIdeally we get to a point where we have a 'global computing service' (very Asiimov's Last Question-esque) through which we can embed IOT devices. This would turn all the sensors and bits of computing power into a global unified knowledge resources that manages the infrastructure of our society\n\nI'm curious how this relates to [truth](thoughts/truth.md), specifically how different people have different views on 'reality' and 'truth'. How do we reconcile that at a global scale?","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/boundary-object":{"title":"Boundary Objects","content":"\nSee also: [contact language](thoughts/contact%20language.md)\n\n## Definitions\nPeter Galisons' notion Trading Zone -\u003e sites where representatives of multiple disciplines come together to work and, as the ydo, establish contact languages for purposes of collaboration\n\nSusain Leigh Star and James Griesemer's Boundary Objects -\u003e objects which both inhabit several intersecting social worlds and satisfy the informational requirements of each (e.g. maps, diagrams, standardized forms, notation, etc.)\n\n## Ecotone\n[Source: Ecotone, *Wikipedia*](https://en.wikipedia.org/wiki/Ecotone)\n\nAn ecotone is a transition area between two biological communities, where two communities meet and integrate. It may be narrow or wide, and it may be local (the zone between a field and forest) or regional (the transition between forest and grassland ecosystems)","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/broken-world-thinking":{"title":"Broken world thinking","content":"\n'Broken world thinking' -\u003e focus on constant process of entropy and undoing of work and what we can do to slow/halt this process rather than introducing new things. Curious how this relates to [climate tech](thoughts/climate%20tech.md) and general escapist vibes of people like Elon wanting to escape to space rather than fixing problems with our current world.","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/building-in-public":{"title":"Building in Public","content":"\n[Source: You and Your Research by *Richard Hamming*](https://www.cs.virginia.edu/~robins/YouAndYourResearch.html)\n\n\"He who works with the door open gets all kinds of interruptions, but he also occasionally gets clues as to what the world is and what might be important.\" — Richard hamming\n\nInvite distractions but get a better sense of the world\n\nRelated: [Collaborative thinking](posts/collaborative-thinking.md)\n\n## As a form of EA\nWorking and being vocal about your work is a way to amplify your [effective](/thoughts/effective%20altruism.md) impact radius. By doing so, you can change other people's thinking around giving, money, and charity through discussion\n","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/burnout":{"title":"Burnout","content":"\nFrom [In Over Our Heads](thoughts/In%20Over%20Our%20Heads.md)\n\nRelated: [pain](thoughts/pain.md) is not the unit of effort\n\nFreudenberger (who first coined the term burnout): \"almost always an indication that the person's goals have been externally imposed. Somehow [they] embarked on his present course because it was expected of [them]... [they were] never the authentic source of [their own] choices and consequently they afford little real satisfaction\"","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/calculus":{"title":"Calculus","content":"\n## Partial Derivatives\n### Linear\nFunctions with more than one variable. e.g. $f(x)$ where $x \\in \\mathbb{R}^3$ the following multivariate linear\n\n$$\n\\begin{equation}\n\\begin{split}\nf(x_1, x_2, x_3)\u0026 = a_1x_1 + a_2x_2 + a_3x_3 + b \\\\\n \u0026 = \\sum_{i=1}^3 a_ix_i + b \\\\\n \u0026 = a^Tx + b\n\\end{split}\n\\end{equation}\n$$\n\n\nThe gradient is then the partial derivative with respect to each variable\n\n$$\\nabla f(x) = \\begin{bmatrix}\\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\frac{\\partial f}{\\partial x_3}\\end{bmatrix} = \\begin{bmatrix}a_1 \\\\ a_2 \\\\ a_3\\end{bmatrix}$$\n\n### Quadratic\ne.g. $f(x)$ where $x \\in \\mathbb{R}^2$ and $A = \\begin{bmatrix}2 \u0026 -1 \\\\ -1 \u0026 1\\end{bmatrix}$ \n\n$$\n\\begin{equation}\n\\begin{split}\nf(x)\u0026 = \\frac 1 2 x^TAx + b^Tx + c \\\\\n \u0026 = \\sum_{i=1}^2 \\sum_{j=1}^2 a_{ij}x_ix_j + \\sum_{i=1}^2b_ix_i + c\n\\end{split}\n\\end{equation}\n$$\n\nIf $A$ is symmetric, $\\nabla f(x) = Ax+b$. In the non-symmetric case, $\\nabla f(x) = \\frac 1 2 (A + A^T)x + b$\n\nGeneralizations of gradients for $d$ dimensions given:\n1. $A = X^TX$ \n2. $b$ = $X^Ty$\n3. $c = \\frac 1 2 y^Ty$\n\nSo\n1. $\\nabla \\frac 1 2 w^T A w = Aw$ (if A is symmetric)\n2. $\\nabla w^Tb = b$\n3. $\\nabla c = 0$","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/cancel-culture":{"title":"Cancel Culture","content":"\n## Cancel culture and healthy debate\ni think being inclusive and mindful of the opinions is really important\nbut there also needs to be a balance between the weight of creating an unsafe place for ideas vs unsafe places for people\n\nwhere we're trying to communicate in ways that allows for difficult conversations and also at the same time doesn't result in the silencing of voices\n\n\"don't make sweeping statements against core identity groups\"\ncore identity groups -\u003e race, religion, sex, gender, nationality, etc.\n\nshould ideas be treated as separate from the people who proposed them?\nlogically, ideas should be evaluated from the merit of the idea itself\nyet, there are cases when other contextual information is important\n* e.g., when talking about diversity issues, talking from first-hand exp is often a lot more valid than second-hand or third-hand\n* in these cases, does methodology and original source of speaker count as *part* of the idea?","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/carbon-credits":{"title":"Carbon Credits","content":"\n[Source: An Even More Inconvenient Truth from *ProPublica*](https://features.propublica.org/brazil-carbon-offsets/inconvenient-truth-carbon-credits-dont-work-deforestation-redd-acre-cambodia)\n\nCan we create 'credits' that companies can buy to offset their emissions by 'proving' that a forest is sequestering a certain amount of carbon?\n\nYet, in most of these cases, these carbon offsets don't actually work. They either\n1. don't offset the amount they were supposed to do\n2. bought gains that were quickly offset\n3. amount of carbon couldn't be measured accurately\n\nUltimately leading polluters to get off scott-free while the planet still suffers. Is this still ok thought? As long as some trees are saved and foreign aid is going toward protecting forests\n\nCarbon offsets are just \"charismatic carbon\" -- they offer a feel-good story of environmental and social good without doing much\n\nOriginally was a compromise between European, American, and developing nations\n1. European leaders wanted to create policies to encourage industry to pollute less\n2. Americans wanted flexibility\n3. Developing nations (e.g. Brazil) wanted money to deal with climate change\n\nOn paper, this seemed perfect: if it cost too much to reduce emissions in one area, you could 'buy' the equivalent offset. This in theory could incentivize orgs to try and develop more green tech (e.g. solar plant in favour of a coal plant) in anticipation of carbon credit sales\n\nIn practice doesn't work super well\n1. Clean Development Mechanism: 85% of offsets had a 'low likelihood' of creating real impacts\n2. Join Implementation: 75%\n\nLeakage: protecting one patch of land could lead to deforestation somewhere else as loggers work to try and meet quotas\n\nPreserving land and trees is hard in any developing country is hard: the poverty and lack of infrastructure \"drives people to violate whatever protections are in place to plant crops or mine for gold or just have enough lumber to build their homes\"\n\n\u003e When a tree is destroyed, all the carbon accumulated over its lifetime is released back into the atmosphere.\n\nBut there's not a lot of incentive for local residents\n- Rubber sells for about 2 reais/kg (roughly enough for a cup of coffee) whereas a single cow is ~800 reais ($200)\n- Sustainable logging didn't pay enough\n- Government subsidies don't consider enough things\n\t- Digging fish ponds but they don't produce enough\n\t- Rubber-tapping tries but can't afford fertilizer for the poor Amazon soil\n\n\u003e “Cattle is a secure market. You can get a good income selling a calf, an ox,” Silva said.\n\n\u003e “Who is willing to rubber tap nowadays?” Brito said. “Nobody, practically nobody. We want an easier way to live.”\n\nGerrymandering but for trees? A lot of the offset calculations are based off of regional averages for carbon, projects can then take advantage of 'unusually high' concentration areas with certain types of trees to game the system and gain more credits than they should have.\n\nThis could actually benefit indigenous tribes because of their more conservative approach to logging -- in fact, offsets can enable tribes to reduce logging. However, \"some tribal members are [deeply uncomfortable](https://www.newyorker.com/news/dispatch/how-carbon-trading-became-a-way-of-life-for-californias-yurok-tribe) with the idea of selling offsets to companies like this even if they are legitimate, fearing they’re effectively profiting from pollution.\"\n\n### Good Offsets?\n[Source: Buying Offsets](https://negative.sanctuary.computer/offsetting)\n\n1. Transparency: any individual credits can not be purchased more than once\n2. Permanence: credits should not be liable to be undone\n3. Additionality: by facilitating this activity, more carbon was drawn down than would have been\n4. Monitoring and Verification: transparent and public processes for ensuring captured carbon stays where it should","lastmodified":"2023-02-15T01:38:21.233820863Z","tags":null},"/thoughts/cascading-failures":{"title":"Cascading failures","content":"\nEffect can be approximated using a power law distribution\n\n$$p(s) \\sim s^{-\\alpha}$$\n\nwhere $\\alpha$ is the avalanche exponent. $\\alpha$ tends to hover around 1.5-2.\n\nSystems that display some sort of cascading failure are generally characterized by 3 key features:\n1. The system is characterized by some flow over a network, like the flow of electric current in the power grid or the flow of information in communication systems.\n2. Each component has a local breakdown rule that determines when it contributes to a cascade, either by failing (power grid, earthquakes) or by choosing to pass on a piece of information (Twitter).\n3. Each system has a mechanism to redistribute the traffic to other nodes upon the failure or the activation of a component.\n\nExamples from the [*Network Science Book*'s Chapter on Network Robustness](http://networksciencebook.com/chapter/8#cascading): \n\n### Blackouts (Power Grid)\n\nAfter the failure of a node or a link the electric currents are instantaneously reorganized on the rest of the power grid. For example, on August 10, 1996, a hot day in Oregon, a line carrying 1,300 megawatts sagged close to a tree and snapped. Because electricity cannot be stored, the current it carried was automatically shifted to two lower voltage lines. As these were not designed to carry the excess current, they too failed. Seconds later the excess current lead to the malfunction of thirteen generators, eventually causing a blackout in eleven U.S. states and two Canadian provinces.\n\nSimilarly, one of the largest blackouts in North America took place on August 14, 2003, just before 4:10 p.m. Its cause was a software bug in the alarm system at a control room of the First Energy Corporation in Ohio. Missing the alarm, the operators were unaware of the need to redistribute the power after an overloaded transmission line hit a tree. Consequently a normally manageable local failure began a cascading failure that shut down more than 508 generating units at 265 power plants, leaving an estimated 10 million people without electricity in Ontario and 45 million in eight U.S. states.\n\n### Denial of Service Attacks (Internet)\n\nIf a router fails to transmit the packets received by it, the [[thoughts/Internet|Internet]] protocols will alert the neighboring routers to avoid the troubled equipment by re-routing the packets using alternative routes. Consequently a failed router increases traffic on other routers, potentially inducing a series of denial of service attacks throughout the Internet.\n\n### Financial Crises\n\nCascading failures are common in economic systems. For example, the drop in the house prices in 2008 in the U.S. has spread along the links of the financial network, inducing a cascade of failed banks, companies and even nations. It eventually caused the worst global financial meltdown since the 1930s Great Depression.\n\n### Scheduling\n\nAirline schedules include a buffer period between consecutive flights to accommodate short delays. When a delay exceeds this buffer, subsequent flights that use the same aircraft, crew or gate, are also delayed. The consequences of bad weather or mechanical failures can cascade through airline schedules, delaying multiple flights and stranding thousands of passengers. \n\n### Supply and Food Chains\n\nThe disappearance of a species can cascade through the food web of an ecosystem, inducing the extinction of numerous species and altering the habitat of others.\n\nThe shortage of a particular component can cripple supply chains. For example, the 2011 floods in Thailand have resulted in a chronic shortage of car components that disrupted the production chain of more than 1,000 automotive factories worldwide. Therefore the damage was not limited to the flooded factories, but resulted in worldwide insurance claims reaching $20 billion.","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/catch-22":{"title":"Catch 22","content":"\n## Catch 22\nparadoxical situation -\u003e catch-22\n- If a pilot is deemed insane, they don't have to fly.\n- To be deemed insane, a pilot must request to be evaluated.\n- If a pilot requests to be evaluated, this demonstrates that he must be sane.\n- Therefore, no pilot can ever be deemed insane, and no pilot can get out of flying.\n\nno way to win\n- double bind -\u003e a psychological predicament in which a person receives from a single source conflicting messages that allow no appropriate response to be made","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/causal-decision-theory":{"title":"Causal decision theory","content":"\nSee also: [[thoughts/Decision theory|evidential decision theory]]\n\nChoose the act that is most effective in bringing about the best result. Use [[thoughts/causality|causal]] conditional probabilities instead of evidential probabilities to compute expected utility.\n\nWhen states are causally independent of the actions (e.g., when they are fixed prior to the choice), use Dominance Reasoning (see [[thoughts/Decisions under ignorance#Rules|DUI]]).\n\n## Subjunctive Conditionals\n$X \\rightarrow Y$ means that if I were to do X, then Y.\n\n- $P(X \\rightarrow Y)$ is the causal conditional probability of Y given that I do X\n\t- To calculate, fix the causal history of the world up to the moment you do or don't do X\n\t- Then determine how your choice of X or not X influences the probability of Y\n\t- Normally, this is equivalent to $P(Y|X)$ but not true for [[thoughts/Newcomb's Problem]]\n- $P(Y | X)$ is the evidential conditional probability of Y given X","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/causal-tree":{"title":"Causal Tree","content":"\n\u003e Towards real-time read-write [[thoughts/hypertext|hypertext]]\n\nTLDR; a simpler and more understandable form of [[thoughts/CRDT#Operation-based|CvRDT]] that relies on a strong notion of happens-before [[thoughts/causality|causal relationships]] and unique identifiers.\n\n[Paper summary](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.627.5286\u0026rep=rep1\u0026type=pdf)\n\n- The objective is to automate information dissemination the way hyperlink automated associations and search engines automated search.\n- Speculatively, as people become more and more densely connected, they are more and more aware of each other’s details. As a consequence, communications naturally gravitate to compact and speedy update-only forms.\n- Causal Trees\n\t- A tree of atoms. Atoms are triples of `(id, causing_id, letter)`.\n\t\t- Any set of changes can be represented as a set of atom removals and insertions.\n\t\t- Atom removals are represented by a special \"backspace\" atom\n\t\t- `id` is generated in the form of a owner UUID and a Lamport timestamp\n\t- An atom's `id` is always greater than its `causing_id`. This defines a partial [[thoughts/Order theory|order]]\n\t\t- Thus, the tree is a causality tree where each causing atom acts as a parent to its caused atoms\n\t\t- Atoms are stored in append-only causality feeds. Every feed complies with that order: the causing atom always precedes any of its caused atoms\n\t- Inserts happen directly to the right of its `causing_id` (or parent)\n\t- A yarn is a full contiguous sequence of operations at a node\n- Merging feeds: sort by `id`\n\t- This is actually called a weave, which contains every piece of the file to ever exist as well as all the special characters (e.g. backspace)\n\t- Note that backspace only marks an atom as *inactive*, it is never actually removed\n\t\t- This \"backspace\" atom has high priority so always hugs its parent in the resulting weave\n\t- Recovering the plaintext version of the weave is constructed by removing inactive atoms from the weave.\n\n![[thoughts/images/causal tree.png|500]]\n\nAnyone writing something based on causal trees only needs to define two functions:\n1. Reducers: inserts arbitrary atoms into an ordered log\n2. Mapper: traverses the structured log to arrive at a state\n\n![[thoughts/images/causal tree fn.png]]","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/causality":{"title":"Causality","content":"\n## Causality\n- When $a \\rightarrow b$ then $a$ might have caused $b$\n\t- We say event $a$ happens before event $b$ ($a \\rightarrow b$) iff:\n\t\t- $a$ and $b$ occurred at the same node, and $a$ occurred before $b$ in that node's local execution order\n\t\t- $a$ is the sending of some message $m$ and $b$ is the receipt of that same message $m$ (assuming sent messages are unique)\n\t\t- there exists some $c$ such that $a \\rightarrow c$ and $c \\rightarrow b$\n\n## Concurrency\n- When $a \\parallel b$ then $a$ cannot have cause $b$ (and vice versa)\n\t- Concurrent does *not* mean simultaneous, it means two things did not know about each other when they occurred (a is concurrent with b is written as $a \\parallel b$)\n\t- Similar notation to [[thoughts/Order theory|Order theory]]\n\n## Causal Order\n- $\\prec$ is a causal order, it is consistent with causality, a strict total order on events. Usually called the 'happens-before' relation\n\n## Causal Dependence\nThree cases\n1. Act A causes of influences state S\n2. State S causes or influences act A\n3. Some common C causes or influences both S and A\n\nNote some properties:\n- In all cases, $P(S | A) \u003e P(S | \\lnot A)$\n- In cases 2 and 3 $P(A \\rightarrow S) = P(\\lnot A \\rightarrow S) = P(S)$ in other words, A has no effect on S","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/censorship":{"title":"Censorship","content":"\n[Source: Moderation in Infrastructure](https://stratechery.com/2021/moderation-in-infrastructure/)\n\nHow do we draw the line between an end product and infrastructure? How should [infrastructure](thoughts/infrastructure.md) regulate usage on its platform (if at all)? Been thinking about AWS's decision to remove Parler recently and whether it was warranted for AWS to do so. At what level of infrastructure should something become a '[public good](thoughts/public%20goods.md)'? As more and more of our digital infrastructure is built out under private companies, does it change how we govern content on top of it?\n\nThe benefit of retroactive correction in some instances—imagine fixing a typographical error in the proportions of a recipe, or blocking out someone’s phone number shared for the purposes of harassment—should be contextualized against the prospect of systemic, chronic demands for revisions by aggrieved people or companies single-mindedly demanding changes that serve to eat away at the public record.\n\nIs there a difference between censorship at the broadcast level and receiving level? People should choose what they want to see but have no overarching rules over what is 'illegal' content to create/broadcast. States can still mandate for example, required filters for receiving content.\n\n## 3 Types\n1. Government monopolization (e.g. former Soviet union owned all the media outlets)\n2. Prepublication Review (e.g. government prevents information from being revealed, like nuclear weapons program details)\n3. Licensing and registration (e.g. media with limited bandwidth like radio means a centralized authority divides up the space)\n\n## Self-censorship of press\nPublishers know that if they offend the government, their reporters may not be given access to as much information as reporters for rival publications, putting them at a competitive disadvantage. This knowledge can lead a “free” press to censor itself.\n\n## John Stuart Mill\nA famous expression of liberalism\n\n1. All of us are capable of error. If we prevent someone from voicing their opinion, we may actually be silencing the voice of truth.\n2. Erroneous opinions may contain kernels of truth. We ought to let all opinions be voiced so that all parts of the truth are heard\n3. The whole truth left untested is simply a prejudice.\n4. An opinion that has been tested in the fire of a free and open discourse is more likely to have a “vital effect on the character and conduct”\n\nWhen should intervention happen? Mill's Principle of Harm states that the only purpose for which power can be rightfully exercised over any member of a civilized community, against his will, is to prevent harm to others.","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/change-of-basis":{"title":"Change of basis","content":"\nEffectively by constructing new features that take the variable to certain powers. To get a y-intercept (bias), we just raise $x$ to the 0th power to get 1. We can fit polynomials of degree $p$ by raising other powers:\n\n$$\nZ =\n\\begin{bmatrix}\n1 \u0026 x_1 \u0026 x_1^2 \u0026 \\dots \u0026 x_1^p \\\\\n1 \u0026 x_2 \u0026 x_2^2 \u0026 \\dots \u0026 x_2^p \\\\\n\\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\n1 \u0026 x_n \u0026 x_n^2 \u0026 \\dots \u0026 x_n^p\n\\end{bmatrix}\n$$\n\nAs the polynomial degree increases, the training error goes down but the approximation error goes up.\n\nChoosing a basis is hard! We can do something like [[thoughts/Gaussian RBF|Gaussian radial basis functions]] (RBFs) or polynomial basis as these are both universal approximators given enough data.\n\n## Kernel Trick\nLet $Z$ be the basis. With multi-dimensional polynomial bases, actually forming $Z$ which is $k = O(d^p)$ is intractable.\n\nRepresent each column of $Z$ as a unique term. For example, with an $X$ of $d=2$, we can use $p=2$ to get\n\n![[thoughts/images/polynomial-basis.png]]\n\nWe compute $u = (K + \\lambda I)^{-1}y$\n\nand for testing:\n\n$$\n\\begin{aligned}\n\\hat y \u0026= \\tilde Z v \\\\\n\u0026= \\tilde Z Z^T (ZZ^T + \\lambda I)^{-1} y \u0026 \\textrm{minimum of L2-regularized least squares: } v = Z^T(ZZ^T + \\lambda I)^{-1}y \\\\\n\u0026= \\tilde K (K + \\lambda I)^{-1} y \\\\\n\u0026= \\tilde K u \u0026 u \\textrm{ is a (n,1) of kernel weights we learn}\n\\end{aligned}\n$$\n\nThe key idea behind “kernel trick” for certain bases (like polynomials) is that we **can** efficiently compute $K$ and $\\tilde K$ even though forming $Z$ and $\\tilde Z$ is intractable.\n\nWe call $K = ZZ^T$ the Gram Matrix.\n\nFinally, we call the general degree-p polynomial kernel function $K_{ij} = k(x_i, x_j) = (1 + x_i^Tx_j)^p$. Computing $k$ is only $O(d)$ time instead of $O(d^p)$.\n\nThus, computing $K$ is $O(n^2d + n^3)$:\n1. Forming $K$ takes $O(n^2d)$ time\n2. Inverting $K+\\lambda I$ which is a $(n,n)$ takes $O(n^3)$\n\nAll of our distance-based methods have kernel versions\n\n## Learned Basis\nWe can also learn basis from data as well. See [[thoughts/latent-factor model]]","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/climate-tech":{"title":"Climate Tech","content":"\nNot just about investing in carbon removal or carbon offsets also about investing in the [infrastructure](/thoughts/infrastructure) to make it possible. \n\n[The Land Ethic](https://www.cooperative-individualism.org/leopold-aldo_land-ethic-1949.pdf) simply enlarges the boundaries of the community to include soils, waters, plants, and animals, or collectively: the land. It changes the role of Homo sapiens from conqueror of the land community to plain member and citizen of it.\n\nRelated: [degrowth](thoughts/degrowth.md)\n\n## Measuring Offsets\n\u003e You can not mitigate what you can not measure.\n\nThe Greenhouse Gas (GHG) Protocol consists of \"Scopes\", each of which has multiple sub categories. In order to calculate our current carbon footprint, we looked into the emission categories within Scope 1, Scope 2, and Scope 3.\n\n- Scope 1: Direction Emissions. These are the business activities the company performs that directly create emissions.\n- Scope 2: Indirect Emissions. These consist of the purchased electricity, steam, heating, and cooling for own use.\n- Scope 3: Indirect Emissions. Includes goods and services, goods, fuel, transportation distribution, and business travel.\n\nAttempting to pay people to offset carbon through [carbon credits](thoughts/carbon%20credits.md)\n\n## Investment Facts!\n[Source: Climate tech $16b mid-year investment action report](https://climatetechvc.substack.com/p/-climate-tech-16b-mid-year-investment)\n\n* Compared to just a year before, there were **~50% more climate deals** in Q2’21 vs Q2’20\n* In the first half of 2021, climate tech startups raised **~$16b across ~250 venture deals**\n* Mobility sector deals are the largest on average (~50% of total H1 2021 funding) whereas Food \u0026 Water and Mobility attract the greatest diversity across investment firms (\u003e50% of investors are active in these sectors)\n\n![Investment Diversity across sectors](https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fff4c664b-816c-45ef-9e5d-720d1b279c2f_861x475.png)*Investment Diversity across sectors*\n\n## Neutral Infrastructure\nSource: [Microsoft Finds Underwater Data Centers Practical](https://www.datacenterknowledge.com/microsoft/microsoft-finds-underwater-data-centers-practical) and [Power, Pollution and the Internet, NYT](https://www.nytimes.com/2012/09/23/technology/data-centers-waste-vast-amounts-of-energy-belying-industry-image.html).\n\nMight be software infrastructure but it has lots of [political](thoughts/Do%20Artifacts%20Have%20Politics.md) implications (e.g. climate impact, territory disputes, etc.). It's 'reduced cost' does not factor in long-term negative externalities like warming the ocean. (also: [software and politics](thoughts/software%20and%20politics.md))\n\n\"Many of these solutions are readily available, but in a risk-averse industry, most companies have been reluctant to make wholesale change.\" This is largely due to the anonymity involved in the industry where even the federal government was unable to determine how much energy its own data centres consume.\n\n\u003e \"They don’t get a bonus for saving on the electric bill. They get a bonus for having the data centre available 99.999 percent of the time.\"\n\nLow utilization can mean that the energy wasted is as much as 30x the amount of electricity used if it was at 100% utilization.\n\n## Company Initiatives\n### Stripe\nhttps://stripe.com/climate\n\ntldr; we need to develop new carbon removal tech, the ones we have right now are [unlikely to scale to well enough](https://iopscience.iop.org/article/10.1088/1748-9326/aabf9f) to tackle the problem as it stands right now\n\n\"Today, carbon removal solutions face a chicken-and-egg problem. As early technologies, they’re more expensive, so don’t attract a critical mass of customers. But without wider adoption, they can’t scale production to [become cheaper](https://en.wikipedia.org/wiki/Experience_curve_effects).\"\n\n\"Early purchasers can help new carbon removal technologies get down the cost curve and up the volume curve. Experience with manufacturing learning and experience curves has shown repeatedly that deployment and scale beget improvement, a [phenomenon](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0052669) seen across DNA sequencing, hard drive capacity, and solar panels.\"\n\n### Shopify\nGeneral ethos: we don't know what works so let's invest in a little bit of everything\n\n\u003e There’s no easy fix for climate change, and no solution that will singlehandedly solve the problem. We have to try every possible nature-based and engineered option.\n\nMix of solutions that make a difference now (evergreen tech: 24%) but also emerging tech with big impact down the line (frontier portfolio: 76%) [Rationale](https://cdn.shopify.com/static/sustainability/How-to-Kick-Start-the-Carbon-Removal-Market_Shopifys-Playbook.pdf)\n\nFrontier\n1. Direct Air Capture -\u003e directly pulling carbon out of the air and storying it permanently\n2. Product -\u003e storing carbon into usable products (e.g. concrete)\n3. Ocean -\u003e large bodies of water as carbon sinks while also reducing ocean acidification\n4. Biomass -\u003e sequester carbon in organic material, using organic material for energy\n5. Mineralization -\u003e turning carbon into a mineral to store\n\nEvergreen (creating a buffer against climate change until we figure out how to unscrew ourselves)\n1. Forest -\u003e planting, restoring, and protecting forests\n2. Soil -\u003e farming techniques that improve soil health and carbon storage\n3. Renewable Energy -\u003e investing in fossil fuel alternatives\n4. Transportation -\u003e reducing emissions from transportation","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/clocks":{"title":"Clocks","content":"\nMeasuring time in the context of computer systems\n\n## Physical Time\nTwo types of clock\n1. Physical clock: number of seconds elapsed\n2. Logical clock: count events, e.g. messages sent\n\nTime is hard! So many different ways of measuring time\n- Greenwich Mean Time (GMT): the normal human time format, based on Earth rotation\n- International Atomic Time (TAI): some multiple of Caesium-133 resonant frequency\n- Compromise, UTC is TAI with corrections to account for Earth rotation\n- Unix Time: number of seconds since the epoch (Jan 1, 1970) not counting leap seconds\n- ISO8601: year, month, day, hour, minute, second, and timezone offset relative to UTC\n\nPeriodically adjust local clock with a server with a more accurate time source using Network Time Protocol (NTP) or Precision Time Protocol (PTP)\n\nHow do we estimate time over a network?\n- NTP Client sends out a request at $t_1$\n- NTP Server receives request at $t_2$\n- NTP Server sends a response at $t_3$\n- NTP Client receives a request at $t_4$\n- Round-trip network delay = $\\delta = (t_4-t_1) - (t_3-t_2)$\n- **Estimated** single-trip network delay = $\\delta / 2$\n- Estimated server time when client receives response, so clock skew is $\\theta = (t_3 + \\delta / 2) - t_4$\n- If $\\theta \u003c 125ms$, slew the clock: speed it up/slow it down by 500ppm until clocks are in sync\n- If $125ms \\leq \\theta \u003c 1000s$, step the clock: suddenly reset client clock to estimated server timestamp\n- If $\\theta \\geq 1000s$, panic and do nothing (leave it to the humans!)\n\n## Logical Time\nProblem is that *even with synced clocks* we can have $t_2 \u003c t_1$ with a message A at $t_1$ with a response B at $t_2$. Here, the timestamp [[thoughts/Order theory|order]] is inconsistent with expected order! This can happen when the clock skew is *less* than the one way network latency.\n\nSo we use logical clocks to work based off of *the number of events that have occurred rather than actual time passed.*\n\n### Lamport Clocks\nProvides a **partial order** on events\n\nLogic\n- On initialization, set `t := 0` for each node\n- On any event on local node, `fn tick() -\u003e t += 1`\n- On sending message $m$, `fn send(m) -\u003e tick(); actually_send(t, m)`\n- On receiving `fn receive(t', m) -\u003e t = max(t, t') + 1; do_something(m)`\n\nProperties\n- If $a \\rightarrow b$ then $L(a) \u003c L(b)$\n- However, $L(a) \u003c L(b)$ does not imply $a \\rightarrow b$\n- Possible that $L(a) = L(b)$ for $a \\neq b$\n\nThis means that two identical Lamport timestamps might not correspond to the same unique event. However if we include the node $N(e)$ for the node where event $e$ occurred, then $(L(e), N(e))$ **uniquely identifies** event $e$.\n\nWe attempt to define a total [[thoughts/causality|causal]] order\n\n$$(a \\prec b) \\iff (L(a) \u003c L(b)) \\lor (L(a) = L(b) \\land N(a) \u003c N(b))$$\n\nHowever even now, given timestamps $L(a) \u003c L(b)$, we can't tell whether $a \\rightarrow b$ or $a \\parallel b$\n\nTo separate [[thoughts/causality|causality]] from concurrent events, we need vector clocks!\n\n### Vector Clocks\nProvides a **causal order** on events\n\nInstead of having a single counter `t` for all nodes, we keep a vector timestamp $a$ of an event for *each* node so we have $V(a) = \\langle t_1, t_2, \\ldots, t_n \\rangle$ where $t_i$ is the number of events observed by node $N_i$\n\nEach node has a current vector timestamp $T$, on an event on node $N_i$, increment vector element $T[i]$\n\nLogic\n- On initialization , set `t := [0] * n`\n- On any event on node $N_i$, `fn tick() -\u003e t[i] += 1`\n\t- Each time a process experiences an internal event, it increments its own clock in the vector by one\n- On sending message $m$ from node $N_i$, `fn send(m) -\u003e tick(); actually_send(t, m)`\n- On receiving `fn receive(t', m) -\u003e t = tick(); zip(t, t').map(max); do_something(m)`\n\nThus, a vector timestamp of an event $e$ actually represents all of its *[[thoughts/causality|causal]] dependencies*: $\\{ e \\} \\cup \\{a | a \\rightarrow e \\}$\n\nE.g. $\\langle 2, 2, 0 \\rangle$ represents first two events from $N_1$, first two events from $N_2$, and no events from $N_3$\n\nOrdering\n- $T= T' \\iff T[i] = T'[i] \\ \\forall i \\in \\{1, \\ldots, n\\}$ (T and T' are same if each element has the same value)\n- $T \\leq T' \\iff T[i] \\leq T'[i] \\ \\forall i \\in \\{1, \\cdots, n\\}$ (T happened at the same time or earlier than T' if each element in T is less than or equal to its value in T')\n- $T \u003c T' \\iff T \\leq T' \\land T \\neq T'$ (T happened earlier than T' if each element in T is less than its value in T', at least one element in T differs from T')\n\t- $T \\parallel T' \\iff T \\nleq T' \\land T' \\nleq T$ (T is incomparable to T')\n\nProperties (based on [[thoughts/Order theory|Order theory]])\n- $V(a) \\leq V(b) \\iff (\\{a\\} \\cup \\{e | e \\rightarrow a\\}) \\subseteq (\\{b\\} \\cup \\{e | e \\rightarrow b\\})$\n- $V(a) \u003c V(b) \\iff (a \\rightarrow b)$\n- $V(a) = V(b) \\iff (a = b)$\n- $V(a) \\parallel V(b) \\iff a \\parallel b$\n\nYou can tell that versions are in conflict when neither vector clock “descends” from the other. In order for vector clock B to be considered a descendant of vector clock A, each marker in vector clock A must have a corresponding marker in B that has a revision number greater than or equal to the marker in vector clock A. Markers not contained in a vector clock can be considered to have revision number zero.\n\nVector Clock Example\n![[thoughts/images/vector clock example.png]]\n\n## Hybrid Logical Clocks\nPhysical and logical clocks both have non-ideal properties.\n- Logical clocks don't actually store any sort of date-time when events happen. Clients usually have a notion of time through actual wall time\n- BUT wall time isn't perfect either as clock drift is non-trivial and users can manually turn time backwards on their local machines\n\n*Note that this is not a substitute for Vector Clocks as they only provide partial order instead of causal order*\n\nCan we combine them to achieve better properties? \n\nHybrid Logical Clocks (HLCs) achieve\n- partial ordering\n- constant space\n- bounded different from physical time\n\nWe can store a tuple containing:\n- `pt`: physical time (wall time)\n- `l`: logical time (holds maximum `pt` so far)\n- `c`: capturing causality when `l` is equal\n\nThis tuple can be used directly as a replacement for a physical clock timestamp (and in fact works as a superposition on top of the NTP protocol without any interference)\n\n### Pseudocode\n- Initial state\n\t- `l := 0`\n\t- `c := 0`\n- Send / local event\n\t- `l' := l`\n\t- `l := max(l', pt)` update `l` to `pt` if applicable\n\t- if `pt` is the same (`l == l'`):\n\t\t- `c += 1` increment causality as logical time is the same\n\t- if `pt` is updated:\n\t\t- `c := 0` reset `c`\n\t- timestamp message with `(l, c)`\n- Receive of message `m`\n\t- `l' := l`\n\t- `l := max(l', m.l, pt)`\n\t- if all logical clocks are the same `l == l' == m.l`:\n\t\t- `c := max(c, m.c) + 1` set to max causality known\n\t- if our logic clocks are the same but message logical clock is behind `l == l'`:\n\t\t- `c += 1` (ignore as message clock is behind)\n\t- if our logic clock was behind the message logical clock and just got updated `l == m.l`\n\t\t- `c := m.c + 1`\n\t- otherwise `pt` was just updated\n\t\t- `c := 0` reset `c`\n\t- timestamp message with `(l, c)`","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/clustering":{"title":"Clustering","content":"\n\nSet of techniques to find components that belong together.\n\nNote: Grouping is how the human visual system perceives things and clustering is the actual algorithm itself.\n\nWe want to assign examples to \"groups\".\n\n## Methods\n- [[thoughts/K-means|K-means]] (most popular)\n- [[thoughts/density-based clustering]]\n- Ensemble Clustering\n\t- Like [[thoughts/Random Forest|random forest]] but for voting for clustering\n\t- This is problematic because of the label switching problem -- we can get clustering with permuted labels on each initialisation\n\t\t- Don't vote on what specific class each cluster is\n\t\t- Instead, vote on whether points are in the same cluster (label independent)\n\t\t- Then, come up with labels after voting\n- [[thoughts/hierarchical clustering]]","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/collaborative-software":{"title":"Collaborative software","content":"\nEach user device has a local replica of the data and this local replica can be updated anytime (ideally even while offline), and re-sync with others when network is available\nChallenge: how do we reconcile concurrent updates?\n\nTwo main families of algorithms\n- Conflict-free Replicated Data Types ([[thoughts/CRDT|CRDTs]]) -- persists the causal order of operations\n- Operational Transformation -- persists the final output of operations\n\n## A spectrum\n[Source](https://publish.obsidian.md/jessmartin/Collaboration+is+a+spectrum+from+asynchronous+to+fully+synchronous)\n\n-   full async - no collaboration ever - has to be completely disconnected\n-   async branching - [[thoughts/git|git]] flow, working in parallel universes temporarily, then merging back together\n-   peripheral awareness - working in the same space while working separately (parallel play)\n-   fully sync - pair programming  \n\nWhen we're collaborating with others, there's a natural human tendency to desire some privacy while working through something, the freedom to take a piece of the creative work and play out different ideas, move things around, edit and refactor, without fear of judgement or the burden of having to explain or communicate our thinking or concern for overhauling sections where another is actively reading or working.\n\nHow do we make private 'forking' really easy and seamless?\n\n## Knobs over Switches\n[Source](https://medium.com/mit-media-lab/meet-coco-a-real-time-co-creative-learning-platform-for-young-people-bdfe23edd5a7)\n\nCoCo has been doing a lot of important pioneering work in this direction.\n\nTypically, in the context of digital creative tools, there are primarily two predominant modes of engagement that are often being developed or thought about.\n\n1. Tools for working on your own on creative projects and then sharing the published works with others.\n2. Tools for working together on the same creative project with others (such as, drawing on the same canvas, making edits to the code in the same project, or writing together in the same document, etc.)\n\nJust like how a knob affords finer control over one’s preferences, similarly, a CoCo space is designed to provide creators with the agency to choose when and in what way they’d like to engage with their peers, based on their own comfort and preferences at any moment.\n\n1. Just being together: parallel play\n\t- Just being together and sharing a context with someone is itself a form of communication. In a CoCo space, creators can work on their projects in a shared digital context, in the _presence_ of others.\n\t- This is cursor chat and presence\n2. Finding inspiration\n\t- It can be challenging for young people to get started on a blank canvas in any open-ended creative environment. In a CoCo space, even though learners get to work on their own projects, they are always surrounded by multiple points of inspirations in the form of the mini live windows showing their peers’ creative explorations in real-time.\n3. Live remixing\n\t- CoCo spaces also support live remixing of code and other digital assets between peers. Any creator can drag and drop a piece of code from another creator’s project on to their mini window and it will instantly appear in their own project.\n\t- It is similar in essence to a sight of children sitting around the same table and freely passing and sharing craft materials with one another.\n\t- Part of why I think Midjourney was so successful was this! People could see what other people used as prompts and remixed it in their own work\n4. Creative Interaction\n\t- The CoCo Blocks environment introduces a variety of new peer programming blocks — Signals, Waves, and Shared Variables. Creators can use these blocks to make their project trigger something in their peers’ projects in real-time and also get to see the outcome instantly.\n5. Collaborative experiences\n\t- In addition to supporting _collaborative_ _projects_ where creators can contribute different parts to a single project, CoCo spaces also afford building new types of _collaborative_ _experiences_ as a group.\n\t- For instance, creators can collectively imagine and program a new kind of multiplayer pacman game where the pacman passes through each of their projects turn by turn and they can use shared variables to have a common score!","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/collections":{"title":"Collections","content":"\n\u003e A _collection_ is a group of resources that have been selected for some purpose.\n\nResource-type: a novel, biography, etc. (ordering on the type of artefact)\nResource-kind: coin collection, stamp collection, etc. (ordering on the medium of artefact)\n\nA collection itself can also be a resource. An index is a description resource that contains information about the location and frequencies of terms in a collection to enable more efficient search.\n\nWhat then is a [library](thoughts/library.md)? According to Glushko, they are [organizing systems](thoughts/organizing%20system.md) which \"select, collect, organize, conserve, preserve, and provide access to information on behalf of a community of users.\"\n\n","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/colour":{"title":"Colour","content":"\n## Texture\nDetail in an image that is at a scale too small to be resolved into its constituent elements and at a scale large enough to be apparent in the spatial distribution of image measurements\n\nSometimes thought of as patterns composed of repeated instances of one or more identifiable elements called *textons*\n\nCan be used for\n- object identity (tell what it is from the textures)\n- object's shape (based on spatial deformation of texture)\n\n**Shape from texture**: Estimating surface orientation or shape from texture\n\nTypically, texture is a property of a region, not a point. But, then we run into a boundary segmentation problem. We comproimise by using a local window to compute a texture and assign it to a point.\n\n### Synthesis\n1. Inpainting (filling in holes)\n2. Produce large quantities of texture for [[thoughts/computer graphics|computer graphics]]\n\nRandomness parameter is actually the size of the patch (less randomness means sample is larger thus more accurate)\n\n## Colour\nTwo lights whose spectral power distributions appear identical to most observers are called metamers\n\nChromatic Adaptation: colour perception starts to skew if exposed to a certain colour light for an extended period of time\n\nContrast effects: nearby colours affect what is perceived\n\n### Colour Filter Arrays\nOne implementation of photo sensors \n1. Microlens\n2. [optional] Colour Filter (what spectral sensitivity functions do we use for each colour? Human colour sensitivity differs between colours as well)\n3. Photodiode\n4. Potential well\n\nTwo design choices to make when designing CFAs:\n1. What spectral sensitivity functions (SSFs) do we use for each colour filter?\n2. How do we spatially arrange filters to create the best mosaic for CFAs?\n\nRAW Bayer Image gives us direct pixel data\n\n### CFA Demoisaicing\nHow do we produce the full RGB image from mosaiced sensor output?\n\n- Bilinear Interpolation: average your 4 neighbours\n- Bicubic Interpolation -\u003e needs more neighbours, may overblur\n- Edge-aware interpolatin \n\n### Grassman's Law\nTL;DR, colour matching is, to an accurate approximation, linear\n\nFor colour matches\n- symmetry ($U = V \\iff V = U$)\n- transitivity ($U = V$ and $V = W \\implies U = W$)\n- proportionality ($U = V \\iff tU = tV$)\n- additivity ($U=V$ and $W=X$, then $(U+W)=(V+X)$)\n\n### Colour Space\nChoice of primaries is equivalent to choice of colour space. In RGB, we choose monochromatic energies.\n\nRGB is additive whereas CMY is subtractive.\n\nRGB and CIE are linear.\n\nMcAdam ellipses are regions where colour differences are imperceptible to the average human eye.\n","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/communities":{"title":"Communities","content":"\n## Types of Communities\n1.  Interest-based → same interests/passions\n2.  Location-based → same geographical location, place of work, etc.\n3.  Vibe-based → group energy\n4.  Circumstance-based → external influence, put into the same group\n\nCan we ever have fully [digital commons](thoughts/digital%20commons.md)?\n\nHow large can communities get before they decay? Relevant: [group limits](thoughts/group%20limits.md), [in-group bias](thoughts/in-group%20bias.md)\n\n## Turing Test for communities\n*heuristic* from Austin Wu\n\nA very [computational](thoughts/computability.md) view of communities but is it possible to test for value alignment within a community like a Turing Test? If the community feels and behaves like a person, then its [values](thoughts/value%20setting.md) are aligned?\n\nHow do we quantify this if vibes are unoptimizable?\n\nSee also: [Turing Test](thoughts/Turing%20Test.md) \n\n## 90/9/1 Rule\nThe \"90–9–1\" version of this rule states that for websites where users can both create and edit content, 1% of people create content, 9% edit or modify that content, and 90% view the content without contributing.\n\nWas called \"participation inequality\" by researchers at AT\u0026T labs\n\n the 80/20 rule known as the [Pareto principle](https://en.wikipedia.org/wiki/Pareto_principle \"Pareto principle\") states that 20 percent of a group will produce 80 percent of the activity, however the activity is defined.\n \n a type of power law (zipf's law)\n \n Size of the community might matter? a form of [Dunbar's Number](thoughts/Dunbar's%20Number.md) e.g.\n* small communities like family group chats -\u003e almost everyone creates content\n* large communities like LinkedIn -\u003e most people consume, vocal minority\n \nthough size might just be a proxy for sense of belonging in a group. i.e. if you strongly identify with said group (family) you are more likely to participate and contribute\n\nin larger communities then, the approximately normal distribution of people who are engaged in the community may lead to some type of power law\n\n## Expanding circles of trust\nGetting people sitting on the outside circle to suggest activities that would make them feel included.\n\nHaving things be opt-in gives them power","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/complexity":{"title":"Complexity","content":"\n## Measures of Complexity\n- [Vapnik–Chervonenkis dimension](https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_dimension): cardinality of the largest set of points that a binary classification algorithm can learn.\n- [Kolmogorov complexity](https://en.wikipedia.org/wiki/Kolmogorov_complexity): length of the shortest computer program that produces the object as output. (see also [[thoughts/Gall's law|Gall's Law]])\n- Essential Complexity: irreducible, non-eliminable part of the system\n- Accidental Complexity: everything else to make it work\n\n## Making Simple Software\n[Source talk by pvh](https://vimeo.com/780013486)\n\n- Why is example code normally so simple? Well, it lives in an ideal world. It only cares about the happy path\n\t- **Defensive code is complex**\n- Vigilance works for small systems... but not large complex ones!\n\t- Type systems off-load mental state and assumptions about the code and make it explicit","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/computability":{"title":"Computability","content":"\n## The computational metaphor\n[Source: Digital Salon with Stephen Wolfram: Building a New Kind of Science, *Palladium Mag*](https://palladiummag.com/2020/08/04/digital-salon-with-stephen-wolfram-building-a-new-kind-of-science/)\n\nThere is a creaking issue in universities where 70% of incoming students want to study computer science but only 5% of faculty is in computer science. What's really going on is we want to study computer science as a proxy for the computational paradigm for everything around us\n\nIs the universe computable? Implies the universe has finite precision.\n\nIs there a computable $x$ for all $x$?\n\n## General Computability\nSource text from The Mechanical Mind by Crane\n\n### What is a computer?\n- device which processes [representations](/thoughts/representation) in a systematic way\n-   algorithm → method for calculating the value of a function\n\t-   \"effective procedures\" → procedures which, if applied correctly, are entirely effective in bringing about their results (always work)\n\t-   computable if the algorithm gives the value of a function for any argument\n\t-   church's thesis → anything that can be executed by a Turing machine is computable\n-   conditions to be considered an algorithm\n\t-   definite next step\n\t-   finite number of steps\n\n### Turing machine\n- the simplest possible device that could perform any computation no matter how complicated\n    -   has long (infinitely long) tape with squares\n    -   device that can write/read the symbols on the tape\n    -   device can have and change internal states\n    -   device can move tap one left or one right\n    -   possible operations are dictated by machine's 'machine table'\n        -   a set of instructions of the form 'if the machine is in state X and reading symbol S, then do Y and move tape right/left'\n\n### Instantiating vs Computing function\n-   instantiating → being an instance of/describable by a function\n-   computing → employs representations of input and output\n-   even if a person could be modeled by a Turing machine, that would not show that thinkers are computers, rather, it would show that a thinker instantiates a function, not that it computes that function.\n-   much too difficult to calculate everything in real-time, employ the use of heuristics to help us make best judgements (e.g. Ten Commandments)\n","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/computer-graphics":{"title":"Computer Graphics","content":"\n## Coordinate Frames\nLet $A$ be the original basis and $B$ be the new basis\n\n$$\\begin{bmatrix}x \\\\ y \\\\ 1 \\end{bmatrix}_B = \\begin{bmatrix}a \u0026 b \u0026 c \\\\ d \u0026 e \u0026 f \\\\ 0 \u0026 0 \u0026 1\\end{bmatrix}\\begin{bmatrix}x \\\\ y \\\\ 1\\end{bmatrix}_A$$\n\nThen:\n- $\\begin{bmatrix}a \\\\ d\\end{bmatrix}$ is $i_A$, how to transform the $x$ coordinate\n\t- $a$ is how much of $i_B$ we need to make one $i_A$\n\t- $d$ is how much of $j_B$ we need to make one $i_A$\n- $\\begin{bmatrix}b \\\\ e\\end{bmatrix}$ is $j_A$, how to transform the $y$ coordinate\n\t- $b$ is how much of $i_B$ we need to make one $j_A$\n\t- $e$ is how much of $j_B$ we need to make one $j_A$\n- $\\begin{bmatrix}c \\\\ f\\end{bmatrix}$ is $O_A$, the translation of the entire frame\n\t- $c$ is how much of $i_B$ we need to get from $O_B$ to $O_A$\n\t- $f$ is how much of $j_B$ we need to get from $O_B$ to $O_A$\n\nThe translation from $P_A$ to $P_B$ can be represented as $P_B = O_A + x_Ai_A + y_Aj_A$\n\n## Transformation Matrices\n- `Translate(x,y,z)`\n\t- $$\\begin{bmatrix}x' \\\\ y' \\\\ z' \\\\ 1 \\end{bmatrix} = \\begin{bmatrix}1 \u0026 \u0026 \u0026 a \\\\ \u0026 1 \u0026 \u0026 b \\\\ \u0026 \u0026 1 \u0026 c \\\\ \u0026 \u0026 \u0026 1\\end{bmatrix}\\begin{bmatrix}x \\\\ y \\\\ z \\\\ 1\\end{bmatrix}$$\n- `Rotate(z,theta)`\n\t- $$\\begin{bmatrix}x' \\\\ y' \\\\ z' \\\\ 1 \\end{bmatrix} = \\begin{bmatrix}\\cos \\theta \u0026 -\\sin \\theta \u0026 \\\\ \\sin \\theta \u0026 \\cos \\theta \u0026 \\\\ \u0026 \u0026 1 \u0026 \\\\ \u0026 \u0026 \u0026 1 \\end{bmatrix}\\begin{bmatrix}x \\\\ y \\\\ z \\\\ 1\\end{bmatrix}$$\n- `Scale(x,y,z)`\n\t- $$\\begin{bmatrix}x' \\\\ y' \\\\ z' \\\\ 1 \\end{bmatrix} = \\begin{bmatrix}a \u0026 \u0026 \u0026 \\\\ \u0026 b \u0026 \u0026 \\\\ \u0026 \u0026 c \u0026 \\\\ \u0026 \u0026 \u0026 1\\end{bmatrix}\\begin{bmatrix}x \\\\ y \\\\ z \\\\ 1\\end{bmatrix}$$\n## Viewing Transformation\n- Defined using\n\t- eye point\n\t- target point\n\t- up vector\n\n$$\\vec k = \\frac{P_{eye}-P_{ref}}{\\lVert P_{eye}-P_{ref} \\rVert}$$\n\n$$\\vec i = \\frac{V_{up} \\times \\vec k}{\\lVert V_{up} \\times \\vec k \\rVert}$$\n\n$$\\vec j = \\vec k \\times \\vec i$$\n\n$$M_{cam} = \\begin{bmatrix}\ni_1 \u0026 j_1 \u0026 k_1 \u0026 P_{eye1} \\\\ \ni_2 \u0026 j_2 \u0026 k_2 \u0026 P_{eye2} \\\\\ni_3 \u0026 j_3 \u0026 k_3 \u0026 P_{eye3} \\\\\n0 \u0026 0 \u0026 0 \u0026 1\n\\end{bmatrix}$$\n\n$$M_{view} = M_{cam}^{-1}$$","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/computer-networking":{"title":"Intro to Computer Networking \u0026 P2P","content":"\n\u003e This post is the source material for my workshop on 'Intro to Computer Networking \u0026 P2P' at Hack the North 2022\n\n## A brief history\nA hallmark of the modern day human is the ability to communicate with each other. From spoken word to written language and through to even radio and telephone, we've spent a lot of time innovating on new ways to transmit data between people and places. With the introduction of the first computers, it was only a matter of time before we figured out how to make our computers talk too.\n\n![[thoughts/images/p2p internet.png]]\n\nEarly computer networks looked pretty similar to landline telephone connections. There is a physical wire directly connecting you from point A to point B for the duration of the connection. This was called **circuit switching**.\n\nOf course, during the early days when you could still count the number of computers connected to the internet on your fingers, this was not problematic. But as the size of the internet grew, telecommunication networks created huge hubs to be able to handle the volume of traffic. The problem was, this hierarchical network -- like all hierarchical networks -- was vulnerable to targeted attack. Knock out a single node and you cut off lots of users, even whole regions.\n\nThis was not a comfortable position to be in during the height of the Cold War. There was a demand for a resilient and fault-tolerant network topology that would adapt to changing configurations and load on the fly.\n\n\u003e To be efficient is to be fragile, to be fragile is to go extinct.\n\nNature of course, has its way of selecting for resiliency. In ecology, there is a concept called [[thoughts/r-K Selection theory|r-K Selection Theory]] related how certain species trade off between quantity and quality of their offspring. It notes that there are predominantly two types of species:\n\n|r-selected|K-selected|\n|--|--|\n|many offspring, low investment| few offspring, high investment|\n|thrive in unstable habitats|thrive in stable habitats|\n\nHow could move the internet away from being a K-selected monolith?\n\nIn 1959 RAND, a Californian think-tank, assigned Paul Baran, a young engineer at that time, to develop a communication system that could survive a nuclear attack. Instead of a static network with hardened switching stations, he proposed a dynamic network with disposable routers that could freely join or leave. Each router would help forward individual little bits of information called packets around the internet. Thus, **packet switching** was born and with it, the internet became an r-selected network.\n\n![[thoughts/images/r vs K-selected species.png]]\n\n## Zooming out\nLet's zoom out a bit to see how this fits into the grander vision of the internet.\n\nThe modern internet, like many things in computer science, has layers of abstraction. It is also a network of networks, composed of many systems connected to each other.\n\n![[thoughts/images/network stack.png]]\n\nWhen you request a website or make an API call, you go down all these layers and then back up at the other end.\n\n- [[thoughts/Application Layer|Application Layer]] -- where applications can access the network services using protocols like [[thoughts/HTTP|HTTP]].\n- [[thoughts/Transport Layer|Transport Layer]] -- ensures data arrives in order, recovers lost data by retrying, sends data to the right process on your machine\n- [[thoughts/Network Layer|Network Layer]] -- routes packet through routers to destination machine\n- [[thoughts/Physical Layer|Physical Layer]] -- connecting individual machines together, transferring the actual bits\n\nWhen we talk about making a request to a server, we normally think about this at the Application Layer. If we make a HTTP request to Twitter to get the latest posts, we think of our request as going directly to Twitters's servers, not hopping around from router to router, snaking its way through various networks to get to its destination and back.\n\nOnce we look at the web from the Application Layer, we see something curious. Although the underlying Transport, Network, and Physical layers of our web are decentralized, centralization has re-emerged on the web once again. When you message a friend on Facebook, it doesn't go directly to them. Instead, it goes to Facebook's servers and it forwards it to your friends device\n\n![[thoughts/images/facebook communication.png]]\n\nThis is the exact centralizing behaviour that we were worried about before.\n\n\u003e To be efficient is to be fragile, to be fragile is to go extinct.\n\nTo decentralize the web is to ensure its resilience and long-term functioning.\n\nWhen we refer to [[thoughts/peer-to-peer|peer-to-peer]] today, we don't mean the underlying networking stack, but rather on the Application level. How can we bypass going through servers to facilitate all of our actions and instead connect directly with our peers?\n\nI'm not saying that platforms are inherently bad. They can enable efficiency at scale by making the average distance between nodes. Platforms become problematic when there is no *meaningful way* to easily switch from one platform to another when we are dissatisfied.\n\nPeer-to-peer applications abate this somewhat. There is no singular failure point; as long as two peers have the application code that connects them together, they don't need to rely on a centralized provider.\n\nOf course, peer-to-peer applications are not without their disadvantages either. Not everything *should* be peer-to-peer, but we should empower developers to at least know about what peer-to-peer is and how to use it in the right contexts.\n\n|Client-server|Peer-to-peer|\n|--|--|\n|Better for persistent applications that need to store data for a long time|Better for low-latency applications like games and video calling (no need to make an extra trip to the server)|\n|Easier to make applications that are mostly about manipulating data and resources|Easier to make applications that are mostly users interacting with each other|\n|Servers waits for requests from clients and responds to them (one-directional)|Nodes have persistent connections so can send updates to each other whenever|\n|Needs hosting services to keep databases or application servers online|There are no privileged nodes that need to be up. No hosting costs!|\n\n\nA lot of my [[thoughts/Rhizome Proposal|independent research]] is around how to make it easier to write peer-to-peer software and make it possible to do the things client-server models are good at in these peer-to-peer contexts (e.g. data persistence).\n\n### Peer-to-peer today\nSo, how do we make peer-to-peer connections today? Like talking with a friend, there are a two key criteria that need to be met before you even start to communicate:\n\n1. You need to know how to find where they are to initiate a conversation\n2. You need a shared language to understand each other\n\nIn the context of peer-to-peer, these are:\n\n1. What is the other user's IP address?\n2. What application or protocol are we running?\n\nIt turns out, we can reuse much of the internet's existing infrastructure to answer both of these questions *with some caveats*.\n\nToday's web is peer-to-peer hostile -- over 79% of peers on the Internet are not directly connectable. Firewalls are frequently configured to allow only outgoing connections, based on the assumption of the client-server model of communication. If a router uses [[thoughts/NAT|NAT]], it hides the 'true' port and IP combination of any machine that is behind it, meaning that connecting to an arbitrary port is often not allowed[^1]. \n\n[^1]: Fun story: IPv4 only supports 4,294,967,296 total addresses. This is less than the total number of devices that are currently connected to the internet. In fact, we 'ran out' of IPv4 addresses in 2011. NAT exists so that instead of every computer getting a public unique address, every home router gets a single public unique address. Computers then only get a private address assigned to them by the router and it *translates* the address so that to anyone external to the network, it looks like all the traffic is coming from and goes to the router. \n\nTo get around this, we can use a technique called **hole-punching**. The idea is that to allow packets to come in from a remote endpoint, the computer behind the NAT or firewall needs to send something to the remote endpoint first. By doing so it creates a “hole” in the NAT or firewall through which communications can proceed.\n\nFor hole-punching to work, peers need some way of looking at themselve s like they would in a mirror to figure out what their external facing IP address is so others can figure out how to reach out.\n\nOne common method is through the use of signalling servers. These servers just forward information between peers all interested in a given topic (e.g. connecting to a given application) so they can exchange the minimum amount of information to be able to directly connect. This ends up effectively being a 'registry' of all people who are interested in connecting with each other.\n\n![[thoughts/images/signalling servers.png]]\n\nUnfortunately, this method still relies on a server to handle special responsibilities. One completely decentralized way of doing this is doing something called a distributed hash table -- a [[thoughts/DHT|DHT]]. Each node holds a small shard of the DHT, so the burden of participation isn’t painful for any one agent. The DHT stores multiple redundant copies of each entry so that the information is available even when the author is offline. Peers can then store info about each other in this DHT to figure out what each other's IP addresses are.\n\n![[thoughts/images/DHT.png]]\n\nOk perfect, now we can start sending messages across to our peers. We can send arbitrary data payloads *but* we can only send it to one person at a time. If we want to talk to a group of people, we need to start conversations with all of them! In this case, the underlying medium is not perfect and we can't ensure that messages will always arrive in the right order.\n\nIn the face of this uncertainty, we still need some way to come to some shared understanding of what the 'state' of the application is. In literature, this is called the [[thoughts/State Machine Replication (SMR)|state machine replication]] problem.\n\nTypically, this can be done using a consensus mechanism where nodes all vote and agree on what the 'right' state of the application is, much like a government election. This is how distributed databases work to come to a consistent state amongst all the replicas. \n\nMore recently, researchers found another way of doing this is using a specific type of replicated data structure called a [[thoughts/CRDT|commutative replicated data type]] or CRDT. This uses mathematical properties of operations to guarantee that even if messages are received out of order, they will all eventually converge to the same result. CRDTs are at the base of a lot of popular 'shared type' libraries like [[thoughts/Hypercore|Hypercore]] or [[thoughts/Yjs|Yjs]], which make it really easy to use JSON-like data-types in your code that automatically receive updates from other peers.\n\n## Conclusion\nThis post was a rough mile-high overview of how peer-to-peer differs from client-server models of computer communication. I hope this enables people like you to explore new realms of possibilities of creating lively digital spaces.","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/computer-vision":{"title":"Computer Vision","content":"\n\u003e CV, broadly speaking, is a research field aimed to enable computers to process and interpret visual data, as sighted humans can\n\nIt can also be thought of as the inverse of graphics.\n\nTypically, it's a pipeline from\n1. Image\n2. Sensing Device\n3. Interpreting Device\n4. Interpretation\n\n## Problems in CV\n1. Measurement. Algorithms for computing properties of the 3D world from visual data. This is literally impossible to invert the image formation process. The best we can do is guess.\n2. Perception and interpretation. Algorithms and representations to allow a machine to recognize objects, people, scenes, and activities. We don't fully understand how human processing mechanisms work yet!\n3. Search and organization. Algorithms to mine, search, and interact with visual data. Scale is absolutely enormous.\n4. Visual imagination. Algorithms for manipulation or creation of image or video content\n\nProblem subtypes\n1. Categorization\n2. Detection\n3. Segmentation\n4. Instance segmentation\n5. Image captioning\n\nSubnotes:\n- [Images, Cameras, Lenses, Filters, Sampling](thoughts/imaging.md)\n- [Colour and Texture](thoughts/colour.md)\n- [Optical Flow and Stereo Vision](thoughts/optical%20flow.md)\n- [Object detection/recognition (Template Matching, Keypoint Descriptors)](thoughts/object%20detection.md)\n- [Object classification (Model fitting, CNNs, Clustering) ](thoughts/object%20classification.md)","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/conceptual-model":{"title":"Conceptual models","content":"\nConceptual models are explanations (usually highly simplified) of how something works. These can be the [desktop metaphor](thoughts/desktop%20metaphor.md) where files, folders, and icons help represent the model of data on the hard drive. We are concerned with mentally held conceptual models -- mental models.\n\nOften times the designer's conceptual model, the system image (how it manifests in reality), and the user's conceptual model are not aligned.\n\nSimilar: [mental model](thoughts/mental%20model.md)","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/connectionist-networks":{"title":"Connectionist networks","content":"\n-   architecture\n\t-   large number of units which are connected to others (connectionism) and the connections have different strengths (weights)\n\t-   units are arranged in layers\n\t-   computation happens in parallel\n-   like in a classical machine, [representations](/thoughts/representation) are assigned to connectionist networks by the people who build them\n-   two types of connectionist representation\n\t-   localist → each unit is assigned a feature as a whole that represents\n\t-   distributed → state of the network as a whole represents something\n\t\t-   often claimed to be one of the distinctive features of connectionism\n\t\t-   connectionist networks is sometimes called parallel distributed processing (PDP)\n-   can be trained to learn\n-   resemble the structure of the brain much more closely than any classical computer\n\t-   really good at pattern recognition","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/consciousness":{"title":"Consciousness","content":"\n\u003e If $x$ is conscious, then there is an experience of what it is like to be $x$\n\nWhat does it mean to be conscious? Is consciousness emergent from matter? Or is it something else entirely (the ether or the soul)?\n\n\"Consciousness is always consciousness of something, and when the object is subtracted, nothing remains to be characterized\" (cannot be of independent origin, [emptiness](thoughts/emptiness.md))\n\nSee also: [Hard problem of consciousness](thoughts/Hard%20problem%20of%20consciousness.md), [Buddhism](thoughts/Buddhism.md), [The Upanisads](thoughts/The%20Upanisads.md), [qualia](thoughts/qualia.md), [self-knowledge](thoughts/self-knowledge.md), [[thoughts/Primary of Consciousness|Primary of Consciousness]], [[thoughts/Nagel's Bat Argument|Nagel's Bat Argument]]\n\nTypes of consciousness:\n- Phenomenal consciousness (felt consciousness) vs Access consciousness\n- Gross consciousness (obvious waking state) vs Subtle consciousness (sleep/deep sleep). In more Indian philosophy, consciousness is that which is luminous (revealing) and has capacity for cognition.\n\nTheories of consciousness\n- Cognitive Theories: consciousness is based in areas that are devoted to cognitive processing (thinking, reasoning, evaluating, memory, etc.)\n\t- Global workspace theory: consciousness arises from highly coordinated, widespread activity in the brain\n\t\t- When signals are broadcast to the global workspace, we become conscious of the sensation\n\t\t- When they remain localized, they are not perceived conscoiusly\n- Sensory Theories: consciousness is based in areas that are devoted to sensory processing\n\t- Block argues that recurrent processing in sensory areas is the NCC for phenomenally conscious perception\n\t- e.g. [Neural Correlates of Consciousness (NCC)](thoughts/Neural%20Correlates%20of%20Consciousness%20(NCC).md)\n- First-order theories: consciousness is a product of the cognitive processing of sensory information\n\t- e.g. [Integrated Information Theory of Consciousness (IIT)](thoughts/Integrated%20Information%20Theory%20of%20Consciousness%20(IIT).md)\n- Higher-order theories: consciousness involves something done to build on that cognitive representation of the sensory experience\n\t- e.g. [Stream of Consciousness](thoughts/Stream%20of%20Consciousness.md)\n\n## Minimal Phenomenal Experience[^1]\nSimplest form in which a state can be phenomenally conscious\n\nDreamless sleep experience is a candidate for this\n\nBackground [phenomenologies](thoughts/phenomenology.md) claim these experiences combine\n- minimal dimensionality (of awareness)\n- maximal prototypicality (overlap with other states/modes of awareness)\n\nIf we find a minimal form of phenomenal experience in all forms of phenomenal content and underlies all conscious experience, then this model would amount to solving the problem of consciousness as such\n\nProblems for interpreting reports of pure awareness in meditative experience\n1. Embodied theory contamination: background theoretical assumptions strongly condition personal beliefs and thus processing and reporting\n2. Conceptual consistency: how does one interpret words like \"perceive\", \"luminous\", \"radiant\" in reports of experiences that are supposed to be \"contentless\"\n3. Performative self-contradiction: \"I experienced a selfless state\" is a self-contradictory \n\n### Metzinger's 6D concept of MPE\n1. PC1 - Wakefulness: phenomenal quality of tonic alertness (intrinsic arousal and focus of attention)\n2. PC2 - Low Complexity: absence of high-level symbolic mental content, perceptual, sensorimotor, emotional content\n3. PC3 - Self-luminosity: the \"clear light\" of primordial awareness\n4. PC4 - Introspective Availability: can we introspect on our current mental state\n5. PC5 - Epistemicity: feeling of knowing or subjective quality of confidence (doesn't logically entail actual knowledge)\n6. PC6 - Transparency/Opacity: transparent means only intentional-content properties of the state can be introspected whereas opacity means properties of the carrier/vehicle of the state can also be introspected\n\n![](thoughts/images/6d%20MPE.png)\n\n### Ascending Reticular Activating System (ARAS)[^1]\nThis system determines the brain's general level of activation.\n\nPure awareness is experienced as \"contentless\" although it is actually a representation of ARAS\n\nThis model is [physicalist](thoughts/Materialism.md) (awareness-as-such is constituted by the brain) and representationalist (awareness-as-such is a neurally constituted representation of the brain's auto-activated wakefulness -- character is tonic alertness with a feeling of knowing)\n\n## Problems with information theories of consciousness\n[Frontiers in Systems Neuroscience](https://www.frontiersin.org/articles/10.3389/fnsys.2014.00225/full)\n\nTwo main camps\n1. Radical behaviourists: all talk of the mind could be translated, without scientific loss, into talk about behaviour\n2. Cognitivists: all talk of the mind (including consciousness) could translated, without scientific loss, into talk about information processing\n\n### Cognitivists\nTheories that equate consciousness with information or information processing are dualist in nature\n\nChalmers (in The Conscious Mind: in Search of a Fundamental Theory) defines information in the actual world as having two aspects\n1. Physical\n2. Phenomenal\n\nHowever, [information](thoughts/information.md) is usually defined at odds to this\n1. Information is often used to refer to non-mental, user-independent, declarative semantic contents, embedded *in* physical implementations (Floridi, 2005)\n\t1. Important distinction: Physical things encode and embed information but themselves are not information\n\t2. James Joyce's copy of Dante's Inferno may _carry_ information, but it is not itself information—it's just an arrangement of paper and ink\n\t3. Your brain when he looks at an octopus may encode information, but it is not itself information\n2. An objective (mind-independent) entity... information can be encoded and transmitted, but the information would exist independently of its encoding or transmission\n\nSeriality problem\n- While the brain works as a parallel distributed network with virtually unlimited resources, conscoius events appear consecutive and momentary capacity is strongly limited. Multi-tasking is notoriously hard. Theories regarding consciousness as a particular case of brain information processing must suggest a specific mechanism for creating serial processes from a collection of parallel ones\n- Not a problem for behaviour-based theories as behaviour is a series of agent-environment interactions. Attention budget, more complex behaviours take more bandwidth and thus require more focus (need to be done in serial). Things can be trained to reduce focus needed (e.g. walking and talking)\n\nProblematic: thermostats (for example) clearly carry information, but are not widely regarded as having any degree of consciousness\n\nChalmers has two options:\n1. Perhaps only some kinds of “physically realized information spaces” are conscious.\n2. Perhaps thermostats are conscious (option that Chalmers chose). Suggests that \"the level of organization at which consciousness “winks out” might be lower than a thermostat but higher than a rock.\"\n\nTononi's [Integrated Information Theory of Consciousness (IIT)](thoughts/Integrated%20Information%20Theory%20of%20Consciousness%20(IIT).md)\n- Resolution to this problem is choosing that only *integrated* information is conscious\n- IIT does not even answer this question directly, only correlating the two and correlation is most definitely neither definition nor causation: \"To recapitulate, the theory claims that consciousness _corresponds to_ the capacity to integrate information\"\n\n### Behaviourist approaches\n[Boris Kotchoubey in Frontiers in Psychology](https://www.frontiersin.org/articles/10.3389/fpsyg.2018.00567/full)\n\nHuman consciousness emerges on the interface between three components of animal behaviour:\n1. Communication\n2. Play\n3. Use of tools\n\nBehaviour, in this context, is a biological adjustment by means of movements and all kinds of movement-related physiological activity\n\nCommunication and play yields symbolic games and, more importantly, [[thoughts/language|language]]\n\nInteraction between symbols and tools results in human [praxis](thoughts/praxis.md)\n\nLife is a continuous battle against the second law of thermodynamics. All organisms' needs can be subsumed as a need in negentropy\n\n1. [Play](thoughts/play.md): Play, therefore, introduces something that can be called “second reality” (Vygotsky, 1978). In this reality the life is going on as if it is the “primary reality,” but with the nice difference that whenever I don't like what happens, I simply stop the process and go out, or start it anew. This makes play suspiciously like consciousness\n2. Tools: A stick is eventually manipulated “just for fun,” and then, suddenly, it turns out to be useful. Thus no animals unable to play can use tools.\n3. Communication: behaviour whose main effect is changing the behaviour of another animal\n\n![](thoughts/images/Sources%20of%20consciousness.png)\n\nConsciousness is then the simulated or [potemkin village](thoughts/potemkin%20village.md) of reality. In words of Karl Popper, instead of dying as a result of our errors, we can let our hypotheses die on our site ([Popper, 1963](https://www.frontiersin.org/articles/10.3389/fpsyg.2018.00567/full#B143)).\n\nWe do not consciously think (construct this virtual reality) all the time. Consciousness is the *capacity* to consciously think ([telerobotics](thoughts/telerobotics.md) vs telepresence)\n\nEssay 2 for PHIL451A: [Consciousness is not Information](thoughts/Consciousness%20is%20not%20Information.md)\n\n\n\n[^1]: This content is sourced from Professor [Evan Thompson](https://evanthompson.me/)'s course materials for PHIL451A at UBC. All rights to this content is retained by Evan Thompson.","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/consensus":{"title":"Consensus","content":"\nConsensus in human systems is actually usually pretty easy because of the social layer of society. This [fault tolerance](thoughts/fault%20tolerance.md) against 51% attacks is due to the fact that convincing the community that any engineered 'truth' is the real on requires subverting every trusted member in the community, most notably media and news sources (also why systems of authoritarian power are so scary). \n\nA difficult problem for [governance](thoughts/governance.md) within [communities](thoughts/communities.md)\n\nNote that this is inherently *different* from collaboration methods like [[thoughts/CRDT|CRDTs]]. Collaboration involves keeping *all* edits and merging them. Consensus involves picking one of several proposed values and agreeing on it.\n\nExample applications include: [[thoughts/State Machine Replication (SMR)|SMR]], [[thoughts/Byzantine Agreement|Byzantine Agreement]]\n\n## Consensus and Humming in the IETF\n[Source: IETF](https://datatracker.ietf.org/doc/html/rfc7282)\n\nOn rough consensus\n- Humming as 'temp checks' for people to voice disagreement but default assumption is optimistic trust\n- \"While counting heads might give a good guess as to what the rough consensus will be, doing so can allow important minority views to get lost in the noise. One of the strengths of a consensus model is that minority views are addressed, and using a rough consensus model should not take away from that.\"\n- \"We can't know who the \"members\" of any given working group would be at any one time, and we certainly can't know who all of the \"members\" of the IETF would be: That's why we refer to \"participants\" in the IETF; the IETF doesn't really have \"members\". Indeed, we often recruit additional implementers and other experts into working groups in order to ensure that broader views are brought into the discussion. So, voting is simply not practical.\"\n\n## Algorithmic Consensus\nThere are four requirements to such an algorithm:\n\n1. Validity. The result must be a value that was submitted by at least one of the processes. The consensus algorithm cannot just make up a value.\n2. Uniform agreement. All nodes must select the same value.\n3. Integrity. A node can select only a single value. That is, a node cannot announce one outcome and later change its mind.\n4. Termination. Also known as progress, every node must eventually reach a decision.\n\nThere are two main protocol paradigms for achieving consensus in the presence of Byzantine nodes:\n1. Classic [[thoughts/Byzantine Faults|BFT]] protocols: typically uses two voting rounds to ensure [[thoughts/consistency|consistency]]\n\t1. One phase to guarantee proposal uniqueness using a quorum certificate of $n-f$ votes\n\t2. The other phase is to convince replicas that the leader is safe to propose new entries\n\t3. Examples include: [[thoughts/Tendermint|Tendermint]], [[thoughts/Tangaroa|Tangaroa]], [[thoughts/HotStuff|HotStuff]], [[thoughts/PBFT|PBFT]]\n2. [[thoughts/longest-chain consensus|Longest-chain consensus]]\n\t1. Examples include: most consensus mechanisms for cryptocurrencies like [[thoughts/bitcoin|Bitcoin]], [[thoughts/ethereum|Ethereum]]\n\n| |Classic BFT|Longest-chain Consensus|\n|--|--|--|\n|Safety/Liveness tradeoff|Favours [safety](/thoughts/safety) in the face of an attack|Favour [liveness](/thoughts/liveness) in the face of an attack|\n|Finality|Instant and deterministic|Probabilistic (at risk of potentially large chain reorganizations and double-spend attacks)|\n|Fork behaviour|Rare but difficult to recover from|Embrace forks, uses in-protocol methods for resolving ambiguity as to which fork is correct|\n|[FLP Result](/thoughts/FLP%20Result) Behaviour|sacrifice either liveness or consistency in the face of an attack (assuming \u003c33% Byzantine as per FLP Result)|Does not apply as longest-chain consensus is non-deterministic|\n|Permission model|Generally permissioned (see [Sandglass](/thoughts/Sandglass))|Permissionless|\n\nNote that there have been attempts to bridge Classic BFT models with [[thoughts/longest-chain consensus|Nakamoto-style consensus]] ones with hybrid consensus models which use a permissionless chain to determine a participant/proposer rotation in a reconfigurable BFT engine.\n\n### Comparisons between different BFT SMR protocols\nAll protocols are of the following:\n1.  protocols for [[thoughts/Byzantine Faults|byzantine fault-tolerant]] [[thoughts/State Machine Replication (SMR)|SMR]]\n2.  All work in the partially synchronous [[thoughts/system model|system model]] and obtain safety (always) and liveness (after GST) in the face of an adversary that controls $f$ replicas out of a total of $n=3f+1$ replicas (per [[thoughts/FLP Result|FLP Result]])\n3.  All these protocols are based on the classic leader-based primary-backup approach where leaders are replaced in a _view-change_ (or election to use [[thoughts/Raft Consensus Algorithm|Raft]] terminology) protocol.\n\nBelow is a comparison of a few top protocols and their tradeoffs in [[thoughts/authenticator complexity|authenticator complexity]]\n\n| |Best-case Latency (rounds)|Normal-case Communication|View-change Communication|Leader Rotation|Responsiveness|\n|--|--|--|--|--|--|\n|[PBFT](/thoughts/PBFT)|2|$O(n^2)$|$O(n^3)$|On suspected fault|Yes|\n|[Tendermint](/thoughts/Tendermint)|2|$O(n)$ using thresholded signatures, $O(n^2)$ otherwise|$O(n)$|Every round|No|\n|[SBFT](/thoughts/SBFT)|1|$O(n)$|$O(n^2)$|On suspected fault|Yes|\n|[HotStuff](/thoughts/HotStuff)|3|$O(n)$|$O(n)$|Every round|Yes|\n\nResponsiveness here refers to the property that a non-faulty leader can drive the protocol to consensus in a time depending on *actual message delays* and not the theoretical upper bound on message transmission delays. In partially synchronous models, we use *optimistic responsiveness*, which requires responsiveness only after GST is reached.\n\nLeader rotation tradeoff:\n- maintaining a stable leader means less overhead and better performance due to stability when the leader is honest and trusted\n- constantly rotating the leader provides a stronger fairness guarantee against stable malicious leaders\n\n### Pipelining\nIn [[thoughts/PBFT|PBFT]], [[thoughts/SBFT|SBFT]], and [[thoughts/HotStuff|HotStuff]] the leader maintains a _window_ of open slots and is allowed to concurrently work on committing all open slots in his active window. Conceptually, this is like [[thoughts/TCP|TCP]] where a sender does not have to wait for the ACK of packet $i$ before sending message $i+1$. This window can *significantly increase throughput* by allowing the leader to concurrently coordinate several actions of slot commitments.\n\n## Impossibility Results\nWhen consensus is impossible to achieve:\n1. [[thoughts/33% Impossibility Result|33% Impossibility Result]]\n2. [[thoughts/PSL-FLM Impossibility Result|PSL-FLM Impossibility Result]]\n3. [[thoughts/FLP Result|FLP Result]]\n4. [[thoughts/LR Permissionless Result|LR Permissionless Result]]","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/consistency":{"title":"Consistency","content":"\n## Definitions\n### ACID Consistency\nThe state satisfies application-specific invariants (e.g. every course with students enrolled must have at least one lecturer) at any given point in time\n\n### Replication Consistency\nMany models to choose from! Most common being read-after-write consistency\n\nImagine a scenario where\n- Client writes to servers A and B but request to A fails (so only B has correct state)\n- Client reads from servers A and B but request to B fails (so only client gets A's incorrect state)\n\nClearly, client is getting inconsistent results. We can fix this via a **[[thoughts/quorum|quorum]] read.**\n\n## Atomic Commitment Problem\nBig problem with distributed transactions: atomic commitment problem\n- Either all nodes must commit or all must abort\n- If any node crashes, all must abort\n\nUsually done through two-phase commit (2PC)\n- Client begins a transaction with database nodes A and B\n- When done, the client *commits* the transaction with the coordinator\n- Coordinator tells both A and B to prepare for the commit\n- If both A and B think it is fine for them to commit, then coordinator tells both to commit (A and B cannot go back on their response to prepare, if they said they are prepared for the commit they must commit when the coordinator tells them to)\n\nBut what if the coordinator crashes? The algorithm is blocked until coordinator recovers. We can use a fault-tolerant two-phase commit (uses [[thoughts/message broadcast#Total order broadcast|total order broadcast]])\n\n## Linearizability\nDefined as consistency in the face of concurrent reads/writes.\n\nInformally: every operation takes effect atomically sometime after it started and before it finished. All operations behave as if executed on a *single copy of the data*\n\nNot to be confused with serializability: transactions having the same effect as if they were run in some serial order. Also contrasting with [[thoughts/causality|causal]] relationships, linearizability is defined in terms of real-time whereas [[thoughts/causality|causal]] is defined in terms of message sending and receiving.\n\nThe consequence/desired property of linearizability is that every operation returns an \"up-to-date\" value, sometimes called \"strong consistency\"\n\nWe can guarantee linearizability of get (quorum read + read repair) and set (blind write to quorum). If events overlap, either order could happen and is ok.\n\nNot without downsides\n- Performance costs: lots of messages and waiting for responses\n- Scalability limits: leader can be a bottleneck\n- Availability problems: if you can't contact a quorum of nodes, you can't process any operations\n\n## Eventual Consistency\nAlternative to linearizability is eventual consistency.\n\nIf there are no more updates, **eventually** all replicas will be in the same state.\n\nBut how do we know when there are no more updates? This can be an indefinite amount of time. An upgraded version of this is strong eventual consistency which has a few additional rules:\n- Eventual delivery: every update made to one non-faulty replica is eventually processed by every non-faulty replica\n- Convergence: any two replicas that have processed the same set of updates are in the same state\n\nProperties\n- Does not require waiting for network communication\n- [[thoughts/causality|Causal]] broadcast can disseminate updates\n- Conflicts arising from concurrent updates need to be resolved\n\n## Summary\nSummary of minimum [[thoughts/system model|system model]] requirements for various forms of consistency\n\n|Problem|Must wait for communication|Requires synchrony|\n|--|--|--|\n|atomic commit|all participating nodes|partially synchronous|\n|consensus, total order broadcast|quorum|partially synchronous|\n|linearizable get/set|quorum|asynchronous|\n|eventual consistency, causal broadcast, FIFO broadcast|local replica only|asynchronous|\n","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/constructionist":{"title":"Constructionism","content":"\n\u003e constructed by the child using inborn mental equipment but operating on information provided by the environment\n\n## [Mindstorms](thoughts/Mindstorms.md)\n\"As children construct things in the world, they construct new ideas and theories in their minds, which motivates them to construct new things in the world, and on and on.\"\n\n\"I never met anyone who was, at once, so playful and so serious about ideas.\"\n\nPiaget has demonstrated that children learn fundamental mathematical ideas by first building their own, very much different (for example, preconservationist) mathematics. And children [[thoughts/language development|learn language]] by first learning their own (\"baby-talk\") dialects. So, when we think of microworlds as incubators for powerful ideas, we are trying to draw upon this effective strategy: We allow learners to learn the \"official\" physics by allowing them the freedom to invent many that will work in as many invented worlds.\n\nWhy there is no good answer to \"how do I learn CS\" \n\"I see Piaget as the theorist of learning without curriculum and the theorist of the kind of learning that happens without deliberate teaching... But 'teaching without curriculum' does not mean spontaneous, free-form classrooms or simply 'leaving the child alone.' It means supporting children as they build their own intellectual structures with materials drawn from the surrounding culture\"\n\n\u003e \"They'll handle the details. Indeed, they insist on it. For a project to feel like your own, you must have sufficient autonomy. You can't be working to order, or slowed down by bureaucracy.\" -- [Paul Graham](http://paulgraham.com/own.html)\n\n## [Design Justice](thoughts/Design%20Justice.md)\nPedagogical approach that centers [context](thoughts/context.md), situated knowledge, and learning by doing.\n\nPapert rejected the banking method of education: educator transmits a piece of information to the learner's brain\n\nInstead, learning is *experiential*: it takes place through an active process where the learning develops the ability to modify or transform an object or idea.\n\nCore principles\n1. People do not get ideas, they make them\n2. People construct new knowledge with particular effectiveness when they are engaged in constructing personally meaningful products\n\n\"Instead, design justice pedagogies must support students to actively develop their own critical analysis of design, power, and liberation, in ways that connect with their own lived experience\"\n\nHowever, if resource constraints become an excuse to avoid examining the root of the problem area, then designers will almost always end up, at best, providing Band-Aids for deep wounds and, at word, actively serving existing power structures.","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/contact-language":{"title":"Contact Language","content":"\nSee also: [boundary object](thoughts/boundary%20object.md)\n\n## Digital Contact Languages\nContact Language: broadly speaking, this [[thoughts/language|language]] served to facilitate collaboration across the groups it interconnected.\n\nThe rise of the Kindle points out that even the concept of a link—a “uniform resource locator,” or URL—is under great stress. Since Kindle books don’t live on the World Wide Web, there’s no URL pointing to a particular page or passage of them. The same goes for content within any number of mobile apps, leaving people to trade screenshots—or, as _The Atlantic_’s Kaitlyn Tiffany [put it](https://www.theatlantic.com/technology/archive/2021/06/screenshots-gremlins-internet/619062/), “the gremlins of the internet”—as a way of conveying content.","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/content-addressed-storage":{"title":"Content addressed storage","content":"\n\u003e If I identify the book by its content, saying \"Check out the book called *Why Information Grows* by César Hidalgo. The ISBN is 0465048994.\", you will be able to get any copy of the book from any source and know that you're reading the information I recommended.\n\u003e \n\u003e By contrast, if I used location-addressing to identify the book, I would have to point to a location, saying something like \"Go to the news stand at Market \u0026 15th in Philadelphia and ask for the thing 16 inches from the south end of the third shelf on the east wall\"\n\nContent-addressed storage or abbreviated CAS, is a way to store information so it can be retrieved based on its content, not its location.\n\nLocation-addressed: e.g. HTTP, you lookup a content by its location (URI). Whoever controls the location controls the content. This location-addressed approach forces us all to pretend that the data are in only one location (even if multiple people have copies of it!)\n\nContent-addressed: using the content's cryptographic hash to identify it. These links are permanent because the cryptographic hash for a piece of content never changes. \n\n## Immutable Objects, Mutable References\nThe [[thoughts/Merkle-DAG|Merkle-DAG]], immutable content-addressed objects, and mutable pointers to the Merkle-DAG, instantiate a dichotomy present in many successful distributed systems\n\n[[thoughts/IPFS|IPFS]] accomplishes this by creating a separate prefix `/ipns/\u003cNodeID\u003e` ofr mutable paths. One can prove ownership because only the owner of the private key of `NodeID` can publish to it ","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/context":{"title":"Context","content":"\nContent only has meaning if it has context\n-   [emptiness](thoughts/emptiness.md)/dependent-origination: does this connect to context as potentially an [epistemic](thoughts/epistemology.md) instrument?\n\n### Context on the web and in articles\n-   footnotes as dynamic context → layers of context maybe?\n-   hover cards \u003c footnotes/marginalia \u003c summary of article \u003c article\n-   on data\n\t-   for data in web2, application is the context\n\t-   how do we make data as first class citizens?\n\t-   https://solidproject.org/\n\nThe context in [context collapse](posts/context-collapse.md)\n\n\n","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/convex":{"title":"Convex","content":"\nA set is convex if line between two points in the set stays in the set.\n\n![[thoughts/images/convexity.png]]\n\nA function $f$ is convex if all the points above $f$ form a convex set. That is,\n- If $f''(w) \\geq 0, \\forall w$\n- A convex function multiplied by a non-negative constant is convex\n- Norms and squared norms are always convex\n- The sum of convex functions is convex\n- The max of convex functions is a convex function\n- The composition of a convex function $g$ and linear function $h$, $g \\circ h$ is convex","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/convolutional-neural-networks":{"title":"Convolutional Neural Networks","content":"\nRather than picking from fixed convolutions, we learn the elements of the filters.\n\nA convolution is a [[thoughts/imaging#Linear Filters|linear filters]] that measures the effect one signal has on another signal.\n\nIf $x$ is the $(n,n)$ input signal (image) and $w$ is the $(2m+1, 2m+1)$ filter, then the 2D convolution is given by\n\n$$z[i_1,i_2] = \\sum_{j_1=-m}^m \\sum_{j_2=-m}^m w[j_1,j_2] x[i_1+j_1,i_2+j_2]$$\n\n### Convolutional Layer\nStandard is DxWxH\n\n$K$ is the number of filters, $F$ is the spatial extent of filters (kernel size), $S$ is the stride, and $P$ is the padding\n\n- $W_{out} = (W_{input} - F + 2P)/S + 1$\n- $H_{out} = (H_{input} - F + 2P)/S + 1$\n- $D_{out} = K$\n\nTotal number of learnable parameters: $(F \\times F \\times D_{input}) \\times K + K$.\n\n### Pooling Layer\nMakes representation smaller, more manageable and spatially invariant. \n\n- $W_{out} = (W_{input} - F)/S + 1$\n- $H_{out} = (H_{input} - F)/S + 1$\n- $D_{out} = D_{input}$\n\nTotal number of learnable parameters: 0.\n\n### Layer Summary\n- Convolutional Layer: applies a set of learnable filters\n- Pooling Layer: performs spatial downsampling\n- Fully-connected Layer: same as any regular neural network\n\nA CNN then just learns a hierarchy of filters\n\n### Properties of Convolution\n1. Associative. $G \\otimes (F \\otimes I(x,y)) = (G \\otimes F) \\otimes I(x,y)$\n2. Symmetric. $(G \\otimes F) \\otimes I(x,y) = (F \\otimes G) \\otimes I(x,y)$\n\nCorrelation, on the other hand, is generally not associative.\n\nFor 1D Gaussians, we note $G_{\\sigma_1}(x) \\otimes G_{\\sigma_2}(x) = G_{\\sqrt{\\sigma_1^2 + \\sigma_2^2}}(x)$. Convolving with $G_\\sigma(x) \\otimes G_\\sigma(x) = G_{\\sqrt 2 \\sigma}(x)$\n\n### Boundary Effects\n1. Ignore these locations: make the computation undefined for the outsize $k$ rows/columns\n2. Pad with zeroes: return zero whenever of value of $I$ is required at some position outside the image\n3. Assume periodicity: wrap image around\n4. Reflect border\n\n### Pillbox\nA 2D pillbox is rotationally invariant but not separable\n\n$$f(x,y) = \\frac{1}{\\pi r^2}\n\\begin{cases} \n  1 \u0026 \\textrm{if} x^2 + y^2 \\leq r^2 \\\\\n  0 \u0026 \\textrm{otherwise}\n\\end{cases}\n$$\n\nAn efficient implementation would represent a 2D box filter as the sum of a 2D pillbox and some \"extra corner bits\"\n\n### Gaussian Filters\n- Box filter doesn't apply well for lens defocus. A circular pillbox is a much better model for defocus\n- Gaussian is a good general smoothing model\n  - for phenomena\n  - whenever the CLT applies\n\nGaussian filters are rotationally invariant.\n\nWe get $G_\\sigma(x,y) = \\frac{1}{2\\pi\\sigma^2}\\exp^{-\\frac{x^2+y^2}{2\\sigma^2}}$ where $\\sigma$ is the standard deviation\n\nFor a 3x3, we then need to quantize and truncate it, evaluating $G_\\sigma(x,y)$ wherever in the filter. Increasing $\\sigma$ means more blur. Problem with 3x3 is that it truncates too much of the distribution (does not sum up to one), this can cause unintentional darkening.\n\nIn general, the Gaussian filter should capture $\\pm3\\sigma$ for $\\sigma = 1$ which gives us a 7x7 filter.\n\n#### Efficiency\nAs both the 2D box filter and 2D Gaussian filter are separable, it can be implemented as two 1D convolutions which convolve each row and then each column separately.\n\nA 2D filter is separable if it can be expressed as an outer product of two 1D filters\n\nA seperable 2D Gaussian only does $2m$ multiplications at each pixel (one for each 1D filter). Considering the image has $n \\times n$ pixels, then this is a $2m \\times n^2$ multiplications. Assuming $m \\approx n$, this is $\\mathcal{O}(n^3)$\n\n#### Fourier Transform\nThe basic building block of the fourier transform is the periodic function.\n\n$$Asin(\\omega x + \\phi)$$\n\nwhere $A$ is the amplitude, $\\omega$ is the angular frequency and $\\phi$ is the phase. Fourier's claim was that you could add enough of these to get any periodic signal!\n\n### The Convolution Theorem\nLet $i'(x,y) = f(x,y) \\otimes i(x,y)$ be the convolution.\n\nThen, $\\mathcal{I}'(w_x,w_y) = \\mathcal{F}(w_x,w_y)\\mathcal{I}(w_x,w_y)$ which is just a simple element-wise multiplication after applying a Fourier transform to each.\n\nAt the expense of two Fourier transforms and one inverse Fourier transform, convolution can be reduced to (complex) multiplication. This speeds up the cost of FFT/IFFT for the image and filter to $\\mathcal{O}(n^2\\log n)$ and $\\mathcal{O}(m^2\\log m)$ respectively, dropping the total cost of convolution to $\\mathcal{O}(n^2)$\n\n### Convolution Sizing\nConvolving two filters of size $m \\times m$ and $n \\times n$ results in a filter of size\n\n$$(n + 2 \\lfloor \\frac m 2 \\rfloor) \\times (n + 2 \\lfloor \\frac m 2 \\rfloor)$$\n\nMore broadly for a set of $K$ filters of sizes $m_k \\times m_k$ the resulting filter will have size \n\n$$(m_1 + 2 \\sum_{k=2}^K \\lfloor \\frac{m_k}{2} \\rfloor) \\times (m_1 + 2 \\sum_{k=2}^K \\lfloor \\frac{m_k}{2} \\rfloor)$$\n\n","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/cozy-software":{"title":"Cozy software","content":"\n\u003ecozy eternal beta test mode\n\nre: [digital mindfulness](thoughts/digital%20mindfulness.md)! Not everything needs to be built at scale -- sometimes it can just be for family and friends :)) Normalize creating playful and non-[instrumental](thoughts/instrumentalism.md) technology\n\n## An app can be a home-cooked meal\nSource: [Robin Sloan](https://www.robinsloan.com/notes/home-cooked-app/)\n\nClay Shirky: “Situated software, by contrast, doesn’t need to be personalized — it is personal from its inception.”\n\nI can, at this point, make the things happen on computers that I want to make happen. At the same time, I would not last a day as a professional software engineer. Leave me in charge of a critical database and you will return to a smoldering crater.\n\nI am the programming equivalent of a home cook.\n\n## Personal Software\n### Spring '83\n[Source](https://www.robinsloan.com/lab/specifying-spring-83/)\n\nI love the disclaimer at the top: \"It’s okay to share this link, but I want to underscore that I am sending it specifically to you with the hope that you will … really think about it! At such a primordial stage, a proposal like this doesn’t need diffuse, drive-by attention. It needs, instead, close consideration and generous imagination.\"\n\n- \"There are no analytics, obviously. Nothing is counted. Boards can’t load tracking pixels, and they can’t ping remote analytics APIs. Sorry, folks … you’ve got to let go of the numbers. In 2022, they are not helpful feedback, but rather a clear warning you are in the wrong place.\"\n- When you operate a server, you get a universe for free (see also: [[thoughts/World Building#World Seed|world seed]]).\n\n### Spatial Computing\n[Source](https://www.figma.com/file/OYg9sU8nNTpOczssb2A4BH/Scrapchat-with-Rebane)\n\n\u003e fuck responsive layouts, all my homies hate responsive layouts\n\n- There’s unexpected energy in the space of “being able to lay out elements visually on a 2d plane and know that the browser isn’t going to wrap them somewhere you didn’t mean”.\n- The [spatial web](https://maggieappleton.com/spatial-web?curius=1573)\n\t- https://nette.io/\n\t- https://www.kosmik.app/\n\t- https://sprout.place/\n- https://twitter.com/azlenelza/status/1418749070336684034\n- https://twitter.com/raunofreiberg/status/1450479522609090562\n\n## Handmade Web\nFrom J.R. Carpenter's [*A Handmade Web*](http://luckysoap.com/statements/handmadeweb.html)\n\n\u003e I evoke the term 'handmade web' to refer to web pages coded by hand rather than by software; web pages made and maintained by individuals rather than by businesses or corporations; web pages which are provisional, temporary, or one-of-a-kind; web pages which challenge conventions of reading, writing, design, ownership, privacy, security, or [[thoughts/identity|identity]].\n\n## Folk Software\n[Source](https://maggieappleton.com/folk-interfaces)\n\n\u003e People reappropriating existing software to solve their own unique problems\n\nFolksonomies are informal taxonomies developed by users on social sharing platforms. Usually in the form of tags on sites like Flickr, Tumblr, or Instagram.\n\nFolk creations fill a gap. They solve problems for individuals and small communities in a way that that centralised, top-down, industrial creations never can. They are informal, distributed practices that emerge from real world contexts.\n\nRelated to [[thoughts/Tools for Conviviality]]\n\n## Fun Sites\n- [[posts/casual magic|fun experiments with sunsets]]\n\t- [p2p sunsets](https://old.mark-beasley.com/peer-peer-sunset/index.html)\n\t- [animated digital sunset](https://tiffanyq.github.io/sunrise/)\n- [Little towns of people's plots :))](https://tilde.town/~troido/cadastre/town.html)","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/creation-vs-maintenance":{"title":"Creation vs Maintenance","content":"\nSo much of today's society revolves around *creating new things* rather than *maintaining existing things*. Yet,  the two go hand in hand - [innovation](thoughts/innovation.md) without the ability to scale and maintain is frivolous, and [maintenance](thoughts/maintenance.md) without innovation is stagnation.\n\n\u003e Almost no buildings adapt well. They're _designed_ not to adapt; also budgeted and financed not to, constructed not to, administered not to, maintained not to, regulated and taxed not to, even remodelled not to. But all buildings (...) adapt anyway, however poorly, because the usages in and around them are changing constantly. -- Stewart Brand\n\nThere is importance in indigenous knowledge and [traditional knowledge](thoughts/traditional%20knowledge.md).\n\nWeb3: shouldering the cost of maintenance among the users rather than centralizing it with the creators\n\nDo Eastern vs Western cultures have diff takes on this? \"Over the course of the 20th century, open societies that celebrated diversity, novelty, and progress performed better than closed societies that defended uniformity and order.\"\n\n## MVP vs Product\n[Source: I could do that in a weekend! by *Dan Luu*](https://danluu.com/sounds-easy/)\n\nNot just building out an initial system, but also about how maintainable and scalable the system is for the foreseeable future.\n\nBusinesses that actually care about turning a profit will spend a lot of time (hence, a lot of engineers) working on optimizing systems, even if an MVP for the system could have been built in a weekend.\n\nThis reminds me of a common fallacy we see in unreliable systems, where people build the happy path with the idea that the happy path is the “real” work, and that error handling can be tacked on later. For reliable systems, error handling is more work than the happy path. The same thing is true for large services -- all of this stuff that people don't think of as “real” work is more work than the core service\n\n## On shifting the focus too quickly\n\"One important topic of conversation is the danger of moving too triumphantly from innovation to maintenance. There is no point in keeping the practice of hero-worship that merely changes the cast of heroes without confronting some of the deeper problems underlying the innovation obsession.\"","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/creative-writing":{"title":"Creative writing","content":"\n## CRWR200\n### Common misconceptions\n- Creative [[thoughts/writing|writing]] is about creating 'literature' and not genre stories: it is more so a question of quality than content\n- Writing is an innate talent: writing is a tool that can be honed and practiced\n- No real world application for creative writing: almost all conversations, media, arguments, involve some form of convincing the other side! what better way to do that than through story telling\n- The riddle of storytelling\n\t- Imagine two groups of early humans competing for the same resources who lived pretty much the same\n\t- The first group gossiped and told stories during their leisure time while the second group continued working\n\t- We know the first group survived because that's us! So why is story telling so evolutionarily beneficial? It's a form of simulation (see also: [[thoughts/consciousness#Behaviourist approaches|behaviourist approaches to consciousness]])\n\n### Classic Story Structures\n- Freytag's Pyramid\n\t- Exposition\n\t- Rising Action\n\t- Climax\n\t- Falling Action\n\t- Denouement\n- Kurt Vonnegut's Shape of Stories\n- Joseph Campbell's \"Hero's Journey\" (story wheel)\n\t- Character is in a zone of comfort\n\t- But they want something\n\t- They enter an unfamiliar situation\n\t- Adapt to it\n\t- Get what they wanted\n\t- Pay a heavy price for it\n\t- Then return to their familiar situation\n\t- Having changed\n- Three Act Structure\n\t- Act I: Get your guy up a tree\n\t- Act II: Throw rocks at him\n\t- Act III: Get him outta the tree\n\n### Aspects of Stories\n- McGuffin: an object, device, or event that is necessary to the plot and the motivation of the characters, but insignificant, unimportant, or irrelevant in itself.\n- The universal grammar for stories: character + conflict = change\n- Plot: the how of the story. Explicit. A series of actions, taken by characters, towards their wants, needs or desires\n- Theme: the why of the story, the \"so what\". Should be\n\t- Universal\n\t- Specific\n\t- Implied\n- Summary (general information, tell) vs Scene (specific descriptions, show)\n\n### Writing Pitfalls\n- Structural ambiguity: missing important story beats (e.g. Four undramatic plot structures) -- you need character, conflict, and change\n* Cliché/Familiar phrasing: don't do things that are incredibly overdone\n* Awkward exposition: having conversations that characters would never actually have for the sake of reader understanding\n* Abstractions: don't invoke abstractions, make it concrete, reify it\n- Vagueness (unclear) vs Ambiguity (up to interpretation)\n- Deus Ex Machina: god from the machine, heavy handed use of magic or coincidence to solve a conflict\n- Characters: be aware of your defaults\n\t- There not always a person but instead an element of storytelling -- a vehicle on which the action of the story plays out\n\n### Storytelling techniques\n- Voice\n\t- How your characters speak, their voice and diction\n\t- The language you use as the author\n- Irony\n\t- Verbal irony: the device by which we say one thing and mean another\n\t- Dramatic irony: the device by which the audience has crucial information that the characters do not\n\t- Cosmic irony: our understanding of the human condition, in which efforts are thwarted despite our best intentions\n\n### Poetry\n- Assonance: repetition of a vowel sound between consonants that may or may not match\n- Consonance: repetition of the consonant that concludes a word or syllable\n- Alliteration: repetition of an initial consonant sound\n- Rhyme\n\t- True rhyme: both the vowel and consonant of the last accented syllable correspond\n\t- Internal rhyme: the end of one line rhymes into the beginning or middle of noather\n\t- Off-rhyme: near-rhyme, slightly discordant or 'not quire there' rhymes (four-inch, door hinge)\n- Line: a typographical break representing a slight oral pause or hesitation\n\t- It adds a kind of emphasis both to the last word of the line and the first of the next line\n\n### Non-fiction\n- Journalism\n\t- Objective, facts only\n\t- Invisibility of the author\n- Literary Journalism\n\t- Employs literary (storytelling) techniques\n\t- Has a crafted narrative structure\n\t- Subjectivity\n\t- Types\n\t\t- Immersion/personal journalism\n\t\t- op ed (opinion piece)\n\t\t- profile\n- Personal Essay\n\t- Conversational discussion of a topic or idea that the author is interested in\n\t- Drive by the author's narrative Voice\n\t- Usually grounded in a personal experience but discusses larger issues more explicitly than other forms\n\t- Often more Summary than other forms\n- Memoir\n\t- A \"story\" about an event or aspect of the author's life\n\t- Reads much the same way a piece of short fiction does\n\t- Mostly in scene\n\t- Events are shown through character's actions and interactions playing out in real time\n\t- Difference with autobiography\n\t\t- One event vs an entire life\n\n### Comics\n- Reality to Symbol spectrum\n- Three Ages of American Comics\n\t- Golden Age (1930s - 1954):  modern comic books were first published and rapidly increased in popularity. The superhero archetype was created and many well-known characters were introduced\n\t- Silver Age (1954 - 1970s): the Code restricted many topics from being covered in stories: this prevented certain genres, such as crime and horror comics, from being sold at most comic book shops, and also helped superheroes stay popular and culturally relevant\n\t- Bronze Age (1970s - 1980s): underground comix movement in response to the restrictions of the Code, and was part of the broader counterculture of the 1960s\n- Will Eisner popularized the term graphic novels/sequential art\n- Stages of making a comic\n\t1. Script: lays out story and dialogue, describes each panel in detail\n\t2. Thumbnails/Roughs: rough sketches that work out the general blocking of panels and page layout\n\t3. Pencils: refines \u0026 finalizes the roughs, works out details \u0026 nails down specifics\n\t4. Inks: finalizes penciles, eliminates unused pencil lines and any excess sketchiness\n\t5. Colours\n\t6. Letters: lettering, word balloons, caption boxes, SFX","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/credible-exit":{"title":"Credible exit","content":"One sub-branch of the Exit, Voice, and Loyalty model (based on [[thoughts/game theory|game theory]]).\n\n## Exit, Voice, and Loyalty\nThere are two agents.\n1. The Citizen\n2. The Government\n\nThe assumption is that there is a change implemented by the Government which negatively harms the Citizen. The Citizen has one of three actions:\n\n1. Exit: Citizen leaves\n2. Voice: Citizen attempts to change the situation\n\t1. Government can either respond with 1) Respond or 2) Ignore\n\t2. If the Government chooses 2) Ignore, then the Citizen must choose between Exit or Ignore\n3. Loyalty: Citizen does nothing, waits passively for conditions to improve\n\n## Credible Exit\nA few dimensions for credible exit:\n- **I can export my data.** But usually, this doesn't work as data is *application specific*. No other app knows how to interpret that export unless it is explicitly supported. Export has the downside of being static. If you continue to use the app, your export becomes invalid. This makes export only really useful for hard exit.\n- **Data should be in a useful format**: exit happens through a common formats that work in other apps\n- **You have all the tools to use the data without the app**: in other words, either the data is independent of application logic, or the application logic is transparent (i.e. the app is open source)","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/crutch-and-shoe-metaphor":{"title":"Crutch and Shoe metaphor","content":"\nThose with broken legs will use crutches. Shoes however, will enhance performance no matter what. ","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/cryptography":{"title":"Cryptography","content":"\n\u003e Cryptography is the practice and study of techniques for secure communication in the presence of adversarial behaviour.\n\nThe following is a list of primitives one may want to accomplish using cryptography\n\n### Data Representation\nStoring plain versions of some data is often risky (e.g. passwords.) Can we create one-way functions that transform potentially large amounts of data or sensitive data into a unique[^1] value that can be used for comparison or addressing.\n\n[^1]: Up to the limits of probability (e.g. more unlikely than picking the same grain at random as someone else on the beach)\n\nThe main primitive for this are [[thoughts/hash function|hash functions]] which can enable [[thoughts/content addressed storage|content-addressed storage]] (e.g. [[thoughts/CID|CID]]s)\n\n### Secure Communication\n[[thoughts/encryption|Encryption]] can be used to make sure that only intended recipients can receive the message or data you want.\n\nMostly accomplished using\n1. [[thoughts/Symmetric Key Cryptography|Symmetric Key Cryptography]] (e.g. [[thoughts/RSA|RSA]] or [[thoughts/Elliptic-curve Cryptography (ECC)|ECC]])\n2. [[thoughts/Asymmetric Key Cryptography|Asymmetric Key Cryptography]]\n\n### Message integrity and Authentication\n1. Integrity: can the recipient be confident that the message has not been accidentally modified?\n2. Authentication: can the recipient be confident that the message originates from the sender?\n3. Non-repudiation: can the message's authenticity be unchallengeable?  (i.e. if I send a message, I can't later  maintain I did not)\n\nThere are multiple ways of accomplishing this:\n1. [[thoughts/hash function|Hash functions]]\n2. [[thoughts/MAC|MACs]]\n3. [[thoughts/digital signatures|Digital Signatures]]\n\n### Guarantees\n\n\n| |Hash|MAC|Digital Signature|\n|---|---|---|---|\n|Integrity|Yes|Yes|Yes|\n|Authentication|No|Yes|Yes|\n|Non-repudiation|No|No|Yes|\n|Kind of keys|None|Symmetric|Asymmetric|\n\n### Efficiency\nMACs can be computed three orders of magnitude faster than digital signatures. For example, a 200MHz Pentium Pro takes 43ms to generate a 1024-bit modulus [[thoughts/RSA|RSA]] signature of an MD5 digest and 0.6ms to verify the signature, whereas it takes only 10.3$\\mu s$ to compute the MAC of a 64-byte message on the same hardware in our implementation. There are other publickey cryptosystems that generate signatures faster, e.g.,\n[[thoughts/Elliptic-curve Cryptography (ECC)|elliptic curve]] public-key cryptosystems, but signature verification is slower.\n\n","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/dao":{"title":"DAO","content":"\n\u003e Communities organized around a shared set of rules enforced on the blockchain through a smart contract. \n\n[Source: A beginner’s guide to DAOs by *Linda Xie*](https://linda.mirror.xyz/Vh8K4leCGEO06_qSGx-vS5lvgUqhqkCz9ut81WwCP2o)\n\nDAOs give us structured ways to [collect](https://foundation.app/blog/pleasrdao), [invest](https://metacartel.xyz/), and [build](https://raidguild.org/) together.\n\nInherently transparent, every aspect of the org is public.\n\nThe most infamous DAO, [The DAO](https://en.wikipedia.org/wiki/The_DAO_(organization)), was a decentralized VC fund. Eventually raised $150M but had $60M hacked, leaving a negative impression/skepticism around DAOs for a while.\n\nStable employment is possible through DAOs, Empty Set Dollar DAO is paying a $180k salary to their community manager\n\nAll members can still be anonymous and built reputations attached to their [pseudonym](thoughts/pseudonymity.md) rather than real [[thoughts/identity|identity]], hopefully helps to create a more even playing field\n\n## Potential Issues\n- How does this work for people who want to keep things under NDA/keep IP safe?\n- Not everything can be codified, what happens in vaugely defined/legal gray zones?\n- Often times no legal protections outside the rules governed by the smart contracts facilitating the DAO\n- [Tragedy of the Commons](thoughts/tragedy%20of%20the%20commons.md): how do we ensure all members of the DAO have stake and participate?\n- How/can we enforce who joins a DAO? Would this lead to lower quality discussion and higher noise due to lack of [value alignment](thoughts/value%20setting.md) and [group limits](thoughts/group%20limits.md)?","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/data-distributions":{"title":"Data Distributions","content":"\n-   Machine Learning and [AI Systems](posts/ai-systems.md) excludes the tail ends of the distributions\n\t-   this is where minorities live, ends up reproducing existing systems of power (re: [To live in their Utopia](thoughts/To%20Live%20in%20their%20Utopia.md), [Matthew Effect](thoughts/Matthew%20Effect.md))\n\t-   synthetic/generative/federated models suck at these\n\t-   most interesting cases ARE outliers (esp. in medical AI)\n\n## Contextual Data\nShould data and [information](thoughts/information.md) be contextualized all the time?\n\n1. [context](thoughts/context.md) is important when dealing with historical data. Knowing why certain decisions were made is extremely important\n2. We want data to be anonymized to a certain extent. Exposing patient data, for example, is a huge risk.\n\nHow do we choose what context to include and what not to include?\n\n","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/data-mining":{"title":"Data mining","content":"\nData mining is a way to generate new information by combining facts found in multiple transactions, and it can also be a way to predict future events.\n\nTypical steps of data mining\n1. Learn about the application\n2. Identify data mining task\n3. Collect data\n4. Clean and preprocess the data\n5. Transform data or select useful subsets\n6. Choose data mining algorithm\n7. Data mining\n8. Evaluate visualize and interpret results\n9. Use results for profit or other goals\n\nIn a table\n- a row is an *example* or *sample*\n- a column is a *feature*\n\nFeature types:\n- Categorical\n\t- binary\n\t- nominal: name-like\n- Numerical (counts, ordinal, continuous)\n\t- Allows us to interpret examples in points in feature space\n\nWays to approximate other data with numerical features\n- Text:\n\t- Bag of words: word counts\n- Images: gray-scale intensity\n- Graphs: adjacency matrix\n\nData can not be clean when data is\n- duplicated\n- missing\n- full of outliers\n- noisy\n\nCoupon collector problem: you generally need to see $O(n \\log n)$ samples to see all n possible values which have equal probabilities\n\n## Predictive Policing\nThe use of data mining to deploy police officers to areas where crimes are more likely to occur. It is based on the observation that individual criminals act in a predictable way.","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/death":{"title":"Death","content":"\nConceptions of death in [The Upanisads](thoughts/The%20Upanisads.md) and [Epicurueanism](thoughts/Epicurueanism.md)\n\n## Death in contemporary terms[^1]\n1. State of being dead\n2. The momentary event of dying\n\t1. Ending of the dying process (denouement death): separates the dying process from the subsequent disintegration\n\t2. Point when extinction is assured (threshold death): irreversable loss of [consciousness](thoughts/consciousness.md)/personhood/functioning\n\t\t1. Medical Criteria\n\t\t\t1. Irreversible cessation of circulatory-respiratory function (traditionally)\n\t\t\t2. Irreversible cessation of the functioning of the entire brain, including the brain stem (the modern biomedical criterion)\n\t\t\t3. Irreversible cessation of the functioning of the cerebral cortex (newer controversial idea that the cortex is the locus of consciousness)\n\t3. Loss of integrated functioning (integration death)\n3. The process of dissolution (dying)\n\n![](thoughts/images/perspectives%20on%20death.png)\n\n## Near Death Experiences (NDEs)[^1]\n\u003e Subjective experiences occurring when people are physiologically near death or when they believe themselves to be near death\n\nGreyson Scale\n1. Cognitive Features\n\t1. Time distortion\n\t2. Thought acceleration\n\t3. Life review\n\t4. Revelation\n2. Affective Features\n\t1. Peace\n\t2. Joy\n\t3. Cosmic unity\n\t4. Encounter with light\n3. Paranormal Features\n\t1. Vivid sensory events\n\t2. Apparent extrasensory perception\n\t3. Precognitive visions\n\t4. Out-of-body experiences\n4. Transcendental Features\n\t1. Sense of \"otherworldly\" environment\n\t2. Sense of a mystical entity\n\t3. Sense of deceased/religious spirits\n\t4. Sense of border/point of no return\n\n![](thoughts/images/mental%20states.png)\n\nProblem with these is that we don't know exactly when the experiences happen in relation to the time-course of the near death experience\n- Reports only give us the patient's subjective representation of time, not the objective time when the experience was actually happening\n- Have virtually no direct evidence about what states of the brain are associated with NDEs\n\n[^1]: This content is sourced from Professor [Evan Thompson](https://evanthompson.me/)'s course materials for PHIL451A at UBC. All rights to this content is retained by Evan Thompson.","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/debt":{"title":"Debt","content":"\n[Source: Debt - the first 5000 years, David Graeber on *Kernel*](https://kernel.community/en/learn/module-2/debt)\n\nRelated: [money](thoughts/money.md)\n\nOn the basis of human exchange: we only have a relationship with the other (as equals) when the exchange is incomplete, i.e. when there is debt.\n\n\u003e Someone will give you something and the expectation is that you will give them something in return, though not something of _exactly the same_ value as that would indicate you no longer wish to relate with them\n\nBy this definition then, a community is one where everybody is a *little bit* in debt to everyone else which gives us an excuse to continue seeing each other.\n\nMoney then, appears to be a way to have quantified and transferable promises. (An aside, why do we even feel the need to [quantify](thoughts/quantization.md) promises??)\n\nHowever, **the philosophy of debt as something which cannot be forgiven only ever crops up in situations of structural coercion and extreme inequality.**\n\n### Against the Econ 101 argument\nBarter → money → credit is not only wrong, it's backwards.\n\nWe have never found any evidence for an entirely barter-based society. In places without money, there are usually rough credit systems instead: \"a cow is roughly like a canoe is roughly like a good necklace\". Of course, people can shirk this but your reputation is then tarnished and that can be social suicide in small communities.\n\n### Markets and Government\nTraditionally, free markets and governments have been seen as opposing principles.\n\nHistorically, in fact, markets tend to be created _by_ governments as a side-effect of military operations and to fund armies.","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/decentralization":{"title":"Decentralization","content":"\n![[thoughts/images/decentralization.png]]\n\nSee also: [[thoughts/inevitability of centralization|inevitability of centralization]]\n\n## 3 Axes of Decentralizatiaon\n1. Architectural Decentralization: how many physical computers is a system made of? how many computers can fail before the network fails?\n2. Political Decentralization: how many individuals/organizations ultimately control the computers that the system is made up of?\n3. Logical Decentralization: are the data structures used to represent the system more monolithic or swarm-like? if you cut the system in half (both providers and users), will both halves continue to fully operate as independent units?\n\nNotes:\n* Architectural centralization often leads to political centralization (at least in the physical world, less true for digital spaces)\n\n## Centralization\n[Source: Why Decentralization Matters by *Chris Dixon*](https://onezero.medium.com/why-decentralization-matters-5e3f79f7638e)\n\nFollow a predictable life cycle along the S-shaped adoption curve.\n\nAt the beginning, will do everything they can to garner usage and appear more valuable as platforms with multi-sided positive network effects. However, when they move up the S-curve, their power grows. Eventually, the relationships turn from [positive sum](thoughts/positive%20sum.md) to [zero sum](thoughts/zero%20sum.md). Thus, to continue growing, they must extract from users (e.g. selling user data, taxing profits, etc.)\n\n\u003e Centralized systems often start out fully baked, but only get better at the rate at which employees at the sponsoring company improve them. Decentralized systems start out half-baked but, under the right conditions, grow exponentially as they attract new contributors.\n\n### Types of Centralization\n[From IETF Draft](https://www.ietf.org/archive/id/draft-nottingham-avoiding-internet-centralization-03.html#name-authors-address)\n\n1. Proprietary Centralization: creation of a protocol/application with a fixed role for a specific party (e.g. making a protocol for streaming on Zoom). Generally undesirable as it most often reflect commercial goals (strong desire to capture financial benefits by \"locking in\" users to a proprietary service)\n2. Beneficial Centralization: need for a single, globally coordinated \"source of truth\" (e.g. DNS). Need for coordination in establishing p2p connections (endpoint mutual discovery typically requires a third party)\n3. Inherited Centralization: depending on a centralized \"lower-layer\" protocol. Having only a single implementation of a protocol is also an inherited centralization risk because applications that use it are vulnerable to the control it has over their operation (can still happen with open source! maintaining forks for example is costly)\n4. Platform Centralization: platform for centralization -- while the protocol itself is not centralized, it facilitates the creation of centralized services and applications (can help to mitigate this through [[thoughts/federation|federation]])\n\nStandards efforts should focus on providing concrete utility to the majority of their users as published, rather than being a \"framework\" where interoperability is not immediately available.\n\n## Why Decentralize?\n1. [**Fault tolerance**](thoughts/fault%20tolerance.md), less likely to fail accidentally because they rely on many separate redundant components\n2. **Attack resistance**, no central point to attack\n3. **Collusion resistance**\n\n### Decentralization as Activism\n[Source: Resistant protocols: How decentralization evolves by *John Backus*](https://www.gwern.net/docs/technology/2018-07-25-johnbackus-howdecentralizationevolves.html)\n\n\u003e Decentralization doesn't work in a vacuum, mainstream decentralized systems require a degree of activism to keep the system working\n\n\"BitTorrent seems to represent the minimum viable decentralization required to stay alive as defined by the law at the time\"\n\nDecentralization is a tactic for diffusing risk for many and lowering the risk for the activists that operate the most sensitive parts of the system.\n\n**Over applying decentralization isn't a strategy unless your goal is obscurity**\n\n### Counterpoints\n#### Faul Tolerance\nCommon mode failure, all pieces can [[thoughts/fault tolerance|fail]] for the same reason. (e.g. all nodes in a blockchain run the same software but that software has a bug)\n\nTo counteract this,\n- have multiple competing implementations\n- knowledge of technical considerations behind underlying [protocol](thoughts/Protocol.md) must be public and democratized\n- core stakeholders should be from multiple companies/orgs or just multiple volunteers\n- use [proof of stake](thoughts/proof%20of%20stake.md) to move away from hardware centralization risk\n\n#### Attack Resistance\nFrom a purely mathematical and [[thoughts/game theory|game theory]] perspective, decentralization may not even matter. In a finality reversion (e.g. 51% attack), a huge loss of say $50M is still $50M regardless of whether you have validators in 1 org or 10.\n\nHowever, after considering coercion, decentralization becomes much more important. It's much harder to threaten 100 people than 1.\n\n#### Collusion Resistance\n\u003e Collusion is \"coordination that we don't like\"\n\n[Consensus](thoughts/consensus.md) model relies on **uncoordinated choice model**, the assumption that the game consists of many small actors that make decisions independently\n\nYet, 90% of the entire Bitcoin network's mining power can show up at the same conference (as 7 men). Yet, some coordination is good (e.g. strong community spirit and banding together to implement patches and fix bugs)\n\nWays to counteract:\n1. Find a happy medium that allows enough coordination for a protocol to move forward but not enough to enable attacks\n2. Try to make a distinction between beneficial coordination and collusion and make the former easier and the latter harder\n\nRelated: decentralization on the [Internet](thoughts/Internet.md)\n","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/decentralized-marketplace":{"title":"Decentralized marketplace","content":"\nRelated: [[thoughts/decentralization|decentralization]], [[thoughts/funding|funding]], [[thoughts/web3|web3]]\n\n## Nanopayments\n\"When you wake up in the morning and flick on a light switch, do you pause to think about how many tiny fractions of a penny that electricity costs? Or do you just flick on the light so you don’t bump your head?\n\nAnd if you could pay for other kinds of services the same way you pay for electricity — a tiny flow of resources that could be turned on or off at any moment — what possibilities would that open up?\"\n\nCan be done through 2 main ways:\n1. [[thoughts/state channels|State channels]]\n2. Amortized cost through probabilistic payments (i.e. 1% chance to win $100 instead of $1 payment). Over time, the value transmitted on-chain will in expectation match the value represented in the probabilistic nanopayments.\n\n## Orchid\n[Website](https://www.orchid.com/)\n\nTLDR; decentralized VPN with nanopayment channels based on xDAI L2 chain\n\nProviders on Orchid run the Orchid server which accepts connection requests and provides VPN service in exchange for immediate payment via nanopayments. Orchid providers stake OXT tokens in an Ethereum smart contract (the directory) to advertise their services to clients. Orchid clients then select providers randomly, weighted by proportional stake, so that the probability of picking a particular provider is equal to their fraction of the total stake.\n\nThey also offer prepaid access credits: A frictionless payment system\n\nOrchid’s Prepaid Access Credits provide users the option to pay in fiat for VPN credits denominated in the xDAI stablecoin through a simple in-app purchase on mobile devices. The credits are only spendable with Orchid’s preferred providers for VPN service.\n\n## Golem\n[Website](https://blog.golemproject.net/golem-primer/)\n\nBased on Polygon L2 using a native ERC-20 GLM\n\nTLDR: Golem democratizes society’s access to computing power by creating a decentralized platform where anyone can build a variety of applications, request computational resources and/or offer their idle systems in exchange for cryptocurrency tokens\n\n\u003eFrom large universities to scientists or artists, anyone can leverage the world’s unused computing power to conduct data intensive research and complex computations through the Golem Network\n\nThe basic premise of the Golem Network is as follows:\n1. providers make some resources available to potential requestors for a price,\n2. requestors rent those resources and pay the providers in exchange.\n\nThe costs of an activity are based on a pre-agreed set of coefficients that specify the price the requestor is required to pay for the time the activity is running, the processor time used and for starting any activity in the first place.\n\nPayments and transactions happen through [[thoughts/ethereum|Ethereum]].\n\n### Registry\nUses an application registry so anyone can publish their own applications. Goals:\n\n1. Give developers a way to publish their integrations and reach out to users in a decentralized manner\n2. Give requestors a place to look for specific tools fitting their needs\n\n3 categories of users:\n1. Authors: publish applications\n2. Validators: review and certify applications as safe by adding them to a whitelist\n3. Providers: can choose whom to trust by selecting validators' whitelist\n\n","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/decision-tree":{"title":"Decision Tree","content":"\nA simple program consisting of if-else decisions (decision stumps) based on the features.\n\n- We can create a bunch of decision stumps and define a \"score\" for each possible rule.\n\t- An intuitive way of thinking about this is as classification accuracy: \"if we use this rule, how many examples do we label correctly?\"\n\t- We can create a tree using *greedy recursive splitting*: using a sequence of stumps to fit a tree\n- However, accuracy isn't perfect. Sometimes splitting doesn't immediately improve accuracy. We can get around this by generally selecting feature test that maximizes information gain\n\t- Entropy of set $S$ of data samples is defined as $H(s) = - \\sum_{c \\in C}p(c)\\log(p(c))$, where $C$ is the set of classes represented in $S$ and $p(c)$ is the empirical distribution of class $c$ in $S$.\n\t- Generally, select feature test that maximizes information gain: $I = H(S) - \\sum_{i \\in {children}}\\frac{|S^i|}{|S|}H(S^i)$\n\n```julia\nInput: Vector y of length n with numbers {1,2,..k}\ncounts = zeros(k)\nfor i in 1:n\n  counts[y[i]] += 1\nentropy = 0\nfor c in 1:k\n  prob = counts[c] / n\n  entropy -= prob * log(prob)\nreturn entropy\n```\n\n## Tradeoffs\nAdvantages\n- Easy to implement\n- Interpretable\n- Learning is fast, prediction is very fast\n- Can elegantly handle a small number of missing values during training\nDisadvantages\n- Had to find optimal set of rules\n- Greedy splitting often not accurate, can require very deep trees\n- Can only express 'and' relations, not OR\n\n## Pseudocode for choosing decision stumps\n```\n// time complexity: O(ndk), O(nd) if k=1 (binary classifier)\ndecision_stump(feature matrix X, and label vector Y):\n  compute error: number of times y_i does not equal most common value for feature j\n  for each threshold t:\n\t  set y_yes to most common label of objects i satisfying rule (x_ij \u003e t)\n\t  set y_no to most common label of objects i satisfying rule (x_ij \u003c= t)\n\t  set y_pred[i] to be our preditions for each object i based on the rule\n\t\t  y_pred[i] = y_yes if satisfied, y_no otherwise\n\t  compute error e which is the number of objects where y_pred_i != y_i\n\t  store the rule (j, t, y_yes, y_no) if it has the lowest error so far\n  return the best decision stump based on score\n```\n","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/degrowth":{"title":"Degrowth","content":"\n[Source: People are realizing that degrowth is bad by *Noah Smith*](https://noahpinion.substack.com/p/people-are-realizing-that-degrowth)\n\nIf we interpret \"degrowth\" as the decision to fix global GDP at its current level, this completely screws over an the existing 40% of the global population that earns less than $2.50 a day while the already rich continue to enjoy their cushy life styles.\n\nIf we wanted to avoid keeping a good chunk of the globe in poverty, we then need to define a new income distribution where everyone who is above the mean is driven down to the mean and everybody above can comfortably grow to the mean. Yet in this case, convincing the vast majority of people living in developed countries to freeze world income at about $17,000/year would be near impossible -- pretty much political suicide for any platform.\n\nIn fact, this would also just not work economically because of how interconnected the global economy is now. \n\n\"When COVID hit, poor countries were devastated not just by the virus but by the **[aftershocks of virus-induced slowdowns in consumption in rich countries](https://documents1.worldbank.org/curated/en/799701589552654684/pdf/Costs-and-Trade-Offs-in-the-Fight-Against-the-COVID-19-Pandemic-A-Developing-Country-Perspective.pdf)**.\"\n\nEK on degrowth:\n\n\u003e I think that if the political demand of the [degrowth] movement becomes you don’t get to eat beef, you will set climate politics back so far, so fast, it would be disastrous. Same thing with S.U.V.s. I don’t like S.U.V.s. I don’t drive one. But if you are telling people in rich countries that the climate movement is for them not having the cars they want to have, you are just going to lose. You are going to lose fast…This is where the politics of [degrowth] for me fall apart…\n\nThe ideal would not be to reduce economic growth, but to reduce consumption as a whole in order to increase investment and [funding](thoughts/funding.md) for new [green technology](thoughts/climate%20tech.md).\n\n\u003e Instead of “consume less”, their message should be “consume less today, so you can consume more tomorrow”","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/democracy":{"title":"Democracy","content":"\nFor representational democracy to work, we need to trust people to make informed decisions at the polls, so that we can hold politicians accountable to the real interests of their constituents\n\n## Salience principles for democracy\nBy Susanna Siegel\n\n\u003e “Salience principle of importance”: idea that the press should make clearly available info that the public needs to know for democracy to work\n\n- For the majority, they focus mainly on their own interests, interactions, and social pressures that leave politics and state institutions in the background. By default, political consciousness stays in the background of consciousness (Lippmann revers to these people as 'deaf spectators')\n- Politics can become salient through elections, contact with the government (e.g. jury duty, drivers license, or a 'brush' with the law)\n\t- John Rawls: \"In a well-governed state only a small fraction of persons may devote much of their time to politics\"\n- Lipmann: we need to bridge by means of mass communication. Journalists then, are the [epistemic](thoughts/epistemology.md) bridges between government and the public\n- Importance principle\n\t- \"make salient information that is important for the public to know about\"\n\t- Newsworthiness: whatever is actually important for the public to know about\n\t- In a different context, can refer to whether it will attract attention if reported in a news outlet\n- To make something salient is to put it forward as both demanding attention and deserving it. In can be distinct from actual uptake (as the receiving end can experience it as demanding of attention but not classify it as deserving it)\n- Accountability/watchdog journalism: reporting on the working of government or political campaigns\n\t- Product in the leaders a fear of public embarrassment or public discrediting, public controversy, or fear of losing an election\n- Problem of democratic [attention](thoughts/attention%20economy.md)\n\t- The library is full of good books, and the sad fact is that none of us will ever read them all. \n\t- Arises from a combination of three points\n\t\t1. Professional journalism is governed by an importance principle of salience\n\t\t2. If journalism fulfilled the importance principle, some roles would depend on readers taking in information made salient by journalism\n\t\t3. For much important information, many readers have no interest in it, feel no prior motivation to learn it, and face substantial obstacles to paying attention to information even when it is widely available, and even when it would yield knowledge that would be useful to have\n\t- **The problematic upshot is that democracy imposes an attentional demand that can't easily be met**\n\t- Representative democracy relies on a population with stable, well-formed opinions about public policy who are disposed to select representatives ready to respect their preferences\n\t- Important news is often not sensational\n\t\t- Social media platforms on the other hand highlight content that captures user attention (maximizes occurrent engagement). Markers of virality are not co-extensive with information that is important for the public to know about\n\t\t- Framing, style, presentation matters a lot\n- Public-as-protagonist principle\n\t- \"recommends framing and selecting information to invite readers to view themselves and one another as potential political participants\"\n\t- Stories should make explicit when it can the ways in which the reading public has a stake in how the story unfolds and how the reader can affect its outcome\n\t\t- Not every reader will be a potential protagonist in every story. However, every regular reader is likely to encounter a story in which they feel addressed as a potential protagonist eventually\n\t- Underlying belief that there are many publics\n","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/density-based-clustering":{"title":"Density-based clustering","content":"\n- Clusters are defined by “dense” regions.\n- Examples in non-dense regions don’t get clustered\n- Clusters can be non-convex\n\nIt is **non-parametric** (there is no fixed number of clusters $k$)\n\n## DBSCAN\nMain idea: merge all neighbouring core points to form clusters\n\nDefines\n- Epsilon ($\\epsilon$): distance we use to decide if another point is a “neighbour”\n- MinNeighbours: number of neighbours needed to say a region is “dense”\n\t- If you have at least minNeighbours “neighbours”, you are called a “core” point\n\nPsuedocode\n- For each example $x_i$ :\n\t- If $x_i$ is already assigned to a cluster, do nothing.\n\t- Test whether $x_i$ is a ‘core’ point ($\\geq$ minNeighbours examples within $\\epsilon$).\n\t\t- If $x_i$ is not core point, do nothing (this could be an outlier).\n\t\t- If $x_i$ is a core point, make a new cluster and call the “expand cluster” function.\n\t\t\t- Assign to this cluster all $x_j$ within distance $\\epsilon$ of core point $x_i$ to this cluster. \n\t\t\t- For each new “core” point found, call “expand cluster” (recursively).\n\nIssues\n- Ambiguity of \"non-core\" boundary points\n- Sensitive to the choice of $\\epsilon$ and minNeighbours","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/design-goals":{"title":"Design Goals","content":"\nGoals in the context of HCI are things that can be defined in a given context, then evaluated.\n\nHuman task involves the steps to do something, whereas human needs are general wants of the user, what they want to get accomplished. Usability goals are primarily objective, user experience goals are more subjective.\n\n### Usability Goals\nUsability refers to ensuring that interactive products are easy to learn, effective to use, and enjoyable from the user's perspective. Following 6 goals:\n\n1. Effective to use (effectiveness). Is the product capable of allowing people to learn, carry out their work efficiently, access the information that they need, or buy the goods that they want?\n2. Efficient to use (efficiency). Once users have learned how to use a product to carry out their tasks, can they sustain a high level of productivity?\n3. Safe to use (safety). What is the range of errors that are possible using the product, and what measures are there to permit users to recover easily from them?\n4. Having good utility (utility). Does the product provide an appropriate set of functions that will enable users to carry out all of their tasks in the way they want to do them?\n5. Easy to learn (learnability). Is it possible for the user to work out how to use the product by exploring the interface and trying certain actions? How hard will it be to learn the whole set of functions in this way? Should have good transfer effects (where knowledge acquired earlier improves one's ability to learn/perform in another context)\n6. Easy to remember how to use (memorability). What types of interface support have been provided to help users remember how to carry out tasks, especially for products and operations they use infrequently?\n\nExamples of commonly used usability criteria\n-   time to complete a task (efficiency)\n-   time to learn a task (learnability)\n-   number of errors made when carrying out a task over time (memorability)\n\n### User Experience Goals\nThese are concerned with how users experience an interactive product from their perspective, rather than assessing how useful or productive a system is from its own perspective\n\nDesirable aspects of UX\n- Satisfying\n- Enjoyable\n- Helpful\n- Fun\n- Provocative\n\nUndesirable aspects of UX\n- Making one feel stupid or guilty\n- Cutesy\n- Gimmicky\n- Frustrating\n\nThese are combined in a user's multi-faceted experience of a product\n\n### Design Principles\n\u003e Generalizable abstractions intended to orient designers toward thinking about different aspects of their designs\n\nConcerned with what users should see and do when carrying out their tasks using an interactive product: the dos and don'ts of interaction design.\n\n1. High visibility: ensure functions are easy to find and intuitive.\n2. Feedback: time sensitive information about what actions has been done and what has been accomplished.\n3. Constraints: ways of restricting the user interaction to those which are valid in any given moment.\n4. Consistency: an interface which follows rules, such as using the same operation to select all objects.\n5. Affordance: attributes should obviously signal what they can use it for. Afford means \"to give a clue\"\n\nThe problem when applying these to real world is that trade-offs can arise between principles (e.g. increased constraint might mean less visibility).","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/design-requirements":{"title":"Double Diamond Model of Design","content":"\nTwo main 'diamonds' of diverge-converge, one to find the right problem and the other to find the right solution (fulfilling human needs).\n\n![Double-Diamond Model: Discover, define, develop, deliver](https://upload.wikimedia.org/wikipedia/commons/b/bd/Double_diamond.png)*Discover, define, develop, deliver*\n\n![Interaction Design Lifecycle](https://www.researchgate.net/profile/Andre-Andre-8/publication/327907730/figure/fig1/AS:675449290100740@1538051068743/Interaction-Design-Lifecycle-Model.ppm)\n\nThe 4 basic activities for interaction design are as follows:\n1. Discovering requirements (discover/define phase). Deciding what to design is key, and exploring the problem space is one way to decide. The goal is understanding the target users and the support an interactive product could provide.\n2. Designing alternatives (develop phase). This can be 2 parts, conceptual design (producing the conceptual model of the product) or concrete design (detail of the product like colours, sounds, images, etc.)\n3. Prototyping alternative designs to be communicated and assessed (develop phase). The process of designing behaviour of interactive products as well as look and feel. Doesn't necessarily need working software!\n4. Evaluating the product and the UX it offers (develop phase). Determine the usability and acceptability of the product or design measured in terms of a variety of usability and user-experience criteria.\n\nHere are a few good questions to ask to better understand the problem:\n-   what are the human needs?\n-   who are the stakeholders?\n-   what are the central tasks?\n-   what might we want to learn? (evaluation goals)\n-   who should our participants be?\n\n## Requirements\nRequirements are **stable** descriptions of users' aspirations, goals, constraints, expectations etc that form a sound basis from which to start design activities (not rigid, might shift over long periods of time). They are also statements about an intended product that specifies what it is expected to do or how it will perform.\n\nDiscovering and communicating reqs is important bc defining what needs to be built supports technical developers and allows users to contribute more effectively\n\n### Steps\n1.  identify **human needs**\n-   which the proposed interactive system will support; task, goals, conditions; current problems and strengths\n2.  identify all **users and other stakeholders**\n-   who do or perform the activity: groups, capabilities, motives, needs\n3.  set **levels of support (metrics)**\n-   functionalities the system will provide; environmental constraints and user/stakeholder characteristics\n-   metrics: how we know if we have succeeded → can be quantitative or qualitative\n-   fit criterion is something that can be used to assess when the solution meets the requirement\n\n### Kinds\n1. **functional requirements:** describe what the product will do\n2.  **nonfunctional requirements:** describe the characteristics (sometimes called constraints) of the product\n\t1.  **data requirements:** capture type, volatility, size/amount, persistence, accuracy, and value of required data\n\t\t-   eg. app for buying/selling stocks has to have up-to-date and accurate data which is likely to change many times a day\n\t2.  **environmental requirements:** context of use; circumstances in which the interactive product will operate. made up of:\n\t\t1.  **physical environment:** lighting, noise, movement, dust expected in operational environment. Will users need to wear protective clothing, which may affect the choice of interface type?\n\t\t2.  **social environment**: will data need to be shared? does sharing have to be synchronous or async?\n\t\t3.  **organizational environment**: how good is user support likely to be, how easily is it obtained, how efficient or stable is the communication infrastructure, etc?\n\t\t4.  **technical environment**: what tech will the product run on or need to be compatible with, and what technological limitations might be relevant?\n\t3.  **user characteristics:** capture key attributes of user group. collection of characteristics for a typical user is a **user profile**\n\t\t-   eg. abilities and skills, educational background, preference, personal circumstances, disabilities, novice/expert/casual or frequent user etc\n\t4.  **usability goals and user experience goals**\n\t\t-   **usability engineering:** approach in which specific measures for usability goals are agreed upon early in the dev process and used to track progress","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/desire-paths":{"title":"Desire path","content":"\n\u003e The path usually represents the shortest or most easily navigated route between an origin and destination. The width and severity of erosion are often indicators of the traffic level that a path receives. Desire paths emerge as shortcuts where constructed paths take a circuitous route, have gaps, or are non-existent.\n\n[Source: Fools and their time metaphors by *Aaron Z. Lewis*](https://aaronzlewis.com/blog/2019/02/11/fools-and-their-time-metaphors/)\n\n_Desire paths_ or _free-will ways_: “paths and tracks made over time by the wishes and feet of walkers, especially those paths that run contrary to design or planning.” In other words, an unexpected behaviour that emerges as the result of poor design.","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/desktop-metaphor":{"title":"Desktop Metaphor","content":"\n## Beyond the Desktop Metaphor\n**An interface that intentionally exploits the vulnerability of human beings for financial or otherwise selfish gain is inhumane and also despicable.**\n\n**An interface that unintentionally allows the former to take place has  \nnot been considerate of the full extent of human fragility, and is therefore still inhumane.**\n\nIsn't this just [design justice](thoughts/Design%20Justice.md)? Considerate design. Desktop metaphor is also just really outdated.\n\nHow do we move beyond sliding and tapping and explore other ways of [interaction design](thoughts/interaction%20design.md)? Reimagining applications and instead using modules and [workflows](thoughts/workflows.md)\n\n## Browser Metaphors\nLinus Lee on [Materials](https://thesephist.com/posts/materials/)\n\nWhat is the right software metaphor for “a point in my browsing history”?\n- Something discrete like files? Or something continuous like a video recording, from which you can “clip out” a section?\n- Do we want hierarchy, so we can organize sessions into sub-sessions? Is browsing history a flat sequence of events, or sections with sub-parts?\n- What should each “session” remember about its contents? Just the URL? Maybe occasional screenshots? Scroll history?\n- Do browsing sessions have _weight_? A session with two windows and 30 tabs each certainly feels heavier than one where I just Googled a question and found an answer in the first tab I opened. How does this manifest in the metaphor?\n- Some browsing sessions are definitely more salient and important to remember than others. How should we express this property?\n\nA lot of this feels familiar to Atlas Recall","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/digital-commons":{"title":"Digital Commons","content":"\nHow might we analogize [urban planning](thoughts/urban%20planning.md) to social media and digital spaces? -\u003e https://medium.com/@jasminewsun/jane-jacobs-social-media-83b4265a1d12\n\n## Online Parks\n[Eli Pariser in Wired](https://www.wired.com/story/to-mend-a-broken-internet-create-online-parks/)\n\n\u003e When technologists refer to platforms like Facebook and Twitter as “walled gardens”—environments where the corporate owner has total control—they’re literally referring to those same private pleasure gardens that Whitman was reacting to. And while Facebook and Twitter may be open to all, as in those gardens, their owners determine the rules.\n\n- [[thoughts/friction|friction]] is essential to public space.\n\t- \"Public spaces are so generative precisely because we run into people we’d normally avoid, encounter events we’d never expect, and have to negotiate with other groups that have their own needs.\"\n\t- Rapid growth can quickly overwhelm and destroy it—as anyone who has lived in a gentrifying neighborhood knows.\n- public goods require constant, active care and [[thoughts/maintenance|maintenance]]\n\t- nuanced labor of governance and maintenance—finding the balance between welcoming everyone and providing safety and comfort for everyone—is critical to the health of online communities\n\n## Internet Studio Gardens\nBy [Jon Borichevskiy](https://jon.bo/posts/internet-studio-gardens/)\n\n[[thoughts/software principles|Principles for Internet Spaces]]\n1. Places where they might drift over to peers in adjacent spaces for the chance – but not the obligation – to respond or otherwise reflect upon, completing the loop at the speed of a lazy river instead of a light circuit (see: [friction](thoughts/friction.md), [pace layers](thoughts/pace%20layers.md))\n2. There might even be different seasons of [play](thoughts/play.md): periods of divergent planting and nurturing followed by collective harvesting and pruning (see: [exploit explore](thoughts/exploit%20explore.md))\n3. Just permeable enough to be discovered by those curious enough to add their own drawings and words. **Details just hidden enough to be carefully unearthed by the intentional visitor**\n\n## Creating Digital Spaces\nCan we create digital common spaces like parks and things without everyone online needing to be exceedingly intentioned?\n\nCommons should be safe, low pressure contexts for random interaction. They are public spaces where a lot of people coincidentally share the same space for a short period in time. It has the same energy as commuting -- a familiar yet ever-changing context.\n\nThe park and the trees may stay the same most times you visit yet the people on the benches and walking on the paved paths are always different. One can sit and observe all the people moving by, [wondering what their life is like.](https://en.wikipedia.org/wiki/People-watching).\n\n\u003e \"What would it look like to do that with your favourite internet neighbourhoods?\"\n\nThis is a small reflection on potential new avenues to explore for digital spaces. Not to say that any existing ones are bad but I am interested to see what new direction we can take to explore how we use technology to further human connection.\n\n### Serendipity in Public Spaces\nSerendipity is bumping into new people you otherwise wouldn't have talked to or sought out. It's the casual bus or subway chatter, the queue neighbour, or stranger reading on a park bench. It's the opposite of intentionality.\n\nAre there ways to be _less_ intentional with digital interactions?\n\nIf you want to meet with someone you need to schedule it or visit a link, etc. There is no 'random' interaction. Even algorithmic experiences are like being carried away by the TikTok or Facebook algorithm rather than something out of the blue. Though these experiences may seem random at times, they are explicitly curated with an _end goal_ in mind.\n\nAre there any spaces that don't have ulterior motives and are just places of gathering? The only example that comes to mind where 'coincidental' interaction happen is within currated [interest groups](thoughts/social%20graphs.md) like online network forums around [games](thoughts/games.md) or technologies or early communities lead by superconnectors like the [Whole Earth 'Lectronic Link (WELL)](thoughts/From%20Counterculture%20to%20Cyberculture.md). How can we recreate these public 'watering holes' for people to gather around? \n\n### Permanence in Private Spaces\nPermanence means that the environment reflects that people have been there. A shared garden to tend to, a bookshelf to work through, a guestbook of all the people who have dropped in and out.\n\nSo many of our mediums have now tended towards [real time](thoughts/ephemereal%20content.md) in an effort to replicate the fleeting nature of face-to-face conversation; vanishing messages, video chats, and audio rooms. Yet, rarely do any of these platforms leave any indication whether a conversation ever happened between two people.\n\nIs there any way we can create shared *artifacts* that are permanent and can be grown over time? A digital indication that a space is lived in and occupied?\n\nAs of now, most platforms keep a primative chat log or history but thats it. What if there was a way to create digital [gardens](https://twitter.com/samihusseni/status/1329499588982575104) to foster and maintain existing relationships? A commonspace you could both take care of, share, and contribute to. Completely private common spaces often allow users to put whatever and allow people can construct their own digital nooks and cozy spaces.\n\nMaybe this involves having a shared calendar, todo list, books. Or even just a space to co-live and co-exist in [virtual worlds](thoughts/virtual%20worlds.md). Most online RPG games (think Animal Crossing, Minecraft, Stardew valley) give the option for users to have a shared space to exist and build together (and where both people don't necessarily both need to be present for the space to function). Why doesn't this exist outside of the gaming sphere?\n\nCan we create permanence of artifacts without sacrificing ephemerality in medium?\n\n## Tools for Digital Spaces\nGiven that there are so many different types of digital spaces, I wanted to explore how different tools are supporting and facilitating different sorts of digital human interaction. Can we use urban planning to help us [plan digital spaces](https://medium.com/@jasminewsun/jane-jacobs-social-media-83b4265a1d12)?\n\nThe hope is to be able to move away from the 'feed'-based model of browsing the social internet and to create safe spaces to interact at different scales.\n\n\u003e The “feed”–an archaic form of content consumption that is effectively just a direct visual manifestation of the data structure that powers it – is a medium that is effectively designed to be consumed alone.  --[Humphrey Obuobi](https://www.somewheregood.com/garden/trust-and-safety/)\n\n### Town Square\nMany-to-many relationships like clubs, families, larger interest groups. \n\n#### Questions\n* How do we ensure that people feel connected in large groups and find \nwhat they are looking for?\n* Should communities be gated or public? Does this matter?\n* How do we moderate content while ensuring individuals feel safe?\n\n#### Tools\n* Forums -\u003e Gathering based on interest\n* Game lobbies and public squares -\u003e A temporary bringing-together of otherwise completely unrelated individuals\n* Meeting rooms and Gather.town -\u003e Intentional spaces to meet and mingle with coworkers and friends\n\n### Parasocial Relationships\nOne-to-many 'broadcast' relationships.\n\n#### Questions\n* How do we ensure these relationships are healthy for all parties involved?\n* Should content be moderated in this relationships? Is this the responsibility of the individual, the platform, or the viewer?\n\n#### Tools \n* Twitch, Celebrities, and Internet Figures -\u003e Gathering around a single person because of personality/content\n* Newsletters and personal sites -\u003e Public places of exploration and self-identity, self-owned corners of the [internet](thoughts/Internet.md)\n\n### Private Channels\nSpaces for one-to-one interaction.\n\n#### Questions\n* Almost all of these mediums are on a sliding scale of how '[real-time](thoughts/ephemereal%20content.md)' the medium is, yet none of them are obsolete. Why is that?\n* Who has power in the channels? What tools are there for safety?\n\n#### Tools \n* Letters and Mail -\u003e Completely asyncronous text based communication\n* Messages -\u003e Instantaneous text or audio based communication with a history log. No immediate urgency to reply\n* Calling -\u003e Audio/video based live communication","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/digital-mindfulness":{"title":"Digital Mindfulness","content":"\nOn methods to reclaim ourselves from the [attention economy](thoughts/attention%20economy.md). How do we enable [friction](thoughts/friction.md) to give people the space to think and reflect?\n\n[reflect](posts/reflect.md) tries to do this a little\n\n## Time\n[Source: The present time by *Kernel*](https://kernel.community/en/learn/module-3/time)\n\n\u003e Instead of having sequential conferences on bulletin boards like The Well where you would take hours to **craft a response** to something, we ended up with a digital space where we were constantly being interrupted [...] We end up in this state of constant emergency interruption which I don't think is healthy neurologically or culturally.\n\nThis is an opportunity for us to reclaim our attention, to *properly* build out asynchronous experiences so that people can work in their own time rather than the rushed, [ephemereal content](thoughts/ephemereal%20content.md) we're so used to now.\n\n\"I don't want a job - I want my basic needs fulfilled and a degree of comfort and security which will enable me to make a meaningful contribution. Jobs are an artifact of the industrial age and a certain way of existing in time.\" Jobs are just the societally accepted norm for fulfilling basic needs. (Bullshit Jobs)\n\nSide note: people who [introduce](thoughts/introductions.md) themselves by talking about their job make me feel really weird. You're just describing the means you take the keep yourself alive -- what are the ends? What makes you *feel* alive?\n\n## Designing for slowness\n\n\u003e \"what if you had to commute to websites\"\n\u003e https://twitter.com/spencerc99/status/1401320086183366657\n\n*Exploring the Reflective Potentialities of Personal Data with Different Temporal Modalities: A Field Study of Olo Radio*\n\nThis feels so magical to me; being able to create technology that evokes and recalls, creating spaces for reflection and a chance to reincorporate rather than gogogogopleasefocusonme all the time.\n\n- \"There are also growing calls in the [HCI](thoughts/human%20computer%20interaction.md) community to develop alternative approaches to designing interactions with personal data that better support experiences of contemplation, interpretation, and slowness\"\n- Slowness as a form of reflection. Key features of the Olo Radio:\n\t- takes time to understand\n\t- manifests change through time (big [*A Tale for the Time Being*](thoughts/A%20Tale%20for%20the%20Time%20Being.md) energy)\n\t- leverages different forms of time to prompt reflection by manifesting their presence in everyday life\n- Rather than organizing music through name or playlist (inherent or user groupings), Olo Radio chooses to organize information through data residue (unintentional data generated through regular usage). Allows the user to browse music by time of day listened to, how long ago you listened to it, or when in the year you listened to it.\n\t- Incentivizes revisiting of the past rather than the constant discovery of the new. (w the exception of once-a-year recaps like Spotify Wrapped)\n\t- How do we introduce temporality into objects to appreciate their inner processes?\n\t\t- Water fountain display of number of water bottles saved in lifetime\n\t\t- Transit time between websites? (bring back [friction](thoughts/friction.md))\n\t\t- \"Natural decay\" of physical objects -- how do we transfer this into the digital realm?\n\t\t- Dispo as a way to fake 'scarcity' in digital photos\n- Temporal seeking of memory and the element of surprise/anticipation\n\t- “I took to blocking off time to use it. It was less of a casual thing for me. …I’d start with Life mode. I’d pick a position, turn [the volume] up, lie on the couch, and close my eyes. …I’d get a vague idea of where I was [in time]. A pattern would eventually emerge. [Songs would] sometimes spark a flash of a specific memory, like a date I was on years ago or visions of my parents’ home. …I’d start to get these tense feelings about what the next song would be. Where would it bring me back to? …When I was in the zone, time flew by. I could listen for an hour without really noticing.”\n\t- “It was playing on Day, just in the background. …This Daft Punk song came on. That caught my ear. I sensed it could’ve been on a playlist I’d listen to before my [ski] competitions when I was younger. …I switched to Life and the slider shot back to the start [of my Last.FM]. This was years ago, so it would’ve been around the right time. …I anticipated Year would put [the slider] somewhere in the winter months. And, it did! I put it back to Life. …The next one in the queue was a Chemical Brothers song. And that’s when I knew I was in my old playlist.”\n\t- Increasing focus on active and intentional listening (I'm going to block off time to enjoy this) rather than just passive listening (put it on in the background while I work)\n- Blackspots emerging in one's digital history when devices and services breakdown\n\t- The result of [infrastructural](thoughts/infrastructure.md) inversion\n\t- What happens when data is lost in a 'complete' record? How does that affect the experience? The recall?","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/digital-permanence":{"title":"Digital Permanence","content":"\nOnce you share something, you can't unshare it, the [internet](thoughts/Internet.md) feels intractable.\n\n**What do we lose when we lose deletion?**\n\nRelated: [cancel culture](thoughts/cancel%20culture.md), [right to be forgotten](thoughts/right%20to%20be%20forgotten.md), [ephemereal content](thoughts/ephemereal%20content.md)\n\n## The Internet is a collective hallucination\n[Source: The Internet Is Rotting *in The Atlantic*](https://www.theatlantic.com/technology/archive/2021/06/the-internet-is-a-collective-hallucination/619320/)\n\n\"Of course, there’s a keenly related problem of permanency for much of what’s online. People communicate in ways that feel ephemeral and let their guard down commensurately, only to find that a Facebook comment can stick around forever. The upshot is the worst of both worlds: Some information sticks around when it shouldn’t, while other information vanishes when it should remain.\"\n\n## Anonymity and [Pseudonymity](thoughts/pseudonymity.md)\nLibrex and the free exchange of ideas on college campuses\n* silencing of ideas\n* people go to colleges not to just read textbooks\n* but to talk to professors who've studied it deeply and get their opinions on it\n* but what happens when those professors feel like their can't express their opinions?\n* what happens when a student is offended by that opinion and the professor is at risk of losing their job?\n\n\"61% of students on Ivy League campuses are afraid to speak their minds because of campus culture\"\n\ndifference between public and private selves\n* friedman chooses to minimize this difference as much as possible\n* extra mental effort to separate the two, need to remember what parts of yourself to portray to what people\n\ni think for me from an engineering perspective like if i'm dishonest with others i will too quickly become dishonest with myself and in so doing i will not truly be able to think deeply about the world and come up and build revolutionary ideas there's something about honesty that feels like it's that first principles thinking\n\n* being scared to be completely vulnerable and honest\n* changing frame of life\n\t* people change over time, yet the internet doesn't feel super accepting of these changes\n\t* your opinions 10 years ago can still be critiqued as if you hold them today\n\t* should normalize growth\n\t* if people STILL hold views that are problematic by today's standards, then THAT's problematic\n\nA theorem is only a fact in the [context](thoughts/context.md) of the axioms on which it is based. Axioms are treated more like postulates, accepted only tentatively and defining a branch of mathematics.\n\nThe uncertainty principle governs what we can call facts in all systems. Including mathematics.\nIt more or less says that you can only explain a system using criteria defined in that system.\n\n## Social media\n[Source: Lifting the mask by *Edward Snowden*](https://edwardsnowden.substack.com/p/lifting-the-mask)\n\n\"One history of the Internet — and I'd argue a rather significant one — is the history of the individual's disempowerment, as governments and businesses both sought to monitor and profit from what had fundamentally been a user-to-user or [peer-to-peer](thoughts/peer-to-peer.md) relationship. The result was the centralization and consolidation of the Internet — the true y2k tragedy. This tragedy unfolded in stages, a gradual infringement of rights: users had to first be made transparent to their internet service providers, and then they were made transparent to the internet services they used, and finally they were made transparent to one another. The intimate linking of users' online personas with their offline legal identity was an iniquitous squandering of liberty and technology that has resulted in today's atmosphere of accountability for the citizen and impunity for the state. Gone were the days of self-reinvention, imagination, and flexibility, and a new era emerged — a new eternal era — where our pasts were held against us. Forever.\"\n\n\"Everything we do now lasts forever... The Internet's synonymizing of digital presence and physical existence ensures fidelity to memory, identitarian consistency, and ideological conformity. Be honest: if one of your opinions provokes the hordes on social media, you're less likely to ditch your account and start a new one than you are to apologize and grovel, or dig in and harden yourself ideologically. Neither of those \"solutions\" is one that fosters change, or intellectual and emotional growth\"\n\n\"The forced identicality of online and offline lives, and the permanency of the Internet's record, augur against forgiveness, and advise against all mercy. Technological omniscence, and the ease of accessibility, promulgate a climate of censorship that in the so-called free world instantiates as self-censorship: people are afraid to speak and so they speak the party's words... or people are afraid to speak and so they speak no words at all...\"\n\n\"Even the most ardent practitioners of cancel culture — which I've always read as an imperative: Cancel culture! — must admit that cancellation is a form of surveillance borne of the same technological capacities used to oppress the vulnerable by patriachal, racist, and downright unkind governments the world over. The intents and outcomes might be different — cancelled people are not sent to camps — but the modus is the same: a constant monitoring, and a rush to judgment.\"\n\n## Blockchain\nThe sheer immutability of [[thoughts/blockchain|blockchain]] data—you can’t delete a block without redoing the chain, something semi-impossible in practice—puts it in obvious violation of [[GDPR]].\n\nSo long as the wallet is unassociated with real personal data, either on chain or off, it shouldn’t be subject to the many data restrictions of [[thoughts/GDPR|GDPR]] by a strict reading of it. But as soon as a company like Coinbase does a KYC to verify your identity, this data gets linked at [[thoughts/GDPR|GDPR]] violation happens once again.","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/digital-signatures":{"title":"Digital signatures","content":"\n\u003e Signatures are cryptographic functions that attest to the origin of a particular message.\n\nIt is infeasible for Alice to generate a signed message that appears to have been generated by Bob.\n\n- Aggregating signatures: have multiple signatures signed by various people and then you can aggregate it into a single signature, which makes it more efficient in terms of size\n- Thresholding signatures: multiple people split a key into multiple parts, and you require some fixed number of people to agree to sign a message to be able to actually sign it with the full key\n\t- In a $(k,n)$-threshold signature scheme, there is a single public key held by all replicas, and each of the $n$ replicas holds a distinct private key.\n\n## Signatures Schemes\nRequire 3 algorithms\n1. Key generation algorithm: `seed -\u003e public_key, private_key`\n2. Signing algorithm: `msg, private_key -\u003e msg, signature`\n3. Verification algorithm: `msg, signature, public_key -\u003e boolean`\n\n## Signed Blobs\n[From Farcaster Docs](https://www.farcaster.xyz/docs/signed-blob)\n\nBlobs are [[thoughts/security#Message Digest|cryptographically signed]] so that it cannot be tampered with\n\nThe structure that holds this data is called a Signed Blob, and it contains three properties:\n\n-   `body` - the JSON object that the user wants to store\n-   `merkleRoot` - the hashed body (should be renamed to hash)\n-   `signature` - the signed hash\n\n### Signing\n1.  Construct the JSON object with the properties in the exact order as specified.\n2.  Convert the object to a string to make it hashable.\n3.  Hash the string using [keccak256](https://en.wikipedia.org/wiki/SHA-3) and store this value as the merkleRoot\n4.  Sign the merkleRoot with the user’s Ethereum wallet, creating a recoverable ECDSA signature and store this in the signature property.\n\n### Verifying\n1.  Convert the body to a string to make it hashable.\n2.  Hash the string using [keccak256](https://en.wikipedia.org/wiki/SHA-3) and check that it matches the merkle root\n3.  Perform an ecRecover on the signature with the merkle root to retrieve the address.\n4.  Check that the recovered address matches the expected address.\n\n## Signed Message Digests\n- Signature of long messages is computationally expensive\n- We can compute a fixed-length \"fingerprint\"\n\t- Apply hash function $H$ to message $m$, giving a fixed size message digest, $H(m)$\n- Signed message digest\n\t- Bob sends message $m$ and signed digest $K_B^-(H(m))$\n\t- Alice receives $m$ and computes $H_{new}(m)$\n\t- Alice receives signed digest $K_B^-(H(m))$ and computes $K_B^+(K_B^-(H(m)))$\n\t- If $K_B^+(K_B^-(H(m))) = H_{new}(m)$, the message is considered signed (and untampered)\n- Alternatively, [[thoughts/MAC|MACs]]\n\n","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/disrupting-routine":{"title":"Disrupting routine","content":"\nFrom *[The Morning Paper](https://blog.acolyer.org/2021/02/08/the-ants-and-the-pheromones/)*\n\nThe ‘reward equation’ models how ants communicate using pheromones, and our own brains keep track of rewards using dopamine. The reward equation includes a decay or ‘forgetting’ parameter, so what happens if you disrupt established solutions for long enough that their hold is broken?\n\n**If you disrupt all of the pheromone trails around their nest, is that they converge on a new solution in the environment, but it won’t necessarily look the same as the one they had before the disruption**\n\n","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/distributed-systems":{"title":"Distributed Systems","content":"\nA distributed system can be defined as multiple computers (nodes) communicating via a network trying to achieve some task together.\n\n## Martin Kleppmann's Course\nNotes from [Martin Kleppmann's Distributed Systems Course](https://www.youtube.com/watch?v=UEAMfLPZZhE\u0026list=PLeKd45zvjcDFUEv_ohr_HdUFe97RItdiB) (he's the guy who wrote \"Designing Data-Intensive Applications\" O'Reilly 2017). He has a set of [course notes on his teaching site as well](https://www.cl.cam.ac.uk/teaching/2122/ConcDisSys/dist-sys-notes.pdf).\n\n\u003e How do we share data amongst different concurrent entities?\n\n- Recommended Reading\n\t- \"Distributed Systems\" by van Steen \u0026 Tanenbaum: Implementation detail heavy, more practical\n\t- \"Introduction to Reliable and Secure Distributed Programs\" (2nd ed) by Cachin, Guerraoui \u0026 Rodrigues: Theory heavy\n\t- \"Designing Data-Intensive Applications\" by Kleppmann: More oriented toward distributed databases\n\t- \"Operating Systems: Concurrent and Distributed Software Design\" by Addison-Wesley: links to Operating Systems\n\n### Why distributed?\n- Things are inherently distributed: sending a message from your phone to your friend's phone\n- Reliability: even if one node fails, the system as a whole keeps functioning\n- Performance: get data from a nearby node rather than one centralized server halfway around the world\n- Solve bigger problems: some amounts of data can't fit on just one machine\n\n### Why *not* distributed?\n- Communication may fail (and we might not even know it has failed)\n- Processes may crash (and we might not know)\n- All of this can happen nondeterministically\n- Thus we need to think about [[thoughts/fault tolerance|fault tolerance]]\n\n### Notes\n- [[thoughts/RPC|RPCs]]\n- [[thoughts/fault tolerance|Fault Tolerance]]\n\t- See [[thoughts/fault tolerance#Two Generals Problem|Two Generals Problem]] and [[thoughts/fault tolerance#Byzantine Generals Problem|Byzantine Generals Problem]]\n- [[thoughts/system model|System models]]\n- [[thoughts/clocks|Physical and Logical Time]]\n- [[thoughts/causality|Message ordering and Causality]]\n- [[thoughts/message broadcast|Message broadcast]]\n- [[thoughts/replication|Replication]]\n- [[thoughts/quorum|Quorum]]\n- [[thoughts/consensus#Distributed Systems|Consensus]]\n- [[thoughts/consistency|Consistency]]","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/distributed-web":{"title":"Distributed Web","content":"\nNew web technologies and communities seeking to reduce or eliminate central points of control on the web\n\n## Distributed Press\n[Source](https://github.com/hyphacoop/distributed-press-organizing/wiki/Publishing-to-the-Distributed-Web)\n\nThe Distributed Web enables us to share content that **resist centralized forms of censorship**\n\nDistributed Press uses [[thoughts/IPFS]] and [[thoughts/Hypercore]] as our initial content sharing protocols. In addition to the familiar https, you can view our published content using the ipfs and hypercore schemes on compatible browsers.","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/double-consciousness":{"title":"Double-consciousness","content":"\nTerm from DuBois, 1989\n\nRelated: [hermeneutical injustice](thoughts/hermeneutical%20injustice.md), [epistemic injustice](thoughts/epistemic%20injustice.md)\n\nIn the context of marginalized knowers needing to model how their actions are perceived by dominantly situated kn owers.\n\nTom Robinson exhibits this in *To Kill a Mockingbird*, when he recognizes his 'mistake' in saying he felt sorry for Ewell.\n\n\u003e He knows what actually took place because he has the epistemic resources (for example, a non-subordinating notion of pity) to do so. At the same time, he also knows what is happening in the courtroom, for he has the epistemic resources to know something else: how his words and actions will be perceived by those without the epistemic resources required to know him and his world of experience.\n","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/downward-causation":{"title":"Downward Causation","content":"\nIn hierarchical systems, downward casuation implies that higher, more abstract, levels of a system can influence lower level parts of the system.]\n\nOne example of this is [telerobotics](thoughts/telerobotics.md), where we have 'higher-level' mental thoughts that coincide with lower level atomic and physical actions (i.e. muscles moving to get us to the fridge)","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/economics":{"title":"Economics","content":"\n\u003e Our goal as economic designers is to craft the systems that drive our selected set of values.\n\n[Source: Prosocial economics for game design by *Daniel Cook*](https://lostgarden.home.blog/2020/01/11/prosocial-economics-for-game-design-%EF%BB%BF/)\n\nEconomics is predominantly concerned with the central Economic Problem, namely\n-   **Limited resources**: There are limited resources in the world;\n-   **Unlimited needs**: Greedy humans have essentially unlimited needs for those resources.\n\nHowever, assumptions in the early economic models of human behaviour are problematic:\n1. Homo economicus: The most common behavioral model assumes that humans are atomic individuals who operate rationally and selfishly.  We know now that humans have limited attention, are contextually altruistic, are highly [tribe flourishing](thoughts/tribe%20flourishing.md), and exhibit a wide range of irrational cognitive biases.\n2. Individuals are the best judge of their needs: Our brains are not conscious of the base psychological processes driving some of our most pressing needs and are thus unable to value relationships rationally.\n3. Weak social modeling: Most economics models ignore basic human behavior such as friendship networks, affiliation networks, limits on cognitive resources (ex: attention) or altruism.\n\nEconomics embraces reductive [[thoughts/Utilitarianism|utilitarianism]] and posits you can put a price on anything. We tend to be intrinsically motivated to connect to others and invest long term in a relationship where no extrinsic value is ever publicly admitted. When a relationship transitions into being an extrinsically rewarded transactional relationship, the relationship often suffers a catastrophic loss of value. (This is the same reason that just throwing money at [open source software](thoughts/Making%20and%20Maintenance%20of%20OSS.md) often doesn't work, it kills the intrinsic drive to create)\n\n### Selfishness\n[Source: Does Studying Economics Breed Greed? by *Adam Grant*](https://www.psychologytoday.com/us/blog/give-and-take/201310/does-studying-economics-breed-greed)\n\nThose that practice economics — and to a degree modern American capitalism — are heavily invested in an implicit system of [self-centered](thoughts/selfish.md) moral values.\n\n\"The repetitive doctrine that humans are best modeled as selfish rational optimizers creates a set of selfish social norms that practitioners consciously or subconsciously follow. The act of studying economics makes you a morally worse human-being (by most definitions of morality.)\"\n\nHow do we move beyond the study of scarcity and towards a study of abundance and [positive sum](thoughts/positive%20sum.md) goods? ","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/effective-altruism":{"title":"Effective Altruism","content":"\nVery utilitarian, approach that the suffering of a few is okay as long as the greater good benefits?\n\nRelated: [The ones who walk away from Omelas](thoughts/The%20ones%20who%20walk%20away%20from%20Omelas.md), [[thoughts/quantization|quantization]]\n\nWhat about self-care? How does the self fit into the greater whole? Is it [selfish](thoughts/selfish.md) to take care of oneself?\n\n## What is EA?\nEarning to give. How do we reduce the stigma around wealth?\n\nWork can have huge impacts on the type of change we can make in the world. We spend ~80k hours, makes sense to spend atleast 1% of it thinking about what to dedicate the other 99% to.\n\nHow do we time donations to maximize impact? Turns out there's no 'goldilocks zone' in the continuum.\n* When you're young: justify putting it off by saying \"oh I'll donate when I have more money\"\n* When you're old: justify not doing it by saying \"oh that's too much of my money I'm giving away\"\n\n## Shallow Puddle Analogy\nStory from [source: The Drowning Child and the Expanding Circle by *Peter Singer*](https://forum.effectivealtruism.org/posts/SwG8Tj9RkG8DzpM4f/the-drowning-child-and-the-expanding-circle)\n\nOne morning, you notice a child has fallen in and appears to be drowning. To wade in and pull the child out would be easy, but it will mean that you get your clothes wet and muddy, and by the time you go home and change you will have missed your first class.\n\nDo you have any obligation to rescue the child? Unanimously, most people say they do. Does it matter if other people walk by the pond and do nothing? Most people still say no. Does it matter if the child were far away, in another country perhaps? Most people still say no.\n\n\"We are all in that situation of the person passing the shallow pond. We can all save the lives of people, both children and adults, who would otherwise die, and we can do so at a very small cost to us: the cost of a new CD, a shirt, or a night out at a restaurant or concert, can mean the difference between life and death to more than one person somewhere in the world.\"\n\n## Ineffective Altruism\n[Hal in Reboot](https://reboothq.substack.com/p/ineffective-altruism?s=r)\n\nIneffective altruism eschews metrics, because “What does doing good look like?” should be a continuously-posed question rather than an optimization problem.\n\n\u003e Strengthening community is also important for our shared future, even if it isn’t measurable. \n\nAs an ideology of allocating resources, it is recognized as explicitly political, rather than cloaking itself in the discourse of science and rationality.\n\nWhat is the best we can do as a collective and community rather than at the individual level?\n\nI'm curious if there *has* been attempts to [[thoughts/quantization|quantize]] efforts of mutual aid and solidarity? If so how what does that computation come out to. Thinking about it, don't most quantizations of these things have huge error bars? How do EA folks choose between prioritizing something that is almost certainly good vs something that could have a very small change of huge upside? Seems to me they are basing it off of expected value of the distribution which.... isn't reasonable in most cases I feel (especially in cases when the long tail for these distributions can explode as $t \\rightarrow \\infty$)\n\nPotentials include capping tail end of distribution?\n\n\u003e Seventh-generation decision making, for example, is an indigenous principle that is enshrined in the Constitution of the Iroquois Nation. It mandates Iroquois leaders to consider the effects of their actions over seven generations, encompassing hundreds of years. Seven generations is a long time, but it is also a finite amount of time. (a form of [[thoughts/traditional knowledge|traditional knowledge]])\n\nKarl Popper had a really good way of putting this, which now sides him very solidly on the side which would choose to save the child in [[thoughts/The ones who walk away from Omelas|The Ones Who Walk Away From Omelas]]\n\n\u003e Similarly we must not argue that the misery of one generation may be considered as a mere means to the end of securing the lasting happiness of some later generation or generations; and this argument is improved neither by a high degree of promised happiness nor by a large number of generations profiting by it. All generations are transient. All have an equal right to be considered, but our immediate duties are undoubtedly to the present generation and to the next.\n","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/embedded-AI":{"title":"Embedded AI","content":"\nMore in [post on AI systems](posts/ai-systems.md)\n\n## Dreyfus\nDreyfus believed that, for any AI system to achieve any sort of general intelligence, it must also exhibit Dasein (being in the world). Thus, \"a successful Heideggerian AI would need a perfect model of the human body – and by implication, that Dasein must be expressed as a human being, organically as well as existentially\".\n\nDreyfus's critique of the [frame](thoughts/frame%20problem.md) approach → descriptions of typical situations like going to a birthday party\n-   however, this quickly grows out of hand once again as any AI program using frames to organize millions of meaningless facts so as to retrieve the relevant frames is going to be caught in a cycle of finding frames for recognizing relevant frames for recognizing relvant facts\n\n## Approaches to embedded AI\n### Rodney Brook's behaviourist approach\n\nIt turns out to be very difficult to reproduce in an internal representation for a computer the necessary richness of environment that would give rise to interesting behaviour by a highly adaptive robot\n\nThis is generally avoided by human beings because their model of the world is the world itself\n\nSolution is to build a mobile robot that uses the world itself as its own representation (referring to its sensors rather than to an internal world model)\n\nProblems\n-   does not learn\n-   operates in a fixed world, responding only to a small set of possibly relevant features that their receptors can pick up\n\n### Phil Agre's pragmatist model\nUse of deictic representations: instead of representing a particular object in the world, we represent a role that an object might play in a certain time-extended pattern of interaction between an agent and its environment\n\ne.g. when a virtual ice cube defined by its functions is close to the virtual player, a rule dictates a response, e.g. kick it\n\nProblems\n- no learning takes place. As such, finesses rather than solves the frame problem\n\n### Merleau-Ponty's discriminatory model\n-  as an agent learned, skills are not stored as internal representations\n-   rather experiences are presented to the learned as more finely discriminated situations\n\t-   e.g. as you learn to cook, experiences are presented that are more finely discriminated like having a better cooked egg vs a poorly done one\n-  if the situation does not clearly solicit a single response or if the response does not produce a satisfactory result, the learner is led to further refine the discrimination\n\n### Walter Freeman's neurodynamic model\n-   basic Cartesian model\n\t1.  the brain receives input from the universe by way of its sense organs\n\t2.  out of this stimulus information, the brain abstracts features, which it uses to construct a representation of the world\n-  Treat the computer/brain as a passive receiver of bits of meaningless data, which then have significance added to them\n\t-   big problem is, how the brain binds the relevant features together (searle's chinese room)\n-   concept of energy states\n\t-   state tends toward minimum \"energy\"\n\t-   minimum energy states are called attractors\n\t-   brain states that tend towards a particular attractor are called that attractor's \"basin of attraction\"\n\t-   when learning, the brain forms a new basin of attraction for each new significant class of inputs → significance of past experience is preserved in an attractor landscape\n-   each new attractor does not represent a thing, rather, the brain's current state is the result of the sum of the animal's past experience with the thing\n\t-   constantly updated landscape of attractors is correlated with the agent's experience of the changing significance of things in the world (intentional arc)\n-   no fixed representations, when an animal learns to respond to a new odor, there is a shift in all other patterns (even those not directly involved with the learning)\n\t-  different from GOFAI, memory stores in computers in which each item is positioned by a discrete address or branch of search tree","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/emergent-behaviour":{"title":"Emergent Behaviour","content":"\nHow complex behaviour can arise out of seemingly simple rules? Is there anything special that causes emergent behaviour?\n* Ant simulations\n* Mold simulations\n* [Community](/thoughts/communities) dynamics\n\nInteresting to think about in context of single agents in multi-agent systems. How does [consciousness](thoughts/consciousness.md) arise? Is it just because of the rules itself (a [reductionist](thoughts/Reductionism.md) approach) or is there something larger at play?\n\n[Gall's law](thoughts/Gall's%20law.md): simple alphabets produce behaviors. Even simple rules like Conway's game of life can be Turing Complete!\n\nHow does this fit into low [bandwidth](thoughts/bandwidth.md) communication?\n\n## Emergentism\n\u003e Once a certain level of complexity is reached, there is a kind of qualitative leap where completely new sorts of physical laws can “emerge”—ones that are premised on, but cannot be reduced to, what came before\n\n- In this way, the laws of chemistry can be said to be emergent from physics: the laws of chemistry presuppose the laws of physics, but can’t simply be reduced to them.\n- In the same way, the laws of biology emerge from chemistry: one obviously needs to understand the chemical components of a fish to understand how it swims, but chemical components will never provide a full explanation.\n- In the same way, the human mind can be said to be emergent from the cells that make it up.\n\n## Combination Problem\nHow do microlevel experiences combine to form macrolevel ones?\n\n\"Take a sentence of a dozen words, and take twelve men and tell to each one word. Then stand the men in a row or jam them in a bunch, and let each think of his word as intently as he will; nowhere will there be a consciousness of the whole sentence\"\n\n### [Panpsychist](thoughts/Panpsychism.md) response\nMental properties belong only to genuine individuals, not to mere aggregates\n\nThen, what is the boundary of the genuine individual? This is a problem of embodiment. To be a genuine individual is not simply to be a particular (as opposed to a conglomerate or universal) but also a system that has some kind of bounded organizational unity through [autopoiesis](thoughts/autopoiesis.md) -- this is a body\n\nTheir own emergence problem: how do genuine individuals emerge from particular that aren't individuals/subjects of experience? It doesn't solve the problem of accounting for the place of consciousness in nature, it just relocates it","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/emptiness":{"title":"Emptiness","content":"\nEmptiness is like the mathematical concept of 0.\n- It seems to have no value, yet is it the foundation of mathematics.\n- Without 0, you cannot have 1, 2, 3, so forth.\n\nEmptiness thus does not mean nothingness (0 is not null), emptiness is the base case through which existence is meaningful.\n\n\u003e In order for a glass to even be empty, it should first and foremost be there.\n\nEmptiness means empty of independent existence -- all things are [interdependent](thoughts/interdependence.md)\n\nThus, form is emptiness but emptiness is form (existence is to depend on others).\n\n## Indra's Net\n[Source: Indra's net on *Wikipedia*](https://en.wikipedia.org/wiki/Indra%27s_net)\n\nImagine a net stretching out infinitely in all directions with a monadic-like jewel at each node that reflects every one, including itself. These objects are nodes in a net of [[thoughts/ontology|ontological]] interdependence, one in all and all in one.\n\n![](thoughts/images/Indra's%20Net.png)","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/encryption":{"title":"Encryption","content":"\n\u003e A process of converting the original representation of the information (plaintext) into an alternative form (ciphertext). Ideally, only authorized parties can decipher a ciphertext back to plaintext and access the original information.\n\nAn encryption algorithm comprises\n- a method for encrypting data\n- a method for decrypting data\n- a secret key used in the decryption/encryption method\n\nThe two types of encryption are\n1. [[thoughts/Asymmetric Key Cryptography|Asymmetric Key Cryptography]] (sometimes called public-key cryptography)\n2. [[thoughts/Symmetric Key Cryptography|Symmetric Key Cryptography]]\n\nTrapdoor: a mathematical function that is easy to go one way but hard to go the other way (an effectively one-way function)\n- Common functions include [[thoughts/RSA|RSA]] (prime factorization) and [[thoughts/Elliptic-curve Cryptography (ECC)|ECC]]\n- [[thoughts/RSA|RSA]] for example, is a trapdoor because multiplying primes is easy but factoring the result back into its component primes is hard.\n- The bigger the spread between the difficulty of going one direction in a Trapdoor Function and going the other, the more secure a cryptographic system based on it will be\n\nLanguage\n- $A$: Alice\n- $B$: Bob\n- $K_A$: Alice's encryption key\n- $K_B$: Bob's decryption key\n- $m$: plaintext message\n- $K_A(m)$: ciphertext, encrypted with key $K_A$\n- $K_B(K_A(m)) = m$\n\nTypes of attacks\n1. Ciphertext-only attack: knowns $K_A(m)$ but not $m$\n2. Known-plaintext attack: for some $m$ knows $K_A(m)$\n3. Chosen-plaintext attack: knows $K_A$ but not $K_B$\n","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/ephemereal-content":{"title":"Ephemereal and Real-time Content","content":"\nOne of the things that keeps face-to-face friendships strong is the [nature of shared experience](http://psycnet.apa.org/psycinfo/2001-00651-001): you laugh together; you dance together; you gape at the hot-dog eaters on Coney Island together.\n\n\u003e The internet is often hailed for bringing people closer together. The apparent collapse of the physical space between users is achieved by slashing down the time between the moment in which a message is sent and received, until it’s close to real time. For millions of years, the only real-time communication we’ve had as a species involved physical presence. Thus, real-time digital communication makes us feel physically close (from [[thoughts/neutrality#Net Neutrality|The Neutrality Pyramid]])\n\n### video\n* movies\n* vlogs\n* vine/tiktoks\n\n### text\n* email\n* sms\n* snapchat messages\n* https://honk.me/\n\nOpposite of [digital permanence](thoughts/digital%20permanence.md)\n\n## Raider's of the Lost Web\n[Source: RAIDERS OF THE LOST WEB on *the Atlantic*](https://www.theatlantic.com/technology/archive/2015/10/raiders-of-the-lost-web/409210/)\n\nIt is really tempting to cover for mistakes by pretending they never happened.\n“In Supreme Court opinions, every word matters … When they’re changing the wording of opinions, they’re basically rewriting the law.”\n\n“It’s _gone_ gone. A piece of paper can burn and you can still kind of get something from it. With a hard drive or a URL, when it’s gone, there is just zero recourse.”\n\nThe promise of the web is that Alexandria’s [library](thoughts/library.md) might be resurrected for the modern world. But today’s great library is being destroyed even as it is being built. Until you lose something big on the [Internet](thoughts/Internet.md), something truly valuable, this paradox can be difficult to understand.\n\n\"Ephemerality is built into the very architecture of the web, which was intended to be a messaging system, not a library.\" (maybe we need more [friction](thoughts/friction.md)?)\n\nModern content is sometimes actually assembled on the fly through the likes of Ruby, Django, Next.js, etc. Not actual 'flat'/self-enclosed pages\nThe data may exist but not the in the format it was originally delivered in\n\nRelated: [Mangrove Theory of the Internet](thoughts/Mangrove%20Theory%20of%20the%20Internet.md) and slowness, [Dark Forest Theory of the Internet](thoughts/Dark%20Forest%20Theory%20of%20the%20Internet.md)\n\n## Ephemeral vs Accretive Content\n[Source](https://interconnected.org/home/2023/01/20/map_room)\n\nSee also: [[thoughts/digital permanence]]\n\n- Ephemeral tools are about the conversation. Slack is one. Zoom is another.\n\t- Memory resides in the users\n- Accretive tools build over time. Developer tools tend to work like this: platform-as-code. Wikis are the main one: Notion is accretive.\n\t- Memory resides in the tool","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/epistemic-authority":{"title":"Epistemic Authority","content":"\nOn when to [trust](thoughts/trust.md) [epistemic](thoughts/epistemology.md) claims\n\nTrusting the word of others is necessary to expand knowledge beyond perception, e.g. we will never know what it is like to be another person (see [Nagel's Bat Argument](thoughts/Nagel's%20Bat%20Argument.md))\n\n## Epistemic Authority with Anand Vaidya\n[YouTube talk](https://www.youtube.com/watch?v=oPUbuLUiK5Y)\n\n- How do we distinguish between appeals to authority that are rationally/ethically problematic and appeals to authority that are morally and rationally wholesome and skillful\n- Two concepts and distinctions\n\t1. Epistemic Culture: what do members of the culture take to be valid sources of knowledge\n\t2. Epistemic Self: an individual epistemic agent within a culture might have their own idiosyncratic belief about how the source work, how they're weighted, etc.\n- Three Knowledge Sources\n\t1. [Testimony](thoughts/testimony.md)\n\t2. Perception\n\t3. Inference\n- Dogmatism: when one cannot understand differences in epistemic cultures\n- We're finite, we can only think and see certain amounts of the world and so our brains and bodies are in sub-personal way always helping us intelligently ignore huge swaths of information\n- Question about demarcation of appeals to authority between good and bad turns into a much larger question that goes into the [philosophy of mind](thoughts/philosophy%20of%20mind.md) and philosophy of neuroscience, the nature of [the self](thoughts/the%20Self.md), how that is created, and how that thing epistemically gains and accesses information in the first place through retention\n- Defeaters\n\t- Overriding defeater: given evidence presented, this piece of evidence is a countering piece of evidence that overrides the argument for what they're saying\n\t- Undermining/undercutting defeater: some kind of source is fundamentally wrong and nothing comes out of it\n- Is it worth to assess overriding testimonial information from authorities? Whether critical thinking is good?\n\t- Michael Huemer: you shouldn't! Critically thinking is epistemically irresponsible.\n\t\t- We can look to scientific cultures as epistemic enterprises for techniques to make things more robust\n\t- Anand's counter-argument: you always need to critically evaluate at least the following\n\t\t1. who are the authorities?\n\t\t2. are they currently properly performing their authority?\n\t\t3. what does their authority amount to, within their expertise?\n\t- In being an expert and giving expert testimony means that we want the expertise that the person has to be spoken for and performed -- we want an expert performance\n\t\t- Can be suspect when the information upon which the expert is drawing is ambiguous\n\t\t- Skepticism starts to creep in because of the bureaucratic complexity through which the message is being delivered\n\t\t\t- Media wise\n\t\t\t- Interface between medical professions and politics\n\t\t\t- Corporations that are providing the actual vaccines\n\t- \"Best bet view\": if the weighted average of authorities who meet these tests say something, we should trust that it's true (this depends on epistemic culture and epistemic self)\n- Throwing something from one epistemic culture that's disjoint from another epistemic culture cannot lead to reconciliation without a shared epistemic culture\n- Two views on argumentation\n\t- Epistemic: trading of assertions has a way of leading to a better epistemic position either for both parties or for the conjunction of the two parties ([positive sum](thoughts/positive%20sum.md))\n\t- Non-epistemic: trying to pull one side to another ([zero sum](thoughts/zero%20sum.md))\n- Not only an issue of [trust](thoughts/trust.md) but also psychological exhaustion. One of the requirements of any epistemic enterprise is the use of attention\n\t- Information that puts its receivers into an almost constant state of some kind of cognitive dissonance negative impacts their ability to attend and assess the information\n- It is incredibly important to understand who is an epistemic peer and epistemic non-peers and the differences between peer-disagreement and non-peer-disagreement\n\t- Huemer counterpoint: non-peers can still be good at catching peers in their performance\n- Punditry: speaking with a certain level of diction, speed, volume, etc. and it will sound like whatever you are saying is true\n- One of the main components of collective action is collective belief. We want everyone to do $f$ but that requires everyone to believe that doing $f$ is right\n- How to ensure it's possible to accurately evaluate whether or not someone is an authority\n\t- Negative: Not always useful to be screaming about bias\n\t\t- At any scale reasonably worth caring about, bias will exist as long as there is order to the universe and entropy hasn't taken over. Bias is what enables salience, for distinction to even be made among differing classes.\n\t\t- However, bias in the context of decision making is something that is seen as a strict negative. Bias here (in the form of preexisting bias, technical bias, or emergent bias) implies a negative systematic preference for the epistemic trust of some agent over enough. \n\t- Positive: Look at it mathematically, think about what's at stake and think about what the tolerance threshold is that we can have in the relevant domain\n\t\t- From a purely mathematical perspective, this is factual. Achieving consensus is difficult, especially among a wide net of epistemic agents. In fact, without formal processes like voting or delegation, just peer-based discussion leads to a factorial explosion in time-taken to reach consensus.\n\t\t- Thus in most cases, rough consensus (I found this proposal particularly interesting: https://datatracker.ietf.org/doc/html/rfc7282) or trusting delegates (e.g. authorities like the CDC) to not be biased and accurately evaluate other authorities (e.g. scientists and pharmaceutical companies responsible for inventing/deploying the vaccine) is usually suitable when balancing tradeoffs between speed (for example when timeliness during a pandemic is important) and correctness (making sure vaccines are safe to the general public).\n\t- Positive: Increased diversity (of critical thinking skills) leads to a decrease in the probability of the whole group being accurate in evaluating whether or not someone is an authority. You can fool some people some of the time but you can't fool all the people all of the time\n\t\t- I agree with Lincoln here in saying that diversity is greatly important for reducing the chance we 'flatten' entire perspectives and ignore critical facts. *The Unflattening* by Nick Sousanis is a great graphic novel exploring how having a limited number of fixed perspectives prevents one from seeing the whole picture.\n\t- Positive: Listen to voices not being heard and figuring out how to repackage what they're saying in a way that is significant -- it is a unique skill to be trained as a cross-cultural philosopher. These philosophers can then teach experts to communicate better.\n\t\t- Unsure about how this is super relevant to accurately assessing whether one is to be trusted as an epistemic authority. Yes, I agree that being a cross-cultural philosopher is important. I believe that philosophers are the [boundary people](thoughts/boundary%20object.md) between multiple fields and enable cross-field germination. Though, I argue this only allows experts to communicate with each *other* better, but not the general public. Perhaps this is the role of [knowledge distillers](thoughts/knowledge%20distillation.md) like teachers and those who specialize specifically in pedagogy?","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/epistemic-injustice":{"title":"Epistemic injustice","content":"\nfrom *Epistemic Injustice* by Miranda Fricker\n\nRelated to social [power](thoughts/power.md)\n\nTypes of epistemic injustice:\n1. [Testimonial](thoughts/testimony.md) Injustice: giving a deflated level of credibility to a speaker's word for no other reason other than identity prejudice in a way that harms the speaker\n2. [Hermeneutical Injustice](thoughts/hermeneutical%20injustice.md): the injustice of having some significant area of one's social experience obscured from collective understanding owing to hermeneutical marginalization\n\nLearning new epistemic resources is difficult for multiple reasons\n1. Lack of [trust](thoughts/trust.md) between groups\n2. Dominantly situated knower being unwilling to confront destabilizing truths\n3. Reluctance or inability of dominant group to recognize the value of the epistemic resources they're being taught\n\nTwo main kinds of testimonial injustice\n- Receiving more credibility than they otherwise would have (credibility excess)\n- Receiving less credibility than they otherwise would have (credibility deficit)\n\t- E.g. speaker's accent -- indicating certain educational/class/regional background\n\t- Although can be beneficial in some cases, see the [Jester's Privilege](https://en.wikipedia.org/w/index.php?title=Jester#Jester's_privilege)\n- Specifically, this is in the context of the *knower* being wrongly judged in their capacity to be accurate\n\t- Injustice means it must be harmful but also wrongful\n\t- Injustice also carries a connotation of [intentionality](thoughts/intentionality.md) to it: it is very hard to believe that one who accidentally misjudges another is committing an injustice against someone (personal belief of Fricker here)\n\nTwo modifiers for testimonial injustice\n- Persistent: repeated frequently, for example when the injustices occur in the context of their professional life\n- Systematic: centered within a system of [power](thoughts/power.md), fundamental to the predominant social, economic, or political practice\n","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/epistemology":{"title":"Epistemology","content":"\n## Validity\n- [truth](thoughts/truth.md)\n- [epistemic injustice](thoughts/epistemic%20injustice.md)\n- [hermeneutical injustice](thoughts/hermeneutical%20injustice.md)\n- [indeterminancy](thoughts/indeterminant.md)\n- [testimony](thoughts/testimony.md)\n\n## Of the self\n- [qualia](thoughts/qualia.md)\n- [self-knowledge](thoughts/self-knowledge.md)\n- [the self](thoughts/the%20Self.md)\n\n## Doubt\n- [Descartes' Meditations](thoughts/Descartes'%20Meditations.md)\n- [Knowledge Argument](thoughts/Knowledge%20Argument.md)\n\n## Schools of Thought\n- [Root Verses on the Middle Way (MMK)](thoughts/Root%20Verses%20on%20the%20Middle%20Way%20(MMK).md)\n- [Nyāya](thoughts/Nyāya.md)","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/ethereum":{"title":"Ethereum","content":"\n[Blockchain](thoughts/blockchain.md) with a built-in Turing-complete programming language to allow individuals to write smart contracts and decentralized applications (dApps) which dictate their own rules around ownership, trasnaction formats, and state transition functions.\n\nEther (ETH) is the actual currency. All transactions (sending ETH, using a dApp, executing a smart contract) cost a gas fee to disincentivize bad actors from spamming.\n\nCurrently uses [proof of work](thoughts/proof%20of%20work.md) but soon to switch to [proof of stake](thoughts/proof%20of%20stake.md).\n\n## Understanding\n- Has a built-in Turing-complete scripting language built on top of the Ethereum VM that perform transactions and send them to the [blockchain](thoughts/blockchain.md)\n\t- VM details\n\t\t- Stack: up to 1024 32-byte fields\n\t\t- Memory: infinite in size but more size means more gas\n\t\t- Storage: permanent for contracts (verifiable using a Merkle trie)\n\t\t- Environment variables: VM can access block number, time, mining difficulty, previous block hash etc.\n\t\t- Logs: append-only storage in a specific block (not state)\n\t\t- Sub-calling: VM can call other contracts\n\t- To prevent halting problem from taking up all computational resources, we implement a \"gas fee\" to charge every computational step\n\t- The more bytes the `data` field in each transaction is, the more expensive it becomes\n- State is the database (key value mapping addresses to account objects)\n- Contracts are programs that run on top of the database\n\nThis feels like time-share all the way back in the day but decentralized and now on the global scale. Crazy\n\n## dApps\nCombine smart contracts (the backend) with a frontend user interface. Typically,\n- open-source\n- public data + records\n- uses a cryptographic token to keep the network secure","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/ethics":{"title":"Ethics","content":"\nEthics is the rational systematic analysis of **morality**. Morality is the compass of what people ought to or ought not to do, especially when it can cause benefit or harm to other people.\n\nEthics is focused on the voluntary, moral choices. Ethics is *not* concerned about involuntary choices or choices outside the moral realm.\n\nWorkable ethical theory: produces explanations that aim to be persuasive to a skeptical, yet open-minded audience about what is \"right\" or \"wrong\"\n\nEspecially important for technologists to grapple with as common wisdom may not exist for novel situations brought about by new technologies (see: [[thoughts/Collingridge dilemma|Collingridge Dillemma]])\n\n## 4 Unworkable Ethical Theories\n1. Subjective Relativism: \"who are you to criticise my values\"\n\t- There's no universal standard of right or wrong, each individual must decide for themselves\n\t- *Everything* is equally valid, not that \"I can see how people can arrive at different conclusions\"\n2. Cultural Relativism: \"who are you to criticise my culture's values\"\n\t- Moral actions are based on a culture's actual moral guidelines\n\t\t- Traditions develop because they meet a need, but once a tradition has been established, people behave in a certain way because it’s what they’re supposed to do, not because they understand the rationality deeply embedded within the tradition.\n\t- It is presumptuous to judge another culture's values\n3. Divine Command Theory: \"stealing is wrong because the Bible says so\"\n\t- We should use holy books (or any sort of appeal to authority) as guides for moral decision making\n\t- Only effective to those who already believe in the same beliefs as us\n\t- See also [[thoughts/religious authority|appeals to religious authority]]\n4. Ethical Egoism\n\t- People's self-interest is their only ethical obligation\n\t- What's good for the market (modelled by selfish agents) is good for society\n\t- However, does not respect the ethical point of view\n\t\t- The ethical point of view is the understanding that other people and their core values are also worthy of respect\n\n## Workable Theories\n1. [[thoughts/Kant|Kantianism]]\n2. [[thoughts/Utilitarianism|Utilitarianism]]\n3. [[thoughts/Social Contract Theory|Social Contract Theory]]\n4. [[thoughts/virtue ethics|Virtue Ethics]]\n\n![[thoughts/images/ethical theories.png]]","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/evaporative-cooling":{"title":"Evaporative Cooling Effect","content":"\nSources: [The Evaporative Cooling Effect in *BumblebeeLabs*](https://web.archive.org/web/20101012105003/http://blog.bumblebeelabs.com/social-software-sundays-2-the-evaporative-cooling-effect/) and [Evaporative Cooling of Group Beliefs in *LessWrong*](https://www.lesswrong.com/posts/ZQG9cwKbct2LtmL3p/evaporative-cooling-of-group-beliefs)\n\n\u003e \"The people who are the most eager to talk are the ones who the least number of people are interested in hearing.\"\n\nEvaporative Cooling is the slow decay of a community into mediocrity as its most 'high energy' or high value individuals exit.\n\nIt is a way to think about communities in terms of the average quality of its members.\n\nWhen the most high value members realize there isn't much left for them to gain, they leave (Groucho Marx rule: you stop attending any event which would have you as participant).\n\nThis drop the average quality of the community down and the next level notices and then also finds it underwhelming. This continues until you get to a point where the people in the community are so unaware they no longer notice/care.\n\n\"If anyone can join your community, then the people most likely to join are those who are below the average quality of your community because they have the most to gain.\"\n\n## Social Gating\nMechanisms which allow participants to self-select out of the group (vs traditional direct exclusion). \n\ne.g.\n- nicheness/technicality (high prerequisite knowledge)\n- social stigma\n- high cost (time and money)\n- difficult entry (hazing)\n\n## Geeks, MOPs, and sociopaths in subculture evolution\n[From the article of the same name](https://meaningness.com/geeks-mops-sociopaths)\n\n- Creators: riff off of each other, produce examples and variants, and share them for mutual enjoyment, generating positive energy\n- Fanatics: don’t create, but they contribute energy (time, money, adulation, organization, analysis) to support the creators.\n- Creators and fanatics are both geeks. They totally love the New Thing, they’re fascinated with all its esoteric ins and outs, and they spend all available time either doing it or talking about it.\n- Mops: fans, but not rabid fans like the fanatics. They show up to have a good time, and contribute as little as they reasonably can in exchange.","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/explainability":{"title":"Explainability","content":"\n[European Union adopted new data-protection rules](https://arxiv.org/abs/1606.08813) in 2016 that include a legal right to an explanation of decisions made by algorithms.\n\nAs AI systems become more influential in their power and incorporated into more and more important decision making, explainability is extremely important for the sake of algorithmic [accountability](thoughts/accountability.md). \n\nFor now though, the current advances in deep learning mean that most representations of the neural network state have a distributed [representation](thoughts/representation.md) of content, meaning that there is no 'single-neuron' for certain decisions as semantic symbols do not arise here.\n\nSemantic meaning only arises in [[thoughts/neural networks|neural networks]] because we inject them or through inductive proding (e.g. LIME for explainability)","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/exploit-explore":{"title":"Exploit Explore Problem","content":"\n\u003e Saying yes requires saying no\n\n## [Machine learning](thoughts/machine%20learning.md)\n[Source: Intro to Reinforcement Learning: The Explore-Exploit Dilemma](https://towardsdatascience.com/intro-to-reinforcement-learning-the-explore-exploit-dilemma-463ceb004989)\n\n-   exploit-explore tradeoff in ML\n    -   hill climbing/optimization problem\n    -   always jump to next step up → greedy search\n-   optimizing to find one's true [values](thoughts/value%20setting.md)\n\n## Pendulum of life\n[Source: The Joy of Wasting Time by *Samson Zhang*](https://www.samsonzhang.com/2021/01/26/the-joy-of-wasting-time-the-exploration-exploitation-tradeoff-of-life.html)\n\n\"The ideal is to find an equilibrium point between external pulls and internal pushes, between exploitation (of your current opportunities via external pulls) and exploration (of your actual passions via internal pushes)... the process of finding equilibrium often takes the form of a damped oscillation over time\"\n\n## Notes\n- how much of this is just [feedback loops](thoughts/feedback%20loops.md) but for learning/interests?\n- how does [play](thoughts/play.md) fit into this?\n\n## Regret Minimization Framework\n[Source: Bezos on the Regret Minimization Framework](https://www.youtube.com/watch?v=jwG_qR6XmDQ)\n\nProject yourself to age 80 and look back on your life. How do I minimize the regrets that I have? Will you regret abandoning this idea?\n\n\u003e When you minimize future regret, you sleep well knowing you're maximizing fulfilment.\n\nIs a life well-lived one that is fully maximized? What if I just want to live for vibes (which are inherently unoptimizable)?","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/exploratory-data-analysis":{"title":"Exploratory data analysis (EDA)","content":"\nHow do you \"look\" at features and high-dimensional examples?\n1. Summary statistics\n\t- Categorical Features\n\t\t- Frequencies\n\t\t- Mode\n\t\t- Quantiles\n\t- Numerical Features\n\t\t- Location\n\t\t\t- Mean\n\t\t\t- Median\n\t\t\t- Quantiles\n\t\t- Spread\n\t\t\t- Range\n\t\t\t- Variance\n\t\t\t- Interquartile ranges \n\t- Entropy: measured \"randomness\" of a set of variables where entropy is $- \\Sigma_{c=1}^k p_c \\log p_c$ and $p_c$ is the proportion of times you have value $c$, range from $[0, \\log k]$\n\t\t- Low entropy means it is very predictable whereas high entropy means it is very unpredictable (roughly, spread)\n\t\t- Normal distribution has the *highest* entropy\n\t- [Not always representative](https://blog.revolutionanalytics.com/2017/05/the-datasaurus-dozen.html)! Don't mistake the map for the territory\n2. Distance or similarities\n\t- Hamming distance: number of times elements aren't equal\n\t- Euclidian distance: how far apart are the vectors (square root of sum of squares)\n\t- Correlation\n\t- Jaccard coefficient: set distance, intersection over union\n\t- Edit distance: for strings, how many characters do I need to change to go from one to the other\n\t- [[thoughts/latent-factor model|Distance in latent space]]\n3. Visualizations\n\t- Basic line plots\n\t- Matrix plot: visualize two features as an image\n\t- Correlation plot\n\t\t- Can add colour to show a third feature (usually categorical)\n\t- Scatterplot","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/fair-betting-quotient":{"title":"Fair Betting Quotient (FBQ)","content":"\nYour fair betting quotient (FBQ) for A is p if you think that the following is a fair bet (you are willing to take either side):\n- If A is true, you win $(1 - p)S$\n- If A is not true, you lose $pS$\n\nBetting table is different from [[thoughts/Decision theory|decision tables]]. Columns are different bets.\n\n|A|Bet for A|Bet against A|\n|-|-|-|\n|T|$(1-p)S$|$-(1-p)S$|\n|F|$-pS$|$pS$|\n\nSuppose a set of credences (or FBQ’s) is incoherent. We can always construct a [[thoughts/Dutch Book]]. Have the agent bet for propositions with credences (or FBQs) that are too high, and against propositions with credences (or FBQs) that are too low.","lastmodified":"2023-02-15T01:38:21.23782087Z","tags":null},"/thoughts/fault-tolerance":{"title":"Fault Tolerance","content":"\nHow do we defend against attacks in [[thoughts/distributed systems|distributed systems]] with no central authority? We want the system as a whole to continue working, even when some parts are faulty\n\n- Failure: system as a whole isn't working\n- Fault: some part of the system isn't working\n\t- Probability of all $n$ replicas being faulty: $p^n$\n\t- Probability of 1 or more replicas being faulty: $1 - (1-p)^n$\n\nRelated: [game theory](thoughts/game%20theory.md), [[thoughts/Zooko's Triangle|Zooko's Triangle]], [[thoughts/Sybil Attack|Sybil attack]], [[thoughts/cascading failures|cascading failures]], [[thoughts/Byzantine Faults|Byzantine Faults]]\n\n### Two Generals Problem\nThis thought experiment meant to illustrate the pitfalls and design challenges of attempting to coordinate an action by communicating over an unreliable link. In the experiment, two generals are only able to communicate with one another by sending a messenger through enemy territory. The experiment asks how they might reach an agreement on the time to launch an attack, while knowing that any messenger they send could be captured. It is required that the two generals have their armies attack the city simultaneously to succeed, lest the lone attacker army die trying.\n\nBecause acknowledgement of message receipt can be lost as easily as the original message, a potentially infinite series of messages is required to come to consensus.\n\nThis problem is unsolvable.\n\n### Byzantine Generals Problem\nThis situation can be expressed abstractly in terms of a group of generals of the Byzantine army camped with their troops around an enemy city. Communicating only by messenger, the generals must agree upon a common battle plan. However, one or more of them may be traitors who will try to confuse the others. The problem is to find an algorithm to ensure that the loyal generals will reach agreement.\n\nIt is shown that, using only oral messages, this problem is solvable if and only if more than two-thirds of the generals are loyal; so a single traitor can confound two loyal generals. With unforgeable written messages, the problem is solvable for any number of generals and possible traitors.\n\n## Designing Robust Networks\nSee also: [[thoughts/Network Theory|Network theory]]\n\nDesigning networks that are simultaneously robust to attacks _and_ random failures appears to be a conflicting desire\n\n- The hub-and-spoke network is robust to random failures, as only the failure of its central node can break the network into isolated components, but a single targeted attack can fragment the network.\n- A completely random network lacks hubs, the impact of an attack is similar to the impact of random node removal -- both are equally bad and can easily fragment a network.\n\nTo maximize robustness, we want to maximize the 'breakdown' or critical threshold: $f_c^{tot} = f_c^{rand} + f_c^{targ}$\n\nThis is maximized by having a bimodal degree distribution where an $r$ fraction of nodes have degree $k_{max}$ and the remaining $1-r$ fraction have degree $k_{min}$\n\n### Halting Cascading Failures\nTwo approaches come to mind\n1. Adding new links to increase connectivity and thus $f_c$. However, in most real systems the time needed to establish a new link is much larger than the timescale of a cascading failure.\n2. Removing redundant links and nodes. The size of a cascade can be reduced if we intentionally remove additional nodes right after the initial failure (i), but before the failure could propagate.\n\nThe mechanism of 2. is similar to the method used by firefighters, who set a controlled fire in the fireline to consume the fuel in the path of a wildfire. In a counterintuitive fashion, controlled damage can be beneficial to a network: the Lazarus Effect\n\nThe growth rate of a bacteria is determined by its ability to generate biomass, the molecules it needs to build its cell wall, DNA and other cellular components. If some key genes are missing, the bacteria is unable to generate the necessary biomass. Scientists can *revive* these dead bacteria by removing five additional genes.\n\n### Robustness vs Resilience vs Redundancy\n- Robustness: able to maintain basic functions in the presence of internal and external errors (static).\n- Resilience: able to adapt to internal and external errors by changing its mode of operation to maintain its ability to function (dynamic).\n- Redundancy: presence of parallel components and functions that can replace missing components or functions.","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/feature-selection":{"title":"Feature Selection","content":"\nBetter features usually help more than a better model. Good features would ideally:\n- Allow learning with few examples, hard to overfit with many examples\n- Capture most important aspects of problem\n- Reflects invariances (generalize to new scenarios)\n\nFind the features (columns) of ‘X’ that are important for predicting ‘y’.\n- What are the relevant factors?\n- Which basis functions should I use among these choices?\n- What types of new data should I collect?\n- How can I speed up computation?\n\nThis can help us to remove features. Feature complexity is also correlated with the [[thoughts/fundamental tradeoff|fundamental tradeoff]]. Increased complexity leads to increased overfitting risk. Models (like linear regression) can overfit with large $d$ so reducing $d$ to only useful factors may improve results. \n\nGenerally, there are no right answers but there are wrong answers.\n\n## Association\nFor each feature $j$, compute correlation between feature values $x_j$ and $y$.\n\nUsually gives unsatisfactory results as it ignores variable interactions (e.g. if tacos make you sick, and you often eat tacos on Tuesdays, it will say “Tuesday” is relevant.)\n\n## Regression Weight\nFit [[thoughts/linear regression|linear regression]] weights $w$ based on all features.\n\nTake all features $j$ where weight $|w_j|$ is greater than a threshold\n\nHas major problems with collinearity\n\n$\\hat y_i = w_1 \\textrm{taco} + w_2 \\textrm{tuesday} = 0\\textrm{taco} + (w_1 + w_2) \\textrm{tuesday}$\n\n## Search and Score\n1. Define score function $f(S)$ that measures quality of a set of features $S$\n2. Search for the variables $S$ with the best score\n\nWe create the set of features $S$ by creating every possible combination of $2^d$ features.\n\nHowever, as we have a large number of sets of variables we are prone to optimization bias\n\n$O(2^d)$ runtime\n\n### Forward Selection\n1. Start with an empty set of features $S = []$\n2. For each possible feature $j$, compute scores of features in $S$ combined with feature $j$\n3. Find the $j$ that has the best score when added to $S$\n4. Check if $\\{S \\cup j\\}$ improves on the best score found so far\n5. Add $j$ to S and go back to step 2\n\t1. We can stop when no $j$ improves the score\n\n$O(d^2)$ runtime\n\n## Number of Features Penalties\nWe can again use complexity penalties and penalize the number of features used. This can also be called the $L_0$-norm which is the number of non-zero values.\n\n$$\\lVert w \\rVert_0 = size(S)$$\n\n## Text Features\n1. Bag of Words: represents sentences/documents by word counts:\n2. Bigram: an ordered set of two words\n3. Trigram: an ordered set of three words\n\n## Global vs Local\nGlobal vs. local features allow for “personalized” predictions.\n\nWe add a feature for each 'person' in the system.\n\n![[thoughts/images/global-vs-local-features.png]]","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/federation":{"title":"Federation","content":"\n\u003e In a federated network, users are still interacting with a server, but anyone can run a server that interoperates with others in the network, giving users more providers to choose from\n\nDesigning in such a way that new instances of any [[thoughts/decentralization#Centralization|centralized]] function are relatively easy to create and can maintain [[thoughts/interoperability|interoperability]] and connectivity with other instances.\n\n","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/feedback-loops":{"title":"Feedback Loops","content":"\n## Tight feedback Loops\n[Source: Beware of tight feedback loops by *Brian Lui*](https://brianlui.dog/2020/05/10/beware-of-tight-feedback-loops/)\n\n-  noise in social media\n    -  used to be a town square → hear what you hear\n    -  radio bar model → everyone has a frequency people chose their frequency (substack model)\n    -  competing on substack vs rolling your own\n\n\"Focusing on tight feedback also leads to getting stuck in local maxima. The short turnaround time leads to the pursuit of incremental improvements. Accurate feedback reduces error, but this means reaching and staying at the local maximum. The more accurate and more rapid the loop, the more quickly you’ll arrive at the top of the hill – and the less chance you have of leaving it to climb the mountains of mastery.\"\n\n\"This is because feedback loops which are too short for the overall system makes people focus on inappropriate intermediate goals.\"\n* dangers of intermediate proxies?\n* what about in machine learning? using certain quantities for metrics which are just *proxies* for more difficult to measure qualitative end goals\n\nRelated: [exploit explore](thoughts/exploit%20explore.md) as a metaphor for optimizing life.\n\n[Mimetic](thoughts/mimetic.md) behaviour as a form of feedback loop\n\n","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/fiction":{"title":"Fiction","content":"\n\u003e The future is manifested\n\nShared fiction as a statement about the future instead of a statement of today. They're both fictions in that they can't be (dis)proved and thus can have the same functions in a group of people (bring together, motivate to action, share values/[[thoughts/language|language]], etc.)\n\nBuild as if your creations had [skyhooks](thoughts/skyhooks.md) you could hang them off of.\n\n\u003e To see things as they really are, you must imagine them for what they might be. -- Ruha Benjamin\n\nIn part why I really like reading things like The Book of Predictions where people from the 1970s just make predictions about the far future and see how correct they were. A lot of completely wrong predictions but some are eerily accurate (e.g. distributed and accessible compute). Now, you look at todays predictions of the future and it looks the same as the dreams we had 50 years ago about flying cars and space-faring societies. \n\nWhere are our futures with no famine and disease? With a clean and healthy planet? Of universal free access to information? Where did the ambition go?\n\n## Social Theory as Science\n[Source: Possibilities -- Social Theory As Science and Utopia by *David Graeber*](https://www.revoltlib.com/anarchism/possibilities-essays-on-hierarchy-graeber-david/part-3-chapter-10-social-theory-as-science/)\n\n\"Where, in earlier generations, science fiction projections seemed to regularly become reality a generation later, now they remain trapped on the screen--even if the screen images look increasingly realistic.\" (321)\n\n## The Big Here and Long Now\n\u003e \"Humans are capable of a unique trick: creating realities by first imagining them, by experiencing them in their minds. When Martin Luther King said \"I have a dream\", he was inviting others to dream it with him. Once a dream becomes shared in that way, current reality gets measured against it and then modified towards it.\"\n\nThe act of imagining something makes it real. Art as processes or the seeds for processes - things that exist and change in time, things that are never finished.\n\n## Fiction as shared visions\n _Visions matter_. Visions give people a direction and inspire people to act, and _a group of inspired people is the most powerful force in the world_. If you're a young person setting off to realize a vision, or an old person setting off to fund one, I really want it to be something worthwhile.\n\n## Protocol Fiction\n\u003e But we don’t need just design fictions. We need business model fictions, engineering feasibility study fictions, interop protocol specification fictions, investment return fictions.\n\n[Speculative Infrastructure](https://interconnected.org/home/2022/08/11/casi)","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/file-system":{"title":"File system","content":"\n## Virtual Distributed File System\nFrom [Alluxio's Technical Paper by Haoyuan Li](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-29.pdf)\n\n\u003e Alluxio is an append-only file system, similar to HDFS, that supports standard file operations, such as create, open, read, write, close, and delete\n\nThe storage layer of the ecosystem grew from the Apache Hadoop Distributed File System (HDFS) to a variety of choices, such as file systems, object stores, blob stores, key-value systems, and NoSQL databases to realize different tradeoffs in cost, speed and semantics\n\nOne way of solving the n-to-n problem is to use a VDFS as opposed to exposing APIs. Reduces a lot of overhead in\n- Work: needing to solve similar problems around storage\n- Data storage: ETL (extract, transform, load) pipelines\n\nFor the benefits and values the VDFS provides, we can make the analogy to [[thoughts/IP Addresses|IP]]. The IP layer is the narrow waist that enables the higher layer to innovate without worrying about the lower IP layer, and vice-versa. In the meantime, the virtual file system is an abstraction layer on top of a concrete file system implementation, and it allows applications to be able to access different types of concrete file systems in a uniform way. \n\n### Performance\nWhile caching can dramatically improve read performance, unfortunately, it does not help much with write performance. This is because highly parallel systems need to provide fault-tolerance, and the way they achieve it is by replicating the data written across nodes.\n\nInteresting to note: in big data processing, the same operation is repeatedly applied on massive data. Therefore, replicating programs is much less expensive than replicating data in many cases\n\n","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/formality-considered-harmful":{"title":"Formality considered harmful","content":"\nSee also: [[thoughts/cozy software|cozy software]]\n\n\n[Paper](https://www.csdl.tamu.edu/~shipman/papers/cscw.pdf) by Frank M. Shipman III and Catherine C. Marshall with the same name. On experiences, emerging themes, and directions on the use of formal representations in [[thoughts/interaction design|interactive designs]]\n\n\u003e The cause of a number of unexpected difficulties in human-computer interaction lies in users’ unwillingness or inability to make structure, content, or procedures explicit\n\nWhen people use computer systems, their interaction is usually mediated by abstract representations that describe and constrain some aspect of their work or its content. Computer systems use these abstract representations to support their users’ activities in a variety of ways, like for [[thoughts/information retrieval]]. These abstractions are frequently referred to as formalisms.\n\nAt the formal end of the spectrum, knowledge-based systems require people to encode materials in a representation that can be fully interpreted by a computer program.\n\nA la [[thoughts/Seeing like a State|Seeing like a State]]: excessive formalization may cause people to lose information that falls outside the prescribed structure, and in general require people to make knowledge explicit that may be difficult or undesirable to articulate\n\n## Examples\n- Experiences training information analysts to use NoteCards revealed that they had difficulties\n\t- Chunking information into cards (“How big is an idea? Can I put more than one paragraph on a card?”)\n\t- Naming cards (“What do I call this? Do I have to name this card before I can get it off the screen?”)\n\t\t- Once again, naming things is one of the most difficult parts of anything\n\t- Filing cards (“Where do I put this?”)\n- People tend to cluster things spatially than via links\n\t- Instead of building large interconnected networks of nodes (like the designers expected), users created linkless spaces of nodes arranged in regular graphical patterns that indicated relationships among nodes spatially and visually\n- There are many cognitive costs associated with adding formalized information to a computer system\n\t1. Foremost, users must learn a system’s formal language\n\t2. Even if they know a system’s formal language, users face a mismatch between their understanding of the information and the system’s formal representation (good teachers help to bridge this)\n- Tacit knowledge poses a particularly challenging problem for adding formal structure and content to any system since, by its very nature, people do not explicitly acknowledge tacit knowledge\n\t- When a person is asked to breath normally, their normal breathing will be interrupted\n- Structure changes with time\n\t- Since a user’s understanding of any non-trivial task, such as performing an analysis or completing a design, evolves as they attempt to complete the task, users resist making such commitments\n\t- Same with [[thoughts/terminology#Terminological anchoring|terminological anchoring]]\n\t- There is a perception that information formalized incorrectly or inconsistently will be more difficult to use or simply be of less use than information not formalized.\n\t\t- Hence why we leave many tabs open or things on our desk/desktop\n\n## Fixes\n- Keep things simple and out of the way for the user ([[thoughts/Gall's law]]).\n- Incremental formalization\n\t- In the Hyper-Object Substrate (HOS) (Shipman, McCall, 1994) we have investigated the potential to support users by suggesting possible formalizations based on recognized patterns in textual information. In HOS, suggestions for new attributes or relations in the knowledge base were presented to the user for acceptance, modification, rejection, or just to be ignored\n\t- These are effective as long as they don’t overwhelm a user with too many requests to acknowledge inferred structure\n\n## [[thoughts/tools for thought|Tools for thought]]\nI think this applies for thinking and note-taking too. My thesis is that having a scratch space be incredibly low friction to access (on par with or lower than Apple Notes) is incredibly important to cultivating good knowledge/deadline management. See: [[thoughts/Projects#Tabspace - a scratchspace for your new tab page|TabSpace]]","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/frame-problem":{"title":"Frame Problem","content":"\nIntelligence is (at least partly) a matter of using well what you know. An intelligent being learns from experience, and then uses what is has learned to guide expectations in the future. How does one select the appropriate frame or [context](thoughts/context.md) for any given situation?\n\nThere are an infinite number of contextual frames for any given situation. How do we encode this in discrete systems like in AI?\n\n## Installation problem\nProblem of installing in one way or another all the information needed by an agent to plan in a changing world.\n\nCan be broken down into\n-   [semantic](thoughts/semantics.md) problem → what information do we need to install?\n-   syntactic problem → what system, format, structure, or mechanism do we use to install it\n\nHowever, one cannot realistically create a Spinozistic solution (a small set of axioms and definitions from which we can deduce the rest of our knowledge on demand)\n\nWe run into the problem of induction: give that i believe all of this (have all this evidence) what ought I to believe as well (about the future, or about unexamined parts of the world)? Clearly this will not work (see: [Black swan theory](https://en.wikipedia.org/wiki/Black_swan_theory))\n\nWe need a system that genuinely ignores most of what it knows and operate with a well-chosen portion of its knowledge at any moment\n\nThis is the qualification problem: how do we design a system that reliably ignores what it ought to ignore under a wide variety of different circumstances in a complex action environment?","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/freedom":{"title":"Freedom","content":"\n[Source: Freedom in *Kernel*](https://kernel.community/en/learn/module-3/freedom)\n\n\u003e Freedom is the simple combination of awareness and acceptance. It is the ability to be conscious of the constraints within you live\n\nOur *default* definition of freedom, to just be able to do whatever, falls apart when we consider that we are limited beings (something something freewill). We will never be able to achieve unlimited human capacity and ability, and as such, no matter how comfortable our lives get, we will always feel slightly trapped. Thus, this is a non-functional definition of freedom.\n\nA utopia is not truly a utopia unless we accept our boundaries. In a world of unlimited need, the only way to be 'free' is to accept the finiteness of the world.\n\n## Web3\n[web3](thoughts/web3.md) allows us to codify and define these boundaries for ourselves. By itself, it is not a technology that makes us 'more free,' but by explicitly stating the boundaries we create, we can create the freedom.\n\n\"This is a critical point: the products we create should not aim to make people 'more free' - that way lies false marketing campaigns and disappointment. Our products should be conscious of, and communicate clearly, how they constrain the people who use them.\"\n\n## Free Speech\nIn the US, protection is not given to “libel, reckless or calculated lies, slander, misrepresentation, perjury, false advertising, obscenity and profanity, solicitation of crime,\n\nAnd personal abuse or ‘fighting’ words,” because these actions do not serve the ends of the First Amendment","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/friction":{"title":"Friction","content":"\n## Bring back Friction on the [Internet](thoughts/Internet.md)\n[Source: The case for slowing everything down a bit by *Ezra Klein*](https://www.vox.com/technology/2018/11/19/18101274/google-alphabet-facebook-twitter-addiction-speed)\n\n- The reduction of friction on the web is a business strategy. \"Less friction means more time spent, more ads seen, more sales made. Tech companies lose customers during login screens and security verification, and as a result of slow load times. The country’s top computer science talent is paid billions of dollars to further reduce the milliseconds of delay separating our desires and their fulfillment.\"\n- “The philosophy of the Internet has assumed that friction is always part of the problem,” writes Kosslyn. But look around. The problem now isn’t too much friction; it’s too little. “It’s time,” he says, “to bring friction back.”\n- Friction creates space in the system where judgment can intercede, where second thoughts can be had, where decisions can be made.\n- [[thoughts/writing|Writing]], by contrast, is full of friction. It’s hard and slow, and the words on the page fall short of the music and clarity I imagined they’d have. But it is, in the end, rewarding. It’s where I have at least a chance to create something worth creating. The work is worth it.\n\nRelated: [digital mindfulness](thoughts/digital%20mindfulness.md)","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/friendship":{"title":"Friendship","content":"\n\"The ultimate touchstone of friendship is not improvement, neither of the other nor of the self. The ultimate touchstone is witness, the privilege of having been seen by someone, and the equal privilege of being granted the sight of the essence of another, to have walked with them, and to have believed in them, and sometimes, just to have accompanied them, for however brief a span, on a journey impossible to accomplish alone\" -- David Whyte\n\nFriendship as witnesses to eudaimonic well-being.\n\n\u003e the type of happiness or contentment that is achieved through self-actualization and having meaningful purpose in one's life\n\nadrienne maree brown described relationships like a spiderweb—diaphanous yet strong, thick yet porous. “A web allows things to fall through, like a sieve,” she said. “Some things are not meant to be caught.”\n\nRelated: [Tribe flourishing](thoughts/tribe%20flourishing.md)\n\n## Acceptance Prophecy\n[Source](https://www.theatlantic.com/family/archive/2022/08/making-keeping-friends-attachment-theory-styles/671222/)\n\n\u003e “If people expect acceptance, they will behave warmly, which in turn will lead other people to accept them; if they expect rejection, they will behave coldly, which will lead to less acceptance.”\n\nAssume that people like you. Tempted to ask a gym friend if they want to become a happy-hour friend? Assume they do. Want to reconnect with a friend you’ve fallen out of touch with? Assume they’re in. When we make this assumption, initiative feels less scary. We’re more likely to take some leaps of faith—and eventually navigate the friendship-making process, and life, with more peace, pleasure, and security.\n\n## Commitment\nCommit to some great loves; falling in love with something and building a structure of behaviour for when love falters. Who would they care about if nobody knew?\n\n## Epistemic [trust](thoughts/trust.md)\nFrom *Believing the best: on doxastic partiality in friendship* by Lindsay Crawford\n\nArgues that there is no conflict between friendship and epistemic norms as being a good friend constitutively involves forming attitudes about one's friends that are appropriately responsive to the features that one's friends have that appear to warrant those attitudes\n\n**Note:** property $x$ being constitutive of $p$ is not a normative reason for $p$ to have $x$\n\nIt is *not* true that friendship can normatively require doxastic (logic/belief) partiality but not for the reasons given against partiality by \"evidentialists\"\n\nTypes of deliberation\n1. Practical deliberation: \n2. Theoretical deliberation: \n\n- Partiality: You are more likely to do certain things for someone that you wouldn’t do for others.\n- Doxastic partiality: You are more likely to believe in it\n\nWe can be partial to your friends but they can be wrong given state-given reasons. We can be partial to our friends but not because it is normative to be always partial to our friends\n\n- Partialist: those who argue that friendship can normatively require doxastic partiality\n\t- Someone who failed to be doxastically partial to you would fail to be a good friend to you\n\t- We *ought* (normative statement) to do the various things that partly constitutive of what it is to be a good friend to someone (e.g. be doxastically partial)\n\t\t- This statement stems from the idea that good friendships are invaluable and indispensible component of living a good life. In turn, it makes sense that we ought to cultivate and sustain good friendships\n- Evidentialists: people who claim that what we ought to believe only subject to epistemic reasons, which are directly, transparently available as evidence during deliberation\n\t- There are no reasons to be doxastically partial, because, more generally, there are no non-evidential reasons for belief\n\t- Transparency: the question of whether to believe $p$ gives way to the factual question of whether $p$ holds true because the answer to the latter question determines the answer to the former\n\t\t- First gloss: we inevitably first consult the evidence in deliberation\n\t\t- Second gloss: normative point that evidence is the *only* thing relative in deliberation\n\t\t- However, it is true that $p$ not being true does not stop one from believing that $p$\n\t\t\t- Being a good friend, in my view, need not require being right about what sorts of qualities genuinely deserve one’s love or admiration.\n\nOn deliberation: deliberation concludes in an *attitude* of some kind, not the action itself\n- Practical deliberation about whether to do $\\phi$ concludes in an intention to $\\phi$\n\t- However, practical deliberation can be about theoretical deliberation\n- Theoretical deliberation about whether to believe that $p$\n\nState-given vs appropriately responsive attitudes\n- A reason for an attitude is *state-given* when its status as a reason is grounded in some relation it bears to a property of having that attitude in one's circumstances. e.g. an evil demon will torture you unless you believe that 2 + 2 = 5 is a state given reason to *believe* that 2 + 2 = 5.\n\t- Thus, the approach to thinking that esteeming a good friend because you expect them to esteem you in return is a state-give reason for esteeming them (e.g. makes esteeming the friend practically advantageous)\n- As opposed to appropriately responsive attitudes. These reasons for attitudes are appropriately responsive when they are responsive to what one takes to be \"object-given reasons\" -- that is, it is grounded in some relation that bears to a property of the object of the attitude\n\t- The belief that a friend is kind purely because your friend's kindness is a property of your friend (that is, they actually have the feature)\n\n## Epistemic Norms, The False Belief Requirement, and Love\nBy J. Spencer Atkins\n\nArgues that the demands of romantic love requires that we sometimes become bad epistemic agents\n\n\u003e Companionship is pleasurable and consequently valuable because it affords the opportunity to feel “seen” by another. We can only, according to Braden, view ourselves conceptually—we know things about ourselves—but we need others to view ourselves perceptually, “as concrete objects ‘out there.’” Other consciousnesses function like a mirror. Being seen in this way is recognition of personhood. The feeling of being seen is psychological visibility. Romantic love affords a “uniquely powerful” experience of visibility because lovers share a fascination with one another unlike any other relationship.\n\nDoxastic voluntarism: we can make ourselves belief a proposition\n\n1. False Belief Requirement\n\t- Argues that romantic love sometimes poses the demand to believe falsely\n\t- Knowledge as JTB (see [Knowledge Argument](thoughts/Knowledge%20Argument.md)): $S$ believes that $p$, $S$ is justified in believing that $p$, and $p$ is true\n\t- Belief then, is not knowledge as one can hold false beliefs\n\t- W.K. Clifford: \"It is wrong always, everywhere, and for anyone to believe anything upon insufficient evidence\"\n\t- When love poses the false belief argument, love will be opposed to epistemic norms\n\t- Delaney argues that lovers desire to be loved for the right reasons. That is, person $A$ wants a romantic partner $B$ to love him for properties that $A$ takes central to their self-conception\n2. Doxastic Wronging (the demand not to wrong one another)\n\t- True beliefs can wrong\n\t\t- Example, base rates: \"For instance, suppose that the swanky DC night club, the Cosmos Club, has nearly all black employees and nearly all white club members. A person looking for an employee, where employees and club members both wear tuxedoes, would be epistemically rational to believe that some particular black person is an employee, given the base rate at the Cosmos Club\"\n\t- Three conditions of doxastic wronging\n\t\t1. Directed Condition: belief wrongs a particular person, not just wrong in general\n\t\t2. Belief Itself Condition: holding the belief is what wrongs (not how the belief was formed or the actions that follow from the belief)\n\t\t3. Content Condition: content of the belief wrongs\n\t- Lovers stand in a privileged position -- they know things not usually shared with other people. This position makes them especially vulnerable to doxastic wronging\n\n### Love and False Belief\n*Week 9 Essay for PHIL 240A*\n\n\u003e Evaluate Atkins' argument that love sometimes requires false belief. (Remember that to evaluate an argument, you have to explain what it is, and then say why it is or is not convincing).\n\nAtkin's argument that love sometimes rqeuires false belief extends upon the work of Sarah Stroud and Simon Keller about the conflicts between relationships and epistemology. Both Stroud and Keller claim that those who know each other intimately (either platonic or romantic) should owe each other epistemic partiality. However, Atkin's extends this further and posits that love requires \"something beyond epistemic partiality -- false beliefs.\"\n\nAtkin's calls this the False Belief Requirement (FBR). Atkin's then tries to argue that love is opposed to epistemic norms as follows:\n1. Knowledge is justified true belief (JTB): $S$ believes that $p$, $S$ is justified in believing that $p$, and $p$ is true\n2. Belief then cannot be knowledge as one can hold beliefs that are false\n3. Thus, when poses the false belief argument, love will be opposed to epistemic norms (and thus rationality)\n\nDelaney argues that lovers desire to be loved for the right reasons. That is, person $A$ wants a romantic partner $B$ to love them for properties that $A$ takes central to their self-conception. Atkins then claims that false beliefs are required in order to avoid doxastic wrong-doing -- the wronging of another by having beliefs that do not align with the other's self-conception.\n\nHere, I don't think Atkins' line of argumentation is correct. I agree with Delaney's point about lovers wanting to be loved for properties that they take central to their self-conception. However, I don't think that false beliefs are required for this want to hold true.\n\nTake for example, the cases of *striving* that Atkin's mentions. Cases of striving, as Atkin defines it, occurs when one prematurely sees themselves as what they desire to become. Specifically, \"truth is not required, for example, in striving cases where we desire to premature be seen as what we hope to become.\" Let me illustrate why this is not the case.\n\nSay I want to become a painter -- I am striving to be a painter. But I generally do not claim that I *am* a painter until I am confident and believe that to be the case. If I *do* say that \"I am a painter,\" this is a case of 'fake it until you make it'. The actual underlying belief (and hope) is that I will *eventually be* a painter rather than actually believing that I currently am a painter. In this example, one explicitly repeats an obviously false statement *to others* in order to get external social reinforcement to create necessary social structures to enforce this to happen. My partner then knows that this statement is not necessarily a statement about my current skill with painting but rather a *wish* about a future skill of painting. They would not take the obviously false statement at face value and instead believes in the underlying *true* belief that I strive to be a painter. Much like sarcasm, those socially aware of the situation will believe the real deeper intention over the facade statement. This, to me, is a clear flaw in Atkin's argument that love requires false belief.\n\n","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/functional-programming":{"title":"Functional Programming","content":"\n## Syntax Quirks\n- `$ :: (a -\u003e b) -\u003e a -\u003e b` is function application (adds implicit parentheses and makes it right associative instead of left associative)\n\t1. Normally, `sort \"abc\" ++ \"def\"` would be interpreted as `(sort \"abc\") ++ \"def\"`\n\t2. If we use the `$` operator, we can do `sort $ \"abc\" ++ \"def\"` which is interpreted as `sort (\"abc\" ++ \"def\")` as intended.\n- `.` is function composition. Read the dot as the little dot in $f \\circ g$\n- `\u003c\u003e` is a synonym for `mappend :: Monoid m =\u003e m -\u003e m -\u003e m` or the monoidal append\n- `\u003c$\u003e` is a synonym for `fmap :: (a -\u003e b) -\u003e f a -\u003e f b`\n\t- Intuitively like applying a function to a container\n- `\u003c*\u003e` is like `\u003c$\u003e` but for wrapped functions `(\u003c*\u003e) :: Applicative f =\u003e f (a -\u003e b) -\u003e f a -\u003e f b`\n\t- Intuitively like applying a function in a container to another container\n- Remember that `(\u003c$)` and `($\u003e)` point towards the value that will be kept\n- `void :: Functor f =\u003e f a -\u003e f ()` is implemented as `void x = () \u003c$ x`. Read as: whatever you give me, I will return the unit value\n\n## Terminology\n![[thoughts/images/Haskell typeclasses.png]]\n\n### Category Theory\nIn essence, a simple collection which can be thought of as a graph. Three components\n1. A collection of objects (nodes)\n2. A collection of morphisms (edges).\n\t- If $f$ is a morphism with source C and target B, we write $f: C \\rightarrow B$\n3. A notion of composition of morphisms. \n\t- If we have $g: A \\rightarrow B$ and $f: B \\rightarrow C$, they can be composed resulting in a morphism $f \\circ g: A \\rightarrow C$\n\t- Composition of morphisms needs to be associative. Typically applied right to left\n\nCategory theory to Haskell\n- Objects are *types*\n- Morphisms are *functions*\n- Things that take a type and return another type are *type constructors*\n- Things that take a function and return another function are *higher-order functions*\n- Typeclasses capture the fact that things are often defined for a 'set' of objects at once\n\n### Functor\n\u003e A 'container' of some sort, along with the ability to apply a function uniformly to every element in it\n\nEssentially a transformation between categories. Given categories $C$ and $D$ and a functor $F: C \\rightarrow D$\n1. $F$ maps any object $A \\in C$ to $F(A) \\in D$ (the type constructor)\n2. $F$ maps morphisms $f: A \\rightarrow B \\in C$ to $F(f): F(A) \\rightarrow F(B) \\in D$ (`fmap`). Importantly, this means that all functors must be generic over at least one parameter (e.g. `Maybe` and not `Integer`)\n\t- applying `fmap` is sometimes called 'lifting' as it lifts a function from the normal context into the 'f' world\n\n```haskell\nclass Functor f where\n\t-- fmap maps morphisms\n\tfmap :: (a -\u003e b) -\u003e f a -\u003e f b\n\n\t-- applies a 'constant' function to replace the values in a container\n\t(\u003c$) :: a -\u003e f b -\u003e f a\n\t-- default implementation\n\t(\u003c$) = fmap . const\n```\n\n`fmap` takes a function which maps a value from `a` to `b` and applies it to a Functor `f`. Think of `f` as the container, `(a -\u003e b)` as the function that operates on the 'inner' values.\n\n### Monad\nMonads are functors from a category $A$ to that same category. A container for values that can be mapped over.\n\nThink of it like a context-specific environment. You need a function to transform things outside of it to things in it. You also need a function to manipulate stuff inside of that environment.\n\nA monad is a functor $M: C \\rightarrow C$ along with two morphisms $\\forall X \\in C$\n1. $\\textrm{unit}_X : X \\rightarrow M(X)$ (`return`)\n2. $\\textrm{join}_X: M(M(X)) \\rightarrow M(X)$ (can be recovered from `bind`)\n\n```haskell\nclass Monad m where\n  -- join operation (optional, only one of bind or join need to be defined)\n  join :: m (m a) -\u003e m a\n\n  -- bind operation\n  -- takes an f :: (a -\u003e m b) and applies it to\n  -- the inner value a of m\n  (\u003e\u003e=)  :: m a -\u003e (a -\u003e m b) -\u003e m b\n\n  -- replaces m a with m b\n  (\u003e\u003e)   :: m a -\u003e  m b       -\u003e m b\n\n  -- constructs the simplest monad m using a\n  return ::   a               -\u003e m a\n```\n\nMonad laws\n```haskell\nreturn a \u003e\u003e= k                  =  k a\nm        \u003e\u003e= return             =  m\nm        \u003e\u003e= (\\x -\u003e k x \u003e\u003e= h)  =  (m \u003e\u003e= k) \u003e\u003e= h\n```\n\n## Left and Right Associativity\nAssociativity of an operator determines how operators are grouped in the absence of parentheses.\n\nFor the following examples, we consider a fictional operator `~`\n\n1. Associative: operations can be grouped arbitrarily (e.g. addition, order doesn't matter)\n2. Left-associative: operations are grouped left to right\n\t1. `a ~ b ~ c` is interpreted as `(a ~ b) ~ c`\n\t2. Examples include\n\t\t1. Function application operator\n3. Right-associative: operations are grouped right to left\n\t1. `a ~ b ~ c` is interpreted as `a ~ (b ~ c)`\n\t2. Examples include\n\t\t1. Variable assignment (`=`)\n\t\t2. Exponentiation (`^`)\n4. Non-associative: operations cannot be chained\n\n## Parser Combinators\n\u003e Parser combinators are a technique for implementing parsers by defining them in terms of other parsers\n\nNotes on [Chumsky](https://github.com/zesterer/chumsky)\n\nWhere `a` and `b` are both parsers.\n\nParser Methods\n1. `just(a)` accepts a single string `a`\n2. `a.or(b)` parse `a`, if `a` fails, try parsing `b`\n3. `a.choice(b,c,d...)` try parsing `b`, `c`, `d`, return first one that succeeds\n4. `a.or_not()` optionally parse `a`\n5. `a.ignore_then(b)` ignore pattern `a` then parse `b`\n6. `a.then_ignore(b)` parse `a` then ignore `b`\n7. `a.then(b)` parse both `a` and `b` and return a tuple of `(a,b)`\n8. `a.padded()` ignore whitespace around `a`\n9. `a.repeated().at_least(n)` parse `a` at least `n` times\n10. `a.filter(fn)` only accept `a` if `fn(a)` evaluates to true\n\nResult Methods\n1. `a.collect()` turn results of `a` into an iterator\n2. `a.map(b)` map results of `a` into type `b`\n3. `a.chain(b)` concatenate results of parsers `a` and `b` into collection\n4. `a.copy(b)` duplicate parser definition \n5. `a.flatten()` flatten nested collection\n6. `a.to(b)` marks result of `a` as type `b`\n7. `a.labelled(b)` label result of a with `b`\n8. `a.end()` indicate end of parser\n\n## Racket\n```scheme\n; Quotes are \n` -\u003e quasiquote\n, -\u003e unquote\n' -\u003e quote\n```\n\n```scheme\n; Example program that iterates a program p\n(define (compiler-sub p)\n  (define (process-p p)\n    (match p\n\t  ; match 'begin atom\n      [`(begin ,s ...)\n       ; process-s for each s\n       (TODO process-s s)]))\n  (define (process-s s)\n    (match s\n      [`(set! ,loc ,int64)\n       #:when (and (location? loc) (int64? int64))\n       (TODO)]\n      [`(set! ,loc1 ,loc2)\n       #:when (and (location? loc1) (location? loc2))\n       (TODO)]\n      [`(set! ,loc1 (,binop ,loc2 ,loc3))\n       #:when (and (location? loc1)\n                   (Paren-asm-sub-binop? binop)\n                   (location? loc2)\n                   (location? loc3))\n       (TODO)]))\n  (process-p p))\n```","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/fundamental-tradeoff":{"title":"Fundamental Tradeoff","content":"\nThe fundamental tradeoff has two parts:\n1. How small you can make the training error\n2. How well training error approximates the test error.\n\n$$\\begin{aligned} E_\\textrm{test}\u0026= E_\\textrm{approx} + E_\\textrm{train} \\\\ \u0026= (E_\\textrm{test} - E_\\textrm{train}) + E_\\textrm{train}\\end{aligned}$$\n\nGenerally,\n- Training error goes down when the model gets more complicated, however\n- Approximation error goes up when the model gets more complicated\n","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/funding":{"title":"Funding","content":"\n\u003e Raising funding is just purchasing time to be together\n\n## Bounty Model\nPaying people set amounts for set tasks.\n\nBounty model is tough because\n1. Immediate shared context is required and onboarding new members to do novel work is hard (upfront costs are large)\n2. Keeping people engaged after the tasks are difficult (no long term sense of investment)\n\nHow can we keep individuals engaged with a project on longer term timescales?\n1. Encouraging individuals to create projects with the technology/ideas (e.g. through [hackathons](thoughts/hackathons.md))\n2. Through hiring (contractually bound commitment)\n\n## Grants\nFunding individuals/projects/organizations without the expectation of stake. Can be one-time or recurring.\n\nWhat are the [incentives](thoughts/incentives.md) for people to provide grants then? Within [web3](thoughts/web3.md), a lot of the reason is because of the obsession with profit. Donating to OSS is thereby a way to improve the long term return on their profit/investment. Is this still possible to incentivize grants when the technology/idea itself is not inherently of value (i.e. maybe only has derivative value)? \n\n## Amassing Capital\nUnfortunately, billionaries don't actually do anything. Even if they start with good intentions, they get cynical the more they progress and 'make it to the top'. After having huge amounts of capital, they are scared to give it out as the people who make their way in front of these people are the fakes. Because of the competition, the people who successfully can present are the ones who spent the time polishing the pitch rather than doing fundamental research and important breakthroughs.","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/game-design":{"title":"Game Design","content":"\nRelated: [games](thoughts/games.md)\n\n## Game Design and [Teaching](thoughts/teaching.md)\n[Source: Game designers vs. education researchers on unguided instruction by *Andy Matuschak*](https://klr.tumblr.com/post/159583871898/game-designers-vs-education-researchers-on)\n\n\u003e A mistake we made early on was looking primarily at metrics like retention and monetization. These simply don’t tell us much about what motivates players to play. If I were to build the game again, I would have implemented the togetherness metric for the very first private alpha.\n\nA lot of pedagogy is covers the same questions as game design (especially tutorials): how much explicit guidance should a student/player get in an activity?\n\nThe \"[vow of silence](https://www.youtube.com/watch?v=xrDZ--AuiL8)\": to preserve the joy of discovery, games should carefully structure their activities so that players will learn what they need through [play](thoughts/play.md). An approach very similar to the [constructionist](thoughts/constructionist.md) ones found in [Mindstorms](thoughts/Mindstorms.md)\n\n**We can teach stuff using mechanics and level design** instead of words.\n\nThe goal is to give users/players the freedom to manage their own position relative to their own intellectual \"sweet spot\"\n\n![](/thoughts/images/flow.png)\n\n## [Economics](thoughts/economics.md) and [Game Theory](thoughts/game%20theory.md)\n[Source: Prosocial economics for game design by *Daniel Cook*](https://lostgarden.home.blog/2020/01/11/prosocial-economics-for-game-design-%EF%BB%BF/)\n\n\u003e Multiplayer games can help build a player’s social support network. What would game design look like if our goals included **reducing loneliness**, **decreasing toxicity** and boosting a player’s **positive connections** with others?\n\n### Loneliness\nThe loneliness epidemic is a real thing. It has been medically associated with mortality, depression, and more. In aggregate, chronic loneliness is estimated to shorten lifespan by an average of 15 years.\n\nAdvancing age also makes us more likely to be lonely. Especially as we work on [longevity](thoughts/longevity.md) research, this is a pressing issue to try to solve.\n\nThe best games are designed to be played with [friends](thoughts/friendship.md).\n\n### Toxicity\n\u003e At the root of much toxicity is the misdirection of our human need to belong\n\nWhen humans feel like they lack membership in healthy, eudaimonic, organizations, they experience stress and seek to rapidly remedy the situation (e.g. lashing out at others in hopes that putting others down helps them rise in status).\n\nIn toxic systems every new user is potentially rewarded if they adopt toxic behaviours.\n\n### Prosocial Game Design\nThree main pitfalls\n1. Psychology: there are a lot of requirements to build friendships, like right sized groups of people, correct density, and engagement in mutually dependent reciprocal activities.\n2. Logistics: rigid human limits on how many relationships they can maintain and how long it takes them to form new ones (see: [group limits](thoughts/group%20limits.md))\n3. Economics: games are built on an economic foundation of resources (creation, transformation, trade, and consumption). However, it is hard to get economic incentives to align with those of social behaviour. \"In particular, many of the key elements required by the psychological and logistical aspects of friendship formation are systematically undervalued within common economic practices.\"\n\n### Boundaries between the real world and the [virtual world](thoughts/virtual%20worlds.md)\nThere’s limited permeability of the boundary between the real world and the cartoon world. You can think of this as the designer writing out the import / export laws for their bubble of play\n\n### Elements of the internal economy\n- Tokens: base units of quantity (can represent attention, time, or value). They act as goods, products, or currencies\n- Sources: operations that produce new tokens\n- Pools: stores of tokens\n- Sinks: operations that take tokens out of circulation\n- Transforms: transform one type of token into another\n\nThen agents who perform operations:\n- Players: human agents who trigger various transforms, sources, and sinks\n- [Black Box](thoughts/black%20box.md): computer agents or systems which also trigger transforms, sources, and sinks. Often, players attempt to understand the triggers of this black box.\n\nFrom these, we can model various phenomena like [feedback loops](thoughts/feedback%20loops.md) and ownership\n\nWe can then use these to influence [incentive](thoughts/incentives.md) structures to balance games (e.g. improve a drop rate of a weapon to better increase the rate at which a key boss is defeated)\n\nExamples of internal economic systems:\n- Leveling Systems: XP tokens\n- Items: enables players to perform various transforms on the pool (e.g. a weapon is a token which depletes enemy health tokens to generate XP tokens)\n- Chat: budget of attentional and time resources\n\n### Prosocial Values\n- Friendship: The formation and maintenance of healthy, meaningful friendship networks between players. \n- Thriving individuals: Individuals feel competence, volition, and relatedness, both for themselves and for their friends. \n- Altruism: The promotion of activities that involve intrinsically motivated altruism and cooperation. \n- Positive group norms: The spread and enforcement of shared altruistic social norms within and across groups.\n- Shared goals: The definition and adoption of shared group goals. Players work towards those goals via mutual interdependence, and achieve feelings of purpose and meaningfulness. \n\nAnti-values\n- Individual Toxicity: poorly socialized individuals resort to antisocial behaviours in an attempt to put themselves above the group.\n- Group Toxicity: intergroup friction results in unhealthy interactions\n- Loneliness: sparse relationship networks, we feel this when our social support network fails. Loneliness tells us that our current social situation is untenable long term and we should seek out connection with others.\n\n### Measuring Trust\n[Trust](thoughts/trust.md) is an internal factor that cannot be measured directly so instead we need to rely on proxies.\n1. Pairwise bonds: There are two different (_asymmetric_) bonds for any given pair of player; the bond player A to player B and the bond from player B to player A.\n2. Active time spent together: One of the easiest symmetric bond proxies is simply tracking if players are in the same area together. \n3. Success together in high trust situations\n4. Time spent talking positively to each other\n\nHowever, this 'trust value' should not be public for the sake of avoiding converting it into a metric to optimize for: [Goodhart's Law](thoughts/Goodhart's%20Law.md). Doing so may transform relationships into ones which are transactional in nature with clear extrinsic motivators in the form of your willingness to make that number go up or down. (This is also one of the reasons why ‘likes’ in social media end up being a source of toxicity and in general a very poor practice.)\n\nOne also needs to keep in mind that trust differs across social contexts\n\nFor new players, one of the scariest things is requirement to engage in specialized, high coordination group performances. Building towards high trust using a ladder:\n![](/thoughts/images/trust-ladder.png)\n\n### [Positive Sum](thoughts/positive%20sum.md) Resources\nAn economy of zero sum resources is a world of scarcity. The challenge economics attempts to solve is how we might split up these limited resources in an efficient fashion.\n\nIn [virtual worlds](thoughts/virtual%20worlds.md), we can make almost any resource positive sum. When a monster drops loot for one player, it can also drop loot for any other player that did damage.\n\nHowever, truly abundant worlds are not super fun to play in. How can we design for infinite source and imbalanced economies?\n- Per players caps: cap number of harvestable positive sum resources per player\n- Per group caps: cap total number of harvestable items per group of players\n- Transaction costs: can prevent global pooling with large transaction taxes. This encourages local resource use\n- Appropriate sinks: find ways to drain resources out of the world\n\n","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/game-theory":{"title":"Game Theory","content":"\nModelling decisions where the outcome partially depends upon choices made by other rational agents. Assumes:\n1. Individual Rationality: each player maximizes their own utility and knows the full game tree/table\n2. Common Knowledge of Rationality: each player knows that all other players are rational\n\nTwo ways to look at game theory\n1. Normative tool: how to make rational choices\n2. Descriptive/explanatory tool: help explain social behaviour\n\nSome social practices don't appear rational in normative game theory but can be explained using descriptive game theory\n\nSome distinctions:\n1. [[thoughts/zero sum|Zero-sum]] vs non-zero sum games (e.g. [[thoughts/positive sum]])\n\t- In a zero sum game, the payoffs always sum to 0\n2. Simultaneous vs [[thoughts/sequential games]]\n\t- In simultaneous games, all players choose independently at the same time without knowing what other players will do\n3. Perfect information vs imperfect information games\n4. Symmetric vs non-symmetric games\n\t-  In symmetric games, all actors have the same set of actions to choose from\n5. Two-person vs n-person games\n6. Cooperative vs non-cooperative games\n\t- In cooperative games, players get to choose the outcome together (i.e. form binding agreements in the form of 'if I do A, then you must do B')\n7. Non-iterated vs iterated games\n\t- A non-iterated game is only played once. Iterated games can be played several times.\n\t- A \"supergame\" is a specified # of iterations of a game. Strategies:\n\t\t- C: Always cooperate\n\t\t- D: Always defect\n\t\t- TT: tit-for-tat\n\t\t\t- Cooperate on round 1 and then take same action as opponent in previous round\n\t- Upshot is that the case for cooperation (e.g. TT or C) is strong when the number of games is not known in advance\n\t\t- We can always construct a strategy where D or some version of TT dominates when we know how many games there will be\n1. Finite vs infinite games\n\t- Not to be confused with the James Carse definition of infinite games\n\n### Risk, Ignorance, and Uncertainty\n- Decisions under ignorance ([[thoughts/Decisions under ignorance|DUI]]): the agent is ignorant of all probabilities\n- Decisions under risk ([[thoughts/Decisions under risk|DUR]]): the probability of each outcome is known\n\t- We can maximize expected value to figure out what decision to make\n\t- Generally need to know utility *and* risk values\n- Decisions under uncertainty (DUU): includes risk, ignorance, and intermediate cases\n\n## Game Tables\nUsed to represent simultaneous games\n\nSimilar to decision tables in [[thoughts/Decision theory|decision theory]] but the column is the action of the other agent, and cells are the outcomes for each agent represented as a tuple of numbers.\n\ne.g. Stag Hunt where A and B are hunters and the numbers represent amount of food acquired\n\n| |A|B|\n|-|-|-|\n|A|25,25|0,5|\n|B|5,0|5,5|\n\n(In [[thoughts/zero sum]] games, it is sufficient to only represent the utility of each of the Rows)\n\n- The solution is a set of \"profile\" of choices that are rational for each agent\n- Each cell is a profile which leads to an outcome for both players\n\n## Solutions to games\n### Dominance and admissibility\nS1 dominates S2 iff:\n1. S1 is at least as good as S2 regardless of what other players do.\n2. S1 is superior to S2 in at least one case.\n\nIf there is a dominant strategy, it will be part of the solution profile. If there is no dominant strategy, we eliminate all dominated strategies as inadmissible.\n\n### Equilibrium\nThis rule subsumes the rules for Dominance and Admissibility. Any solution using Dominance or Admissibility is also a [[thoughts/Nash equilibrium]].\n\nMinimax condition: For two-person zero-sum games in particular, a pair of (pure) strategies is an equilibrium if and only if its payoff is the minimum on its row and the maximum on its column\n\nThere may not always be an equilibrium with pure strategies. However,\n\n## Mixed Strategies\nIn a two-person zero-sum game with mixed strategies, there is always an equilibirum. Moreover all equilibria have the same (expected) value\n\nIf a player has options $R_1, \\dots, R_n$, then a mixed strategy selecting $R_i$ with probability $p_i$ written as $[p_1R_1, \\dots, p_nR_n]$ where the probabilities add up to 1.\n\n$[pA, (1-p)B]$ where $0 \\leq p \\leq 1$. This means: choose A with probability $p$ and B with probability $1 - p$.\n\nGiven a table in Standard Form:\n\n| |C1|C2|\n|-|-|-|\n|R1|a|b|\n|R2|c|d|\n\nSteps:\n1. We calculate the EU for the actor represented by Row, EU(Row) = $p(qa + (1-q)b) + (1-p)(qc + (1-q)d)$\n2. We find a $p$ such that EU(Row) only depends on $p$ (by making the coefficient for $q$ zero). To do this normally:\n\t1. $p = (d-c)/(a-b-c+d)$\n\t2. $q = (d-b)/(a-b-c+d)$\n\t3. If $a-b-c+d = 0$ then there are pure-strategy equilibria so use those\n3. We do the same but with $q$\n4. Now set EU(Row) to 0. We essentially want to make EU(Row) constant so there is no incentive to switch\n\n\n\n## Trust and Game Theory\n[Source: The Evolution of Trust by *Nicky Case*](https://ncase.me/trust/)\n\nFor [trust](thoughts/trust.md) to evolve:\n1. Repeat interactions must happen. Trust keeps a relationship going, but you need the knowledge of possible future interactions *before* trust can evolve\n2. Possible win-win situations. This must be a [positive sum](thoughts/positive%20sum.md) game where *both* players can be better off\n3. Low miscommunication. High-tolerance players are possible but if the level of miscommunication is too high (low signal to noise ratio), trust breaks down. Even in low miscommunication situations, it pays to be more forgiving\n\nIn the short run, the rules of the game define what the players do. In the long run, players define the rules. Incentive for us to build the environment and rules we want to play in.\n\nUnfortunately, modern day social media means we have less 'close-friends' and thus repeat interactions than ever. With algorithmic news feeds, miscommunication breeds and win-win situations become scarce.\n\nSee also: [[thoughts/Evolutionary game theory]]\n\n## Applied Game Theory\nGame theory feels hard to apply to the real world due to properties like the [Collingridge Dilemma](thoughts/catch%2022.md)\n\nGames, however, are a great test bed for a lot of game theory given how information rich they are. See [game design](thoughts/game%20design.md)\n\n## Bartle Taxonomy of Player Types\nSee also [[thoughts/evaporative cooling#Geeks MOPs and sociopaths in subculture evolution|Geeks, Mops, and sociopaths]]\n\nA classification of types of actors in video games based on character theory\n\n![[thoughts/images/Bartle taxonomy of player types.png|400]]\n\n1. Achievers: prefer to optimize metrics or other concrete measurements of 'succeeding' in a game\n\t1. Single-player appeal: Every game that can be \"beaten\" are appealing to Achievers.\n\t2. Multi-player appeal: Look to socializers for praise, opportunities to show off their skill and hold elite status to others\n2. Explorers: tendency to dig around, explore, and immerse themselves in the lore and  game world\n\t1. Single-player appeal: flock to games which reward close attention\n\t2. Multi-player appeal: tire quickly of MMORPGs when they finish the content\n3. Socializers: play the game for the social aspect. The game is the tool they use to meet others in-game or outside of it\n\t1. Single-player appeal: rich interactions with NPCs and/or strong online community (e.g. forums and streams)\n\t2. Multi-player appeal: main purpose for the socializer, enjoys mechanics for socializing like guilds, chats, etc.\n4. Killers: thrive on competition from others and feeling superior\n\t1. Single-player appeal: want to achieve top ranks or beat other speedrunners\n\t2. Multi-player appeal: friendly competitive spirit or 'thrill of the hunt'","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/game-writing":{"title":"Game Writing","content":"\nSee also: [[thoughts/games]], [[thoughts/creative writing]], [[thoughts/game design]]\n\n## Loops and Episodes\n- Games are interesting to write for because of the concept of *agential distance* (see: [[thoughts/Games Agency as Art]])\n\t- The agency of the player shapes their own experience of the game\n- Tension\n\t- When the playing strives to fulfil and objective or goal and the game pushes back\n\t- External to the narrative\n- Conflict\n\t- When a character strives to fulfil an objective or goal and an antagonist pushes back\n\t- Internal to the narrative\n- Gameplay loops (called ludic loops by Nguyen)\n\t- A cycle in which the player uses the core mechanics to resolve tension\n\t- These may occur at different [[thoughts/pace layers]] and serve to anchor the player in the game\n\t\t- The narrative should support the gameplay loops to be effective\n- Episodes\n\t- Can be split into more manageable pieces\n\t- Can be released episodically (e.g. DELTARUNE)\n\t- Establishes patterns (and allows you to break these patterns for exaggerated effect)\n- Example story\n\t- Protagonist attends a very elite preparatory school\n\t- All his friends are incredibly smart\n\t- He's the highest scoring kid in the class but... the secret is he has been stealing the answer keys from the teachers lounge since he's started school there. As such, he hasn't actually learned anything in school, just how to steal really well\n\t- All previous episodes have been solo: player versus environment\n\t\t- Security cameras, guards, alarms, etc.\n\t- Episode: this time when stealing the answer key, he sees his best friend also trying to steal the answers. This leads to a reckoning about whether all his friends are actually smart or actually faking it like him\n\t\t- This adds a new element: other NPC characters who are trying to reach the answer key before you do\n\t\t- Adds time pressure and extra dynamism\n\t- Larger commentary is about whether these 'preparatory' institutions really prepare students for the real world or just to get really good at these 'vanity' metrics like GPA that schools always portray\n","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/games":{"title":"Games","content":"\nRelated: [game theory](thoughts/game%20theory.md), [game design](thoughts/game%20design.md), [The Grasshopper, Games, Life and Utopia](thoughts/The%20Grasshopper,%20Games,%20Life%20and%20Utopia.md), [[thoughts/Moving Castles|Moving Castles]]\n\nGames are interesting when the underlying rules are simple (see: [[thoughts/Gall's law|Gall's Law]], low [[thoughts/complexity|Kolmogorov Complexity]]) but exhibit complex behaviour.\n\nThe more I think about it the more I think I eventually want to build games. All of my [[thoughts/peer-to-peer|p2p]] infrastructure work now is to build up the tools possible to explore that space of potential games. Games as explorations in [[thoughts/interaction design|interaction design]].\n\nSee: [[thoughts/Games Agency as Art]], [[thoughts/game writing]]","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/gate-keeping":{"title":"Gate Keeping","content":"\nMass media communications theory\n- Origins in social psychology\n- Gatekeeper makes decisions about what should be passed on and to whom\n- A form of social control\n\n## Digital gate keeping\n- Platforms gate keep by managing [information](thoughts/information.md) flows in many different ways\n- Non-human agents participate through algorithmic filtering (e.g. upvoting content)\n- See centralization of [Internet](thoughts/Internet.md) through search\n\n## Differences from [censorship](thoughts/censorship.md)\n- Censorship is all about blocking\n- Gate keeping is more about access and quality control \n\n## Personalization as a form of gatekeeping\n- Information flow and filtering is based on individual and/or group profiles\n- Bozdag( 2013): personalization leads to more [bias](thoughts/bias.md) rather than less\n- Cass Sunstein: \"information cocoons\"\n- Serves a sort of invisible auto propaganda, indoctrinating us with our own ideas, amplifying our desire for things that are familiar\n\n## Governmental\n[Google Takedown Requests](https://transparencyreport.google.com/government-removals/government-requests)","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/generational-learning":{"title":"Generational Learning","content":"\nRelated: [Theory of Niche Construction](thoughts/Theory%20of%20Niche%20Construction.md) and [Extended Mind Hypothesis](thoughts/Extended%20Mind%20Hypothesis.md)\n\n## Intergenerational social learning\n-   intergenerational transmission of ecological and technical expertise\n-   parental acts bias the environment explored by trial and error learning\n-   trials are guided — social/observational learning\n\t-   partially complete and failed exemplars of the target artefact\n\t-   aid of tools that initially chosen by others\n\t-   access to raw materials in various stages of preparation\n-   natural bargain\n\t-   Skilled practitioners ease their own burdens by having apprentices do low to medium skilled work.\n\t-   Apprentices do grunt work from the perspective of the skilled, but for the beginner, it builds basic skills.\n-   Over both evolutionary and developmental time frames, inner mechanisms have coevolved with and adapted to this rich environment. Language and arithmetical notation enhance our capacity to think","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/generative-models":{"title":"Generative Models","content":"\nGiven data, we want to make more data that look like it\n\nLast 10 years have seen a variety of new deep generative models:\n- Variational autoencoders (VAEs)\n- Generative adversarial networks (GANs)\n- Normalizing flows\n- Diffusion models\n\t- Take training images, and add noise to them in a sequence of steps.\n\t- Until the image basically looks like random noise.\n\t- Train neural network to reverse those steps.\n\t- Generate a new image by starting from random noise and applying the network\n- Text-guided Diffusion\n\t- A Diffusion Model starts from randomly sampled Gaussian noise so there is no way to guide this process to generate specific images. We can augment this process with textual embeddings\n\t- Generate the image and text encoding of each of the image-caption pairs\n\t- Trains to maximize the cosine similarity between image-caption pairs\n\t- After this step is finished, the model is frozen\n\n![[thoughts/images/generative models.png]]","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/git":{"title":"git","content":"\n`git` internals. Heavily inspired by [The Git Parable](https://tom.preston-werner.com/2009/05/19/the-git-parable), a talk by Tom Preston-Werner\n\n## Git Internals\n### Snapshots\nWhat if you could take snapshots of your codebase at any time and resurrect that code on demand?\n\nThe simplest version of this is something you may have done with Photoshop files.\n- You start your work in a directory `project`\n- As you make changes, you want to make a snapshot so you make a copy of your entire working folder and rename it `project-version-1`\n- After the next chunk of work, you make another copy and rename it `project-version-2`\n- In each folder, you include a `message` text file that describes your changes\n- To go back to a previous version, you just delete your current working version of rename your snapshot `project`\n\n### Branches\nWell now we run into a new problem. What if we roll back to a previous version of the code and then make some more changes?\n\nThat is, we create a new snapshot that is *not* a direct descendent of the preceding snapshot.\n\nOur previous snapshot system only worked for a linear system of changes. How might we handle having multiple points where there are active changes being made?\n\nBy looking at your code history as a tree, solving the problem of ancestry becomes trivial. All you need to do is include the name of the parent snapshot in the `message` file you write for each snapshot.\n\nThis is also why there is a lot of arboreal terminology in git: branches, trunk, etc.\n\nNow... we run into another problem. How should we name our snapshots now that we can't use a linear system of numbers?\n\nWell, we can actually just name each branch and then list `branch-name: snapshot-name` pairs that represent the tips of branches. Let's store this in a file called `branches`:\n\n```\nmain: project\ntmp-fix: project-version-2-fix\n```\n\nTo switch to a named branch you need only look up the snapshot for the corresponding name from this file.\n\nTo ensure this file is always up to date, creating an additional snapshot on a branch means we should update the entry in `branches` that corresponds to our current branch to the latest snapshot.\n\n### Branches as Pointers\nAfter using branches for a while you notice that they can serve two purposes. First, they can act as movable pointers to snapshots so that you can keep track of the branch tips. Second, they can be pointed at a single snapshot and never move.\n\nMixing both of these uses into a single file feels messy. Both types are pointers to snapshots, but one moves and one doesn’t.\n\nWe can create another file called `tags` to contain static pointers to snapshots.\n\n### Collaboration\nNow, imagine you are working with a friend on this project. You give them a copy of all of your snapshots, branches, and tags. Your friend happens to go offline for a while and when you meet up again, you both realize you've been using the same naming system for your snaphsots! Now, you both have snapshots called `project-version-23` and `project-version-24` that have different contents. Also, we have no idea who authored which snapshot!\n\nThere are two things we can do to solve this:\n1. Snapshot messages will henceforth contain author name and email.\n2. Snapshots will no longer be named with simple numbers. Instead, you’ll use the contents of the message file to produce a hash. This hash will be guaranteed to be unique to the snapshot since no two messages will ever have the same date, message, parent, and author. Let's use the SHA-1 hash algorithm\n\nNice! Now, we can merge our snapshots (and thus our working trees) without conflicts. Because of how we hash our snapshots to get their names, we know that any two snapshots with the same name actually have the same content too.\n\n### Merges\nThis is what we normally call a merge commit! \n\nHowever, while constructing the snapshot message for the merge, you realize that this snapshot is special. Instead of just a single parent, this merge snapshot has two parents.\n\n### Eliminating Duplication\nWe can use [[thoughts/content addressed storage]] and [[thoughts/Merkle-DAG|Merkle-DAGs]]!\n\n1. Create a directory named `objects`\n2. Go to the most deeply nested directory in the snapshot\n3. Create a temp working file\n4. For each file in the directory\n\t1. Calculate the hash of the contents\n\t2. Add an entry to the temp working file: `blob {hash} {filename}`\n\t3. Copy the file into the `objects` directory and rename it to the hash\n5. Afterwards, find hash of the temp working file and place it in the objects directory (also using the hash as the name). This represents the folder we just traversed\n6. Move up on directory and repeat starting from step 3\n\t1. When we come across the folder we just traversed, we add the following entry to the temp working file: `tree {hash} {dir name}`\n7. Once this has been accomplished for every directory and file in the snapshot, you have a single root directory object file and its corresponding SHA1. We record this in the commit `message`\n\nThus, we avoid storing duplicate files!\n\n### Compression\nText can be very efficiently compressed using something like the LZW or DEFLATE compression algorithms. If you compress every blob before computing its SHA1 and saving it to disk you can reduce the total storage size of the project history significantly.\n\n## Handy Commands\nThink about `git` like a file time machine -- it allows you to traverse and manage an entire multiverse of files\n- Unstaged files: anything you've done to your current branch of the world that hasn't been staged or committed\n- Staged files: things that you've marked as things you want to commit to a snapshot\n- A commit: a snapshot in time\n- A branch: a specific branch of the multiverse\n- A repository: the entire multiverse\n\nHere are some verbs and commands you'll find yourself using a lot locally!\n- Verbs\n\t- `git add {PATH}`: add things to the staging area. Matches whatever directory/file you pass in as the path. For example, using `git add .` adds everything in the current directory. `git add tests/math` adds everything in the `tests/math` folder. `git add '*.js'` adds all JavaScript files (note the quotes here!)\n\t- `git commit -m {MESSAGE}`: save a snapshot of everything in the staging area with a given message\n\t- `git commit -am {MESSAGE}`: amend the previous commit with a new message (if you had a typo, for example)\n\t- `git show {REFERENCE}`: show all changes in a given commit\n\t- `git reset {REFERENCE}`: set our current `HEAD` to the specified commit\n\t\t- Normally, working directly is not affected but staging is updated to match commit\n\t\t- `--soft` keeps the staging area\n\t\t- `--hard` updates both the staging and working directory to match the commit (this is a hard reset)\n\t\t- Use as a local reset button\n\t- `git status`: Show how many commits ahead/behind we are, as well as staged, unstaged, and untracked files\n\t- `git reset {PATH}`: unstage specific files/folders\n\t- `git checkout {BRANCH OR REFERENCE}`: switch branches to the given branch or reference\n\t- `git reflog`: show a list of commits that moved the tips of branches\n\t\t- This is useful for recovering deleted branches and hard resets!\n\t- `git stash`: stash away everything in the staging area\n\t\t- `git stash pop`: take out the changes from the stash and restore it back into the staging area\n\t\t- Good for moving changes across branches (oops, I made my changes on `main` instead of my feature branch!)\n- Nouns (can be used anywhere where `git` expects a reference)\n\t- `HEAD`: current tip of the branch\n\t- `HEAD~2`: go 2 commits back from `HEAD`\n\t- `25c3be7b5`: go to the commit with hash `25c3be7b5`\n\t- `HEAD@{2}`: go back to where `HEAD` was 2 moves ago\n\t- `main@{one.week.ago}`: go back to where `main` branch was a week ago\n\nFor collaboration and online repositories:\n-  `git push {REMOTE} {BRANCH}`: push your local commits on `BRANCH` to a remote repository called `REMOTE`\n\t- To add a new remote: `git remote add {REMOTE} {URL}`\n- `git pull {REMOTE} {BRANCH}`: pull remote commits from `BRANCH` onto your current local branch\n- `git merge {BRANCH}`: merge `BRANCH` into our current branch\n- `git log --oneline --decorate --color --graph`: pretty print history","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/governance":{"title":"Governance","content":"\nRelated: [Moderation](thoughts/Moderation.md)\n\n## Community Governance\n-   bottom-up emergent properties vs top-down governance\n-   homeostasis of communities\n    -   mix of internal and external influence\n    -   secluded vs public: [digital commons](thoughts/digital%20commons.md)\n    -   conforming to labels\n    -   self-fulfilling prophecies\n-   sanctity of natural interactions\n    -   monetizing human interaction (ondeck)\n    -   how do we screen for value alignment?\n        -   interviews? (two-way vibe check)\n        -   publishing list of values\n        -   why introductions are hard: [introductions](/thoughts/introductions)\n            -   can never fully/properly frame yourself\n\n## The Art of Online Governance\n[Source: The Yak Online Governance Primer](https://mirhub.xyz/post/0x3b894393fbd9c879dc8d16d4d18277831bff9fa1/ajdo_so3gw34cltwbwnc2od3s0yt3us9c-c2nnpq_us/)\n\n![](/thoughts/images/online-governance-regimes.png)\n\nSee also: [[thoughts/games#Bartle Taxonomy of Player Types|Bartle Taxonomy of Player Types]]\n\nFour Online Governance Regimes:\n-   **Hobbesian:** Governance ideas responding to wild defaults and low alignment that attempt to foster progress despite conflict and chaos\n\t- Generally ok for early years of a subculture or a social network but fails when it scales or becomes popular (e.g. external influence is too strong)\n-   **Gaia:** Governance ideas responding to wild defaults and high alignment that attempt to foster progress using the patterns and harmonies of nature\n\t- as a warning, see _The Tyranny of Structurelessness_ by Jo Freeman\n-   **Muddler:** Governance ideas responding to structured management with low alignment; commonly known as “herding cats,” attempts to foster progress by structuring local activities\n-   **Citadel:** Governance ideas that assume a consciously architected and structured context, usually with top-down alignment forces \n\n### Traps\n1. Techno Utopia trap\n\t- an attempt 'to build it better' from tabula rasa (v ['move fast and break things'](thoughts/move%20fast%20and%20break%20things.md))\n\t- \"While this blend of tabula rasa thinking and romantic cherrypicking of reference points can occasionally lead to refreshing new insights and much-needed shedding of historical baggage, it can also lead to naive idealism and utopian, wishful thinking, and governance attempts that fail through inevitable disillusionment.\"\n2. Grand Old Institution trap\n\t- opposite of the Techno Utopia trap\n\t- those involved with long-standing research/scholarship in governance and management (e.g. from academia) often approach the question as though the context of new digital tools, information ubiquity, and unusual organizing aims changes almost nothing\n\n## Turing-Complete Governance\n[Source: Turing-Complete Governance by *Saffron Huang*](https://baby.mirror.xyz/O7a922A-9zT4C4UwssRExkftdHywJ-13sR2rxQ-t__k?curius=1294)\n\n- \"Auctioning off or loaning away voting power to those uninvested in quality governance, or want to steer governance towards selfish ends misaligned with the community, is generally a terrible idea.\" (see: [Plato's Ship of State](thoughts/Plato's%20Ship%20of%20State.md))\n- Skeptical about normalizing airdrops as reward for early investors\n\t- \"Imagine if we had airdrops for more decisions relevant to the off-chain world, like participating in local council\" \n\t- Wouldn't this just lead to optimizing for airdrops? This happened with ENS ([Goodhart's Law](thoughts/Goodhart's%20Law.md))\n- \"Turing-Complete governance shouldn’t be advocated as a way to make the most complex algorithm possible. The point is that we can have any inputs we want, and any computational transformation of those inputs to produce some output. Vitalik has pointed out that [simple social systems with](https://vitalik.ca/general/2018/11/25/central_planning.html) more predictable outcomes and understandable processes for tweaking the outcome are more desirable\"\n\t- [Gall's law](thoughts/Gall's%20law.md)\n- \"Imagine if every application on the [Internet](thoughts/Internet.md) by default had a zero-downtime, publicly exposed API\"","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/gradient-descent":{"title":"Gradient descent","content":"\nWhen we minimize or maximize a function, we call it optimization.\n\nGradient descent is essentially an iterative optimization algorithm that takes a guess and refines it using the gradient to make a better guess.\n\nIf the objective function is a convex function, then it will converge to a *global optimum*.\n\nGradient descent finds critical point of differentiable function. Which can be faster than normal equations for large ‘d’ values. It takes $O(nd)$ per iteration so $O(tnd)$ for $t$ iterations.\n\nFormally,\n1. We start with an initial guess: $w^0$\n2. We repeatedly refine the guess: $w^{t+1} = w^t - \\alpha^t \\nabla f(w^t)$\n\t1. $\\alpha$ here is the learning rate.\n\t2. We move in the negative gradient direction as given some parameters $w$ the direction of largest decrease is $- \\nabla f(w)$\n3. We stop when $\\lVert \\nabla f(w^t) \\rVert \\leq \\epsilon$\n\n## Stochastic Gradient Descent (SGD)\nHowever, the runtime of each iteration of regular gradient descent is proportional to $n$. This is problematic when we have large training sets!\n\nInstead of computing the gradient over all training examples, we do it for some random training example $i$. Intuition is that *on average*, the algorithm will head in the right direction\n\nWe can use it when minimizing averages (so all regression losses except brittle regression)\n\nWhen we get close enough to a local minima $w^*$, we enter a region of confusion where some $\\nabla f_i(w)$ point towards $w^*$ and others don't. This confusion region is captured by the variance of the gradients\n- If the variance is 0, every step goes in the right direction (outside region of confusion)\n- If the variance is small, most steps go in the right direction (just inside region of confusion)\n- If the variance is large, many steps point in the wrong direction (middle of region of confusion)\n\nBasically, for a fixed stepsize, SGD makes progress until the variance is too large.\n\n![[thoughts/images/sgd-loss.png]]\n\n### Decreasing Step Size\nIf we decrease the step size as we keep training, we can still converge to a stationary point as long as:\n\n$$\\frac{\\sum_{t=1}^\\infty (\\alpha^t)^2}{\\sum_{t=1}^\\infty \\alpha^t} = 0$$\nA common option is to use $\\alpha^t = O(\\frac{1}{\\sqrt t})$\n\n### Minibatches\nWe can train on a 'mini-batch' $B^t$ of examples. Radius of region of confusion is inversely proportional to $B^t$\n\n### Early  Stopping\nNormally, we stop GD when gradient is close to zero. However, we never know this when doing SGD (as we cannot see the full gradient). We just stop early if the validation set error is not improving (this also reduces overfitting)","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/group-limits":{"title":"Group Limits","content":"\nRelated to the [evaporative cooling](thoughts/evaporative%20cooling.md) effect. Great example of a group limit is [Dunbar's Number](thoughts/Dunbar's%20Number.md)\n\nThe way to 'scale intimacy,' if possible, is to scale horizontally rather than vertically. Create many groups of smaller interest groups (warrens) rather than large groups (plazas).  This mitigates negative impacts of [context collapse](posts/context-collapse.md)\n\nSide: warrens as a way to be [niche at scale](thoughts/niche%20at%20scale.md)\n\n## Social Capacity\nIs there an inverse relationship between number of social connections and their depth? If you multiply them, do you get a person's social capacity?\n\n\u003e \"The amount of social capital you have is pretty fixed,\" Dunbar said. \"It involves time investment. If you garner connections with more people, you end up distributing your fixed amount of social capital more thinly so the average capital per person is lower.\"\n\nBecause of the increased number of 'social connections' people have today, is [context collapse](posts/images/framing/context-collapse.png) inevitable?\n\n\"Yet, when researchers tried to determine whether virtual networks increase our strong ties as well as our weak ones (the ones that Hansen had focussed on), they found that, for now, the essential [Dunbar's Number](thoughts/Dunbar's%20Number.md), a hundred and fifty, has remained constant.\" Is the Dunbar number a metric for social capacity?\n\nDoes social capacity differ across different types of social interactions? e.g. One-to-one vs One-to-many vs Many-to-many (relevant: [digital commons](thoughts/digital%20commons.md))\n\n\"Modern Loneliness\" by Lauv covers a lot of similar topics\n\nRelated: [tribe flourishing](thoughts/tribe%20flourishing.md)\n\n## Research\nI feel there are dangers of large groups, especially within research. Larger groups lead to more bureaucracy and being ok with the average -- an effect of too many cooks in the kitchen. This leads to ideas that are at the middle of the [distribution](thoughts/data%20distributions.md) ([Vanilla Ice Cream effect](thoughts/Vanilla%20Ice%20Cream%20effect.md)) and tends to discourage more radical, out-of-distribution thinking and research.\n\nRelated: [a new DARPA](thoughts/research%20institutions.md), [community perception](thoughts/communities.md)\n\n## Scalability\nWhy do we feel the need to find the billion-person version of communities? Is this just the [Silicon Valley](thoughts/Unrepeatable%20Miracle%20of%20Silicon%20Valley.md) question of scale?\n\nIs [human intimacy](thoughts/friendship.md) scalable? I think not.\n\nWhat if the events were universally accessible but instead of serving everyone, serve those who opt-in to participate more? Cultivation \u003e [moderation](thoughts/Moderation.md)\n\nIf we remove misaligned [incentives](thoughts/incentives.md) and less people come, then tbh that's better, that eliminates the people you didn't want in the first place","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/hackathons":{"title":"Hackathons","content":"\n[Full Post](/posts/hackathons)\n\n## Discussion\n\u003e \"I want hackathons to embody a starting point not a set timeframe\"\n\nHow do we push for hackathons to be the 'start' of the journey rather than saying its the entirety of a short, not super comprehensive event?\n\nIn other words, how can we make hackathons events for people to dip toes into ideas and concepts without having them need to be 'judged' for polish or ability to fully solve a problem?\n\nQuestions to think about:\n-   how do we continue projects beyond their initial timeframe\n-   should hackathons even focus on maintainable projects when they require so much context?\n-   what does \"hacking racism\" mean? what about social good hackathons in general? how realistic is it so try and solve some sort of large societal issue in the span of a few days?\n\n## Hackathons as co-optation ritual\n[Source: Hackathons as Co-optation Ritual: Socializing Workers and Institutionalizing Innovation in the “New” Economy](https://academicworks.cuny.edu/gc_pubs/490/)\n\n[Hackathons] reshape unpaid and precarious work. Writing code and building apps for free becomes an extraordinary opportunity, a ritual of ecstatic labour, and a collective imaginary for fictional expectations of innovation that benefits all.\n\nHackathons ask much of their participants but promise little in return. Why, then, have they become so popular?\n\nMany prototypes that are developed during hackathons, even winning projects, are not really usable.\n\n[Hackathons] translate the values of longstanding hacker subculture into new work norms... using rituals of play and pleasure to co-opt a wide range of talent into the service of corporations and the state without offering participants full-time jobs.\n\nCoding at hackathons as self-expolitation and self-investment... Motivation to participate in hackathons relies on complementary forms of social capital and emotional ties, from networking with potential employers and investors to interacting with old friends.\n\nQuasi-Orwellian precepts:\n1. Work is Play\n2. Exhaustion is Effervescent\n3. Precarity is Opportunity\n\nHacker Subculture -\u003e Work is Play\nInformal meetings and clubs of young amateur hackers were energized by the collaborative (and competitive) tinkering of a DIY ethic relating to 1960s [counter-culture](thoughts/From%20Counterculture%20to%20Cyberculture.md).\n\nHackathons are a multi-site mechanism for both \"manufacturing\" innovation and \"manufacturing consent\"\n\nThe hackathon acts a a multimodal platform for building social capital as well as facilitating and institutionalizing innovation. Yet the hackathon's corporate sponsors are front and center in control of the event.\n\nSponsors fuel the romance of digital innovation by appealing to hackers' apsiration to be multi-dimensional agents of chance. \"Doers, makers \u0026 disruptors,\" one announcement goes\n\nBalance of Recreation and Career\n\"[Hackathons] are also perfect for my creative spur. I work as a corporate consultant and sometimes miss the research thing, the building of things. Hackathons allow me to do this.\"\n\nSponsors don't really think hackathons are a good recruitment tool. Performance on a hackathon team doesn't give an adequate indication of ability to work on a \"real\" team.\n\nHackathons are more important for companies because they need to maintain their 'cool' profile.\n\n\n\n","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/hash-function":{"title":"Hash function","content":"\n\u003e A hash function is any function that can be used to map data of arbitrary size to fixed-size values.\n\n## Properties\n1. Order should matter, should be very unlikely for two messages two have a hash collision\n2. Examples of good hash functions\n\t1. MD5: compute a 128-bit message digest in a 4-step process\n\t2. SHA-1: US NIST standard, 160-bit digest\n\t3. SHA-256 and SHA-512 are more secure\n","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/hedonic-treadmill":{"title":"Hedonic Treadmill","content":"\nWhat does it mean to 'improve' if all we do is take the new baseline as just that -- a baseline? Everything relative to that baseline would be relatively the same.\n\n\u003e \"Improvement in my life — should I not desire it or should I not be in need of improvement? I really want to improve. But it’s precisely because I yearn for it that I’m afraid of remedies that are worse than the disease.\" (Van Gogh, 1879)\n\n## Table Selection\nFrom *[Table Selection](https://blog.nateliason.com/p/table-selection?curius=1577,1419)* by Nat Eliason\n\nIn poker, there's an important concept called \"table selection.\" Your success is not just determined by how good you are but also by the table you choose to play at. \n\nYou can't win as much money if you sit at a table with small blinds. You'll get cleaned out if you sit at a table with players much better than you. To have the best result, you need to find a table where the stakes are high enough to be worth playing and where you have a chance of winning against the other players. \n\nThe \"keeping up with the Joneses\" effect is a symptom of table selection. If you compare yourself to your neighbors or people who are \"near\" you in whatever you index your life on, you will find countless ways to make yourself feel insignificant or behind. ","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/hermeneutical-injustice":{"title":"Hermeneutical injustice","content":"\n\u003e The powerful tend to have appropriate understandings of their experiences ready to draw on as they make sense of their social experiences, whereas the powerless are more likely to find themselves having some social experiences through a glass darkly, with a best ill-fitting meanings to draw on in the effort to render them intelligible\n\n**Hermeneutical injustice** is a subcategory of [epistemic injustice](thoughts/epistemic%20injustice.md) wherein one has no labels/common terminology to describe or explain experiences to others. Historically has been applied in the context of exclusion of marginalized groups from activities which shape the [[thoughts/language|language]] we use.\n\nIdentity affects experience, and experience makes a difference in our judgment.\n\nHermeneutics is the theory and methodology of interpretation.\n\n\u003e It is the injustice of having some significant area of one's social experience obscured from collective understanding owing to a structural identity prejudice in the collective hermeneutical resource\n\nIt is always a form of powerlessness, whether structural or one-off. If one can simply *opt-out*, then it should not be considered hermeneutical injustice.\n\n\u003e \"the dominated live in a world **structured** by others for their purposes\" (emphasis added)\n\nThis quotes from Nancy Hartsock has at least 3 different readings of the meaning of the word structured\n1. Materially: social institutions and practices favour the powerful\n2. [[thoughts/ontology|Ontologically]]: the powerful constitute the social world\n3. [Epistemologically](thoughts/epistemology.md): the powerful have an unfair advantage in structuring collective social understandings\n\n## Willful Hermeneutical Ignorance\nIn *Relational Knowing and Epistemic Injustice: Toward a Theory of Willful Hermeneutical Ignorance* by GAILE POHLHAUS, JR.\n\nPositing that the sociality of the knower is epistemically significant\n1. Situatedness: the knower's social position draw their attention to particular aspects of the world.\n\t1. Note, not as simple as the claim that different experiences lead to different knowledge. Not as strong as the claim that social position leads to automatic knowledge\n\t2. Situations resulting from one's social positioning create common challenges that constitute part of the knower's lived experience and contribute to the context from which they approach the world\n2. Interdependence: epistemic resources are by nature collective\n\t1. Lynn Nelson: \"there are no 'immediate' experiences\" Instead, within any given situation, our experience \"is shaped and made possible by communal ways of organizing things, and *systems* of connected theories, methodologies, and practices\"\n\t2. Related: [[thoughts/language|language]] and [terminology](thoughts/terminology.md). Wittgenstein: \"a language that in principle could be understood by only one person would not be a language at all\"\n\nIt is important to note that being marginally situated leads not to \"different\" knowledge, but, as Harding has argued, to more *objective* knowledge (Harding 1991, 138-163)\n\nThe dominantly situated knower cannot step outside of her situatedness in order to experience the world as others do; however, she can learn to use epistemic resources developed from the experiences of marginalized knowers\n\nWillful hermeneutical ignorance: dominantly situated knower's continued engagement in the world while refusing to learn to use epistemic resources developed from marginalized situatedness\n\nThe marginalized knower possesses a sort of [double-consciousness](thoughts/double-consciousness.md).\n\n## PHIL240A Essay\n\n\u003e Compare and contrast Fricker's concept of hermeneutical injustice with Polhaus' concept of wilful hermeneutical ignorance. Illustrate with an example.\n\nHermeneutical injustice, as defined by Fricker, is the injustice of having a significant portion of one's social experience be ineffable to the collective understanding due to a lack of reliable hermeneutical resources through which to communicate the experience. This is *always* a form of powerlessness, whether structural or one-off -- it is not something that one can opt-out of being (otherwise, it should not be considered hermeneutical injustice). Fricker describes this as a thwarted epistemic agent who is not believed or cannot make sense of her world (Pohlhaus, 716), specifically due to hermeneutical marginalization: \"an unequal participation in meaning-generating practices pertaining to some areas of the social world that is the result of subordination in or exclusion from those practices\" (Fricker 2007, 153-54)\n\nWilful hermeneutical ignorance, on the other hand is a situation where dominantly situated knower continue engaging in the world while refusing to learn to use epistemic resources developed from knowers who are marginally situated. Specifically, wilful hermeneutical ignorance posits that the *sociality* of the marginally situated knower is epistemically significant through two forms 1) situatedness (the knower's social position draws their attention to particular aspects of the world) and 2) interdependence (epistemic resources are, by nature, collective). In the example given by Polhaus where she references the jurors in *To Kill a Mockingbird*, she declares that the \"jurors are culpable as since there is nothing forcing them to use faulty epistemic resources.\" Polhaus notes here that being marginally situated does not lead to \"different\" knowledge, but rather as Harding argued, actually more *objective* knowledge (Harding 1991, 138-163). The inferences that the juror *should* have drawn are unavailable to them because they use epistemic resources that distort how they experience the world and prevent them from rationally understanding how Robinson could have acted the way he did. The *wilful* part comes from the fact that while the dominantly situated knower cannot step outside of their situatedness, they *can* learn to use epistemic resources developed from the experiences of marginalized knowers (much like Atticus Finch does).\n\nWe examine the example the Fricker provides us in *Epistemic Injustice* as an example of hermeneutical injustice but not wilful hermeneutical ignorance. In this case study, the woman in question is Wendy Sanford who is dealing with post-partum depression around the loss of her son. Clearly, in the case provided, she was not aware of the term post-partum depression and had no way to describe this integral part of her social experience. However, upon learning this, it was a hermeneutical breakthrough for her -- as if a \"hermeneutical darkness that suddenly lifted from Wendy Sandford's mind\" which had prevented her from properly understanding her experience. Then, according to Fricker, before realizing the term for her depression, she was \"a thwarted epistemic agent who could not make sense of this aspect of her social experience\" which falls under hermeneutical injustice.\n\nHowever, it is *not* wilful hermeneutical injustice as there is no *other* that is being wilfully ignorant here. Wilful ignorance requires one party or the system to actively forgo good epistemic resources for faulty epistemic resources, which is not the case here. Clearly, Wendy tries to grasp for epistemic resources to explain her social experience through workshops on women's medical and sexual issues.\n\n\u003e In that one forty-five-minute period, I realized that what I'd been blaming myself for, and what my husband had blamed me for, wasn't my personal deficiency. It was a combination of physiological things and a real societal thing, isolation.","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/hierarchical-clustering":{"title":"Hierarchical Clustering","content":"\nHierarchical clustering produces a tree of clusterings\n- Each node in the tree splits the data into 2 or more clusters.\n- Much more information than using a fixed clustering.\n- Often have individual data points as leaves.\n\nOften applied in phylogenetics\n\n## Agglomerative Clustering (Bottom up)\nRequires a \"distance\" measure between two clusters.\n\nCluster distance measures\n1. Distance between closest members of $C_1$ and $C_2$. Also called single-link clustering: $\\min d(a,b), a \\in C_1, b \\in C_2$\n2. Distance between farthest members of $C_1$ and $C_2$. Also called complete-link clustering: $\\max d(a,b), a \\in C_1, b \\in C_2$\n3. Average distance between members of $C_1$ and $C_2$. Also called group average clustering: $\\frac{1}{|C_1||C_2|} \\sum_{a \\in C_1} \\sum_{b \\in C_2} d(a,b)$\n\n1. Starts with each point in its own cluster.\n2. Each step merges the two “closest” clusters.\n3. Stop with one big cluster that has all points.\n\nNaive implementation cost is $O(n^3d)$\n\n## Divisive Clustering (Top-down)\nStart with all examples in one cluster, then start dividing. (e.g., run [[thoughts/K-means]] on a cluster, then run again on resulting clusters)\n\n## Biclustering\nCluster the training examples and features. Helps to figure out the 'why' on why things are clustered together\n- Run clustering method on $X$\n- Run clustering method on $X^T$\n\nA **dendrogram** describes the hierarchy of clusters generated by the clustering methods.\n","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/human-centered-design":{"title":"Human Centered Design (HCD)","content":"\nWhat drives design?\n-  **technology-centered design**: building what we are able to build but risks leaving out challenges of real people\n-   **designer-centered design**: progress made by designer's intuition, imagining user\n-   **user-centered design**: incorporating users heavily into the desing process (e.g. [double-diamond design](thoughts/design%20requirements.md) and iterative design model)\n\nPutting human needs, capabilities, and ways of behaving first. This requires good understanding of human psychology, technology, and good communication (both person-to-person and person-to-machine).\n\n\u003e HCD principle is to avoid specifying the problem as long as possible but instead to iterate upon repeated approximations.\n\n### Importance of user involvement\nInvolving users helps with expectation management\n-   can see capabilities from an early stage\n-   understand better how it will affect their jobs/lives and why the features are designed that way\n\n### Discoverability\nWhen we interact with a product, we need to figure out how to work it. This means discovering what it does, how it works, and what operations are possible.\n\nThis is composed up of 5 fundamental psychological concepts which are the principles of interaction:\n1. **Affordances**:  signifies *what* action is possible. It is the relationship between the properties of an objects and the capabilities of the user that determine how the object could be used. For example, a chair affords (\"is for\") support and therefore affords sitting. If an affordance or anti-affordance cannot be perceived, some means of signaling its presence is required.\n2. **Signifiers**: signifies *where* actions should occur. A mark, sound, or perceivable indicator that communicates appropriate behaviour to a person. Can be a [desire paths](thoughts/desire%20paths.md), a push/pull label, etc. However, we shuld be aware that different cultures associate different meanings with different signifiers.\n3. **Constraints**: limits to the possible interactions with an object. For example, the different sized holes in a scissor suggests different numbers of fingers may fit in each hole and not any more.\n4. **Mappings**: relationship between the elements of two sets of things. For example, a mapping of light switches to light bulbs or the steering wheel to the direction of the wheels. Groupings and proximity are important principles from Gestalt psychology that can be used to map controls to function: related controls should be grouped together. \n5. **Feedback**: communicating the results of an action or some way of letting you know that the system is working on your request. Has to be a balance, little and poor feedback and too much feedback can also be unhelpful and annoying to users. Feedback is essential, but not when it gets in the way of other things, including a calm and relaxing environment.","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/human-computer-interaction":{"title":"Human Computer Interaction (HCI)","content":"\n\u003e Better HCI is better empathy\n\nWhat even is HCI?\n* The human-machine joint performance of tasks\n* Human-computer or human-human communication mediated by computers\n\nMany a clever invention has been termed ‘before its time’ because the inventor did not see how to build a transition from what was known and in use to what was new.\n\n3 main goals of HCI\n1. Designing\n2. Implementing\n3. Evaluating\n\nAs designers, we are **defining systems**, and implementing the structures that **create culture**. We have the responsibility to think about the world as a complicated, ethically fraught place. We are [designing interactions](thoughts/interaction%20design.md)\n\n_Always ask:_ who are my users, and what are their needs?\n\n## Concepts\n- [The Psychopathology of Everyday Things](thoughts/The%20Psychopathology%20of%20Everyday%20Things.md)\n- [Human Centered Design (HCD)](thoughts/human%20centered%20design.md)\n- [Design Requirements](thoughts/design%20requirements.md)\n- [Interaction Failures](thoughts/interaction%20failure.md)\n- [Design Goals](thoughts/design%20goals.md)\n- [User Involvement](thoughts/user%20involvement.md)\n- [Interviews and data recording](thoughts/interviews%20and%20data%20recording.md)\n- [Task-centered Design](thoughts/task%20centered%20design.md)\n- [Mental Models](thoughts/mental%20model.md)\n- [Prototyping](thoughts/prototyping.md)\n- [Page Layout](thoughts/page%20layout.md)","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/hyper-parameter-optimization":{"title":"Hyper-parameter Optimization","content":"\nHow do we efficiently find the  “best” hyper-parameters?\n\nMore complicated models have even more hyper-parameters. This makes searching all values expensive (increases over-fitting risk)\n\n\nSimplest approaches:\n- Exhaustive search: try all combinations among a fixed set of $\\sigma$ and $\\lambda$ values.\n- Random search: try random values\n- Stochastic local search: Generic global optimization methods (simulated annealing, genetic algorithms, and so on)\n- Coordinate search: Optimize one hyper-parameter at a time, keeping the others fixed. Repeatedly go through the hyper-parameters","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/hypertext":{"title":"Hypertext","content":"\nCoined by Ted Nelson in 1965 in \"Literary Machines\"\n\nHe envisioned a world where computers would enable people to write and publish in a new, nonlinear format, which he called **hypertext**.\n\nHypertext was \"nonsequential\" text, in which a reader was not constrained to read in any particular order, but could follow links and delve into the original document from a short quotation.\n\n## Xanadu\nHe also described a project called Xanadu, in which all the world's information could be published in hypertext. He had the dream of a utopian society in which all information could be shared among people who communicated as equals.\n\nHe struggled for years to find funding for his project, but success eluded him.","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/idea-list":{"title":"Idea List","content":"\n## Technical\n- markup any site with a webcrawler + yjs + tldraw\n\t- markupthis.site is not taken!!\n- WASM-based `npm` with [[thoughts/CID|CIDs]] distributed using a [[thoughts/Sloppy Hashing DHT]]\n- https://blog.adamant-lang.org/2019/rust-lifetime-visualization-ideas/ but with vim gutters and program slicing\n- rotmg but actually good lol\n\t- dodge mechanic\n\t- no instakill, should be iframes and way less health (similar to EtG)\n\t- keep soulbound mechanic\n\t- no screen rotation\n\t- multi-floor dungeons, take more inspo from roguelites\n\t- should have one free key a day\n\t- actual good graveyard mechanics to look at past runs/chars\n- latency based quorum sensing, similar to how bacteria release a particular molecule and behave differently if sensors of the molecule are particularly active\n\t- see also: [[thoughts/Sloppy Hashing DHT]]\n- something with https://openai.com/blog/whisper/\n- calvin and hobbes semantic image search\n- IPFS as a versioned package manager for all software\n- [webgpt](https://openai.com/blog/webgpt/) but its for tools for thought\n\t- \"A [reader-generated essay](https://escapingflatland.substack.com/p/reader-generated-essays) is what you get when you can go into someone else’s knowledge graph and make a linear journey through the network, while GPT-5 generates a just-in-time essay that is human-readable.\"\n\t- turning a graph traversal into a beautiful essay\n- a text experience where latency increases as more texts are sent\n- what does entropy + erosion of data look like\n\t- is they ways to make [[thoughts/cryptography|cryptography]] that are valid in time windows?\n- treesitter based CRDT for smart [[thoughts/git|git]] merges\n\t- https://www.wilfred.me.uk/blog/2022/09/06/difftastic-the-fantastic-diff/\n- big touchscreen desk\n\t- what if i just got a huge old flatscreen tv\n\t- mounted 4 pressure sensors on each corner and then got a big sheet of thin glass\n\t- 4 points is enough to pinpoint single-point touch accurately for dragging\n\t- what if you could use it like a scratch space? like an always available figjam/muse board that also supports linking and trails a la [[thoughts/tools for thought#Memex|memex]]\n\t\t- a vision of [communal computing](https://interconnected.org/home/2021/12/21/sage) perhaps\n\t\t- a shared screen which anyone can 'connect' to as an external display\n\t\t- anyone can drag windows/files to and from it\n- wave function collapse for poetry\n\t- bringing shape-shifting text to its most literal form\n\t- [https://oskarstalberg.com/Townscaper/](https://oskarstalberg.com/Townscaper/ \"https://oskarstalberg.com/Townscaper/\") for words\n\t- base representation is word vectors\n\t\t- you can jiggle word vectors around\n\t\t- apply transformations to vectors (e.g. the past tense vector)\n\t\t- some sort of 1d marching cubes which modifies a vector depending on context?\n\t\t\t- potentially transformer related\n\t- image \u003c-\u003e text interop using CLIP/unCLIP/DALL-E?\n- better search\n\t- searching through vectors\n\t\t- (no clue if this would work) integral images but applied to vector similarity search in text documents\n\t\t- viola-jones for text [[thoughts/latent-factor model|embeddings]]\n\t\t- https://github.com/facebookresearch/faiss\n\t- how do we encode sentences/paragraphs/documents as vectors?\n\t\t- https://beta.openai.com/docs/guides/embeddings/text-search-using-embeddings\n\t\t- https://github.com/ryankiros/skip-thoughts\n\t\t- https://github.com/pytorch/fairseq/tree/main/examples/data2vec\n- baba is you but for browser interactions\n\t-   data plane is main source of truth\n\t\t- optionally replicated using [[thoughts/Rhizome Proposal|Rhizome]]\n\t-   data inputs like webcam, keyboard, mouse, window size, etc.\n\t-   relations are from data plane → data plane (no functions!)\n\t\t- e.g. x bounces off of y\n\t-   rendering using canvas (higher performance games/interactions) or plain html elements (UI)\n- data provenance\n\t- https://www.cs.cmu.edu/~NatProg/whyline.html\n- how do we design better UI that reflects true application state?\n\t- https://www.scattered-thoughts.net/writing/relational-ui/\n\t- CRDTs as reducers over event-logs... that produce a view?\n- data lensing for databases\n\t- using https://www.inkandswitch.com/cambria/ maybe?\n\t- some cool [interoperability](thoughts/interoperability.md) things\n\t- CRDTs for databases? https://archive.jlongster.com/using-crdts-in-the-wild\n\t\t- https://cse.buffalo.edu/tech-reports/2014-04.pdf\n\t- distributed state\n- tools for thought applied to IDEs?\n\t- IDEs as graph editors?\n-  website inspo\n\t- fun interactions\n\t\t- https://victoiredouy.com/about\n\t\t- http://www.narrowdesign.com/\n\t\t- https://thebrowser.company/\n\t\t- http://lynnecarty.info/\n\t- misc\n\t\t- https://shapefarm.net/\n\t\t- https://www.epic.net/\n\t\t- https://kernel-mag.vercel.app/post/take-back-the-future\n\t\t- https://rauno.me/\n\t\t- https://www.thesolarmonk.com/posts/a-spacebar-for-the-web\n\t\t- https://linear.app/change\n\t- 3d\n\t\t- https://chartogne-taillet.com/en\n\t\t- http://richardmattka.com/prototypes/red-shift\n\t\t- https://ventureworks.io/\n\t\t- https://henryheffernan.com/\n-   LayoutLM + screenshots → auto-categorization of knowledge\n\t- https://screenotate.com/ but with atlas recall\n    -  maybe turn this into an app which auto-extracts semantic info from screenshots/images on webpages and does something w it idk\n    - how do we prevent https://twitter.com/rsnous/status/1130910375795277824\n-   Marginalia for the web? browser as a graph database, chronological browsing?\n    -   what if you could 3 finger swipe up on a browser to see what pages this page is connected to in a graph\n    -   and you could write on the margins of pages and share those with friends\n        -   a little annotated web\n-   location-based ephemeral social groups with zero-knowledge proofs on location\n    -   each location/city has a chat group which has a compound hash of all people in that location, derive only a boolean of whether a person is in a city or not without revealing exact location\n    -   when a person leaves/arrives at a city, city hash is updated\n- Conversational GPS\n  - why do we even look at a screen when we can just ask for directions as if it was a normal person lol\n- sound-based hashing for cryptographic verification\n- google photos + olo radio (see [attention economy](thoughts/attention%20economy.md))\n* web3 action-space exploration\n\t- chain crawlers indexing smart contracts → creating logical relations\n\t- prolog goal-first search? how can i prove that I can transmute resource A into resource B using relations on the network?\n\t- suggesting what you can do with existing resources in your wallet\n\t\t- over time, emergent best-practices develop (i.e. whats the most obvious thing to do after you buy BTC, what does this [NFT](thoughts/NFT.md) enable me to do?)\n* DreamCoder boolsat\n\t* Creating a LISP-like higher-order language to exploit reusable sub-proofs in specific domains (e.g. graph colouring)\n\t* kinda iffy on the sat problem solver using dreamcoder, not a lot of exploitable structure in the proofs (otherwise we'd have a more reliable human method)\n\t* Background:\n\t\t- https://en.wikipedia.org/wiki/Boolean_satisfiability_problem\n\t\t- https://searchworks.stanford.edu/view/13250178\n\t- NeuroSAT Paper:\n\t\t- https://arxiv.org/pdf/1802.03685.pdf\n\t- DreamCoder Paper:\n\t\t- https://arxiv.org/pdf/2006.08381.pdf\n\t\t- https://www.youtube.com/watch?v=qtu0aSTDE2I\n* Shale: the cloud-native scripting language\n\t* things to prioritize\n\t\t1. great tooling and extensibility\n\t\t\t1. static type hinting (great compile errors that detail relevant variables and possible fixes)\n\t\t\t2. full HTTP server and request engine\n\t\t\t3. compiles down to bytecode using LLVM (find some go/rust bindings for this)\n\t\t\t4. URL-based module imports\n\t\t2. easy to read code\n\t\t3. features u love\n\t\t\t1. pattern matching `match n { ... }`\n\t\t\t2. a block `a = { ... }` is just a zero-arg anon fn `a = () =\u003e { ... }`\n\t\t\t3. object and array destructuring (same as JS)\n\t\t\t4. option container\n\t\t\t\t1. built-in retry mechanisms on failure\n\t\t\t\t2. null coalescing for sensible defaults (converting `Option[Int]` to `Int` for example)\n\t\t\t5. function chaining (really just function composition) `123 -\u003e a -\u003e b` is equivalent to `b(a(123))`\n\t\t\t6. fat arrow fns `someFn = a =\u003e b`\n\t\t4. proper stderr for errors (works well with UNIX pipes, can also read STDIN using `input`)\n\t* notes on syntax\n\t\t1. function chaining using the pipe `-\u003e`\n\t\t2. fat arrow functions `=\u003e` return by default unless you include curly braces (then explicit return is required)\n\t\t3. type checking is OPTIONAL (using `::`)but if annotations are provided, will be caught at compile time (default type is `Unknown`)\n\t\t\t1. explicit casting can be done using the `as()` function\n\t\t\t2. can include `const` to prevent mutations\n* Better personal analytics\n\t* small js bundle\n\t* doesn't sell user data!!\n\t* things to track\n\t\t* rough location of each user\n\t\t* total users\n\t\t* user visit distribution vs time\n* living room\n\t* recreating [communal living spaces](/thoughts/communities) in digital space\n\t* [ephemerality](thoughts/ephemereal%20content.md) and [digital permanence](thoughts/digital%20permanence.md)\n- tabfs but for emails\n\t* [https://bazil.org/fuse/](https://bazil.org/fuse/)\n\t- [https://blog.gopheracademy.com/advent-2014/fuse-zipfs/](https://blog.gopheracademy.com/advent-2014/fuse-zipfs/)\n\t-   listen on any email server\n-  deep foveal VR rendering\n\n## Writing\n- Short stories/speculative fiction\n\t- [[thoughts/CID|CID]] as the library of babel\n\t- Interplanetary communication / state machine\n\t- Packet switched electricity\n\t- Cloud transport fiction\n\t\t- What if we lived in a world where water was incredibly scarce? People would pay huge amounts of money to ship clouds around and 'mine' them for their crops\n\t- saving sun for later\n\t\t- make something we take for granted extremely scarce\n- Poetry\n\t- We like sunset because it's the only time we see the cosmos move\n- Essays\n\t- Analog software: software by analogy and by atomic building blocks that interface with each other\n\t\t- We should be able to directly manipulate them, like files, rather than only indirectly work with them, like layer activations in a neural network.\n\t\t- Software representations for similar ideas should be obviously similar in some way – they should click together, or look similar, or feel similar to the touch.\n\t\t- Ideas should remember where they came from – what blog I copied it from, which author I quoted it from, and so on.\n\t- Good [[thoughts/search|search]] (aggregators) turns random networks into scale-free networks (see: [[thoughts/Network Theory|network theory]])\n\t\t- Servers are just clients that are located in a particular position in the network, and that are not the source of truth for any data; these nodes serve only to reduce latency in the system by replicating information.\n\t- essay on epistemic play + jestermaxxing + mill’s take on why censorship is unethical\n\t- limits to [[thoughts/Byzantine Faults|BFT]]\n\t\t- some malicious activity is indistinguishable from legitimate activity (e.g. deleting a document)\n\t\t\t- *semantic* byzantine fault tolerance vs protocol byzantine fault tolerance\n\t\t- Making distributed systems reliable is inherently impossible; we cling to Byzantine fault tolerance like Charlton Heston clings to his guns, hoping that a series of complex software protocols will somehow protect us from the oncoming storm of furious apes who have somehow learned how to wear pants and maliciously tamper with our network packets. (*[The Saddest Moment](https://scholar.harvard.edu/files/mickens/files/thesaddestmoment.pdf)* by James Mickens)\n\t\t- \"I have never had a real-life experience that resembled a Byzantine fault tolerant protocol.\"\n\t- against recipes\n\t\t-   recipes are for reproducibility, determinism → and thus fungibility\n\t\t-   bad for creatives? or anything that is high flux\n\t\t-   how does this differ for rules, traditions, social norms, algorithms\n\t\t-   redistributes the interestingness into the hands of a few\n\t\t\t- [[thoughts/Seeing like a State]]: similarly concentrates the autonomy and agency of decision making around city planning\n\t- life is different modes of seeing\n\t\t- what you see is what you get\n\t\t- As Thoreau wrote, “It’s not what you look at that matters, it’s what you see.”\n\t\t- [https://nicoles.substack.com/p/you-find-what-you-look-for](https://nicoles.substack.com/p/you-find-what-you-look-for)","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/idea-machine":{"title":"Idea machines","content":"\n[Post by Nadia Asparouhova (she got married!)](https://nadia.xyz/idea-machines)\n\n\u003e Idea Machine: a network of operators, thinkers, and funders, centered around an ideology, that’s designed to turn ideas into outcomes.\n\nRelated: [[thoughts/funding|funding]], [[thoughts/research institutions|research institutions]]\n\n**An Idea Machine is a self-sustaining organism that contains all the parts needed to turn ideas into outcomes:**\n- It starts with a distinct _ideology,_ which becomes a memetic engine that drives the formation of a _community_\n- The community’s members start generating ideas amongst themselves\n- Eventually, they form an _agenda_, which articulates how the ideology will be brought into the world. ([Communities need agendas](https://nayafia.substack.com/p/27-friend-groups) to become idea machines; otherwise, they’re just a group of likeminded people, without a directed purpose.)\n\t- Does agenda come first or ideas? I would think agenda first for more autocratic orgs and ideas for more [[thoughts/autopoiesis|autopoietic]] orgs\n- The agenda is capitalized by one or several major _funders_, whose presence ensures that the community’s ideas can move from theory to practice – both in terms of financing, as well as lending operational skills to the effort. (Without funding, an idea machine is just that: an inert system that needs fuel to turn the crank and get it moving.)\n\n![[thoughts/images/idea machine diagram.png]]\n\nIdea machines are different from _movements,_ which are focused on achieving a specific outcome and are therefore self-limiting (if they succeed, the movement winds down). On the other end of specificity, idea machines are less broad than _paradigm shifts,_ which are widespread, headless, decentralized shifts in cultural norms and attitudes due to changes in systemic conditions.\n\nDefinitions\n1. Ideology: a mimetic engine that drives the formation of a community\n2. Agenda: articulates how the ideology will be brought into the world\n3. Funders: presence ensures the community's ideas can move from theory to practice\n4. Scene builder: sustain the community, develop the agenda, attract new members\n5. Operators: driver operating initiatives which lead to real outcomes\n6. Support organizations: infrastructural organizations whose purpose is to strengthen the values and best practices of the idea machine","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/idealism":{"title":"Idealism","content":"\nEverything is in the mind. The intrinsic nature of ultimate reality is the mind.\n\n## Pratyabhijna Self-awareness\nOn [[thoughts/self-knowledge|Self-knowledge]]\n\nNondual Śaiva philosophical tradition concerned with articulating and defending the idea that everything is Śiva, as well as the practices that lead to this realization\n\nA form of Cosmopsychism which is in turn a form of [[thoughts/ontology|ontological]] idealism\n\n- Ultimate Reality (Śiva)\n\t- Consciousness as the infinite potential for any and all manifest worlds\n\t- Śiva is like a sculptor, a playwright, or a yogin because he spontaneously creates worlds from within himself\n- Conventional Reality\n\t- Embodied worlds created through exclusion\n\t- Manifests because the ultimate desires to experience itself in diverse  forms\n\t- When we imagine, for example, an elephant, our consciousness presents this object ('this') as distinct from our conscious selves ('I'). Despite this distinction, we know 'this' is only imagined and arises from [the self](thoughts/the%20Self.md).\n\t- Consciousness, when this happens, does not become the elephant, nor does it cease to exist as the 'I' when taking on the elephant's form, it simplify manifests itself as something distinct from the 'this'.\n\t- This plasticity is what the Śaivas call \"freedom\"\n- Internality is the reflective awareness 'I', externality is the reflective awareness 'this'\n\t- For objects perceived there are two kinds of externality\n\t\t1. Object of cognition through the external sense\n\t\t2. Object of cognition through the internal sense\n- No ontologically independent external objects\n\t- The internal self must have the notion or essence of object to manifest it as external (?)\n\t- Cannot infer the existence of something that has never been perceived \n\nHas many holes in its axioms but again presented here just to learn:\n1. Intrinsic Existence: consciousness must exist from its own intrinsic perspective, independent of external observers\n2. Composition: consciousness is structured and composed of multiple phenomenological distinctions (elementary or higher order)\n3. Information: consciousness is specific. Each experience is particular and uniquely distinct\n4. Integration: consciousness is unified. Each experience is irreducible and cannot be subdivided into non-interdependent disjoint subsets of phenomenal distinctions\n5. Exclusion: consciousness is definite -- it either has or does not have certain phenomenal distinctions\n\nArgument\n1. We observe causally specific differentiation in our everyday world\n2. Something that is causally specific must be the effect of a specific real cause\n3. Each real cause produces only the effects that are in accord with its nature\n4. Such causes must be either internal or external to consciousness\n5. These causes cannot be external to consciousness because, per Vasubandhu and Dharmakīrti, external objects are irrelevant and logically incoherent\n6. These causes therefore must be internal to consciousness\n7. It is not the nature of something undifferentiated to produce different effects\n8. Consciousness cannot be totally undifferentiated and produce different effects\n9. Consciousness must be inherently differentiated if it is to account for the differentiated awarenesses observed in the conventional world\n10. Since there is no other viable candidate for the cause of this differentiation, the nature of reality is ultimate consciousness that inherently contains the capacity for the expression of all differentiated awarenesses\n\n'Ill-taught' people satisfy themselves with conventional reality call it 'inert', failing to see it is a subset of Śiva. \"Only consciousness can present itself as precisely what it’s not while still remaining itself\"\n\n### The memory argument against Vijñānavādin Buddhists in Utpaladeva’s Pratyabhijñā Corpus\n1. Utpaladeva does not believe that awareness can become an object of another distinct awareness\n2. Memory involves an awareness-event being the object of another awareness-event\n3. Memory thus is impossible unless they're actually part of the same overall awareness (e.g. Śiva)","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/idempotence":{"title":"Idempotence","content":"\n\u003e How do we avoid cases where losing an ACK could lead to users doing an action multiple times (e.g. pressing the like button)?\n\nIdempotence!\n\n$f$ is idempotent if $f(x) = f(f(x))$\n\nFor example\n- Not idempotent: $f(likeCount) = likeCount + 1$\n- Idempotent: $f(likeSet) = likeSet \\cup \\{userID\\}$\n\nIdempotent requests can be retried **without deduplication**.\n\nHowever, this isn't perfect when there are other actors/actions that intermix. For example, $f(f(x))= f(x)$ but $f(g(f(x))) \\neq g(x)$ (e.g. liking, unliking, then liking is not the same as unliking!)\n\nTo somewhat fix this, use tombstones and record logical timestamp for when events happen\n- Then, we can reconcile replicas by propagating the record with the latest timestamp and discard the records with earlier timestamps\n- Then, to fix concurrent writes by different clients\n\t- Last writer wins (LWW): resolve conflicts using a [[thoughts/clocks|logical clock]] that gives total ordering (e.g. [[thoughts/clocks#Lamport Clocks|Lamport clock]]) \n\t- Multi-value register (give all options to let user/algorithm above resolve it): use a [[thoughts/clocks#Vector Clocks|Vector clock]], $v_2$ replaces $v_1$ if $t_2 \u003e t_1$; preserve both $\\{v_1, v_2\\}$ if $t_1 \\parallel t_2$\n\n","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/identity":{"title":"Identity","content":"\nSee also: [[thoughts/self-knowledge|self-knowledge]], [[thoughts/the Self|the self]] \n\n## On Website Redesigns\n\u003e There are endless possibilities as to what a website could be. What kind of room is a website? Or is a website more like a house? A boat? A cloud? A garden? A puddle?\n\u003e \n\u003e Whatever it is, there’s potential for a self-reflexive feedback loop: when you put energy into a website, in turn the website helps form your own identity.\" --[Laurel Schwulst](https://thecreativeindependent.com/essays/laurel-schwulst-my-website-is-a-shifting-house-next-to-a-river-of-knowledge-what-could-yours-be/)\n\nAbout every half a year, I get an intense urge to redesign my website. Some years I overhaul everything, ripping out the content and gutting the divs and p tags. Other years, I make only minor changes, giving it a fresh coat of paint and changing out old typography for new ones.\n\nI find it hard to place a finger on exactly why I feel this way. The colours, font spacing, and content -- they don't feel 'me'. How did something that used to feel so perfect and intimate feel so alien and off-kilter?\n\nOur digital artifacts and spaces are reflections of our real selves. We feel like we outgrow digital spaces just as we change, learn, and grow in real life.\n\nIn part, this is why I think having your own little plot on the internet to change and modify at your own whim is worth protecting. This is our last little bit of land in an era where we leave our wizardly powers to build worlds of our choosing at the door of digital giants.\n\n![[thoughts/images/call for hand made tech.png|500]]\n\n\u003e Think about it: there’s no way to make a web page or a blog that is not an act of playing with its form at the same time as you're creating its content. So it just seemed natural: the world was always telling me that you worked on those two things – the container and its contents – together. ([Robin Sloan on websites and notes](https://every.to/superorganizers/tasting-notes-with-robin-sloan-25629085))\n\nSee also: [[thoughts/cozy software|cozy software]]\n\n## Digital Legibility\nExtensions on [[posts/digital-identity|relational identity]]\n\n- identity constantly shifts in real life depending on who you are around\n- we try to approximate this using multiple accounts -\u003e prevent [[posts/context-collapse|context collapse]]\n- but identity shouldnt feel like different accounts you hop between different digital platforms\n- identity should be the principles of your experience -\u003e applicable across contexts\n- digital identity should enable novel interactions, not try to simplify existing ones\n- identity systems rely on the concentration of power in the hands of operators who cannot possibly be fully aligned (financially, socially, or morally) with all of their users—for example, private social media companies with diverse global audiences must often [make decisions](https://blog.twitter.com/en_us/topics/company/2020/suspension) about what constitutes an act of unjustified censorship versus an act in the interest of public safety, though they are often ill-equipped to do so\n\t- from 0xPARC on zk-identity\n","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/idolization":{"title":"On Idolization","content":"\n[Source: On Idolization by *Matthew Wang*](https://blog.matthewwang.me/life/concise21/2021/03/01/on-idolization.html)\n\n\"I struggled with this significantly in high school. I had the pleasure of working with some absolutely wonderful people. We debated together and against each other; ran conferences and events; did community service. I’d constantly rave about how insane, out of the world, and unbelievable they were. It was constant and nagging. It seeped into my personality.\"\n\n\"You implicitly invalidate any struggles they have, and eschew their private life. Your praise becomes so diluted that it’s meaningless, just another reflex or polite gesture.\"\n\n* Reinforcement of impostor syndrome\n* Recognizing that excessive praise (even if genuine) can be toxic positivity\n\t* Sets unrealistic boundaries for how people should act all the time -\u003e makes it hard for people to be truly vulnerable\n* How can we approach showing appreciation without being over-the-top about it?\n\t* acknowledging and normalizing failure -\u003e [failure resumes](posts/a-failure-resume.md)\n\t* creating safe spaces for vulnerable conversation as well as genuine celebration","lastmodified":"2023-02-15T01:38:21.241820877Z","tags":null},"/thoughts/imaging":{"title":"Imaging","content":"\n## Image Formation, Cameras, and Lenses\nImage formation depends on\n1. Lighting conditions\n2. Scene geometry\n3. Surface properties\n4. Camera optics\n5. Sensor properties\n\n### Image Processing Pipeline\nThe sequence of image processing operations applied by the camera's image signal processor (ISP) to convert a RAW image into a regular JPG/PNG.\n\n1. Lens\n2. CFA\n3. Analog Front-end -\u003e RAW image (mosaiced, linear, 12-bit)\n4. White balance\n5. CFA demoisaicing\n6. Denoising\n7. Colour transforms\n8. Tone reproduction\n9. Compression -\u003e final RGB image (non-linear, 8-bit)\n\n### Examples\n#### Reflection\nSurface reflection depends on viewing $(\\theta_v,\\phi_v)$ and illumination $(\\theta_i,\\phi_i)$ direction along with the Bidirectional Reflection Distribution Function: $BRDF(\\theta_v,\\phi_v,\\theta_i,\\phi_i) = \\frac{\\rho_d}{\\pi}$\n\nAll angles are spherical coordinates w.r.t. the normal line of the surface.\n\nA Lambertian (matte) surface is one which appears the same brightness from all directions. A mirror (specular) surface is one where all incident light is reflected in one direction $(\\theta_v,\\phi_v)=(\\theta_r,\\phi_r)$\n\n#### Cameras\n![Bare-sensor imaging](/thoughts/images/bare-sensor-imaging.png)*All scene points contribute to all sensor pixels*\n\nAs a result, the image is really blurry.\n\n![Pinhole camera](/thoughts/images/pinhole.png)*Pinhole camera*\n\nThe image here is flipped, but no longer blurry. Roughly, each scene point contributes to one sensor. Pinhole camera means you need to get the right size of pinhole. If the pinhole is too big, then many directions are averaged, blurring the image. If the pinhole is too small, then diffraction becomes a factor, also blurring the image.\n\nA few perspective 'tricks' arise out of the pinhole\n1. Size is inversely proportional to distance\n2. Parallel lines meet at a point (vanishing point on the horizon)\n\nSide note, pinhole cameras are really slow because only a small amount of light actually makes it through the pinhole. As a result, we have lenses\n\n#### Lenses\nThe role of a lens is to capture more light while preserving, as much as possible, the abstraction of an ideal pinhole camera, the thin lens equation\n\n$$\\frac{1}{z'} - \\frac{1}{z} = \\frac{1}{f}$$\n\nwhere $f$ is the focal point, $z'$ is the distance to the image plane, and $z$ is the distance to the object.\n\nFocal length can be thought of as the distance behind the lens where incoming rays parallel to the optical axis converge to a single point.\n\nDifferent effects can be explained using physics phenomena. Vignettes are simply light that reaches one lens but not the other in a compound lens. Chromatic aberration happens because the index of refraction depends on wavelength of the light so not all colours can be in equal focus.\n\nSimilarities with the human eye\n- pupil is analogous to the pinhole/aperture\n- retina is analogous to the film/digital sensor\n\n#### Weak Perspective\nOnly accurate when object is small/distant. Useful for recognition\n\n$$P = \\begin{bmatrix}x \\\\ y \\\\ z\\end{bmatrix} \\textrm{projects to a 2D image point} \\ P' = \\begin{bmatrix}x' \\\\ y'\\end{bmatrix} \\textrm{where} \\ m = \\frac{f'}{z_0}, x' = mx, y' = my$$\n\n\n#### Orthographic Projection\n\n$$P = \\begin{bmatrix}x \\\\ y \\\\ z\\end{bmatrix} \\textrm{projects to a 2D image point} \\ P' = \\begin{bmatrix}x' \\\\ y'\\end{bmatrix} \\textrm{where} \\ x' = x, y' = y$$\n\n#### Perspective Projection\n\n$$P = \\begin{bmatrix}x \\\\ y \\\\ z\\end{bmatrix} \\textrm{projects to a 2D image point} \\ P' = \\begin{bmatrix}x' \\\\ y'\\end{bmatrix} \\textrm{where} \\ m = \\frac{f'}{z_0}, x' = f'\\frac{x}{z}, y' = f'\\frac{y}{z}$$\n\n## Image as functions\n### Grayscale images\n2D function $I(x,y)$ where the domain is $(x,y) \\in ([1, width], [1, height])$ and the range is $I(x,y) \\in [0, 255] \\in \\mathbb{Z}$\n\n### Point Processing\nApply a single mathematical operation to each individual pixel\n\n## Linear Filters\nLet $I(x,y)$ be an $n \\times n$ digital image. Let $F(x,y)$ be the $m \\times m$ filter or kernel. For convenience, assume $m$ is odd and $m \u003c n$. Let $k = \\lfloor \\frac{m}{2} \\rfloor$, we call $k$ the half-width.\n\nFor a correlation, we then compute the new image $I'(x,y)$ as follows:\n$$I'(x,y) = \\sum_{j=-k}^k\\sum_{i=-k}^k F(i, j) I(x + i, y + j)$$\n\nFor a convolution, we then compute the new image $I'(x,y)$ as follows:\n$$I'(x,y) = \\sum_{j=-k}^k\\sum_{i=-k}^k F(i, j) I(x - i, y - j)$$\n\nA convolution is just the correlation with the filter rotated 180 degrees. We denote a convolution with the $\\otimes$ symbol.\n\nIn general,\n1. Correlation: measures similarity between two signals. In our case, this would mean similarity between a filter and an image patch it is being applied to\n2. Convolution: measures the effect one signal has on another signal\n\nEach pixel in the output image is a linear combination of the central pixel and its neighbouring pixels in the original image. This results in $m^2 \\times n^2$ computations. When $m \\approx n$, then this is a $\\mathcal{O}(n^4)$\n\nLow pass filters filter out high frequences, high pass filters filter out low frequencies.\n\n### Properties of Linear Filters\n1. Superposition: distributive law applies to convolution. Let $F_1$ and $F_2$ be digital filters. Then $$(F_1 + F_2) \\otimes I(x,y) = F_1 \\otimes I(x,y) + F_2 \\otimes I(x,y)$$\n2. Scaling. Let $F$ be a digital filter and let $k$ be a scalar. $$(kF) \\otimes I(x,y) = F \\otimes (kI(x,y)) = k(F \\otimes I(x,y))$$\n3. Shift invariance: output is local (doesn't depend on absolute position in image)\n\n**Characterization Theorem**: Any operation is linear if it satisfies both superposition and scaling. Any linear, shift-invariant operation can be expressed as a convolution.\n\n## Non-linear filters\n- Median Filter (take the median value of the pixels under the filter), effective at reducing certain kinds of noise, such as impulse noise ('salt and pepper' noise or 'shot' noise)\n- Bilateral Filter (edge-preserving filter). Effectively smooths out the image but keeps the sharp edges, good for denoising. Weights of neighbour at a spacial offset $(x,y)$ from the center pixel $I(X,Y)$ given by a product $\\exp^{-\\frac{x^2+y^2}{2\\sigma_d^2}}\\exp^{-\\frac{(I(X+x, Y+y) - I(X,Y))^2}{2\\sigma_r^2}}$. We call the first half of the product the *domain kernel* (which is essentially a Gaussian) and the second half the *range kernel* (which depends on location in the image).\n- ReLU. $x$ for all $x \u003e 0$, $0$ otherwise.\n\n## Sampling\nImages are a discrete (read: sampled) representation of a continuous world.\n\nAn image suggests a 2D surface which can be grayscale or colour. We note that in the continuous case that \n\n$i(x,y)$ is a real-valued function of real spatial variables, $x$ and $y$. It is bounded above and below, meaning $0 \\leq i(x,y) \\leq M$ where $M$ is the maximum brightness. It is bounded in extent, meaning that $x$ and $y$ do not span the entirety of the reals.\n\nImages can also be considered a function of time. Then, we write $i(x,y,t)$ where $t$ is the temporal variable. We can also explicitly state the dependence of brightness on wavelength explicit, $i(x,y,t,\\lambda)$ where $\\lambda$ is a spectral variable.\n\nWe denote the discrete image with a capital I as $I(x,y)$. So when we go from continuous to discrete, how do we sample?\n- Point sampling is useful for theoretical development\n- Area-based sampling occurs in practice\n\nWe also quantize the brightness into a finite number of equivalence classes. These values are called gray-levels\n\n$$I(x,y) \\implies \\lfloor \\frac{i(x,y)}{M} (2^n - 1) + 0.5\\rfloor$$\n\nTypically, $n=8$ giving us $0 \\leq n \\leq 256$\n\nIs it possible to recover $i(x,y)$ from $I(x,y)$? In the case when the continuous is equal to the discrete, this is possible (e.g. a completely flat image). However, if there is a discontinuouty that doesn't fall at a precise integer, we cannot recover the original continuous image.\n\nA bandlimit is the maximum *spatial frequency* of an image. The audio equivalent of this is audio frequency, the upper limit of human hearing is about 20kHz which is the human hearing bandlimit.\n\nAliasing is the idea that we don't have have enough samples to properly reconstruct the original signal so we construct a lower frequency (fidelity) version.\n\nWe can reduce aliasing artifacts by doing\n1. Oversampling: sample more than you think you need and average\n2. Smoothing before sampling: reduce image frequency\n\nThis creates funky patterns on discrete images called moire patterns. This happens in film too (temporal aliasing), this is why wheels sometimes look like they go backwards.\n\nThe fundamental result (Sampling Theorem): For bandlimited signals, if you sample regularly at or above twice the maximum frequency (called the Nyquist Rate), then you can reconstruct the original signal exactly.\n\n- Oversampling: nothing bad happens! Just wasted bits.\n- Undersampling: things are missing and there are artifacts (things that shouldn't be there)\n\n### Shrinking Images\nWe can't shrink an image simply by taking every second pixel\n\nArtifacts will appear:\n1. Small phenomena can look bigger (moire patterns in checkerboards and striped shirts)\n2. Fast phenomena can look slower (wagon wheels rolling the wrong way)\n\nWe can sub-sample by using Gaussian pre-filtering (Gaussian blur first then throw away every other column/row). Practically, for ever image reduction of a half, smooth by $\\sigma = 1$\n","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/in-group-bias":{"title":"In-group bias","content":"\n## Your Brain on Groups\nEzra Klein in *Why We're Polarized*\n\n\u003e The most important principle of the subjective social order we construct for ourselves is the classification of groups as 'we' and 'they'. Once someone has become a 'they' we are used to dismissing them, competing against them, discriminating against them even if there is no reason for it in terms of our own interests (Tajfel)\n\nHistorically, people have nurtured their prejudices as they believed they reflected reality -- we disliked those we disliked because we had reason to dislike them\n\n### Tajfel's Experiement\n- 64 boys between the age of 14 and 15 all from the same school knowing one another already\n- Sorted into two groups arbitrarily based off some previous shared experience (in this case, 'performance' on a dot estimation test)\n- Tajfel expected no intergroup behaviour as he wanted a baseline yet, even this test showed group identity taking hold and mutating into bias\n- In fact, far from behaviour showing a pure desire to maximize their group's gains, they often gave their group less to increase the difference between them and the out-group\n\nHuman beings evolved to exist in groups. To be part of a group and to see that group thrive meant survival. To be exiled from a group, or to see your group crushed by its enemies, could mean death. Is it really so strange that we evolved to feel the life-and-death stakes of group belonging and status?\n\nPolitics is a team sport\n- \"the behaviour of partisans resembles that of sports team members acting to preserve the status of their teams rather than thoughtful citizens participating in the political process for the broader good\"\n- When people spend endless hours volunteering, planting yard signs, writing checks, what is likely foremost in their minds is that they are furious with the opposing party and want intensely to avoid losing to it -- not a specific issue agenda\n- In *Open versus Closed*\n\t- The least-engaged voters tend to look at politics through the lens of material self-interest \"what will this policy do for me?\"\n\t- The most-engaged look at politics through the lens of identity \"what does support for this policy position say about me?\"\n- Our political identities are not our only identities: polarization is about which identities get activated\n\t- The problem with increasing polarization is that a single vote can now \"indicate a person's partisan perference as well as his or her religion, race, ethnicity, gender, neighbourhood, and favourite grocery story.\" This is no longer a single social identity, partisanship is now a mega-identity\n- Iyengar: \"Political identity is fair game for hatred. Racial identity is not. Gender identity is not.\"\n- Bipartisan cooperation is often necessary for governance but irrational for the minority party to offer\n\n## Ingroup/outgroup bias\n-   get social status points\n-   we will choose to identify with whatever in-group will immediately benefit us the most\n-   why sororities + frats are successful → sunk cost fallacy\n-   amount of boundaries required → well organized events vs serendipitous interactions\n\t-   do serendipitous interactions only come from [ephemereal content](thoughts/ephemereal%20content.md)?","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/incentives":{"title":"Incentives","content":"\nHow do we motivate people? Is [money](thoughts/money.md) effective as an incentive?\n\nHow do we prevent the [tragedy of the commons](thoughts/tragedy%20of%20the%20commons.md), help fund [public goods](thoughts/public%20goods.md), and incentivize [maintenance](thoughts/maintenance.md)?\n\nIn all honesty, I think that the only way to incentivize things is to pull at what intrinsically motivates them and to make what they do feel like [play](thoughts/play.md). Create spaces of local abundance for people to feel comfortable trying new things and enable [tribe flourishing](thoughts/tribe%20flourishing.md)\n\n### Libertarian Paternalism\nThe goal of encouraging the design of [organizing systems](thoughts/organizing%20system.md) and policies that maintain or increase freedom of choice but which at the same time influence people to make choices that they would judge as good ones\n\n","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/indeterminant":{"title":"Indeterminacy","content":"\n\u003e Anirvacanīyatva or indeterminancy\n\nVācaspati Miśra's *Bhāmatī*, a commentary on Śamkara's *Brahmasū-trabhāsya*.\n\nIn this chapter/section, objects of erroneous cognition are used to show how the world as it is experienced can neither be denied an independent status nor established as having one. The key idea is the 'indeterminate' state as to their ontological status.\n\nVācaspati does not doubt the correctness of the [Nyāya](thoughts/Nyāya.md) argument for [philosophical realism](thoughts/philosophical%20realism.md) but more so its completeness. I have cognition of a white horse, not of 'white' and of 'horse'. Vācaspati argues that the sum is greater than the whole -- it is not sufficient that a description of its constituent elements ('this' and 'silver') entirely constitute the unitary object of cognition ('this is silver').\n\n## Cognition-Object relationship\nThe cognition-object relationship here refers to one about [representational](thoughts/representation.md) content.\n\nRepresentation, in this context, means a cognitive state of being 'of' or 'about' the object. Important to note that, in this translation, representation is neutral to theories of perception\n\nExample case where a cognition (thought) is a thought of a specific object\n1. Object gives content (visayatā) to a cognition in the sense it is the subject of the thought and therefore individuates/gives identity to/specifies that cognition\n2. The cognition is then a representation (visayitā) of the object\n\nThe form usually is 'this thing is a shell' which is in the form of $F\\alpha$ where\n- $\\alpha$ is the object ('this thing', dharmin, qualificand, thing being distinguished)\n- $F$ is what it is cognised as (the concept, content of thought, dharma, the distinguisher)\n- Akin to the [Twin Earth Argument](thoughts/Twin%20Earth%20Argument.md), \"this\" can refer to different things\n\t- Like variable naming in programming languages where unification would not unify two 'this' from different scopes\n\n[[thoughts/ontology|Ontologies]] are theories of objects -- a conception of what the world is made up of. Ontologies need to be *interpreted*\n\n## Erroneous Cognition\n- A cognition is valid if it discriminates between that object and all others.\n- Discrimination is correct identification.\n- Erroneous cognition occurs when the subject takes it to be true when it is not.\n- Sublation is the incidence of a later cognition that results in the realization of an earlier cognition being erroneous.\n\nEpistemic indistinguishability: there is no perceived difference between contents of distinct cognitions (i.e. confusing 'this is shell' with 'this is silver')\n\nLet us take the simple perceptual demonstrative judgement of the form 'this is a piece of silver'. This can clearly be a wrong judgement as the relevant object could be a piece of shell.\n\nWhat does an erroneous cognition say about its object (if anything at all)?\n\nWell, this states that object and concept must *both* exist. Even in mistaking the shell of the silver, both shell (instantiated as physical demonstrated object) and silver (instantiated as primary object of cognition) exist. TLDR; erroneous cognition required determinate objects in the determinate world.\n\nThe state of taking 'this' to be silver is not explained simply by explaining that 'this' and 'silver' occur in it. Take for example, the non-erroneous cognition 'this looks like silver' which contains both constituent elements but is epistemically different from the earlier erroneous claim of 'this is silver'.\n\nSo how does an erroneous cognition $G\\alpha$ arise?\n1. Suppose the subject knows when the distinguisher $G$ is valid\n2. $G$ is not necessarily true given the conditions at hand may not be as remembered compared to the conditions under which $G$-identification was last true (temporally different).\n3. It is true that $G\\beta$ where $\\beta$ is a piece of silver at some point in the past\n4. It is true that $\\alpha$ exists\n5. It is false that $G\\alpha$\n6. It is false that $\\alpha$ is perceived as $\\beta$\nThe erroneous cognition arises when the subject believes 5 and 6 to be true instead.\n\nThe question then becomes, what is the object $\\alpha$ that is being individuated here?\n\nFirst, let $F$ and $G$ be incompatible (read: mutually exclusive) qualifiers. That is, if $F\\alpha$ then $\\lnot G\\alpha$ and vice versa.\n\nAdvaitin makes two contradictory conclusions here\n1. Utilizes P1: asserting that an object exists requires there to be a cognition with that object as its content through *pramānas*. Concludes that $G\\alpha$ cannot exist.\n2. Utilizes P2: what doesn't exist must not be the content of any cognition as it is not experienced as all. Concludes that $G\\alpha$ exists.\n\nBoth P1 and P2 rely on relevant (and fairly uncontroversial principles) to come to contradictory results. This argument shows that there is no way of assigning status to $G\\alpha$ and thus indeterminant.\n\n---\n\n## Essay\n\u003e Ram-Prasad summarizes Vācaspati's argument concerning indeterminacy as follows: \"while it is possible to determine the existential status of objects of cognition (and thereby determine the validity or invalidity of particular cognitions), it is indeterminate as to whether objects as a whole are, independently of particular cognitions of them, existent or not\" (118). Unpack this argument. You can focus on the material that Ram-Prasad covers in p. 113-118 (Section 7 and Section 8). Note that \"unpack\" here is just asking you to explain the argument. You don't have to give an evaluation of whether or not it's successful this time.\n\nLet us break this argument down into constituent parts and tackle them piece by piece. \n\nA: *It is possible to determine the existential status of objects of cognition*.\n\nWe first define some terminology. The cognition-object relationship here refers to one about representational content. Representation, in this context, means a cognitive state of being 'of' or 'about' the object. Ram-Prasad uses a specific notation to express these relations:\n- $\\alpha$ is the object of cognition ('this thing', qualificand, thing being distinguished)\n- $F$ is what it is cognised as (the concept, content of thought, the distinguisher)\nHere, Vācaspati does *not* disagree with [Nyāya](thoughts/Nyāya.md) in terms of recognizing objects of cognition as existing independently of consciousness.\n\nB: The second part posits that A implies the ability to *determine the validity or invalidity of particular cognitions.\n\nTo use more of Ram-Prasad's notation, let the object at at hand ('this') be $\\alpha$ and what it is cognised as ('silver') be $F$. The resulting cognition is of form $F\\alpha$. This resulting cognition is a demonstrative, grounded in reference to a \"spatio-temporally indexed object\" and is 'valid' until sublated by subsequent cognition.\n\nHowever, let us consider the 'invalid' case. Let us take the simple perceptual demonstrative judgement of the form 'this is a piece of silver'. This can clearly be a wrong judgement as the relevant object could be a piece of shell. In more formal terms, if the cognition is actually $G\\alpha$ (this is a piece of silver), then $F\\alpha$ would be invalid as each object is *uniquely* distinguished by its distinguisher.\n\nYet, even in mistaking the shell of the silver, both shell (instantiated as physical demonstrated object) and silver (instantiated as primary object of cognition) exist. Erroneous cognition still require determinate objects in the determinate world.\n\nC: Finally, the argument concludes that A and B combined do not allow us to conclude *whether objects as a whole are, independently of particular cognitions of them, existent or not*.\n\nFor this argument, Ram-Prasad refers to Advaitin's seemingly contradictory conclusions which arise from fairly uncontroversial principles (P1 and P2 in the text):\n1. Utilizes P1: asserting that an object exists requires there to be a cognition with that object as its content through *pramānas*. Eventually concludes that $G\\alpha$ cannot exist.\n2. Utilizes P2: what doesn't exist must not be the content of any cognition as it is not experienced as all. Eventually concludes that $G\\alpha$ exists.\nThis argument shows that there is no way of assigning status to $G\\alpha$ and thus the cognition is indeterminant.\n\nExtending this to the world, we use the differences between third and first person accounts of erroneous cognition. The distinguishing characteristic of third person accounts is that the third person's determination of what [[thoughts/causality|causal]] elements were involved in the erroneous cognition of the subject is true. However, this is not guaranteed to hold.\n\nA valid cognition is discriminating, but that is determined only by the judgement of another cognition. In a sense, every cognition requires a third-person account. Yet, we know that every third-person account itself is a first-person cognition merely presuming its validity, no independent judgement as to the truth of the original cognition is possible. We know that whether a cognition is veridical or erroneous is to show whether its object exists or not. As this cannot be done, Ram-Prasad concludes that the existence of the object as a whole is indeterminant.","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/inevitability-of-centralization":{"title":"Inevitability of Recentralization","content":"\nNotes on Gordon Brander's *[Decentralization enables permissionless innovation](https://subconscious.substack.com/p/decentralization-enables-permissionless)*, *[Centralization is Inevitable](https://subconscious.substack.com/p/centralization-is-inevitable)* and *[Redecentralization](https://subconscious.substack.com/p/redecentralization)*\n\nTo be efficient is to be fragile, and to be fragile, over the long run, is to go extinct.\n\n## Network Models\nSee also: [[thoughts/Network Theory|network theory]]\n\nIn 1959 RAND, a Californian think-tank, assigned Paul Baran, a young engineer at that time, to develop a communication system that can survive a Soviet nuclear attack.\n\nHe found that:\n1. The original centralized communication system is obviously vulnerable as the destruction of the hub would destroy communication between the end stations.\n2. The decentralized model, a \"hierarchical structure of a set of stars connected in the form of a larger star\", is also too centralized to be viable under attack\n3. The distributed model, where $k_{max} \\approx k_{min}$, each node has roughly the same number of connections to each other and there are no hubs in the network\n\n![[thoughts/images/decentralization.png]]\n*Baran, 1964 “[On Distributed Communications (Memorandum RM-3420-PR)](https://www.rand.org/pubs/research_memoranda/RM3420.html)“*\n\nBaran’s ideas were ignored by the military. The internet thus relied on distributed protocols that allowed each node to decide where to link, creating preferential attachment. This gave rise to a scale-free model of the [[thoughts/Internet|Internet]] rather than the original mesh-like topology that Baran imagined.\n\nWhile not the ideal distributed model Baran initially envisioned, the decentralized model that was actually implemented had several features that made it *adaptable* to failure. Routers could freely join or leave, something that wasn't possible in the [[thoughts/internet computing#Circuit Switching|circuit switching]] model of the internet.\n\nMessages would be broken up into little packets, and each packet would be independently routed to its destination, finding its own best path. Packets would be passed across the network like hot potatoes until they found their destination. This was the advent of [[thoughts/internet computing#Packet Switching|packet switching]].\n\nNow, it didn't matter if a router was destroyed because the network could dynamically route around the damage and new routers could be dropped in.\n\n## Inevitable Recentralization\nAlthough the underlying protocol layers of our web are decentralized, we see that centralization has re-emerged at the [[thoughts/Application Layer|Application Layer]]: one layer up.\n\nBut this centralization brings the same vulnerabilities that the centralized communication model brings that Baran designed to communication system to avoid. If AWS goes down, it takes much of the internet with it.\n\nToday, we see recentralization around\n- **Trust**: security, and thus identity and payments, are all bound to a given domain\n- **Data**: we have many 'hubs' for proprietary data like Google Drive, Facebook, etc. (see: [[posts/towards-data-neutrality|Towards Data Neutrality]])\n- **Infrastructure**: the actual server farms and cables the internet runs on (failures in companies like CloudFlare and AWS can lead to global disruptions)\n- **Attention**: too much information and not enough attention to give to things. This fundamental scarcity implies search, discovery, ads, spam, and a bunch of other thorny things. (see: [[thoughts/attention economy|attention economy]])\n\nBrander proposes a new rule of thumb:\n\n\u003e If you decentralize, the system will recentralize, but one layer up. Something new will be enabled by decentralization. That sounds like evolution through layering, like upward-spiraling complexity. That sounds like [[thoughts/progress|progress]] to me.\n\nWe see this with hubs on the internet forming, creating [[thoughts/Network Theory|scale-free networks]]. We see this pattern emerge over and over again: a solid sign that there are evolutionary attractors pulling the system in that direction. We know this is true due to the presence of network effects and preferential attachment (e.g. rich-get-richer, economies of scale, running servers is hard, etc.)\n\nThe presence of hubs in scale-free mean that communication can happen efficiently, averaging $\\log \\log N$ hops as opposed to $\\log N$ hops for random networks (see the [[thoughts/Network Theory#Distances in Networks|note on average hop distance in various networks]]). Fitter nodes attract more connections just by virtue of staying alive or being better. This is the Fitness Model of scale-free networks.\n\nBut the problem with scale-free networks is that **they are vulnerable to attack**. Though they are resilient to random failure of the nodes (generally need to remove $\\approx N - 1$ nodes to bring down the network), the removal of a small fraction of hubs is sufficient to break a scale-free network into tiny clusters.\n\n![[thoughts/images/scale-free under attack.png]]*Knocking out even a few hubs quickly breaks down the network. Y-axis is the ratio $\\frac{P_\\infty(f)}{P_\\infty(0)}$ provides the relative size of the largest connected subgraph*\n\nWhen a random shock inevitable causes the collapse of a few hubs, this creates a [[thoughts/cascading failures|cascading failure]] which causes a system-wide collapse. We return to an unstructured, random network.\n\nThe key insight is that this process has a direction, from decentralized to centralized, and collapsing back again.\n","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/information":{"title":"Information","content":"\n\u003e Information is a thing that conveys meaning about stuff, transmitted from one place to another.\n\n[Source: What is Library \u0026 Information Science? by *Stacks \u0026 Facts on YouTube*](https://www.youtube.com/watch?v=pfP7AjwIZI8)\n\nWe store, access, and organize information through [information systems](thoughts/information%20system.md).\n\nCharacteristics\n* Truthfulness: information is correct\n* Aboutness: tells us about something else\n* Thingness: information is a thing, although perhaps intangible\n\nThe study of information in and of itself is a research area too, through and the [Information Professions](thoughts/information%20professions.md)\n\n## Hierarchy\nIn informatics, there exists the concept of an Information Hierarchy, Knowledge Pyramid, or DIKW Hierarchy.\n\nData is transformed into Information, which is transformed into Knowledge, which is then transformed into Wisdom.\n\n\u003e Data is not god-like; it is not absolute truth. It is empathetic. It is imperfect. It is human. \n\n1. Data: raw or elementary observations about properties of objects, events, and their environment\n2. Information: data after aggregation, processing, analyzing, formatting, and organization to add meaning and context\n\n## Information is political\n[Source: Foundations of Information by *Amy J. Ko*](https://faculty.washington.edu/ajko/books/foundations-of-information/#/power)\n\nAs information becomes more abundant and saturated in our world, has information been any more of less important/necessary? We may have access to more of it, but it’s not obvious that this is better—just different.\n\n\u003e While technology has changed the volume, pace, and sources of information in our daily lives, it has not changed its essential power to shape our knowledge and our behavior in the world.\n\nInformation fuels discovery. It enables us to build off of each others work, and accomplish more than what a [single person could](posts/collaborative-thinking.md).\n\nInformation organizes us. The models of thinking and computation (e.g. numbering system) affect how we think about the world writ large and forms the basis for the computational systems which we interact with daily.\n\nInformation regulates us. The law, in its codified and written forms, encodes great injustices and inequities through dictating what rights are and who gets them.\n\nInformation identifies us. Each of us leave informational foot prints as we live our lives through documents, interactions, and conversations.\n\nContrary to Marshall McLuhan’s famous phrase, \"the medium is the message\", it seems as if the vast majority of the power from information is derived from its meaning and [context](thoughts/context.md) rather than its medium or method of transmission.\n\n\u003e Of what value is its microprocessor, its memory, and its applications if there is no content to consume and no people to connect with?\n\nAaron Swartz in the *“Guerrilla Open Access Manifesto”*\n\n\u003e Information is power. But like all power, there are those who want to keep it for themselves. The world’s entire scientific and cultural heritage, published over centuries in books and journals, is increasingly being digitized and locked up by a handful of private corporations. . . . Providing scientific articles to those at elite universities in the First World, but not to children in the Global South? It’s outrageous and unacceptable. . . . We can fight back. Those with access to these resources—students, librarians, scientists—you have been given a privilege. You get to feed at this banquet of knowledge while the rest of the world is locked out. But you need not—indeed, morally, you cannot—keep this privilege for yourselves. You have a duty to share it with the world.\n\n## Information [Representation](thoughts/representation.md)\nHow do we represent documents and information in our databases and collections?\n\nSee also: [[thoughts/visualization|visualization]]\n\n### Indexing\nIndex features\n- index term (textual description)\n- number of words (numerical, length description)\n- etc\n\nWhen indexing, we want to\n1. features that make document easy to find given some similarity measure between query and document (if a term is too broad, it would apply to too many documents)\n2. have high discriminatory power so different documents are sufficiently distinct\n\nSpecificity: degree to which a term is broad or narrow\n\n#### Automatic Indexing\nAutomatic indexing uses a set of algorithms to convert a document into a set of index terms.\n\n1. Tokenization (how do we turn text into tokens?). However, we need to be wary of edge cases like hyphenation, punctutation, abbreviations, numbers, etc.\n2. Stopword removal (removing words that occur very frequently but don't contribute very much to overall meaning of sentence). However, we need to be wary of creating new phrases that never existed and removal of entire phrases (e.g. 'to be or not to be')\n3. Conflation and stemming (recall enhancing technique that takes different forms of words and replaces them by a single form). Example stemmers include Porter and Krovetz stemmers (difference is that Krovetz is more conservative, only stems to words in a dictionary). However, this can reduce precision when stemming results in incorrect words.\n4. Term weights (which terms are the most important? One common approach is to use term frequency between documents -- sometimes called Document Frequency or DF. The larger the DF, the less useful it is to discriminate between two documents. Measure of importance then is the inverse document frequency. The most common measure is term frequency multiplied by inverse document frequency $TF \\times IDF$)\n\n### Catalog\nCatalogs allow for retrieval by simple matching whereby the user has an index term in mind and can then find all items that are indexed by that term.\n\nBy its nature, the catalog is divided, and the subject catalog is on its own. The classification scheme typically mirrors the scheme used to organize the physical items in the library.\n\ne.g.\n- Universal Decimal Classification (UDC)\n- Dewey Decimal Classification (DDC) \n- Library of Congress (LC)\n","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/information-behaviour":{"title":"Information Behaviour","content":"\nDistinction between information behaviour and information practice\n- Behaviour: how we search (e.g. type in a short query, click top result, etc.)\n- Practice: [search](thoughts/search.md) as conditioned by social and technical norms and practices\n\nA combination of [information retrieval](thoughts/information%20retrieval.md), information encountering, information avoidance, etc. Methods of interacting with [information](thoughts/information.md)\n\nA model is a simplified, tentative representation of a phenomenon of interest, often depicted as a graphic. A model describes important factors (variables) and proposes their relationships (associations).\n\n## Information Seeking Behaviour\n### Dervin's Sense-making Model\n![](/thoughts/images/dervin.png)\n\nKnowledge 'is the sense made at a particular point in time-space by someone'\n\nInformation seeking is conceptualized as a gap-bridging process in which the individual makes moves, influenced by information, in time and space to reach a desired outcome or goal to make sense of a ever-gappy 'reality'\n\nIn this model, an information object is not seen simply as an entity that meets or is relevant to an information need. Rather, information embedded in an information object must be conceptualized by the individual in a particular situation in order to influence actions.\n\n### Wilson's Information-seeking Model\n![](/thoughts/images/wilson.png)\n\nPerceived information need is bounded in a [context](thoughts/context.md) (column 1). This perceived need may not be enough if there isn't enough to activate actions if the stress isn't high enough (column 2). Intervening variables may become either barriers to or in support of information seeking activities (column 3). The actual activation mechanism itself is driven by social learning theory.\n\n8 main types of information activities\n1. Starting: initial info-gathering (e.g. searching or asking colleagues)\n2. Chaining: going down the rabbit-holes found in Starting\n3. Browsing: casual search for info in different sources (generally non-intentional)\n4. Differentiating: rough grouping and separating of different identities/origin of sources\n5. Monitoring: keeping updated with developments\n6. Extracting: finding relevant materials in source\n7. Verifying: making sure info is correct\n8. Ending: final search\n\n## 11 Deadliest Sins of Knowledge Management\nFahey and Prusak (1998)\n\n1. Not developing a working definition of knowledge.\n2. Emphasizing knowledge stock to the detriment of knowledge flow.\n3. Viewing knowledge as existing predominantly outside the heads of individuals.\n4. Not understanding that a fundamental intermediate purpose of managing knowledge is to create shared context.\n5. Paying little heed to the role and importance of tacit knowledge.\n6. Disentangling knowledge from its uses.\n7. Downplaying thinking and reasoning.\n8. Focussing on the past and the present and not the future.\n9. Failing to recognize the importance of experimentation.\n10. Substituting technical contact for human interface.\n11. Seeking to develop direct measures of knowledge.\n\n","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/information-foraging":{"title":"Information Foraging","content":"\nDeveloped at XEROX PARC in the late 1990s and was inspired by biomimicry (specifically, animal behaviour theories) \n\n||Animal Foraging|Information Foraging|\n|---|---|---|\n|Goal|Food|Information|\n|Patch|Site containing one or more potential sources for food|A source of information (e.g. website)|\n|Forage|Search for food|Search for information|\n|Scent|How likely a patch will provide food|How promising a source of information appear to user|\n|Diet|Totality of food types that can satisfy hunger for an animal|Totality of information sources that a user may consider useful|\n\n**Rate of gain = Information value / Cost associated with obtaining that information (both actual time/effort and opportunity cost)**\n\n[Bounded rationality is at play here](thoughts/rationality.md)\n\nObviously we don't have perfect estimation for 1) how much information a patch contains and 2) how much time it will take to extract that information. This is where info scent comes in.\n\nThings that contribute to scent:\n1. Perceived credibility\n2. Information density\n3. Length\n\n### Enrichment\nTechniques, tools, and interactions, that maximize the utility of the information foraging. This can happen either between patches or within patches.\n\n**But**, a good user experience involves web pages that are designed so that the user can get the maximum relevant information in the minimum amount of time.\n\nBehaviour enrichments\n- avoiding context switching ([page parking](https://www.nngroup.com/articles/multi-tab-page-parking/): opening multiple pages in rapid-fire succession to save them for later)\n- avoid reading the entire page but still getting the majority of information ([F-pattern scanning](https://www.nngroup.com/articles/f-shaped-pattern-reading-web-content/))\n- typically ignoring banners and the right rail\n\nInteraction enrichments\n- critically thinking about specific keywords for query\n- use of within-page search (ctrl-f) to quickly locate content","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/information-professions":{"title":"The Information Professions: Knowledge, memory, heritage","content":"\n[Source: The information professions: knowledge, memory, heritage by *Marcia Bates*](https://files.eric.ed.gov/fulltext/EJ1060508.pdf)\n\nThe traditional view of disciplines is that they lie on a spectrum where the study of arts and humanities (disciplines of the cultural record) lie on one end and mathematics and physical sciences on the other (the sciences of information). I'm not sure I fully agree with this, I think the pursuit of knowledge and truth in physical sciences ties very well with the pursuit of documentation within the cultural record and humanities. It would be more of a circle than a spectrum.\n\nBates proposes *meta-disciplines* which study the entire spectrum and how they fit together.\n\nExamples of these include information disciplines, communication/journalism, and education.\n\nThe fundamental engine of development of this field of information professions is need. \n\n\u003e Human beings want to retain informational resources, and, after a very short time, these resources collect at such a rate that some principles of selection, organization, etc., need to be brought to bear, in order for the resources to continue to be available for effective use.\n\n3 information flow lineages through the history of life on Earth\n1. Genetic, information about the history of life on Earth is literally encoded in your DNA\n2. Neural-cultural, information is passed down between generations through [[thoughts/language|language]], storytelling, and sharing\n3. Exosomatic, information is embedded into the world around us through [[thoughts/writing|writing]], digital systems, [desire paths](thoughts/desire%20paths.md), etc.\n4. Residue, trace/abandoned information degrading back into nature\n\n\u003e The storage and management of exosomatic information was one of the major contributors to the exponential growth of human knowledge and power over nature.\n\nRelated, [information transfer between and within generations](thoughts/A%20City%20is%20not%20a%20Computer.md)","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/information-retrieval":{"title":"Information Retrieval","content":"\n[Information foraging](thoughts/information%20foraging.md) as a metaphor for exploring information retrieval and seeking. Heavily tied to [search](thoughts/search.md) systems.\n\nA 'closed stack' library facilitates information transfer from collection to information seeker through some intermediary who controls access to said objects. 'Open stack' libraries often allow direct access to information objects (although sometimes with an intermediary's help). Both may utilize some ordering/index.\n\nThe goal of information seekers is to find information that are useful in answering the original query or research questions\n\nSystem Relevance is the measure or degree to which a document 'was about' a topic. This can be used to measure performance of an information retrieval system by seeing the extent to which the system was able to retrieve all the relevant documents in the collection to a query (recall: ratio of relevant documents retrieved to total relevant documents), and only the relevant documents (precision: ratio of relevant documents retrieved to all documents).\n\nHuman relevance is the degree to which the document is useful to the search query of the user. Composed of 3 separate facets\n1. Situational Relevance: useful, efficient, applicability to the task and situation\n2. Cognitive Relevance: suited to the knowledge level of the searcher; contains novel content of interest\n3. Affective Relevance: satisfies user goals and motivations, trustworthy, algns with beliefs and is emotionally engaging, aesthetics\n\nTypes of interactions then are\n1. Between information seeker and intermediary\n2. Between the intermediary and the collection\n3. Between the information seeker and the collection\n\nInformation retrieval has a whole slew of related terminology surrounding it:\n- Indexing (characterizing documents)\n- Retrieval (characterizing information seeker's information problem as a query put to the collection)\n- Information retrival system (combination of method to index, organization of the collection, and method of querying and searching the collection)\n\n## Cranfield/SMART Paradigm\nA 'test collection' is constructed, consisting of a collection of documents, a set of descriptions of information 'needs', and an exhaustive evaluation of the relevance of each document to each information need description.\n\nWhy it may be faulty:\n- relevance assessments are collected once for each information need for each document alone, without reference to any other document (most queries involve looking at multiple sources, relevance can depend on documents they have seen before)\n- evaluation is made of the performance of just the single query that represents each information need (queries are often iterative, you originally may not know what you don't know or what you are looking for)\n- model of the user on which the measures are based limits their appropriateness for other possible user goals\n\nThe dominance of the SMART (very technical and computational approach to information retrieval) means the research in the field of information retrieval was split into two disciplines: information retrieval (mainly CS/computational, study of formal models of information retrieval) and information seeking/use (mainly library/information science, study of people's information-seeking behaviours and uses of and interactions with information systems). As a result, 'interactiveness' was more of an afterthought and relegated to the peripheral.\n\n### Cranfield experiments\n#### Cranfield 1\nFeatured\n- Universal Decimal Classification (UDC): mostly empirically derived for what works best\n- Alphabetical\n- Faceted classification\n- Uniterm system of co-ordinate indexing (allowed boolean AND queries)\n\nIn failure analysis, only 1 in 20 failures were the result of the indexing systems themselves. Majority was human error in either the indexing, searching, or clerical processes of preparing the catalogues. Cleverdon then concluded what then must matter is the underlying document representation.\n\n## Early information retrieval systems\nMostly 'batch', non-interactive 'closed stack' systems.\n\n### Walker (1971)\n\u003e A key difference in interactive terminal search is that data is brought to the searcher rather than the searcher going to the data\n\nCreating an online system as an access point for databases. However, these information retrieval systems required substantial knowledge not only of the characteristics of the database and its indexing systems but also of the details of the query language, boolean algebra for effective queries, and effective techniques for modifying queries given search results. This resulted in a new class of librarians and information scientists -- search intermediaries -- well versed in this new form of information seeking.\n\n5 main filters to forming an effective query\n1. Determining the subject of the information query\n2. Determining the objective/motivation of information-seeking behaviour\n3. Determining the personal characteristics of the inquirer\n4. Establishing the relationship between the query description and the information system\n5. Determining anticipated/acceptable answers\n\nThe problem: most people don't actually know the thing they are searching for. \n\n### Savage-Knepshield and Belkin (1999)\nBennet was looking at some very important [HCI](thoughts/human%20computer%20interaction.md) considerations here, esp. w.r.t. the differences between human searcher and its automated counterpart. Asks some design questions to determine\n\n- characteristics of the searchers served by the facility\n- the conceptual framework presented to the searcher\n- the role of feedback to the searcher during searches\n- operational characteristics of the facility: the command language, display formats and response time\n- the constraints of the terminal and techniques to ameliorate them\n- the effects of the bibliographic database on the user interface for searchers\n- how to introduce the search facility to the user\n- the role of evaluation and feedback in the redesign cycle","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/information-scales":{"title":"Information Scales","content":"\nCreating a browsable store of knowledge that provides something useful at all distance scales (e.g. viewing the entire library, just a subcategory, a single file, etc.)\n- can we create skimmable views on data? see https://twitter.com/kirkbyo_/status/1475523898238197771\n\nCreate a spatially-anchored overview of the different 'branches' of knowledge\n\n## Engelbart Zoom\n*[Engelbart on HyperScope](https://dougengelbart.org/content/view/154/86/)*\n\n*Hyperscope is a browsing tool that enables most of the viewing and navigating features called for in Doug Engelbart's open hyperdocument system framework ([OHS](https://www.dougengelbart.org/about/ohs.html)) to support dynamic knowledge repositories*\n\n![[thoughts/images/hyperscope.png|300]]","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/information-scaling-threshold":{"title":"Information Scaling Threshold","content":"\n\u003e Throughout the Holocene, societies developed additional layers of administration and more information-rich instruments for managing and recording transactions and events as they grew in population and territory\n\u003e \n\u003e _(Shin, et al. 2020. [Scale and information-processing thresholds in Holocene social evolution](https://doi.org/10.1038/s41467-020-16035-9))_\n\nWhen a society hits this information threshold, it stops functioning until it can invent new ways to sense make with the new abundance of information. If they don't pull that transition off, they die.\n\nThe [[thoughts/attention economy]] is a symptom human society hitting this information scaling threshold. Philosopher Paul Tillich [posits](https://archive.org/details/couragetobe100till) that when social sensemaking fails to keep up with reality, we experience it as a kind of mass neurosis. Everybody has a crisis of meaning at the same time. Life stops making sense.\n\nWe've tried to cope through [[thoughts/Dunbar's Number|Dunbar-scale]] spaces and the [[thoughts/cozy software|cozy web]]\n\nMore in Gordon Brander's *[Thinking Together](https://subconscious.substack.com/p/thinking-together)*\n\nResearcher [Simon DeDeo](https://sites.santafe.edu/~simon/) considers it a phase transition in human culture, dividing history into [three eras](https://twitter.com/sfiscience/status/1552000134963073024):\n-   **The premodern/archaic era**, when most information was generated by non-human phenomena like seasons, weather, drought, flood, hail, lightning. “The gods”.\n-   **The modern/postmodern era**, when most information was broadcast by a small number of information “sellers”, and consumed by a large number of information “buyers”.\n-   **The user-generated content era**, where most information is produced/consumed by users, in a tight feedback loop between attention allocation and content production/consumption.","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/information-system":{"title":"Information Systems","content":"\n[Source: Foundations of Information\nby *Amy J. Ko*](https://faculty.washington.edu/ajko/books/foundations-of-information/#/systems)\n\nInformation Systems are processes that organize people, technology, and data to allow people to create, store, manipulate, distribute, and access information.\n\n**The Great Library of Alexandria** is one of the largest information systems in modern history. It was built in Alexandria, Egypt, and part of a larger research institution called the Mouseion. The idea behind the [library](thoughts/library.md) was to be a universal collection of knowledge.\n\nMany influential philosophers worked at the library in the 2nd and 3rd centuries BC, including Euclid (founder of geometry), Homer (author of epic Greek poems), Plato (founder of the first Western university), and Socrates (founder of Western moral philosophy).\n\nWhy build the ARPANET (precursor to the [Internet](thoughts/Internet.md))?\n1. Explore the area of computer networking research (how to share computing resources)\n2. Sharing resources for research communites (e.g. datasets)\n3. Scaling past the speed of the phoneline (2.4kb/s)\n4. Utility for command and control of various military sites (military-industrial complex)\n\n#### Qualities of information systems\n1. Accuracy: how accurate and truthful is data in the system?\n2. Reliability: how many dependencies does it need? How often do those fail?\n3. Learnability: how many skills do you need to acquire to use it?\n\n\u003e Choosing the best system for a particular task then isn’t just about choosing the latest technology, but carefully understanding the task at hand, and what types of systems might best support","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/infrastructure":{"title":"Infrastructure","content":"\nInfrastructure should be\n- Embedded: Infrastructure is \"sunk\" into, inside of, other structures, social arrangements and technologies\n- Transparent: Infrastructure is transparent to use, in the sense that it does not have to be reinvented each time or assembled for each task, but invisibly supports those tasks.\n- Reach/scope: This may be either spatial or temporal -- infrastructure has reach beyond a single event or one-site practice. Occurs across multiple places.\n- Learned: Strangers and outsiders encounter infrastructure as a target object to be learned about. New participants acquire a naturalized familiarity with its objects as they become members.\n- Links with conventions of practices: Infrastructure both shapes and is shaped by the conventions of a community of practice (e.g. the QWERTY keyboard).\n\n[Source: Steps Toward an Ecology of Infrastructure: Design and Access for Large Information Spaces by *Susan Leigh Star and Karen Ruhleder*](https://www.jstor.org/stable/23010792)\n\n## What is infrastructure even?\n-  which came first, the infrastructure or the applications that depend on it?\n\t- \"You can’t build railroads before it is railroad time. _(Chuck Thacker)_\"\n-   things that use infrastructure or technology\n    -   in the beginning not much of a distinction\n    -   first tech → [[thoughts/language|language]]\n        -   how did [[thoughts/language|language]] arise?\n        -   evolve with each other?\n        -   [language as infrastructure for thought](thoughts/language%20of%20thought.md)\n    -   at a certain complexity level, combinatorial explosion of complexity\n    -   does it grows as [emergent behaviour](thoughts/emergent%20behaviour.md)?\n-   is any infrastructure ever new?\n    -   is [everything derivative?](thoughts/originality.md)\n    -   is thought ever new? or is it recombinatorial\n        -   neuroplasticity of culture and language?\n- \"near-ubiquitous accessibility\" (Carter and Acker)\n- \"infrastructure as potential energy held in suspension\" (Boyer)\n\t- \"infrastructure as congealed labor and expertise, such that an electrical grid represents the entanglement and perpetuation of engineering expertise and also a history of materials science and manufacturing that make available substances such as steel, concrete, ceramic, and silicon\"\n- \"living mediation of what organizes life: the lifeworld of structure\" (Berlant)\n\nDo we need to [define infrastructure](https://www.bloomberg.com/opinion/articles/2021-04-09/the-meaning-of-infrastructure-is-a-pointless-debate)?\n\n\u003e Thus, infrastructure design requires a more subtle approach: **creating the right [incentives](thoughts/incentives.md), environments, and dependencies to encourage well-being while preserving user autonomy**.\n\nInfrastructure can be [emergent](thoughts/emergent%20behaviour.md)\n\n\"I have admiringly called this the \"Procrastination Principle,\" wherein an elegant network design would not be unduly complicated by attempts to solve every possible problem that one could imagine materializing in the future. We see the [principle at work](http://yupnet.org/zittrain/2008/03/01/chapter-6-the-lessons-of-wikipedia/#27) in Wikipedia, where the initial pitch for it would seem preposterous: 'We can generate a consummately thorough and mostly reliable encyclopedia by allowing anyone in the world to create a new page and anyone else in the world to drop by and revise it.'\"\n\n## Hard and soft infrastructure\nHard infrastructure refers to hard rules and goods (e.g. parks, laws, highways, etc.)\n\nSoft infrastructure is upheld as a social [protocol](thoughts/Protocol.md), an institution whose maintenance relies on dedication and value alignment. More closely related to [social contracts](thoughts/social%20contracts.md)\n\n## Post-destruction\n*To oblivion and beyond: Imagining infrastructure after collapse*\n\nAn alternate take on [creation vs maintenance](thoughts/creation%20vs%20maintenance.md)\n\nInfrastructures do not function forever. Like everything else, they lose in the universe's constant battle against entropy.\n\nAs Boyer (2016) argues, infrastructures possess a temporal persistence that “points deathward.” Oil refineries along the Texas Gulf Coast, for example, take part in a system of resource extraction that hastens climate change; at the same time, climate change threatens the continued functioning of these refineries, and oil companies have requested federal funds to protect their facilities from the destructive environmental phenomena that they have a hand in creating (Associated Press, 2018).\n\n- Cruel optimism: the experience of placing hope in an object that perpetually prevents the realization of that hope\n- Angry optimism: \"does not attempt to escape or control the dangers of the present or to return to the comforts of the past but instead looks forward to the possibilities of a time beyond these\"\n\nNot just maintenance, but rebuilding. In the context of infrastructure and collapse, cruel optimism is the belief that rebuilding is a way to heal. \"Breakdown might instead represent an opportunity to create futures that do not resemble the past.\"\n\nLifetime of an infrastructure doesn't just cover its functional lifespan. Many components to this:\n1. Service life (assuming ongoing maintenance, duration of functionality)\n\t1. Risk analysis and modelling is one way of calculating thius\n2. Material life (how long will it take for the material of the infrastructure itself to degrade and erode)\n\nIn fact, for the vast majority of infrastructures, the material life of an infrastructure will far outlast its service life (e.g. concrete aqueducts of the Romans almost 2000 years ago).\n\nRepair, they argue, is just an excuse for returning things to what they used to be rather than see it as a chance for change. Berlant's worry is that the repair of infrastructure merely reinstates a comfortable yet crisis producing past\n\nA new form of utopianism in science [fiction](thoughts/fiction.md): \"if present conditions lead inexorably to collapse, how can that collapse be used as a resource from which to build more equitable ways of life\"\n\n## Commons\n*The commons: Infrastructures for troubling times*\n\n\u003e The common usually refers to an orientation toward life and value unbound by concepts and divisions of property, and points to the world both as a finite resource that is running out and an inexhaustible fund of human consciousness or creativity\n\n*Sensus communis*: \"'common sense' is merely the bourgeois order of truth standing in for the universal, what Stoler calls ‘‘a folk [epistemology](thoughts/epistemology.md).’’\"","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/innovation":{"title":"Innovation","content":"\nInnovation: the word to hide the lack of substance. A term gains popularity because it resonates with the zeitgeist, reaches buzzword status, then suffers from overexposure and cooptation.\n\nIn formal economic terms, ‘innovation’ involves the diffusion of new things and practices. The term is completely agnostic about whether these things and practices are good. How much of this is tied back to the definition of [progress](thoughts/progress.md)?\n\n* Proved to be useful -\u003e innovations\n* Proved to be useful over 40 years -\u003e technology\n\n### Innovation as a form of maintenance?\nIs there even a distinction of [maintenance](thoughts/maintenance.md) and [innovation](thoughts/innovation.md)? Is maintenance just micro-innovation?\n\nMaintenance is fixing parts of an existing system whereas innovation is wholistic and changing the whole system\n","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/instrumentalism":{"title":"Instrumentalism","content":"\n[Source: Value Beyond Instrumentalization by *Jasmine Wang*](https://letterstoayoungtechnologist.com/Value-Beyond-Instrumentalization)\n\nReminiscent of the [move fast and break things](thoughts/move%20fast%20and%20break%20things.md) Silicon Valley ethic.\n\n\"This tendency to instrumentalize, or to treat something as a means or resource for achieving some end goal, shows up in the personal lives of many technologists. Many types of “fun” are made [telic](https://en.wikipedia.org/wiki/Reversal_theory#Serious/Playful_(Telic/Paratelic)).\"\n\n\u003e _“All that was good becomes data. All that was beautiful is now efficient.”_ (_Jacques Ellul, in The Technological Society_)\n\nAn inherent [quantization](thoughts/quantization.md) and optimization of everything. Prevalent in [recommendation systems](thoughts/recommendation%20system.md) where poor proxies are often the target of optimization that ignores the humans under them (e.g. engagement metrics rather than satisfaction and wellbeing). [Goodhart's Law](thoughts/Goodhart's%20Law.md)\n\n\"Creation of spaces of local abundance (as opposed to, say, a space like YCombinator, where the space is meant to help you reach a specific external outcome under time-bounded pressure) where technologists can [play](thoughts/play.md) with ideas and think freely, similar to parks and urban forests in a bustling city\"\n\n\u003e  Decide carefully what to pay attention to out of an infinity of possible ends to apply your time and resources, and what worlds you wish to bring about. This is a call to build a beautiful and deeply good future.","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/intellectual-property":{"title":"Intellectual Property","content":"\nAccording to the World Intellectual Property Organization, intellectual property \"refers to creations of the mind: inventions; literary and artistic works; and symbols, names and images used in commerce\"\n\nPerhaps can also be called intellectually monopoly\n\n## Property Rights\nProposed by John Locke\n\n- people have a right to property in their own person.\n- people have a right to their own labour\n- people have a right to those things that they have removed from Nature through their own labor\n\t- no person claims more property than he or she can use\n\t- when people remove something from the common state in order to make it their own property, there is still plenty left over for others to claim through their labor\n\n### Protections\n1. Trade Secret: intellectual property that provide a company with a competitive advantage\n\t1. They *do not* expire\n\t2. Not suitable for IP that needs to be viewed (e.g. a movie)\n\t3. Can be circumvented using reverse engineering\n2. Trademark: a word, symbol, picture, sound, or color used by a business to identify goods\n\t1. For establishing a \"brand name\"\n\t2. If the brand name becomes a common noun (e.g. yoyo, escalator) then the company loses it right to exclusive use\n3. Patent: limited period of time to machines, systems, and other inventions\n\t1. Provides a detailed description of the invention\n\t2. Lifetime is 20 years, after it expires, anyone has the right to make use of its ideas\n4. Copyright: protections for authors with certain rights to original works they have written\n\t1. The right to reproduce the copyrighted work  \n\t2. The right to distribute copies of the work to the public  \n\t3. The right to display copies of the work in public  \n\t4. The right to perform the work in public  \n\t5. The right to produce new works derived from the copyrighted work\n\n#### Software\nCopyright protects the original expression of an idea, not the idea itself\n\nCopyright usually protects the executable program, not the source program. Typically, the source code to a program is confidential, in other words, a trade secret of the enterprise that developed it.\n\nPatent-holding companies aggressively use the courts to enforce their patent rights; these companies are sometimes referred to by their detractors as patent trolls. The *Williamson v. Citrix Online* decision sets a precedent for other courts to strike down software patents that are determined to be “too broad and indefinite”\n\n## Limits to IP Protection\nThere is a tension between the need to reward the creators of intellectual property by giving them exclusive rights to their ideas and the need to disseminate these ideas as widely as possible.\n\nCongress addresses this by only granting exclusive rights for a limited period of time\n\n![[thoughts/images/copyright length.png]]\n\n## Fair Use\nExamples of fair use include citing short excerpts from copyrighted works for the purpose of teaching, scholarship, research, criticism, commentary, and news reporting.\n\n1. What is the purpose and character of the use?\n2. What is the nature of the work being copied?\n3. How much of the copyrighted work is being used?\n4. How will this use affect the market for the copyrighted work?\n\n## Digital rights management (DRM)\nFor protecting after-market IP\n\nDRM refers to any of a variety of actions owners of intellectual property may take to protect their rights. As Christopher May puts it, \"All DRM technologies are aimed at tracking and controlling the use of content once it has entered the market\"\n\nMany experts suggest that any technological \"fix\" to the problem of copyright abuse is bound to fail. All prior attempts to create encryption or anticopying schemes have been abandoned or circumvented.","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/intelligence":{"title":"Can Machines Think?","content":"\nIntelligence as a measure of information conversation ratio. How do we test intelligence of machines vs humans?\n\nIntelligence can only be contextually based on information available. There are no intrinsically difficult questions, only with respect to inputs\n\n## Can intelligence be artificial? (Dretske)\nThere are two ways of thinking about it\n1. Like money → everyone has, some have more than others\n\t-   philosophers view\n2. Like wealth → something possessed by only those who have more than the average amount of money\n\t-   computer scientists view\n\nThought alone is not enough, the thoughts need to do something, and sometimes explain the doing. Actions that are not governed by/explained by thought are not intelligent\n\n## Biological naturalism (Searle)\n[[thoughts/ontology|Ontologically]] equivalent to [[thoughts/Materialism|materialism]]\n\nTwo main theses:\n1.  all mental phenomena from pains, tickles, and itches to the most abstruse thoughts are caused by lower-level neurobiological processes in the brain\n2.  mental phenomena themselves are higher-level features of the brain\n\nEntails that the brain has the right [[thoughts/causality|causal]] powers to produce [intentionality](thoughts/intentionality.md)   \n-   weak AI → principle value of the computer in the study of the mind is that it gives us a very powerful tool\n-   strong AI → the appropriately programmed computer really IS a mind. Computers, given the right programs, can be literally said to understand and have other cognitive states\n-   attempting to refute the claims that\n    1.  the machine can literally be said to understand the story and provide the answers to questions\n    2.  what the machine and its programs do explains the human ability to understand the story and answer questions about it\n\nSearle's [Chinese room argument](thoughts/Chinese%20room%20argument.md) refuting the Turing Test as a valid means for measuring general intelligence.\n\n## Information Processing\n-   argument that rests on the ambiguity of what \"[information](thoughts/information.md)\" is\n-   construing information processing that implies [intentionality](thoughts/intentionality.md)\n\t-   programmed computer does not do information processes, it only manipulates formal symbols\n-   doesn't imply intentionality\n\t-   information transformation → taking info at one end, transforming it, and producing different information as output\n\t-   up to outside observers to interpret the input and output as information the ordinary sense\n-   strong AI only makes sense given the dualistic assumptions that, where the mind is concerned, the brain doesn't matter\n- what about [computability](thoughts/computability.md)?\n\n","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/intentional-arrangement":{"title":"Intentional Arrangement","content":"\nSource: [The Discipline of Organizing by *Glushko*](https://berkeley.pressbooks.pub/tdo4p/chapter/the-concept-of-intentional-arrangement/)\n\n\u003e explicit or implicit acts of organization by people, or by computational processes acting as proxies for, or as implementations of, human [intentionality](thoughts/intentionality.md)\n\nThe intentional arrangements of resources in an [organizing system](thoughts/organizing%20system.md) are the result of design decisions about what is organized, why it is organized, how much it is organized, when it is organized, and how or by whom it is organized.\n\nCan be created by top-down authoritative institutions like libraries, museums, businesses, and governments or bottom-up self-organizing systems composed of aggregated interactions of actors with resource or with each other.\n\nExamples of emergent organization are [desire paths](thoughts/desire%20paths.md), swarm intelligence in local interactions (e.g. ants, bees, fish, etc.), or crowdsourcing. rel: [emergent behaviour](thoughts/emergent%20behaviour.md)\n\nSimilarly, Adam Smith's \"invisible hand\" is another example where individuals collectively generate an outcome they did not directly intend but that arose from their separate self-interested actions as they respond to price signals in the marketplace. This is the basis of a lot of multi-agent system reasoning and economics.\n\nStandardization allows [interoperability](thoughts/interoperability.md) -- especially necessary for information systems that serve many people. No two people organize things the same way. No two people have the same requirements for the same information system.\n\nDesign questions/dimensional perspectives on the design of [organizing systems](thoughts/organizing%20system.md)\n\nMaintaining organizing systems with long expected lifetimes mean that incremental changes to description vocabularies and classification schemes need to happen over time -- even when the categories are not always explicit. (related: [digital-gardening](posts/digital-gardening.md))\n\n### Examples\n#### Enumeration\nPutting the resources into a set without any specification of any properties they might share. Only property that matters is that the resources are in the same set\n\n#### Collocation\nPutting resources in the same location without any additional organization. For a small collection, the proximity-to-use organizing principle is the easiest way to satisfy a requirement to minimize the time to find frequently used resources.\n\n","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/intentionality":{"title":"Intentionality","content":"\n- intentions exhibit cognitive inertia ([self-trust](thoughts/trust.md))\n-  intentionality is derived\n\t- same reason why computer-generated art or AI-assisted [[thoughts/writing|writing]] would not be considered 'novel' or 'intelligent'. The intentionality of the user is what gets injected.\n\t- These tool-assisted generation of artifacts are no more different than fancier pens and paint brushes.\n-  [Chinese room argument](thoughts/Chinese%20room%20argument.md) example tries to show that even programming something with intentionality (a person) with a format program, that formal program carries no additional intentionality\n-   How does intention change with time? Are my intentions in the past just as valid as my current intentions? ([source](https://kernel.community/en/learn/module-3/intention/))\n\t-   Smart contracts and blockchains try to permanently embed and codiy intentionality\n\t-   But, intentionality doesn't mean you can't change though. People aren't permanent, thoughts aren't permanent. Why should we try to make them so?\n\n## Dennet\n-   Based off of repeated behaviour rather than internal mechanisms\n-   This accepts [Brentano](thoughts/Brentano's%20Thesis.md)'s definition of the mental, but proposed materialist way to view intentionality (and intelligence)\n    1.  behaviour should be understood not in isolation but in context and as part of a consistent pattern of behaviour (holism)\n    2.  consistent pattern of behaviour in context can be construed as rational (interpretation)\n        1.  rational → acting so as to best satisfy your goals given what you know and can tell about your situation\n### Rabbit example\n-   We infer that a rabbit can tell a fox from another rabbit, always wanting to get away from the one but not the other\n-   Thus, on a given occasion, we attribute to the rabbit intentional states (beliefs and desires) about a particular fox, on the basis not only of its current behaviour but also of the pattern in its behaviour over time.\n","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/interaction-design":{"title":"Interaction Design","content":"\n[Source: A Brief Rant On The Future of Interaction Design by *Bret Victor*](http://worrydream.com/ABriefRantOnTheFutureOfInteractionDesign)\n\nTools address human needs by amplifying human capabilities. Great tools have parts that fit the problem as well as fit the person.\n\nWe need new mediums for exchange of ideas and active construction of thoughts ([crutch and shoe metaphor](thoughts/crutch%20and%20shoe%20metaphor.md)). Too much telecommunications work will eventually lead us to building crutches rather than shoes. Stop trying to remedy a perceived defect and instead focus on new functionality\n\n\u003e Go ahead and pick up a book. Open it up to some page. Notice how you _know_ where you are in the book by the distribution of weight in each hand, and the thickness of the page stacks between your fingers. Turn a page, and notice how you would _know_ if you grabbed two pages together, by how they would slip apart when you rub them against each other.\n\n\u003e Take a moment to pick up the objects around you. Use them as you normally would, and sense their tactile response — their texture, pliability, temperature; their distribution of weight; their edges, curves, and ridges; how they _respond_ in your hand as you use them.\n\nCurrent technology is very much just *Pictures Under Glass*. All interaction are glassy and feel like they have no connection with whatever task you were performing. Almost as if it was just under a pane of glass. List of interactions you can do with *Picture Under Glass*:\n\n1. Slide\n\nWhen working with our hands, touch does the driving, and vision helps out from the back seat. Moving our limbs and bodies is so well choreographed, its just [telerobotics](thoughts/telerobotics.md) for us. Why should we limit our interactions to a single finger or two? This quite literally just [interaction failure](thoughts/interaction%20failure.md)\n\n## Beyond Touch\n\n\u003e Humanity is using the dynamic medium merely to emulate and extend static representations from the era of paper.\n\nNew representations of thought — written [[thoughts/language|language]], numerals, mathematical notation, data graphics — have been responsible for some of the most significant leaps in the progress of civilization, by expanding humanity’s collectively-thinkable territory. Why then, have we been trapped using the desktop/paper metaphor for the last few centuries? Why have we essentially bottle-necked our [bandwidth](thoughts/bandwidth.md) for interaction design?\n\nTed Nelson, the guy who coined the terms [[thoughts/hypertext|hypertext]] and hypermedia, called the continued use of paper simulations as \"like tearing the wings off a 747 and driving it as a bus on a highway.\"\n\n\u003e And what about screens as a whole? Is the future of computation really just sliding fingers around slabs of glass? -- [Jason Yuan](https://uxdesign.cc/introducing-mercury-os-f4de45a04289)\n\n[Desktop metaphor](thoughts/desktop%20metaphor.md) was originally designed in 1973 to suit a very different need in computation—the need to mirror digital content with its physical equivalent (thus, the need for folders an documents)\n\nPremise of a lot of the work behind [DynamicLand](http://worrydream.com/cdg/ResearchAgenda-v0.19-poster.pdf) and [Jinha Lee](http://www.leejinha.com/home.html)\n\n\n## Computers in Friendlier Forms\nSource: [Omar Rizwan on Notion Blog](https://www.notion.so/blog/omar)\n\n\u003e If you have objects on your computer, you can have holographic projected versions of them on your desk and then you can suck them into physical objects if you want to physicalize them. Or you can turn them back into holographic objects if you have the physical object\n\nOn making things that are just toys:\n- I kind of want to make more things that are just toys where it's fun to interact with the thing, because I feel like that actually sets a very high bar, a game can be fun because it has a story or it has cool characters or there's a scoring system or something. But a toy, it has to be fun to [play](thoughts/play.md) with just because it's fun to play with just from the interactions themselves.\n\nOn physical analogues of software:\n- I think that they're all about trying to take stuff in the computer and give them some of the richness and texture and embodiment of things in the real world and scale also. Where everything on the computer is kind of pristine and closed and perfect and you can't touch it and it doesn't decay, and it all kind of fits in this 11 inch rectangle.\n\n## Modes of Human Communication\nBy upgrading forms of external communication, we can reduce [research debt](thoughts/research%20debt.md) and allow us to [collaborate](posts/collaborative-thinking.md) better\n\n### Conversing (person-to-person)\nFace-to-face, [ephemereal](thoughts/ephemereal%20content.md), improvised. As it stands today, most of this happens through spoken word, hand-waving, and static sketches. This makes grasping the same idea as another person extremely difficult (low [bandwidth](thoughts/bandwidth.md) communication)\n\n\u003e Words are terrible at representing systems\n\nCan we reduce the time to generate models for ideas down from hours to seconds? Is there any way we can integrate the stage into presentations (much like a play)?\n\n### Presenting (person-to-people)\nA lot of this is related to creating good [organizing systems](thoughts/organizing%20system.md)\n\nBlackboards are more flexible than a computer for presentations right now.\n\n\u003e What's the point of a living, dynamic speaker, if the presentation itself is completely static?\n\nCan we create the visuals of a well-polished science YouTube live like a blackboard?\n\nCan we map concept space to physical space and use the stage as an outline of the presentation? Kind of like a book where you can tell how much of it you're finished by the weight of each side, can the audience see what the presenter has already covered?\n\n### Reading/Browsing (media-to-person)\nCan we dynamically create content customizable/personalizable for each user? Are there other channels we can use for communicating information outside just text?\n\nGetting this right is critical for effective [knowledge distillation](thoughts/knowledge%20distillation.md)\n\nIs it possible to create dynamic spatial media? Virtual museums of information? Are there ways to engage with things other than the hands? Can we storytell as a way to ingest and interact with information?\n\n**The focus is on spatial representation of usable knowledge.**\n\nCan we create a [memory palace](thoughts/memory%20palace.md) for people to walk through to recall information and learn new information?\n\n### [Writing](thoughts/writing) (person-to-media)\nAs it stands, writing is just manipulation of symbols. Even for static materials, the symbols just are more literal representations. Coding still, is manipulating indirect [symbolic systems](thoughts/symbolic%20system.md) and [representations](thoughts/representation.md)\n\nCan we show multiple representations of dynamic behaviour? Can we transform between different representations easily?\n\nThe goal is to have manipulation of the behaviour and data itself rather than a structure or set of symbols that 'represents' that behaviour/data -\u003e related to the idea of turtles and the LOGO language in [Mindstorms](thoughts/Mindstorms.md)\n\n### Thinking (person-to-self)\nWhy are almost all representations used in intelletual work (both final product and intermediate scratch work) mostly 2D? Mostly paper or pixels\n\nCan we create dynamic tactile mediums?\n\n\u003e Playfair’s invention of data graphics was transformative because it tapped into capabilities of the human visual system which had gone unused in intellectual work. It may be similarly transformative to tap into the profound capabilities that enable a person to tie a shoelace or make a sandwich, and bring them to bear on more abstract thinking.\n\n## Webstrates\n[Source](https://pure.au.dk/portal/files/91047333/webstrates.pdf)\n\nIn the seventies, Alan Kay introduced the concept of Personal Dynamic Media that let a user “mold and channel its power to his own needs”\n\nTwo decades later, Mark Weiser envisioned a future of ubiquitous computing, where heterogenous devices of varying sizes and capabilities interact easily with each other and technology disappears into the background.\n\nSubstrates are software artifacts that embody content, computation and interaction, effectively blurring the distinction between documents and applications.\n\n## Cool Experiments\n1. https://www.robertxiao.ca/research/lumitrack/\n2. https://www.robertxiao.ca/research/desktopography/\n","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/interaction-failure":{"title":"Interaction Failures","content":"\nInteracting with interfaces is complex, and often poorly designed. Most times,\n1. The tasks are implicit and complex: the machine doesn't \"know\" the user's end goal\n2. Interaction is unpredictable and complex: coordination between human and machine is complicated, usage can be unexpected and evolved, users can change their minds\n\n### Interfaces\n1. Functionality Problem: what are the functions this object can perform? Will it do what I want?\n2. Visibility Problem: what mode is this object in? What sequence of controls do I use to get what I want?\n3. Negative Transfer: what would happen if I do what I usually do?\n\n### Designers\nCan fail to\n1. understand the range of users and their limitations\n2. understand contexts of use\n3. communicate what it does, how it works/worked, etc.\n4. start with basic usability needs, and might try to make it exciting or beautiful first\n\n### Market Pressures\nUser's don't always make good purchase choices\n1. Adding new functionality is relatively easy and cheap whereas adding effective controls/feedback is expensive and costly for time and space\n2. Designer time is expensive\n3. Some consumers value cost or looks over usability","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/interdependence":{"title":"Interdependence","content":"\n- Dependent Existence: for a flower to exist and for us to have experienced it requires the existence of many others. The gardener, the sun, the water, the minerals, the soil.\n\t- In cognitive science, concept of [connectionist representation](thoughts/representation.md)\n\t- In [emergent systems](thoughts/emergent%20behaviour.md), there is no 'conductor' there is only a symphony that interdepend on each other\n- Independent Existence: a separate existence. A flower cannot be by herself or have a self-nature (svabhāva).\n\n## On [friendship](thoughts/friendship.md)\n[From Ava on Substack](https://ava.substack.com/p/how-can-we-be-the-right-kind-of-together?s=r\u0026curius=1573)\n\n\u003e In order to change, I had to accept that other people aren’t fundamentally responsible for my emotional state. _I’m_ responsible for my emotional state. I think I’ve realized this most acutely through writing, which is so individual and painful—no one can really help me with it. It has to be self-generated. Other people can help you edit, and give you feedback, and read over your drafts, but it has to come from you. That’s how everything works, right? No one can help you self-actualize except you.","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/internet-computing":{"title":"Internet Computing","content":"\n*Notes for CPSC 317* [(see all notes)](/tags/CPSC317)\n\nThe [Internet](thoughts/Internet.md) is a network of networks. The main goals was to integrate a number of separately  \nadministrated entities into a common entity\n\nSee also: [peer-to-peer](thoughts/peer-to-peer.md), [[thoughts/security|security]]\n\n## Changing an entrenched internet \n[*Enabling a Permanent Revolution in Internet Architecture* by McCauley, Harchol, Panda, Raghavan, and Shenker](https://dl.acm.org/doi/pdf/10.1145/3341302.3342075)\n\nThe current Internet architecture is both inherently flawed (so we should explore radically different alternative designs) and deeply entrenched (so we should restrict ourselves to backwards-compatible and therefore incrementally deployable improvements).\n\nFor example, the decades-long migration effort from [[thoughts/IP Addresses|IPv4 to IPv6]]\n\nTLDR;\n1. Internet architecture is, and will remain, difficult to change -- clean-slate research and projects seem increasingly impossible\n2. Current focus is on backwards-compatible designs that have been tested in large-scale operational networks\n3. OSI model of the internet sees levels below them as 'logical pipes' to get something from place A to B\n\n## Communication\nNecessary conditions\n- A communication medium\n- Source(s) and destination(s)\n- [Protocol](thoughts/Protocol.md) ([[thoughts/language|language]])\n- Message\n\n### Circuit Switching\nDedicated path between source and destination. Path taken is determined when connection is established. Single stream of info per path\n\nWorks well when  \n- Guaranteed service is valuable  \n- Demand is steady (unchanging rate)  \n- Starting a new conversation is rare\n\n### Packet Switching\nData is divided in packets that are sent individually where each packet is self contained (contains source, destination, and data) and independently routed.\n\nWorks well when  \n- Statistically good performance is good enough\n- Demand is bursty (rapidly changing rate)\n- Starting a new conversation is frequent\n\n### Multiplexing\nMultiple input streams must share the medium. It must be possible to “demultiplex” at the destination\n\nTypes\n1. Time division multiplexing: each person gets a certain amount of time on the channel\n2. Frequency division multiplexing: each person gets a single frequency band on the channel\n3. Code division multiplexing: combines all messages using a specific code that can be decoded if code is known\n4. Orthogonal multiplexing: a combination of techniques\n\n## Network [Protocol](thoughts/Protocol.md) Stack (from most abstract to least)\nEach layer takes data from above adds header information to create new data unit passes new data unit to layer below\n\n1. [Application Layer](thoughts/Application%20Layer.md) ([HTTP](thoughts/HTTP.md))\n2. [Transport Layer](thoughts/Transport%20Layer.md) ([TCP](thoughts/TCP.md), [UDP](thoughts/UDP.md))\n3. [Network Layer](thoughts/Network%20Layer.md) ([IP Addresses](thoughts/IP%20Addresses.md)) -- this is the 'thinnest' part of the network stack!\n4. [Link Layer](thoughts/Link%20Layer.md)\n5. [Physical Layer](thoughts/Physical%20Layer.md)\n\n## Hubs, Switches, and Routers\n1. Hub - broadcasting through cloning bits ([physical layer](thoughts/Physical%20Layer.md))\n\t1. Simplest and cheapest way to create a network\n\t2. Lots of unnecessary traffic\n\t3. Other people can see your traffic\n2. Switch - hub but it knows where other hosts are for direct addressing ([link layer](thoughts/Link%20Layer.md))\n\t1. Keeps a switch table mapping interface number to MAC address\n\t2. If table is initially empty, will behave like a hub and broadcast\n\t3. Can start populating switch table based off of sender field from frames\n\t4. Quicker than a router for internal communication (though some routers have an Ethernet switch built in)\n\t5. If engineered right, can be full-duplex\n3. Router - glue that ties networks together ([network layer](thoughts/Network%20Layer.md))\n\t1. Does NOT support broadcast\n\t2. Serves as a bridge between private home network and the network of the internet provider (which can reach the rest of the internet)\n\t3. Modern routers can also perform\n\t\t1. Network address translation ([NAT](thoughts/NAT.md))\n\t\t2. Assigning [IP addresses](thoughts/IP%20Addresses.md) to hosts using [DHCP](thoughts/DHCP.md)\n\t\t3. Broadcast WiFi signal\n\n## Error Correction\nMethods for [fault tolerance](thoughts/fault%20tolerance.md) in data transmission\n1. Parity Bit\n\t1. Even parity is 1 if number of 1s is odd\n\t2. Can detect odd number of bit flips\n3. 2D Parity Bit\n\t1. Additional parity bits for each row\n\t2. Additional parity bits for each column\n\t4. One last additional bit in last row of parity bits\n5. Checksum\n\t1. Assume data is a sequence of 16-bit integers\n\t2. Addition, 1's complement sum, carry out added back in\n\t3. Checksum is the 1's complement of the computed value\n\t4. Compare with the received data (if same, it is ok)\n\t\t1. Alternatively, compute the same function over the data and checksum\n6. Cyclic Redundancy Check (CRC)\n\t1. Uses only XOR and shift\n\t2. Parameterized by constants G and r\n\t3. r + 1 is the length of G (some power of 2)\n\t4. G is the generator (arbitrary bit pattern)\n\t5. Sender wants to send D\n\t\t1. Chooses r CRC bits, R such that \u003cD, R\u003e is exactly divisible by G (mod 2)\n\t6. Receiver knows G, divides \u003cD, R\u003e by G. If the remainder is non-zero an error is detected!\n\t7. Can detect all burst errors less than $r+1$ bits, and burst errors greater than $r+1$ with probability $1-0.5^r$\n\n## Access Control\n1. Half-duplex - both sides can transmit, but only one at a time\n\t1. Carrier Sense Multiple Access\n\t\t1. Listen before sending, only send if no one else is\n\t2. Collision Detection\n\t\t1. While sending, listen to see if what you are sending is garbled\n\t\t2. If so, give up\n\t3. \"Try again later\" uses binary exponential backoff\n\t\t1. Random backoff between 0 and power of 2 (n increases each time)\n\t4. Turn-based [[thoughts/access control|access control]]\n\t\t1. Controlled by centralized party - polls everyone\n\t\t2. Controlled in a decentralized manner - passes a token between senders\n2. Full-duplex - both sides can transmit at the same time without interference/[NAT](thoughts/NAT.md)\n\n## Network Metrics / Peformance\n- Bandwidth: max rate at which data can be sent over a link, usually in bits per second\n\t- Measured in base 10, kilobit is $10^3$ bits, megabit is $10^6$ bits\n- Sizes: usually in bytes\n\t- Measured in base 2, kilobyte is $2^{10}$ bytes, megabyte is $2^{20}$ bytes\n\t- Except for disk managers, who use bits to make sizes look larger\n- Latency: how long is it from when something is sent to when it is received\n\t- Packet and bit/byte latency: measure start of sending packet/bit/byte to receiving it\n\t- Round trip time: time to send packet and receiving a response\n- Jitter: variation in latency -- interpacket variance\n- Throughput: amount of data moved from one place to another in a given time\n\t- Usually measured in bytes not bits\n\t- \n- Goodput: rate at which *useful* data arrives\n\t- Does not include headers, encoding costs, etc.\n\nDelay\n- Average Service Time: time taken to put the average packet on the wire\n\t- $S = \\textrm{Average packet size} \\times \\frac{8 bits/byte}{\\textrm{Bandwidth}}$\n- Processing Delay: figuring out where packet should go\n\t- Pretty much fixed (almost always variable due to cache hits, network queues, etc. but because of how negligible the times are, we can treat as fixed.)\n- Queueing Delay: waiting time to get access to a link\n\t- Variable\n\t- Increase over service time when idle\n\t- $\\textrm{Delay}_{\\textrm{Queueing}} = \\frac{S}{1-U} - S$ where $S$ is the average service time when no other requests and $U$ is the server utilization (usually traffic intensity)\n- Transmission Delay: time to write packet to medium\n\t- Fixed for bits, variable for packets (dependent on size)\n\t- $\\textrm{Delay}_{\\textrm{Transmission}} = \\frac{\\textrm{Message size} \\times 8 bits/byte}{\\textrm{Bandwidth}}$ for *each* segment (as each router needs to receive the entire packet before adding it to the queue)\n- Propagation Delay: time to move each bit over transmission medium\n\t- Fixed for meter, variable depending on actual length traveled\n\t- $\\textrm{Delay}_{\\textrm{Propagation}} = \\frac{\\textrm{Total distance}}{\\textrm{Link speed}}$\n- End-to-end Delay: sum of all sources of delay\n\nTraffic Intensity\n- Determined by\n\t- Number of packets arriving per second: $a$\n\t- Average packet size: $L$ in bits\n\t- Transmission rate: rate at which bits are disposed of per second: $R$\n- Traffic Intensity: $\\frac{La}{R}$\n\n## Sliding Window\n- When we allow multiple packets in flight, modelling this with a finite state machine is less than ideal\n- We can use a sliding window to represent the 'window' of all bits that are in flight\n\t- Although, better version of this is to just use a proper protocol like [TCP](thoughts/TCP.md)\n- Timeout: how much longer should I wait for the ack for the first packet in my window\n\n- Big window costs us memory\n- Smaller window is easier to reason about\n\n### Go-back-N\n### Receiver\n- When packet is received, send ACK for last packet received in order\n- Discard arriving packet if out of order (receiver window is 1)\n### Sender\n- Can have a specific number of outstanding (unacknowledged) packets in memory: sender's window\n- Start timer on first packet sent\n- On timeout go to last unack'ed packet and resend everything (restart timer)\n- Received ACKs may be cumulative (restart timer on receipt)\n\n[Simulation Link](https://media.pearsoncmg.com/aw/ecs_kurose_compnetwork_7/cw/content/interactiveanimations/go-back-n-protocol/index.html)\n\n### Selective-Repeat Strategy\n### Receiver\n- Each packet is ack'ed individually\n- Out of order packet is stored for later: receiver's window\n- If a packet arrives whose sequence number is too small to fit in the window it will be ACKed and dropped.\n- Only when a packet whose sequence number is too large to fit in the window will it not be ACKed; such packets will be silently dropped.\n### Sender\n- Can have a specific number of outstanding (unacknowledged) packets in memory: sender's window\n- Each packet has its own timer and is individually resent if timeout is reached\n- ACKs received in order move the sender's window\n\n\n[Simulation Link](https://media.pearsoncmg.com/aw/ecs_kurose_compnetwork_7/cw/content/interactiveanimations/selective-repeat-protocol/index.html)\n\nCongestion/Flow Control\n- As long as sender's window size is smaller than the receivers window size, it's fine\n- If the network can't handle a full window's worth of data (packets + ACKs are dropped by routers) then sender can reduce sending window\n- If all packets are ACKed, we can increase the window again (too slow! we can up the pace)\n- Receiver will notify the sender about how much data it can handle (usually included in the ACK)\n- If receiver runs out of space, sender will send a packet every once in a while even though its not supposed to just to check if it now has space\n\n","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/interoperability":{"title":"Interoperability","content":"\n\u003e Portability implies switching platforms, but true interoperability is platform-agnostic.\n\nI think interoperability in the context of the web means being able to transparently understand and share data, agnostic of platform. Closed platforms disallow this as they curate the information they present to end-users/devs rather than letting users control their own data.\n\nA good standard is if I can hit 'export all data' on a platform and I can completely and freely use that elsewhere -- no vendor lock-in. I think this is esp hard for [social graphs](thoughts/social%20graphs.md), there is no common/accepted standard for identity let alone connectedness between individuals\n\nRelated: [tools for thought](thoughts/tools%20for%20thought.md), [[thoughts/credible exit|credible exit]]\n\n## Noun-based Interoperability\nSource: [Riffle: Building data-centric apps with a reactive relational database](https://riffle.systems/essays/prelude/)\n\n\u003e Since the introduction of object-oriented programming, most interoperability has been “verb-based”: that is, based on having programs call into each other using APIs. Indeed, new programmers are often taught to hide data behind APIs as much as possible in order to encapsulate state. Unfortunately, [verb-based APIs create an unfortunate n-to-n problem](https://twitter.com/andy_matuschak/status/1452438198668328960): every app needs to know how to call the APIs of every other app. In contrast, data-based interoperability can use the shared data directly: once an app knows how to read a data format, it can read that data regardless of which app produced it.\n\nHow do we create sources of truth that are *legible outside of the application*, possibly in ways that the application developer never anticipated?\n\n(see: data lensing in [idea list](thoughts/idea%20list.md))\n\n## Beyond Windows\n[Source: Universal data portability by *Alexander Obenauer*](https://alexanderobenauer.com/labnotes/002/)\n\nA modern day [HyperCard](https://en.wikipedia.org/wiki/HyperCard). What other types of [interaction design](thoughts/interaction%20design.md) can we facilitate?\n\n\u003e A window runs a self-contained program, isolated from other programs that […] run at the same time in other windows. (Wikipedia)\n\nWindows and applications silo data. The only way to 'share' data between them is through the file system. What if applications exposed data by default?\n\nAn application then is a specific *view* on types of data rather than a standalone thing. Data can be dragged through different applications. Each data is annotated with a type. There is also a most common interface for data that allows basic-level interop with any application. We can then create an open marketplace for views on data.\n\nApps in this operating system then declare 'default' apps for certain data types.\n\nAbility to not only source local data but remote data too -\u003e fetching from URLs, feeds, etc. \n\nUNIX-level composability -- apps should be atomic building blocks. Creating pipeline apps to transform and massage data (possibly using Clay??). \n\nAuto-grouping of similar data? Set-theory for data?\n\n\"[Engelbart-inspired bootstrapping](https://www.dougengelbart.org/content/view/226/269/). A system with which you can, as a user, co-evolve both the tool and your methodologies simultaneously to build up better whole systems (those systems which include the human and the tool).\"\n\n### Semantic Data/Markers\nAuto-run scripts/data transformations to data.\n\nMarkers like 'today' that point to a new date every day. Auto generate a day-summary for the next day. etc.\n\n### Chronological Data Querying\nWhat data was created a few days ago? etc.\n\n## Adverserial Interoperability\n[Source: Adversarial Interoperability by *Cory Doctorow*](https://www.eff.org/deeplinks/2019/10/adversarial-interoperability)\n\n\u003e When you create a new product or service that plugs into the existing ones _without the permission_ of the companies that make them. Think of third-party printer ink, alternative app stores, or independent repair shops that use compatible parts from rival manufacturers to fix your car or your phone or your tractor.\n\n## Data Lenses\nSource: [Ink and Switch on Cambria](https://www.inkandswitch.com/cambria/)\n\nAn organization must balance their desire to change their API against their customers' reluctance to change something that works for them. The result is strong pressure to preserve backward compatibility over time, often across many versions.\n\nDevelopers rely on tribal knowledge to inform them which operations are safe—for example, they intuit that they can respond with additional data, trusting existing clients to ignore it, but not require additional data in requests, because existing clients won’t know to send it. Developers also often resort to shotgun parsing: scattering data checks and fallback values in various places throughout the system’s main logic. This can often lead not just to bugs, but also security vulnerabilities.\n\nHowever, in practice, most interoperability requires a tradeoff between\n- Consistency: both sides see a meaningfully equivalent view of the world\n- Conservation: neither side operates on data they can’t observe\n- Predictability: the local intent of every operation is preserved\n\n### Cambria\nOver time, a project using Cambria will accumulate many lenses, each describing the relationship between two versions. Migrations between distant versions are created by composing lenses into a graph where each node is a schema, and each edge is a lens. To translate data between two schemas, Cambria sends it through the shortest available path in the lens graph. These lenses must be kept in a place where even old versions of the program can retrieve them, such as in a database, at a well-known URL, or else as part of the document itself.\n\n![](https://www.inkandswitch.com/cambria/static/lens-graph.svg)\nCaveats:\n- Imagine a lens that combines a firstName and lastName fields into a single fullName. This lens works reliably in one direction. All names already stored in the system could be combined into a single field, but there are many names which could not be reliably converted back to “first” and “last” names. The result is a so-called lens that can only run reliably in one direction.","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/interpretive-labour":{"title":"Interpretive Labour","content":"\n## Interpretive Labour\nSource: [Research Debt in *Distill Pub*](https://distill.pub/2017/research-debt)\n\nThere is a tradeoff between energy put into explaining an idea, and the energy needed to understand it. This energy differential is called 'interpretive labour'\n\nMost research is one-to-many, where there are a lot more people trying to understand a subject than explaining it. As a result, the quality of explanations have an **outsized impact** for the better.\n\n![Interpretive Labour Multiplier](https://distill.pub/2017/research-debt/assets/publish-one-many-crop.jpg)\n\nCost of understanding increases when there are more source to try to understand. This may be why people specialize so that there is less noise. Related: [group limits](thoughts/group%20limits.md)","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/intersubjectivity":{"title":"Intersubjectivity","content":"\nRelated: [[thoughts/interdependence|interdependence]], [[thoughts/phenomenology|phenomenology]]\n\nSubjectivity is the perception or experience of reality from within one's own perspective\n\nEdmund Husserl: Intersubjectivity is most simply stated as the interchange of thoughts and feelings, both conscious and unconscious, between two persons or “subjects,” as facilitated by empathy","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/interval-scale":{"title":"Interval scale","content":"\nAny interval scale can be linearly transformed (ordinal transformation) between each other and not be affected\n\nAssign to each outcome $x$ a value $v(x)$ such that $v(x) \\geq v(y) \\iff x \\geq y$ and $v(x) = v(y) \\iff x \\sim y$\n\n## von Neumann-Morgenstern Theorem (vNM)\n\nWe need interval scales for most of the rules for [[thoughts/Decisions under ignorance|DUI]], and we need them for [[thoughts/Decisions under risk|DUR]]. vNM tells us how to construct an interval utility scale.\n\nWe find your utility for $x$ by measuring the risks that you are willing to take to get $x$. vNM shows that your utility for a lottery is equal to its expected utility.\n\n\u003e If your preferences have enough structure (i.e., if they satisfy the vNM conditions), then they can be represented by a utility function u (unique up to positive linear transformation) which has the expected utility property.\n\n### Lotteries\n- We have a set of basic prizes/outcomes\n- We can compose lotteries (if $L_1$ and $L_2$ are lotteries, then so is $[pL_1, (1-p)L_2]$)\n\t- This creates compound lotteries\n\n\n![[thoughts/images/vNM.png]]\n\nPeterson argues that vNM is ok for descriptive [[thoughts/Decision theory|decision theory]] but not normative decision theory (vNM does not distinguish the meaning of utility from the measurement of utility)\n\nNormative decision theory involves prescribing actions which needs a strong version of EU max: acts are rational because they maximize expected utility. This demands a concept of utility that is independent from the measurement of utility itself (or we get a circular argument)\n\n### Axioms\n1. vNM 1, Completeness: $A \\succ B$ or $A \\sim B$ or $B \\succ A$\n2. vNM 2, Transitivity: if $A \\succ B$ and $B \\succ C$ then $A \\succ C$\n3. vNM 3, Independence: $A \\succ B$ if and only if $ApC \\succ BpC$\n4. vNM 4, Continuity: if $A \\succ B \\succ C$ there $\\exists p, q$ such that $ApC \\succ B \\succ AqC$\n5. vNM 5, Probability: it does not matter if you are awarded prize A if you first roll a die and then roll it again, or make a double roll, provided that you only get the prize if you get two sixes\n\t1. If $pq + (1-p)r = s$ then $(AqB)p(ArB) \\sim AsB$","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/interviews-and-data-recording":{"title":"Interviews and Data Recording","content":"\n- What is data? Anything that is useful for understanding a particular design, user needs, and user behaviour.\n- What does it mean to collect user data? What techniques can be used, and how useful and reliable is the data that is collected?\n\nFive Key Issues\n1. Settings Goals. Goals will influence the nature of data gathering sessions, the data gathering techniques to be used, and the analysis to be performed.\n2. Identifying Participants. Those who fit the profile of types of people from whom data can be gathered are called the study population. Types of sampling are as follows:\n  - Probability Sampling: simple random sampling or stratified sampling\n  - Nonprobability Sampling: convenience sampling or volunteer panels\n    - Convenience Sampling: sample includes those who were available rather than those specifically selected\n3. Relationship with Participants: informed consent with a clear and professional relationship between participant and researcher (however, informed consent is generally not required when gathering requirements data for commercial company where a contract usually exist between collector and provider)\n\nTriangulation: the investigation of a phenomenon from at least two different perspectives. This is mostly focused on verification and reliability of data rather than making up for the limitations of another type of methodology\n1. Triangulation of data: data is drawn from different sources at different times/places/people\n2. Investigator triangulation: different researchers (observers, interviewers, and so on) have been involved in collecting and interpreting the data\n3. Triangulation of theories: use of different theoretical frameworks through which to view data\n4. Methodological triangulation: employ different data gathering techniques\n\n## 3 Methods for Data Recording\n1. Notes + Photographs -\u003e least technical and most flexible way of recording data, but can be difficult to capture the right highlights.\n2. Audio + Photographs -\u003e less intrusive than video, allows observers to focus on the activity rather than on trying to capture every spoken word.\n3. Video -\u003e highest fidelity. Things to keep in mind: 1) whether to fix cam position or use a roving recorder 2) where to point the camera 3) understanding the imapct of the recording on the participants\n\n## Interviews\n\u003e A conversation with a purpose\n\nGood for exploring issues, learning more about tasks, and getting inside user's head.\n\nCriteria for good interview:\n    -   Before:\n        -   get questions right → should support goals, should be easy to understand/answer\n        -   be organized → check equipment, have necessary docs\n        -   run pilots\n    -   During:\n        -   structure time\n        -   give participants context\n        -   use props and visuals → easier to show than tell\n    -   Listen well throughout!\n\n1. Open-ended/unstructured -\u003e exploratory and similar to conversation. Can be time-consuming but can also produce rich insights\n2. Semi-structured -\u003e plans basic script with both closed and open questions but probes interviewee until no new relevants info is there\n3. Structured -\u003e predetermined questions like a questionnaire, study is standardized (same questions with each participant)\n4. Group interviews -\u003e 3-10 people selected to provide a representative sample of the target population. Useful for investigating shared issues rather than individual experiences\n\nAsking questions like \"Can you tell me a bit more about...\" is called probing\n\n### Planning\nWhen developing Interview Questions, keep in mind open questions are best suited where the goal of the session is exploratory; closed questions are best suited where the possible answers are known in advance. Break long or compound questions into separate questions\n\nA lot of decisions to make:\n- Choosing a framework\n- Level of participation to adopt\n- How to make a record of the data\n- How to gain acceptance into the group being studied\n- How to ensure that the study uses difference perspectives\n\nEthnography: the description of the customs of people and cultures. A distinguishing feature of ethnographic studies compared with other data gathering is that a situation is observed without imposing any a priori structure or framework upon it, and everything is viewed as \"strange\".\n\n| Technique | Good for | Kind of Data | Advantages | Disadvantages |\n| --------- | -------- | ------------ | ---------- | ------------- |\n| Interviews | Exploring issues | Mostly qualitative (some quantitative) | Interviewer can guide, encourages contact between researchers and users | Artificial environment might be intimidating, remove them from usual environment |\n| Focus Groups | Collecting multiple viewpoints | Mostly qualitative (some quantitative) | Highlight areas of agreement/conflict, encourages contact between researchers and users | Possibility of dominant characters |\n| Questionnaires | Answering specific questions | Quantitative and Qualitative | Can reach many people with low resource requirements | Design is key, response rates may be low |\n| Direct observation in the field | Understanding context of user activity | Mostly qualitative | Observational insights | Very time-consuming, huge amounts of data |\n| Direct observation in a controlled environment | Captural detail of individuals | Quantitative and qualitative | User can focus on task without interruption | Data may be of limited use due to artificial environment |\n| Indirect observation | Observing users in natural environment without distraction | Quantitative (logging) and qualitative (diary) | Can be long due to automative recording | Large amounts of data implies need for tools to support analysis, participants may exaggerate memories |\n\n### Running the interview\nBefore starting, make sure that the goals of the interview have been explained to the interviewee and that they are willing to proceed. Listen more than talk, repond with sympathy but without bias, and to appear to enjoy the interview.\n\n1.  **Intro**\n    -   interviewer introduces themselves\n    -   explain why you're doing the interview\n    -   reassure interviewee re: ethical issues\n    -   ask interviewee if they mind being recorded\n2.  **Warm-up session**\n    -   easy, nonthreatening questions\n3.  **Main session**\n    -   questions presented in logical sequence\n    -   probing questions at the end\n    -   order may vary in semi-structured interview\n4.  **Cooling-off period**\n    -   easy questions to defuse any tension\n5.  **Closing session**\n    -   interviewer thanks interviewee\n    -   switch off recorder or put notebook away\n\n## Observation\nUsers may be observed directly by the investigator as they perform their activities or indirectly through records of the activity that are studied afterward.\n\nObservation can also result in a lot of data to sift through and can be complicated to do well than at firs appreciated. As such, a clearly stated goal is important to have focus for an observation session.\n\nExample frameworks:\n- The person: Who is using the technology at any particular time?\n- The place: Where are they using it?\n- The thing: What are they doing with it?\n\n3 common approaches\n1. Simple observation: user is given a task, the evaluator just watches. This gives no insight into users' decision process\n2. Think aloud: subjects asked to say what they are thinking/doing. However, its hard to talk while concentrating and thinking may alter the way people naturally perform the task.\n3. Co-discovery learning: two people work together on a task and normal conversation is monitored.\n\n### Degree of Participation\n1. Passive Observer: observer who adopts an approach at the outsider end; does not take part in the study environment at all\n2. Participant Observer: adopts an approach at the insider end; becomes a member of the group being studied\n\n### Coding Sheet\n\u003e A data recording instrument in which a list of itemized coding options are structured\n\nThis standardizes observation practices which makes it more objective.\n\nConsider:\n-   evaluation goals (break it all down!)\n-   stage of design\n-   observation method/types of data\n\t-   what would potentially be an interesting finding from this particular style?\n\t-   e.g. for think-aloud, it might be good to record action vs spoken comments\n\n## Questionnaire\nSurvey vs Questionnaire: the questionnaire is a *part* of the survey. The questionnaire is just the concrete things you're asking.\n\nPros\n-   cheap\n-   does not require presence of evaluator\n-   many results can be quantified\n\nCons\n-   preparation is \"expensive\" → need to design questions well\n-   can have low response rate or low quality response\n-   difficult to do in-depth \"probing\"\n\nA questionnaire is good when motivation is high enough without anyone else present. If persuasion is needed, a structured interview is probably better\n\n### Designing a Questionnaire\nKeep in mind\n- what info is sought?\n- how would you analyze results?\n- what audience do you want to reach?\n- what will you do with your analysis?\n\nDon't use vague questions, pilot the questionnaire before testing.\n\nQuestions\n- should not be transferable to other interfaces, can't be interpreted in different ways depending on judgment (i.e. domain specific and clear wording)\n-  avoid double-barreled questions and leading questions\n-  to de-bias: neutral language, can have random order of questions for different participants\n-  for validity\n\t-  use previously validated questionnaires\n\t-  triangulation (ask multiple questions about the same matter)\n\t-  piloting\n\n#### Types of questions\n- Open-ended (hard to analyze rigorously)\n- Closed (easily analyzed but can be hard to interpret if not well-designed)\n\t-  checkboxes and ranges\n\t\t-   range of answers to demo questions is predictable: offer a predefined list\n\t\t-   interval doesn't have to be equal in all cases, depends on what you want to know\n\t\t-   mention how many boxes to check, be consistent with ascending/descending order\n\t-   Likert and semantic differential scale\n\t\t-   used for measuring opinions, attitudes, and beliefs\n\t\t-   widely used for evaluating user satisfaction\n\t\t-   Likert: a five, seven, or nine-point agreement scale used to measure respondents' agreement with various statements\n\t\t-   semantic differential scale: rely on choosing pairs of adjectives to explore a range of bipolar attitudes about particular opinions\n\t-   ranked (closed)\n\t\t-   respondent places ordering on items in a list\n\t\t-   useful to indicate preferences\n\t\t-   forced choice\n\t-   multi-choice (closed)\n\t\t-   offered choice of explicit responses\n\nChecklist\n-   think about ordering of questions → impact can be influenced by order\n-   consider if different versions are needed for different populations\n-   provide clear instructions on how to complete questionnaire\n    -   eg. if answers can be saved and completed later\n-   think about length → avoid questions that don't address study goals\n-   consider allowing respondents to opt out at different stages especially if long → better to have some than none\n-   think about layout and pacing\n\n## Data and Analysis\n- Subjective: what you were told what happened\n- Objective: what you captured using your senses\n- Quantitative: data in the form of numbers or data that can be easily translated into numbers. Focuses on ascertain magnitude, amount, or size of something\n- Qualitative: data in the form of words and images. Focuses on nature of something (themes, patterns, and stories)\n\nNote that quantitative data is not always objective! Subjectivity can come from participants in how they express opinions or from investigators during the data capturing/interpreting/analysis process.\n\nSimilarly, it is unfair to try to [quantize](thoughts/quantization.md) all qualitative data. This needs justification. Also be wary of translating small populatino sizes into percentages.\n\n### What to focus on\n1. What are the most important needs/tasks to support?\n2. What are the repeated patterns?\n3. Key issues/areas that could be improved\n4. What surprised you?\n5. What is essential/nonessential in implementation\n\n### Steps\n1. Initial reactions or observations (identify patterns, simple numerical analysis like averages, ratios, percentages)\n2. Data cleansing (checking for erroneous entries and anomalies)\n3. Analysis\n\n### Qualitative Analysis\n#### Thematic Analysis\nThemes are a small number of high-level patterns that answer your evaluation questions.\n\nGoing from codes (descriptive labels) to categories (grouping imposed on codes) to themes (interpretive patterns). Deductive analysis is just the inverse (starting at themes and arriving at codes)\n\nDo an initial pass to check of internal consistency: make sure themes occur across several or all participants. Then, step back to see if an overarching narrative emerges from the themes. One can them remove themes or look into why there are conflicts.\n\nOne way of doing this is using affinity diagrams:\n1.  record each idea/observation/problem/etc on individual card or post-it notes\n2.  look for notes that seem to be related\n3.  sort notes into groups until all used\n    -   sort and resort as necessary\n\n#### Categorizing Data\n-   scheme of data: code the data according to categories\n\t-   if analysis frame is chosen beforehand: deductive analysis\n\t-   if study is explanatory and it is important to let themes emerge from data: inductive analysis\n-   can then analyze with appropriate methods like counting averages # of problems or identifying recurring patterns\n\n### Critical Incident Analysis\nHelps identify significant subsets of data for more detailed analysis.\n\nThis is not about summarizing all incidients, more like finding gold nuggets. Incidents need not be bad all the time, can be either desirable or undesirable.\n\n","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/introductions":{"title":"Introductions","content":"\nwhy i always dislike introductions\n* apply [labels](thoughts/quantization.md) to things too early\n* people have expectations (oh so you're an artist? show me your work)\n    * self-imposed as well\n    * a bad amount of [idolization](thoughts/idolization.md)\n    * as a side note, same reason why calling yourself a writer vs someone who writes are two very different vibes (i *dabble*)\n* first of many experiences → why do we feel the need to get it right at the start?\n\n## Intersectional Identities\n\u003e \"A man may be regarded as the point of intersection of an indefinite number of circles representing social groups\" -- -   Cooley, Human Nature and the Social Order (1922)\n\nCooley imagined affiliations and interests as a system of coordinates, with each additional group determining one's individuality and identity more accurately.\n\n\"These 'reciprocally constructing phenomena' that may empower one person with increasing self-actualization, burden others with exponentially debilitating oppression.\" Related: the matrix of domination and intersectional theory in [Design Justice](thoughts/Design%20Justice.md)\n\n### About Page\n[Source: About Andrew Kortina, Wide-Eyed](https://kortina.nyc/about-andrew-kortina/?curius=1296)\n\n\"It strikes me that these labels are more often conversation enders than conversation starters, attempts to reduce a vast complexity into a neat, little word, with the lossiest of compression algorithms.\"\n\nWe cheer for the clothes, not the people. As Feynman said, \"honors is epaulets, honors is uniforms\"\n\n## Communication\n[bandwidth](thoughts/bandwidth.md) of communication mediums\n* 6 word story → baby shoes for sale, never worn\n* creativity in interpretation\n* low bandwidth mediums require interpretation\n    * requires human interpretation\n        * if its good, we refer to it as creativity\n        * if its bad, we just call it heuristics\n* will we ever get to a point where introductions become useless because we already know everything about each other?\n\t* what about pre-stalking people on social media before meeting them? is this just people projecting their identities?\n   \n\n","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/kernel":{"title":"Kernel Curriculum","content":"\n\u003e \"Too often, the people disrupting any industry don't understand deeply what it is they're disrupting. This is definitely the case with cryptocurrencies and the current financial system. It really is well worth your time to stop and become familiar with more history so that you can understand why we are where we are, what led us here, and - only then - what solutions might actually benefit you and those you care about.\"\n\n## Module 0\n- [Trust](thoughts/trust.md)\n- [Money](thoughts/money.md)\n## Module 1\n- [Meaning](thoughts/meaning.md)\n- [Value](thoughts/value.md)\n- [Security](thoughts/security.md)\n- [Understanding Ethereum](thoughts/ethereum.md)\n- [The promise of the Blockchain](thoughts/blockchain.md)\n## Module 2\n- [Questions](thoughts/questions.md)\n- [Money and Speech](thoughts/money.md)\n- [Debt](thoughts/debt.md)\n- [Banking](thoughts/banking.md)\n- [Engineering Money](thoughts/money.md)\n## Module 3\n- [Intentionality](thoughts/intentionality.md)\n- [Freedom](thoughts/freedom.md)\n- [Remember](thoughts/tools%20for%20thought.md)\n- [Time](thoughts/attention%20economy.md)","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/knowledge-distillation":{"title":"Knowledge Distillation + Teaching","content":"\n[Source: Patterns in confusing explanations by *Julia Evans*](https://jvns.ca/blog/confusing-explanations/)\n\nHeavily linked with [research debt](thoughts/research%20debt.md). What makes for effective [teaching](thoughts/teaching.md) and knowledge distillation?\n\nContent addressing\n-   [games](thoughts/game%20design.md) + interactive content \u003e just reading\n-   constructivist approach: how can we create worlds for people to explore on their own? how do we give agency back to students?\n-   how do we create content that caters for all levels of understanding?\n  -   possible relation to a thing in [project list](thoughts/idea%20list.md) where I thought about creating multi-level blogs\n-   segregation of content?? tends to segregate students\n-   https://newsela.com/about/content/\n\n## Confusing Explanations\nTop things to avoid in explanations and blog posts\n1. **Inconsistent expectations of the reader's knowledge**: it might explain in great detail how a `for` loop works but the next paragraph immediately following implicitly assumes knowledge like how `malloc` works for example. In this case, nearly zero people will understand how `malloc` works without understanding how a `for` loop works. Pick 1 specific person and write for them\n2. **Strained Analogies**: don't try too hard to write a Big Complex Analogy, otherwise more energy will be spent by the user trying to figure out what exactly are the similarities and differences between the two\n3. Jargon without providing context\n4. Unsupported information and statements\n5. Explaining the \"wrong\" way to do something without saying it’s wrong\n6. \"What\" without the \"why\"","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/language":{"title":"Language","content":"\n\u003e Language is the systematic and conventional use of sounds (or signs or written symbols) for the purpose of communication or self expression (Crystal, 1995 as cited in Hoff 2014:4)\n\nLanguage\n- Uses both iconic and symbolic representations\n\t- Iconic: direct connection between the sound/shape/look of a word and its meaning\n\t- Symbolic: no connection between the sound/shape/look of a word and its meaning\n\nChildren learn language through exposure to language, not through being taught explicit rules. Language must be learned through exposure, and the language you learn is based on the language you hear/see (input)\n\nThe goal of language is to learn a productive grammar that can generate (or produce) an infinite number of phrases that others can understand.\n\n- Involves knowledge of \n\t- Sounds ([[thoughts/phonetics|phonetics]])\n\t- Words ([[thoughts/phonology|phonology]], [[thoughts/semantics|semantics]])\n\t- Grammar ([[thoughts/morphology|morphology]], [[thoughts/syntax|syntax]])\n\t- Social and communicative Function ([[thoughts/pragmatics|pragmatics]], [[thoughts/sociolinguistics|sociolinguistics]])\n\n- Language Productivity: you can come up with (or generate) new words and sentences, even if you have never said them before\n- Language Comprehension: you can understand infinite combinations of morphemes and words, even if you have never heard them before\n\n## Components of Language Knowledge\n- [[thoughts/phonetics|Phonetics]]\n- [[thoughts/phonology|Phonology]]\n- [[thoughts/morphology|Morphology]]\n- [[thoughts/syntax|Syntax]]\n- [[thoughts/semantics|Semantics]]\n\t- Semantic organization: organizing the world between cognitive organization and language\n- [[thoughts/pragmatics|Pragmatics]]\n- [[thoughts/sociolinguistics|Sociolinguistics]]\n\nSee also:\n- [[thoughts/language development|language development]]\n- [[thoughts/language of thought|language of thought]]\n- [[thoughts/linguistic relativism|linguistic relativism]]\n- [[posts/new-words|New Words]]\n\n","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/language-development":{"title":"","content":"## Approaches to study of language development\n- Language socialization: A description of children’s language use in social contexts and an account of the social processes by which children come to use language in the manner of their culture\n- Linguistic: the Language Acquisition Device (LAD) must contain some knowledge of the structure of language in order for language acquisition to be possible -- this innate knowledge cannot be specific to any particular language thus it is a Universal Grammar (UG)\n- Learnability approach: focuses on explaining the fact that language is acquired (i.e., that language is learnable).\n- Developmental approach: focuses on explaining the course of language development.\n### Nature vs Nurture\n- Is the development of language in children the result of human innate knowledge (e.g. walking upright) or is it the result of the experiences of children and how they are raised (e.g. learning calculus)?\n- Empiricism: the mind at birth is like a blank slate; all knowledge and reason come from experience\n- Nativism: knowledge cannot come from experience alone. The mind must have some preexisting structure in order to organize and interpret experience \n- Interactionism/[[thoughts/constructionist|constructivist]]: acknowledges there must be some innate characteristics of the mind that allow it to develop language based on experience but places greater emphasis on accounting for children's language-learning experiences\n### Cognitivism vs Behaviourism\n- Behaviourism: change in behaviour occurs in response to the consequences of prior behaviour; behaviour can be fully accounted for in terms of things external to the mind\n- Cognitivism: we cannot understand behaviour without understanding what is going on inside the mind of the organism producing the behaviour\n### Nature vs. Nurture\n- Nativism (nature): innate knowledge underlies language, focus on the ease/speed  \nthat children learn language without formal instruction (maturation)  \n- Empiricism (nurture): everything comes from experience (learning)\n\t- We know that human children who are not exposed to language early in their lives do not reach the same proficiency in adulthood\n### Critical Period\n- Critical period hypothesis: language must be learned within a biologically determined window (comparable to birds and imprinting)\n- Sometimes also called the sensitive period or optimal period (less sensitive than critical period)\n### Measuring sound discrimination\n- Prosody: includes learning about the intonation, stress, pitch of a language.\n- Categorical perception: when a range of stimuli that differ continuously are perceived as belonging to only a few categories \n- Phoneme Boundary Effect: example of categorical perception. e.g. the phonemes /b/ and /p/ differ along a single acoustic continuum (voice onset time), but listeners hear each stimulus as either a /b/ or a /p/, nothing in between\n- Distributional learning: learning from simply being exposed to frequency distributions of speech sounds in one's surroundings\n- Statistical learning: learning by counting the frequency with which one stimulus is followed by another\n- Rule learning: a stronger claim than statistical learning, claims that babies can learn a pattern that must be described in terms of symbols (or variables) that stand for any sound. Babies learn algebraic rules, not just statistical regularities\n- Phonological bootstrapping hypothesis: children use phonological cues (e.g. nouns tend to have first-syllable stress whereas verbs have second-syllable stress) to break into grammatical structure \n- Prosodic bootstrapping hypothesis: pauses and changes in intonation at phrase boundaries\n### 5 stages in early speech production\n1. Reflexive Crying and Vegetative Sounds\n\t1. Burps, sneezes, anything that accompanies biological functions\n2. Cooing and Laughter (elicited by social interaction)\n3. Vocal Play or Expansion Stage\n\t1. In first few months, the only recognizable speech sounds are vowel-like. The first recognizable consonant-like sounds are heard at around 2 to 3 months of age, and tend to be back of the mouth (velars), such as [g] and [k].\n4. Reduplicated Babbling (e.g. bababa)\n\t1. Deaf child also babble but at a later time than other children. The number of sounds produced gets smaller (not larger) over time.\n5. Non-Reduplicated/Variegated Babbling (e.g. bagiga)\n\t1. Wordless sentences are often referred to as jargon\n- Impacts of experience in speech production\n\t- Input from adults – affects sounds and prosody in babbling. This is also influenced by the language that they hear (babbling drift)\n\t- Vocal feedback from own productions  \n\t- Social feedback\n### Phoneme Acquisition Time\n- Why are some phonemes acquired later than others?  \n\t- Ease of articulation  \n\t- Frequency in the input  \n\t- Markedness  \n\t- Functional load – how many words in the language use this sound?\n- Early: /p/, /b/, /d/, /m/, /n/, /j/, /w/, /h/\n- Middle: /t/, /k/, /g/, /f/, /v/, /tʃ/, /ŋ/, /dʒ/\n- Late: /θ/, /ð/, /s/, /z/, /ʃ/, /ʒ/, /l/, /r/\n### Experimental approaches for studying infant's perception\n- Cross-language speech perception: see Werker \u0026 Tees\n- High-amplitude Sucking Technique\n\t- Babies like to hear sounds\n\t- Babies lose interest in a sound when it is presented repeatedly (habituation)\n\t- Babies who have lost interest in a previously repeated sound will become interested if a new sound is presented (dishabituation)\n\t- Works best for \u003c0;4\n- Conditioned Head Turn Procedure\n\t- Babies are interested in moving toys\n\t- Using the presentation of the moving toy as a reward, babies can be trained to turn their heads when they hear a change in a sound being presented\n\t- Works best for 0;5-1;0\n- Intermodal Preferential Looking Paradigm\n\t- Placing a child on their mother's lap in front of two video monitors, which play two different events simultaneously.\n\t- A speaker between the two monitors plays a verbal sentence that matches only one of the videos.\n\t- A hidden observer measures how much the child looks at each screen.\n\t- If the child watches the correct monitor longer and more quickly than the incorrect monitor, they are deemed to have understood the sentence.","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/language-of-thought":{"title":"Language of Thought","content":"\nCan we use [[thoughts/language|language]] as the method of querying memory? \n\n## Language of thought hypothesis\n- proposes thinking occurs in a mental language, this is called mentalese\n    -   computations in a classical way\n    -   classical computational architecture distinguishes between data-structures and rules/programs which operate on said structures\n-  [[thoughts/neural networks|neural networks]] or [connectionist networks](thoughts/connectionist%20networks.md) challenges any argument for mentalese (as they don't fall under the GOFAI/classical computation category)","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/latent-factor-model":{"title":"Latent-Factor Models","content":"\nLike [[thoughts/change of basis]] but instead of hand-picking the features, we learn them from data.\n\n*Part weights* are a change of basis from $x_i$ to some $z_i$. The canonical example is Principal Component Analysis (PCA)\n\n## PCA\nPCA is parametric and does *not* provide unique global optimum. \n\nTakes in a matrix $X$ and an input $k$ and outputs two matrices such that $X \\approx ZW$:\n- $Z$ is a (n,k) matrix. Each row $z_i$ is a set of features/part weights\n- W is a (k,d) matrix. Each row $w_c$ is a part/factor/principle component\n\t- We can think of $W$ as *rotating* data so that the slope is zero\n- Approximation of one $\\hat x_{ij}$ is $(w^{j^T}z_i) = \\langle w^j, z_i \\rangle$\n\t- Each $x_i$ can be thought of as a linear combination of all the factors\n\nAssumptions:\n- Assumes $X$ is centered (each column of $X$ has a mean of zero)\n\nUse cases:\n- Dimension reductionality: Effectively allows us to reduce the dimensionality of X if $k \u003c d$\n\t- Actually, it only ever makes sense if $k \\leq d$\n- [[thoughts/outlier detection|Outlier detection]]: if PCA gives a poor approximation, $x_i$ could be an outlier\n- [[thoughts/visualization|Data visualization]]: $k=2$ to visualize high-dimensional objects\n\nWe minimize\n\n$$\\begin{aligned}\nf(W,Z)\u0026= \\sum_{i=1}^n \\sum_{j=1}^d (\\langle w^j, z_i \\rangle - x_{ij})^2 \u0026 \\textrm{Approximating } x_{ij} \\textrm{ by } \\langle w^j, z_i \\rangle \\\\\n\u0026= \\sum_{i=1}^n \\lVert W^Tz_i - x_i \\rVert^2 \u0026 \\textrm{Approximating } x_i \\textrm{ by } W^Tz_i\\\\\n\u0026= \\lVert ZW - X \\rVert_F^2 \u0026 \\textrm{Approximating } X \\textrm{ by } ZW\n\\end{aligned}$$\n\nIf we do alternating minimization,\n1. Fix Z and optimize W: $\\nabla_wf(W,Z)=Z^TZW-Z^TX$\n2. Fix W and optimize Z: $\\nabla_wf(W,Z)=ZWW^T-XW^T$\n\nWe converge to a local optimum which will be a global optimum if W and Z are randomly initialized (if you don't pick a saddle point)\n\nFor large X, we can also just use [[thoughts/gradient descent#Stochastic Gradient Descent (SGD)|SGD]] and cost per iteration is only $O(k)$\n\n### Choose $k$ by variance explained\nHow much of the variance can be explained by the choice of factors?\n\nFor a given $k$, we compute the variance of the errors over the variable of each given $x_{ij}$\n\n$$\\frac{\\lVert ZW-X \\rVert_F^2}{\\lVert X \\rVert_F^2}$$\n### Uniqueness\nOptimal $W$ is non-unique:\n1. Scaling problem: Can multiply any $w_c$ by any non-zero $\\alpha$\n2. Rotation problem: Can rotate any $w_c$ within the span\n3. Label switching problem: Can switch any $w_c$ with any other $w_c$\n\nTo help with uniqueness,\n1. Normalization: We ensure $\\lVert w_c \\rVert = 1$\n2. Orthogonality: We enforce $w_c^Tw_{c'}=0$ for all $c \\neq c'$\n3. Sequential fitting, we fit each $w_i$ in sequence\n\n## Multi-Dimensional Scaling\nGradient descent on points on a scatter point; try to make scatterplot distances match high-dimensional distances\n\n$$f(Z) = \\sum_{i=1}^n\\sum_{j=i+1}^n (\\lVert z_i - z_j \\rVert - \\lVert x_i - x_j \\rVert)^2$$\n\nNo $W$ matrix needed! However, cannot be done using singular value decomposition (a matrix factoring technique). We need [[thoughts/gradient descent]].\n\n- Non convex\n- Sensitive to initialization\n- Unfortunately, MDS often does not work well in practice; MDS tends to “crowd/squash” all the data points together like PCA.\n\n## t-SNE\n\u003e t-Distributed Stochastic Neighbour Embedding\n\nHowever, using Euclidean (L2-norm) may not be a great representation of data that lives on low-dimensional manifolds. In these cases, Euclidean distances make sense “locally” but Euclidean distances may not make sense “globally”.\n\n![[thoughts/images/manifold distance example.png]]\n\nt-SNE is actually a special case of [[#Multi-Dimensional Scaling]]. The key idea is to focus on distance to “neighbours”, allowing gaps between distances to grow\n\n## Word2Vec\nEach word $i$ is represented by a vector of real numbers $z_i$\n\nTrained using a masking technique.\n- Takes sentence fragments and hides/masks a middle word\n- Train so that $z_i$ of hidden word is similar to $z_i$ of surrounding words\n\n$$p(z_i) = \\prod_{j \\in \\textrm{surrounding}} \\frac{\\exp(z_i^Tz_j)}{\\sum_{c=1}^\\textrm{\\# words} \\exp(z_c^Tz_j)}$$\n\nGradient descent on for $-\\log(p(z_i))$","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/learning":{"title":"Learning Frameworks","content":"\n\u003e Learning as an act of becoming really good at exploring terrain -- Shaun Martin\n\nFramework for knowledge\n1.  Sensing → info intake, active reading\n2.  Reasoning → asking questions, applying knowledge, critical thinking\n3.  Acting → learning by doing\n\nHow does this tie with [academia](thoughts/academia.md) and whether individuals are scared to try new things?\n\nAs historically human creatures, learning and obeying [social contracts](thoughts/social%20contracts.md) is how we've survived. As a result, we can distinguish actions as either discovery (child-like curiosity, discovering the world and its [[thoughts/causality|causal]] relations) or ritual (following exact actions because you were taught to fit in).\n\nThere was an experiment of subjecting young children (~5-6yrs) to a game of Powerball where a ball could be passed back and forth between 3 people. Later in the game, the ball wasn't passed to one of the children, leading to feelings of social exclusion. This then led the young children to adopt more ritualistic approaches to learning rather than discovery-based.","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/library":{"title":"Libraries","content":"\n[Source: Fugitive Libraries by *Shannon Mattern*](https://placesjournal.org/article/fugitive-libraries)\n\nLibraries are not universally welcoming spaces. At least 87% of librarians are white, and stories of discrimination/hostility for their race/class/sexual identity/disability are not uncommon. There is a lot of reinforcement of outdated values embedded in classification.\n\nThere is a concept called \"[double-consciousness](thoughts/double-consciousness.md)\" which is essentially the \"sense of always looking at one’s self through the eyes of others, of measuring one’s soul by the tape of a world that looks on in amused contempt and pity\" especially felt by minorities. Historical library practices can shape contemporary technologies.\n\nHow neutral should libraries be? Historically, neutrality has been a core value for a lot of librarians, but has often been used to justify \"disengagement from crises in urban communities.\"\n\nUndercommons: a place allowing for \"ongoing experiment\" with informal ways of learning together, of building futures together\n\nFugitivity then, is the mode of being other than settled, especially recognizing that there are spaces and modalities that exist separate from the logical, the logistical, the housed and the positioned.","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/life":{"title":"Life Definition","content":"\n# Spinoza\n[Source: Spinoza -- Understanding the emotions Clare Carlisle](https://www.theguardian.com/commentisfree/belief/2011/mar/14/spinoza-understanding-emotions)\n\nEvery individual thing has *conatus*: it strives to persevere in its existence. In order to live, we need power, or energy, and because various external influences can diminish our power, we seek not only to sustain this power, but to increase it.\n\nThe mind's power of thought, and the body's power of movement – fluctuates over time. Joy arises with the feeling of an increase in power, and the emotion of sadness when power is diminished.\n\n## Ozma of Oz\n-   Tik-Tok → \"Thinks, Speaks, Acts, and Does Everything but Live\"\n-   Tin Man vs Tik-Tok\n\t-   Tin Man used to be living (born a real man) but lost his body over time due to a series of wood chopping 'accidents'\n\t\t-   a modern tale of the ship of Theseus\n\t\t-   does the original entity persist through the gradual replacement of each of its parts, if it doesn't, where does it stop being the same entity?\n\t\t\t-   same thing with ideas, what separates [original from derivative](thoughts/originality.md)?\n\t\t-   two differences\n\t\t\t-   replacement pieces are different material from the parts they replace (tin vs flesh) does this matter?\n\t\t\t-   Tin Man tells his own story from when he used to be a creature of flesh and bones → has a memory\n\t-   Tik-Tok has neither of those two differences\n\t\t-   built in a tinker's shop\n\t\t-   Tik-Tok is treated as a [conscious](thoughts/consciousness.md) being\n\t\t-   but is not treated as being able to live\n-   Conclusion from Tik-Tok story\n\t-   neither thinking nor consciousness entails being alive\n-   Hilary Putnam's ingenious argument (attributed to Paul Ziff)\n\t-   x is a mechanism → x is ~alive\n\t-   by first order logic\n\t\t-   if x is ~alive → x is not alive\n\t\t-   if x is not alive → Tik-Tok is not conscious\n\t\t-   this is a contradiction of Tik-Tok's label which proclaims he can think\n\n## Traditional connection between thinking and being alive\n-   suspects the distinction between what is alive what is mechanical is not clear-cut\n-   two criteria of life\n\t-   structural (important for plants)\n\t\t-   biochemical definition of life → digestion, growth, reproduction, self-motion, perception, etc.\n\t-   behavioural (important for animals)\n\t\t-   any program that matched some reasonably good psychological theory of how people behave would thereby satisfy the behavioural criteria for consciousness and life\n-   x is conscious does entail that x is alive\n\t-   Descartes would agree but posits that we _should_ alter language such that this entailment no longer holds","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/linear-algebra":{"title":"Linear Algebra","content":"\nA lot of content summarized from [Mark Schmidt's notes on Linear Algebra](https://www.cs.ubc.ca/~schmidtm/Documents/2009_Notes_LinearAlgebra.pdf)\n\n## Notation\nGenerally column major\n\n- Scalar (1,1): $\\alpha$\n- Column Vector (m, 1): $\\begin{bmatrix}a_1 \\\\ a_2 \\end{bmatrix}$\n- Row Vector (1, n): $\\begin{bmatrix}a_1 \u0026 a_2\\end{bmatrix}$\n- Matrix (m, n): $\\begin{bmatrix}a_{1,1} \u0026 a_{2,1} \\\\ a_{1,2} \u0026 a_{2,2}\\end{bmatrix}$\n\n## Operations\n### Transpose\n$(A^T)_{ij} = (A)_{ji}$\n\nA matrix is **symmetric** if $A = A^T$\n\n### Vector Addition\nAssociative (brackets don't matter) and commutative (order independent)\n\n$$a + b = \\begin{bmatrix}a_1 \\\\ a_2 \\end{bmatrix} + \\begin{bmatrix}b_1 \\\\ b_2 \\end{bmatrix} = \\begin{bmatrix}a_1 + b_1 \\\\ a_2 + b_2 \\end{bmatrix}$$\n\n### Scalar Multiplication\nAssociative (brackets don't matter) and commutative (order independent)\n\n$$\\alpha b = \\alpha \\begin{bmatrix}b_1 \\\\ b_2\\end{bmatrix} = \\begin{bmatrix}\\alpha b_1 \\\\ \\alpha b_2\\end{bmatrix}$$\n### Inner Product\nBetween two vectors of the same length, multiply each element together to get a scalar result\n\n$$a^Tb = \\sum_{i = 1}^{n}a_ib_i = \\gamma$$\n\nA specific version of this is the **dot product** which can be expressed as the inner product between two vectors, $a \\cdot b = a^Tb$\n\n- Commutative: $a^Tb = b^Ta$\n- Distributive across addition: $a^T(b+c) = a^Tb + a^Tc$\n\n### Outer Product\nBetween two vectors of the same length, create a matrix multiplying each combination of elements in each vector.\n\nGiven two vectors $u = \\begin{bmatrix}u_1 \\\\ u_2 \\\\ \\vdots \\\\ u_m \\end{bmatrix}$ and $v = \\begin{bmatrix}v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix}$,\n\n$$u \\otimes v = A = \\begin{bmatrix}u_1v_1 \u0026 u_1v_2 \u0026 \\dots \u0026 u_1v_n\\\\ u_2v_1 \u0026 u_2v_2 \u0026 \\dots \u0026 u_2v_n \\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ u_mv_1 \u0026 u_mv_2 \u0026 \\dots \u0026 u_mv_n \\end{bmatrix}$$\n\nThe resulting matrix $A$ is always rank-1.\n\n### Multiplication\nIn general, we can multiply matrices A and B when the number of columns in A matches the number of rows in B\n\nIf A is (m, n) and B is (n, p), then AB is (m, p)\n\n![[thoughts/images/matrix multiplication.png|400]]\n\n- Associative: $A(BC) = (AB)C$\n- Distributive across addition: $A(B + C) = AB + AC$\n- Generally not commutative: $AB \\neq BA$\n- Transposing reverses order: $(AB)^T = B^TA^T$\n- Matrix powers don't change order: $(AB)^2 = ABAB$\n- Matrix-vector multiplication always yields a vector: $x^TAy = x^T(Ay) = (Ay)^Tx = y^TA^Tx$\n\n## Properties\n### Vector Norm\nA scalar measure of a vector's length\n\n- $\\Vert x \\Vert \\geq 0$ \n- $\\Vert x \\Vert_2^2 = x^Tx$ \n\n- Euclidean Norm (L2-Norm): $\\Vert x \\Vert_2 = \\sqrt{\\sum_{i=1}^n x_i^2}$\n\t- Also note that $\\lVert x \\rVert^2 = \\lVert x \\rVert_2^2 = r^Tr = \\langle r,r \\rangle$\n- Manhattan Distance (L1-Norm): $\\Vert x \\Vert_1 = |r_1| + |r_2|$\n\t- How many 'blocks' you need to traverse\n- L$\\infty$-Norm: $\\Vert x \\Vert_\\infty = \\max(|r_1|, |r_2|)$\n\t- How many blocks you have to walk in any one dimensions\n\n### Rank\n- The dimension of the vector space generated (or spanned) by its columns.\n- This corresponds to the number of linearly independent columns of A.\n\t- This minimal set of vectors that span a space is called a basis\n\n### Orthogonal\nIf for some set of vectors $q$:\n- $q_i^Tq_j = 0$, we call $q_i$ and $q_j$ orthogonal\n- $q_i^Tq_j = 1$, we call $q_i$ and $q_j$ orthonormal\n\nInner product of square orthogonal matrices is the identity matrix: $Q^TQ = I = QQ^T$\n\n### Linear Dependence\nA vector is linearly dependent on a set of vectors if it can be written as a linear combination of them\n\n$$c = \\alpha_1 b_1 + \\alpha_2 b_2 + \\dots + \\alpha_n b_n$$\n\nA set of vectors is linearly dependent if and only if the zero vector can be written as a non-trivial combination of any of the vectors.\n\nA matrix with fully independent columns has **full column rank**. If this is the case, $Ax = 0$ implies that $x = 0$\n\n## Special Matrices\n### Identity Matrix\n1's on the diagonal and 0's otherwise. $I_n$ denotes an (n,n) identity matrix.\n\nMultiplication by the identity matrix yields the original matrix. Columns of the identity matrix are called elementary vectors.\n\n### Diagonal Matrix\n$$D = \\begin{bmatrix}d_1 \u0026 0 \u0026 0 \\\\ 0 \u0026 d_2 \u0026 0 \\\\ 0 \u0026 0 \u0026 d_3 \\end{bmatrix}$$\n\n## Spaces\n### Range (Column-space)\nSubspace spanned by the columns of a matrix.\n\nA system $Ax=b$ is solvable if and only if b is in $A$'s column-space\n\n### Subspace\nA non-empty subset of vector space that is closed under addition and scalar multiplication\n\nPossible spaces of $\\mathbb{R}^3$\n- 0 Vector\n- Any line or plane through the origin\n- All of $\\mathbb{R}^3$\n\nWe say that the vectors generate or span the subspace when you can reach any point in the subspace through a linear combination of the vectors.\n\n## Matrices as transformation\nViewing $Ax = T(x)$\n\nA linear transformation can't move the origin. But, if there are linearly dependent columns, there are non-zero vectors that *can* be transformed to zero. The set of vectors that can be transformed to 0 is called the null-space.\n\nNull space: $\\mathcal N (A)$ is all $x$ such that $Ax = 0$\n\n### Fundamental Theorem of Linear Algebra\n- $r$ is the dimension of the column-space which is the same as the dimension of the row-space\n- The null-space is orthogonal to the row-space\n\n## Inverses\nWe can find the inverses if and only if A is square and doesn't have null-space outside of the zero vector (otherwise we either lose information to the null-space or can't get to all vectors)\n\nIf the inverse exists, it is a unique matrix such that $A^{-1}A = I = AA^{-1}$\n\nSome identities\n- $(A^{-1})^T = (A^T)^{-1}$\n- $(\\gamma A)^{-1} = \\gamma^{-1} A^{-1}$\n- Assuming both $A^{-1}$ and $B^{-1}$ exist, $(AB)^{-1} = B^{-1}A^{-1}$\n\nSpecial inverses of diagonal matrices\n\n$$D=\\begin{bmatrix}d_1 \u0026 0 \u0026 0 \\\\ 0 \u0026 d_2 \u0026 0 \\\\ 0 \u0026 0 \u0026 d_3 \\end{bmatrix}$$\n\n$$D^{^-1}=\\begin{bmatrix}1/d_1 \u0026 0 \u0026 0 \\\\ 0 \u0026 1/d_2 \u0026 0 \\\\ 0 \u0026 0 \u0026 1/d_3 \\end{bmatrix}$$\n\n## Solving Linear Equations\nGiven A and b, we want to solve for x in $Ax = b$\n\nSay, $\\begin{bmatrix}2 \u0026 -1 \\\\ 1 \u0026 1\\end{bmatrix}\\begin{bmatrix}x \\\\ y\\end{bmatrix} = \\begin{bmatrix}1 \\\\ 5\\end{bmatrix}$.\n\nWe can interpret this multiple ways:\n1. By rows: $x$ is the intersection of the hyperplanes $2x-y=1$ and $x+y=5$\n2. By columns: $x$ is the linear combination that yields the RHS in $x\\begin{bmatrix}2 \\\\ 5\\end{bmatrix} + y \\begin{bmatrix}-1 \\\\ 1\\end{bmatrix} = \\begin{bmatrix}1 \\\\ 5 \\end{bmatrix}$\n3. Transformation\n\n$Ax=b$ generally has a solution when $b$ is in the column-space of A. It has a single unique solution if the columns of A are linearly independent.\n\nIf $Ax=b$ has as solution we say it is consistent.\n\nBasically, $x = A^{-1}b$\n\nWe can solve using Gaussian Elimination","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/linear-regression":{"title":"Linear Regression","content":"\nVector dimensions:\n- $w$ is $(d, 1)$ (weights)\n- $y$ is $(n,1)$ (targets)\n- $x_i$ is $(d, 1)$ (features)\n- $X$ is $(n,d)$ each row is $x_i^T$\n\nLinear regression makes predictions $\\hat y_i$ using a linear function of $x_i$: $\\hat y_i = w^Tx_i$\n\nWe set $w$ to minimize the sum of squared errors: $f(w) = \\sum_{i=1}^n (w^Tx_i - y_i)^2$\n\n1. Take the derivative of $f$ and set it equal to 0 $f'(w) = 0$ gives us $w = \\frac{\\sum_{i=1}^n x_iy_i}{\\sum_{i=1}^n x_i^2}$\n2. Check to second derivative to make sure we have a minimizer (if double derivative is positive). $f''(w) = \\sum_{i=1}^n x_i^2$. As $x_i^2$ by definition must always be positive, this is a minimizer.\n\nIn d-dimensions, we minimize\n\n$$\\begin{equation}\n\\begin{split}\nf(w) \u0026= \\frac 1 2 \\sum_{i=1}^n (w^Tx_i - y_i)^2 \\\\\n \u0026 = \\frac 1 2 \\lVert Xw - y \\rVert^2 \\\\\n \u0026 = \\frac 1 2 w^TX^TXw - w^TX^Ty + \\frac 1 2 y^T y \\\\\n \u0026 = \\frac 1 2 w^TAw - w^Tb + c\n\\end{split}\n\\end{equation}$$\n\nwhere $A$ is a matrix, $b$ is a vector, and $c$ is a scalar\n\nThe generalized version of “set the derivative to 0 and solve” in d-dimensions is to find where the gradient is zero (see [[thoughts/calculus|calculus]]). We get\n\n$$\n\\begin{equation}\n\\begin{split}\n\\nabla f(w) \u0026= \\begin{bmatrix}\n\\frac{\\partial f}{\\partial w_1} \\\\\n\\frac{\\partial f}{\\partial w_2} \\\\\n\\vdots\\\\\\\n\\frac{\\partial f}{\\partial w_d}\n\\end{bmatrix}  \\\\ \\\\\n\n\u0026= \n\n\\begin{bmatrix}\n\\sum_{i=1}^n (w^Tx_i - yi)x_{i,1}  \\\\\n\\sum_{i=1}^n (w^Tx_i - yi)x_{i,2}  \\\\\n\\vdots\\\\\\\n\\sum_{i=1}^n (w^Tx_i - yi)x_{i,d}  \\\\\n\\end{bmatrix} \\\\ \\\\\n\n\u0026=\n\nAw - b \\\\\n\n\u0026= X^TXw - X^Ty\n\\end{split}\n\\end{equation}\n$$\n\nWe can fit to polynomial equations using a [[thoughts/change of basis]]\n\n## Cost\nOf solving equations in the form $Aw = b$\n1. $O(nd)$ to form vector $b$\n2. $O(nd^2)$ to form matrix A\n3. Solving a $(d,d)$ system of equations is $O(d^3)$\n\nOverall cost is $O(nd^2+d^3)$\n\n## Robust Regression\nWe minimize the L1-norm of residuals instead of L2-norm\n\n$$f(w) = \\lVert Xw - y \\rVert_1$$\n\nHowever, as the L1-norm uses the absolute function, it is non-differentiable at 0. We can use a smooth approximation of the L1-norm instead, like Huber loss:\n\n$$\nh(r_i) = \n\\begin{cases} \n      \\frac 1 2 r_i^2 \u0026 |r_i| \\leq \\epsilon \\\\\n      \\epsilon (|r_i| - \\frac 1 2 \\epsilon) \u0026 \\textrm{otherwise}\n   \\end{cases}\n$$\n\nAbsolute error is more robust and non-convex errors are the most robust.\n- Generally not influenced by outlier groups\n- But it is non-convex so finding global minimum is hard\n\n## Brittle Regression\nYou want to minimize size of worst error across examples. For example, if in worst case the plane can crash or you perform badly on a group.\n\nWe can instead minimize the $L_\\infty$ norm which is convex but non-smooth. This effectively minimizes the highest error (effectively Minimax regret in [[thoughts/Decisions under ignorance|DUI]]).\n\nThe smooth approximation to the max function is the log-sum-exp function:\n\n$$\\max_i \\{ z_i \\} \\approx \\log( \\sum_i \\exp(z_i))$$\n\n## Penalizing Model Complexity\nOptimize $score(p) = \\frac 1 2 \\lVert Z_p v - y \\rVert^2 + p$ where $p$ is the degree of the polynomial.\n\nOther ones also exist which replace the $p$ term with $\\lambda k$ where $k$ is the estimated degrees of freedom (for polynomials, $k = p + 1$). $\\lambda$ controls how strongly we penalize complexity.\n\n$\\lambda = 1$ is called the Akaike information criterion (AIC)\n\nSee also: [[thoughts/regularization]]\n","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/linguistic-relativism":{"title":"Linguistic Relativism","content":"\nSee: [[thoughts/language|linguistics]]\n\n## Does language dictate how we think about the world?\n- importance of vocabulary\n- do we need labels and [terminology](thoughts/terminology.md) to discuss things\n- false dichotomies\n- Sapir-Whorf hypothesis is true -- but the effects are far more pronounced for programming languages than for spoken languages.\n\nThe [[thoughts/language|language]] you write code in ends up shaping huge parts of you worldview even when you're not programming (sapir-whorf, [language of thought](thoughts/language%20of%20thought.md)). The best purpose of language in general, and programming languages in particular is to expand the domain of thinkable thoughts\n\nThe power of programming languages (and why you may want to learn them, even if not intent on building software) is that they let you get you hands dirty with building and using ur own abstractions. ([Mindstorms](thoughts/Mindstorms.md), computation as a form of language, [constructionism](thoughts/constructionist.md))","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/liveness":{"title":"Liveness","content":"\n\u003e A promise in [[thoughts/distributed systems|distributed systems]] that claims that \"something good\" will eventually happen. A system will never enter a state such that no progress cannot be made.\n\nOne such example of a liveness property is [[thoughts/consistency#Eventual Consistency|eventual consistency]].","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/local-first-software":{"title":"Local-first software","content":"\n\u003e By centralizing data storage on servers, cloud apps also take away ownership and agency from users. If a service shuts down, the software stops functioning, and data created with that software is lost.\n\n## Ink and Switch\n[You own your data, in spite of the cloud](https://www.inkandswitch.com/local-first/)\n\nTo sum up: the cloud gives us collaboration, but old-fashioned apps give us ownership. Can’t we have the best of both worlds?\n\n- Traditional web app model: \"If it's not stored in the server database, it didn't really happen\"\n- Local-first model: \"The client's local storage is what matters -- the server is just for multi-user sync and backup\"\n\nLocal-first ideals include\n1. No spinners: your work at your fingertips\n\t- All operations can be handled by reading and writing files on the local disk, and data synchronization with other devices happens quietly in the background.\n2. Your work is not trapped on one device\n3. Network is optional\n4. Seamless collaboration\n\t1. Auto-merging changes using a [[thoughts/CRDT|CRDT]] or OT\n\t2. Asynchronous changes that need review (e.g. suggestions or pull requests)\n5. The long now (optional permanence/digital longetivity)\n\t- When you do some work with local-first software, your work should continue to be accessible indefinitely, even after the company that produced the software is gone.\n6. Security and [[thoughts/privacy|privacy]] by default\n\t- Many professionals cannot use cloud apps due to regulatory compliance and confidentiality obligations.\n7. User retains ownership and control\n\t- You should be able to copy and modify data in any way, write down any thought, and no company should restrict what you are allowed to do.\n\nA potential digital dark age is looming. The documents created in cloud apps are destined to disappear when the creators of those services cease to maintain them. Cloud services defy long-term preservation. No Wayback Machine can restore a sunsetted web application. The Internet Archive cannot preserve your Google Docs.\n\nServers have a role to play in the local-first world — not as central authorities, but as “cloud peers” that support client applications without being on the critical path. For example, a cloud peer that stores a copy of the document, and forwards it to other peers when they come online, could solve the closed-laptop problem.\n\nThe key difference between traditional systems and local-first systems is not an absence of servers, but a change in their responsibilities: they are in a supporting role, not the source of truth.\n\nActive questions:\n1. CRDTs accumulate a large change history, which creates performance problems. These pile up, but can’t easily be truncated because it’s impossible to know when someone might reconnect to your shared document after six months away and need to merge changes from that point forward.\n2. Network communication remains an unsolved problem. The use of P2P technologies in our prototypes yielded mixed results. On one hand, these technologies are nowhere near production-ready: [[thoughts/NAT|NAT]] traversal, in particular, is unreliable depending on the particular router or network topology where the user is currently connected.\n3. Visualizing document history is important and difficult. How do we communicate this version history to users? How should users think about versioning, share and accept changes, and understand how their documents came to be a certain way when there is no central source of truth?\n\n## TLFS\nFrom [Cloudpeers](https://cloudpeers.co/)\n\nThe Local-First SDK offers a stack to write applications as productively as when using state-of-the-art cloud-based architectures. It enables building serverless apps that traditionally require backend engineers to build, scale and maintain.\n\nReally great SDK but unsure how this differs from existing platforms like [[thoughts/Yjs|Yjs]] or [[thoughts/Hypercore|Hypercore]] (aside from being non-JS native). Could see this being useful for cross-platform live collaboration.\n\nActually uses a Cambria-like system for data lensing which is cool.\n\n## Locutus\nLocutus is a decentralized key-value database. It uses the same [small world](https://freenetproject.org/assets/papers/lic.pdf) routing algorithm as the original Freenet design, but each key is a cryptographic contract implemented in WASM, and the value associated with each contract is its state.\n\nLocutus is *not* append-only and has mutable state.\n\nSplits are merged using [[thoughts/CRDT|CRDTs]]","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/logical-fallacies":{"title":"Logical fallacies","content":"\n1. Slippery Slope: conclusion based on the premise that if A happens, then B, C, ..., X, Y, Z will happen too. So A means Z will happen. But in reality, none of the steps logically entail each other.\n2. Hasty Generalization: conclusion based on insufficient or biased evidence\n3. Post hoc ergo propter hoc: conclusion that if A occurred after B, then B must have caused A\n4. Genetic fallacy: conclusion that the origins of a person, idea, institute, or theory determines its nature, character, or worth\n5. Begging the claim: circular conclusion where the result is validated in the claim\n6. Circular argument: restates the argument rather than proving it\n7. Either/or (false dichotomy): oversimplifying an argument by reducing it to two sides or choices\n8. Ad hominem: attack on the character of a person rather than their opinions or arguments\n9. Ad populum: eoptional appeal to speak to positive/negative concepts rather than the real issue at hand (e.g. if you were a *true* x)\n10. Red herring: diversionary tactic that avoids key issues by diverting it to another argument\n11. Straw man: oversimplifies an opposing viewpoint and attacks weakened argument","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/longest-chain-consensus":{"title":"Longest-chain consensus","content":"\nSee also: [[thoughts/consensus|consensus]]\n\nRequires $f \u003c \\frac n 2$\n\nPrimarily studied in the synchronous [[thoughts/system model|system model]]. Three forms:\n1. Permissioned + [[thoughts/Public-key Infrastructure|PKI]]\n2. Permissionless + [[thoughts/proof of work|PoW]]\n3. Permissionless + [[thoughts/proof of stake|PoS]]\n\nPseudocode properties (all implementations should satisfy these!):\n1. Initialize a hard-coded \"genesis block\" $B_0$ so everyone knows where the chain starts\n2. In each round $r = 1,2,3, \\dots$\n\t1. One node is chosen as a leader. This leader can prove itself as leader to other nodes, non-leaders cannot pretend to be a leader or manipulate their chances of becoming a leader.\n\t2. Leader can create a set of round-$r$ blocks where all of there predecessors are strictly created in some previous round, each with a predecessor block. Blocks form an in-tree rooted at the genesis block.\n\nHonest behaviour\n1. Form block $B$ using all known pending pending transactions\n2. Set the predecessor of $B$ to be the current longest chain, break ties arbitrarily\n3. Immediately broadcast $(B, predecessor)$ to all other nodes\n\n## Balanced Leaders\nWe define a sequence $l_1, l_2, \\dots, \\in \\{ H, A \\}$ as $w$-balanced if in every window $l_i, l_{i + 1}, \\dots, l_j$  where $j - 1 \\geq w$ and a strict majority of leaders in that sequence are honest.\n\nOn finality: if $f \u003c \\frac n 2$, we can consider all but the last $k$ blocks in the chain finalized. $k$ is up to the user to determine what parts of the chain they want to consider finalized.\n\nIf we assume that the rate of block production is slow relative to the maximum message delay $\\Delta$ then inadvertent honest forks rarely occur.\n\nWe define $B_k(G)$ as the last $k$ blocks of the longest chain where $G$ is the current tree of all transactions known. $B_k(G)$ is potentially ill-defined if there are multiple longest chains.\n\nTheorem: if a leader sequence is $2k$-balanced, then for every possible sequence $G_0, G_1, \\dots$ has\n1. The common prefix property: $\\forall i, B_k(G_i)$ is well defined\n2. Finality: one a block is confirmed, it is always confirmed, $B_k(G_0) \\leq B_k(G_1) \\leq \\dots$\n3. Liveness: if a transaction is known to all honest nodes, it will eventually be included in $B_k(G)$\n\nIn the case that we chose completely random leaders:\n- we can expect randomly chosen leaders to be reasonably balanced\n\t- on average, expect $1 - \\frac f n \u003e \\frac 1 2$ nodes to be honest\n\t- bigger window length $w$ means that we are less likely to see $\\geq 50\\%$ Byzantine nodes\n\t- Probability of a given length $w$ window being $\\geq 50\\%$ Byzantine is $\\leq e^{-cw}$ where $c$ is some constant (exponential is good!)\n\t- Probability of a given length $\\geq w$ window being $\\geq 50 \\%$ Byzantine is $\\leq T^2 e^{-cw}$ where $T$ is the length of the sequence we're considering\n\t- Thus we get a failure probability less than some $\\delta$ if $w \\geq c_2 (\\ln T + \\ln \\frac 1 \\delta)$\n- however, there is a small but non-zero chance of balancing failure","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/longevity":{"title":"Longevity","content":"\nHow much of human existence is just us trying to create impact beyond our incredibly short lifespans? If we extend life beyond its natural lifespan, do we need to reconsider how we define [life](thoughts/life.md)?\n\nPermanent land preserves, the Global Seed Vault, the internet itself as the foundational communications technology of a global age. These are not only [public goods](thoughts/public%20goods.md), they are the cultural practices that maintain such goods over generations.\n\n[Money](thoughts/money.md) is power, and many are already looking for ambitious and impactful ways to spend their billion-dollar treasuries. Could [funding](thoughts/funding.md) long-term research like creating [a new DARPA](thoughts/research%20institutions.md) be the way forward?","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/lost-knowledge":{"title":"Lost knowledge","content":"\nSource: [Searching for Lost Knowledge in the Age of Intelligent Machines in *The Atlantic*](https://www.theatlantic.com/technology/archive/2016/12/the-search-for-lost-knowledge/506879/)\n\n\u003e What if other objects like the Antikythera Mechanism have already been discovered and forgotten? There may well be documented evidence of such finds somewhere in the world, in the vast archives of human research, scholarly and otherwise, but simply no way to search for them. Until now.\n\n- Undiscovered public knowledge: coined by Don Swanson. A problem that occurs when researchers arrive at conclusions independently from one another, creating fragments of understanding that are “logically related but never retrieved, brought together, [or] interpreted,”\n\t- Are better tools for [collaborative thinking](posts/collaborative-thinking.md) with [networked thought](posts/networked-thought.md) potential ways to counteract this?\n\t- What about everything we *don't know that we already know?*\n\nHow do we effectively [[thoughts/search|search]] for information?\n\n\u003e \"The prime action of use is selection, and here we are halting indeed. There may be millions of fine thoughts, and the account of the experience on which they are based, all encased within stone walls of acceptable architectural form; but if the scholar can get at only one a week by diligent search, his syntheses are not likely to keep up with the current scene.\"\n\u003e \n\u003e -- [As We May Think](https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881), Vannevar Bush","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/machine-learning":{"title":"Machine Learning","content":"\n## Theory\nCourse notes on CPSC340 with Andreas Lehrmann and Mark Schmidt\n\nWe produce a lot of data (see: [[thoughts/Data Capitalism|data capitalism]])\n\n- [[thoughts/data mining|Data mining]]: automatically extract useful knowledge from large datasets\n- Machine learning: automatically detect patterns in data and use these to make predictions or decisions\n\t- Typically, AI $\\subset$ ML $\\subset$ Deep Learning\n- Typically, data mining is more human-in-the-loop and more application specific whereas machine learning is more hands-off and general\n- Both similar to statistics but more emphasis on larger datasets, predictions instead of descriptions, and more general models\n\nHealthy skepticism is good though:\n\n\u003e \"The combination of some data and an aching desire for an answer does not ensure that reasonable answer can be extracted from a given body of data\"\n\u003e \n\u003e - John Tukey\n\nMain topics:\n- [[thoughts/exploratory data analysis|Exploratory Data Analysis]]\n- [[thoughts/supervised learning|Supervised learning]]\n- [[thoughts/No Free Lunch Theorem]]\n- [[thoughts/unsupervised learning|Unsupervised Learning]]\n- [[thoughts/gradient descent|Gradient Descent]]\n- [[thoughts/regularization|Regularization]]\n- Regression\n\t- [[thoughts/linear regression|Linear Regression]]\n\t- [[thoughts/multi-class classification|Multi-class classification]]\n- [[thoughts/binary classification|Binary classification]]\n- [[thoughts/maximum likelihood estimation|MLE]]\n- [[thoughts/latent-factor model|Latent-factor models]]\n- [[thoughts/recommendation system|Recommender System]]\n- [[thoughts/neural networks|Neural Networks]]\n- [[thoughts/convolutional neural networks|CNNs]]\n- [[thoughts/Autoencoders]]\n- [[thoughts/semantics#Deep Learning Semantics|Deep learning Semantics]]\n- [[thoughts/transformers|Transformers]]\n- [[thoughts/generative models|Generative Models]]\n\nRelated background:\n- [[thoughts/linear algebra|Linear Algebra]]\n- [[thoughts/probability|Probability]]\n- [[thoughts/calculus|Calculus]]\n\t- [[thoughts/automatic differentiation|Automatic Differentiation]]\n\n## Philosophy\n### GOFAI (good old-fashioned AI)\n-   this view believes that the mind is a computer with certain special characteristics — namely the fact that its internal states and processes can be regarded as thinking or reasoning\n-   finding meaning in a body of symbols, like finding rationality in a body of behaviour, is finding a certain kind of consistent, reliable pattern\n-   problem solvers often use canny, methodical exploration\n\t-   neither algorithmic nor random\n\t-   a familiar sort of articulate reasoning or thinking a problem out\n\t\t-   \"if only i could get that, then I could nail this down; but in order to get that, I would need such and such\"\n-   GOFAI is very narrow-minded and vulnerable to unexpected variations and oddities in the problems and information they were given\n-   grounded in the possibility of translation — semantic interpretation\n\n### NFAI (new-fangled AI)\n- see also: [[thoughts/neural networks]]\n-   falls under connectionism and [connectionist networks](thoughts/connectionist%20networks.md)\n\t- relies on computers the same way a weather service does, to simulate digitally systems that are not in themselves digital\n-   adept at finding various sort of similarities among patterns, at recognizing repeated (or almost repeated) patterns and filling in missing parts of incomplete patterns\n-   NFAI learns from examples (but not in the same way humans do)\n-   inspired by the structure of the brain, but more deeply, by the importance and ubiquity of non-formal pattern reasoning\n-   very grab-bag term → anything that isn't GOFAI\n-   argument that a lot of human intelligence is not embodied in anyone, its a part of the world: [Extended Mind Hypothesis](thoughts/Extended%20Mind%20Hypothesis.md)\n-   e.g. through the design of tools like hammers, our architecture, etc.\n-   definition of understanding → appropriates and takes charge of its own conceptual resources and grasps the point of them for itself\n\n","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/maintenance":{"title":"Maintenance","content":"\nMaintenance: the gritty upkeep work that keeps the [infrastructure](thoughts/infrastructure.md) of the world running.\n\n## [Incentivizing](thoughts/incentives.md) Maintenance\n*The Maintainers*: the individuals whose work keeps ordinary existence going rather than introducing novel things. Related to [paid open source](posts/paid-open-source.md), how do we incentivize maintenance?\n\nIs maintenance just the battle against the [tragedy of the commons](thoughts/tragedy%20of%20the%20commons.md)? \"Fundamentally, digital infrastructure has a free rider problem. Resources are offered for free, and everybody (whether individual developer or large software company) uses them, so nobody is incentivized to contribute back, figuring that somebody else will step in.\" [Source](https://techcrunch.com/2018/06/23/open-source-sustainability)\n\nWho are all the maintainers behind the thousands of libraries we depend on each day? Is maintenance a form of Ghost Work?\n\nCan we use [web3](thoughts/web3.md) to 'codify' maintenance as a value? Is maintenance inherently centralized (i.e. we need a centralized body to uphold a [public good](thoughts/public%20goods.md))\n\n## [Innovation](thoughts/innovation.md) is overvalued\n[Source: Hail the maintainers by *Andrew Russell and *](https://aeon.co/essays/innovation-is-overvalued-maintenance-often-matters-more)\n\n[The Maintainers Organization](https://themaintainers.org/) and their [fellowship](https://themaintainers.org/summer-fellow)\n\n\"What happens _after_ innovation, they argue, is more important. Maintenance and repair, the building of infrastructures, the mundane labour that goes into sustaining functioning and efficient infrastructures, simply has more impact on people’s daily lives than the vast majority of technological innovations.\"\n\n\"These shuttles brought high-tech employees from hip, pricey urban homes to their lush suburban campuses, without exposing them to the inconvenience of public transportation or to the vast populations of the poor and homeless who also call Silicon Valley their home.\" -\u003e similar to some concepts in [From Counterculture to Cyberculture](thoughts/From%20Counterculture%20to%20Cyberculture.md) talking about displacement of people during the 'back to the land'  movement by the New Communalists\n\n**It is crucial to understand that technology is not innovation.** This preoccupation with novelty is unfortunate because it fails to account for technologies in widespread use, and it obscures how many of the things around us are quite old.\n\nThe stalest innovation stories focus on well-to-do white guys sitting in garages in a small region of California, but human beings in the Global South live with technologies too. Which ones? Where do they come from? How are they produced, used, repaired?\n\nRelated: [Lindy Effect](thoughts/Lindy%20effect.md), [broken world thinking](thoughts/broken%20world%20thinking.md)\n\nThird, focusing on [infrastructure](thoughts/infrastructure.md) or on old, existing things rather than novel ones reminds us of the absolute centrality of the work that goes into keeping the entire world going. We need to acknowledge and attribute where we are today to the shoulders of the giants we stand on.\n\n\"Feminist theorists have long argued that obsessions with technological novelty obscures all of the labour, including housework, that women, disproportionately, do to keep life on track.\"\n\n## Maintenance and Care\n[Shannon Mattern in Places Journal](https://placesjournal.org/article/maintenance-and-care)\n\n\u003e “All of the incentives for all the actors are against maintenance. Nobody ever named a maintenance project, nobody ever got recognized for a maintenance project, nobody ever much got blamed for deferring maintenance during the time while they were in office.”\n\n### Rust: urban infrastructures\n\nOutsiders sometimes make the mistake of focusing on the rusty bridges and broken pipes — the “defective objects” themselves — whereas local fixers are more concerned with “the social and political relationships in which [those objects are] embedded.”\n\nAs Nikhil Anand writes in _Hydraulic City_, \"The maintenance of water infrastructures binds residents, plumbers, engineers, and politicians in an (uneven) system of “hydraulic citizenship.”\"\n\nWe should always ask: what, exactly, is being maintained? “Is it the thing itself,” Graham and Thrift ask, “or the negotiated order that surrounds it, or some ‘larger’ entity?” Often the answer is all of the above. \n\nWe should also remember that the preservation of our world — the human one — is sometimes at odds with caring for the ecological context. Perhaps not every road _should_ be repaired. Geographer Caitlin DeSilvey encourages us to embrace entropy within the built world, to ask ourselves _for whom_ we engage in preservation, and to consider cultivating an acceptance of “curated decay” where appropriate.\n\n### Dust: domestic maintenance, housework, care work\n\nMaintaining life — that’s a big job. Joan Tronto and Berenice Fisher define care as “everything that we do to maintain, continue, and repair ‘our world’ so that we can live in it as well as possible.\n\n**We care for things not because they produce value, but because they already have value.**\n\nAryn Martin, Natasha Myers, and Ana Viseu propose that a critical practice of care would “pay attention to the privileged position of the caring subject, wary of who has the power to care, and who or what tends to get designated the proper or improper objects of care.”\n\n### Cracks: repair of objects\n\n“repair not only extends the use value of objects but becomes a mechanism of social interaction.” People gather around, watch, and chat. The shop is a space of public pedagogy, an “operating theater” where the repairman opens gadgets, demonstrates technical skills, and perhaps encourages observers to mend rather than discard their own broken things\n\n### Corruption: curators who clean and maintain data\n\nHistorian Nathan Ensmenger reports that “from the early 1960s to the present, software maintenance costs have represented between 50 and 70 percent of all total expenditures on software development.”\n\nThe internal maintenance work isn’t supposed to be visible to end users, who tend to like the idea that they’re working with “raw” data. Yet “data never come as raw,” Plantin observes. “Multiple interventions are always needed before data can be reused.”","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/math":{"title":"Math","content":"\nThree pillars of Math\n1. Definitions: so you know what you're talking about, the communicate ideas to others, [[thoughts/boundary object|boundary object]]. In [[thoughts/distributed systems|distributed systems]] talks especially, disagreements over tech are actually just disguised disagreements over definitions (e.g. on what [[thoughts/decentralization|decentralization]] means, see also [[posts/new-words|word meaning]] and [[thoughts/semantics|semantics]])\n2. Theorems\n\t1. Possibility results (e.g. protocols like [[thoughts/Raft Consensus Algorithm|Raft]] or [[thoughts/Tendermint|Tendermint]]) articulate assumptions under which solution has desired properties\n\t2. Impossibility results (e.g. [[thoughts/PSL-FLM Impossibility Result|PSL-FLM]] and [[thoughts/FLP Result|FLP]] results) tell you to avoid wasting time trying to design something that cannot exist\n3. Proofs: arguments of why we know these theorems are actually true statements\n\t1. Can guide you to what the solution might look like (specifically, in the realm of possibility results)\n\t2. Can help you asses whether changes to the solution void the properties it originally had","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/maximum-a-posteriori-estimation":{"title":"Maximum a Posteriori (MAP) Estimation","content":"\nMaximizes $\\hat w \\in \\arg\\max_w \\{ P(w|D) \\}$\n\nGiven our data, what is the model $w$ is the best model?\n\nThis is connected to [[thoughts/maximum likelihood estimation|MLE]] through [[thoughts/probability#Bayes' Theorem|Bayes' Rule]]:\n\n$$P(w|D) = \\frac{P(D|w)P(w)}{P(D)} \\propto P(D|w)P(w)$$\n\nIntuitively, $P(w)$ is accounting for how 'likely' this model is. We can also treat this as a regularizer.\n\n$$\\begin{aligned}\n\\hat w \\in \\arg\\max_w \\{ P(w|D) \\} \u0026\\equiv \\arg\\max_w \\{ \\prod_{i=1}^n P(D_i|w)P(w)\\} \\\\ \u0026\\equiv \\arg\\min_w \\{ -\\sum_{i=1}^n\\log(P(D_i|w)) - \\log(P(w)) \\}\n\\end{aligned}$$\n\nWhere $-\\log(P(w))$ acts like the regularizing term. In fact, many regularizers are equivalent to negative log-priors.\n\n## Relation between regularized loss functions\n### L2-Regularized Least Squares\nIf we assume a Gaussian likelihood and a Gaussian prior, then MAP estimation is equivalent to minimizing $f(w) = \\frac{1}{2} \\lVert Xw-y \\rVert^2 + \\frac{\\lambda}{2} \\lVert w \\rVert^2$\n\n### L2-Regularized Robust Regression\nIf we assume a Laplace likelihood and a Gaussian prior, then MAP estimation is equivalent to minimizing $f(w) = \\lVert Xw-y \\rVert_1 + \\frac{\\lambda}{2} \\lVert w \\rVert^2$","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/maximum-likelihood-estimation":{"title":"Maximum Likelihood Estimation (MLE)","content":"\nMaximizes $\\hat w \\in \\arg \\max_w \\{ P(D|w) \\}$\n\nSuppose we have a dataset $D$ with parameters $w$. For example,\n1. We flip a coin three times and get $D = \\{ \\textrm{H}, \\textrm{H}, \\textrm{T} \\}$\n2. The parameter $w$ is the probability that this coin lands heads\n\nThe likelihood as a probability mass function $P(D|w)$. MLE is choosing a $\\hat w$ that maximizes the likelihood ($\\hat w \\in \\arg \\max_w \\{ P(D|w) \\}$)\n\n![[thoughts/images/mle-example.png]]\n\nIn the case above, $\\hat w$ is $\\frac 2 3$\n\n## Notation\nargmin and argmax return the set of parameter values achieving the minimum and maximum values respectively. For example:\n\n$$\\arg \\min_{w} \\{ (w-1)^2 \\} \\equiv \\{ 1 \\}$$\n\n$$\\arg \\min_{w} \\{ cos(w) \\} \\equiv \\{ \\dots, -2\\pi, 0, 2\\pi, \\dots \\}$$\n\nWe can also show that maximizing the MLE is equivalent to minimizing the negative log-likelihood. That is,\n\n$$\\hat w \\in \\arg\\max_w \\{ \\prod_{i=1}^n P(D_i|w) \\} \\equiv \\arg\\min_w \\{ - \\sum_{i=1}^n \\log(P(D_i|w)) \\}$$\n\nThis is true because logarithm is strictly monotonic so the location of the maximum doesn't change if we take the logarithm. Changing the sign flips the max to the min.\n\nThis is typically easier to compute as it turns a product of probability into a sum.\n\n## Generative vs Discriminative\n- Discriminative maximizes $P(y|X,w)$\n\t- Least squares, robust [[thoughts/linear regression]], logistic regression fall under this category\n\t- We don't model X so we can use complicated features\n- Generative maximizes $P(y,X | w)$\n\t- [[thoughts/Naive Bayes]]\n\t- Needs to model X\n\n## Relation between loss functions\n### Least squares (squared L2-loss of residuals)\nIf we let the likelihood function of the labels be Gaussian:\n\n$$P(y_i|x_iw) = \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{(w^Tx_i-y_i)^2}{2}\\right)$$\n\nThen the MLE of $w$ is the minimum of $f(w) = \\frac{1}{2} \\lVert Xw-y \\rVert^2$\n\n### Absolute error (L1-loss of residuals)\nIf we let the likelihood function of the labels be Laplacian:\n\n$$P(y_i|x_iw) = \\frac 1 2 \\exp(-\\vert x^Tx_i-y_i \\vert)$$\n\nThen the MLE of $w$ is the minimum of $f(w) = \\lVert Xw-y \\rVert_1$\n\n### Logistic loss\n$h$ is the sigmoid function $\\frac{1}{1+\\exp(-x)}$. If we let the likelihood function of the labels be\n\n$$P(y_i|w,x_i) = h(y_iw^Tx_i) = \\frac{1}{1+\\exp(-y_iw^Tx_i)}$$\n\nThen the MLE of $w$ is the NLL, which we can show to be equivalent to the logistic loss\n\n$$NLL(w) = \\sum_{i=1}^n\\log \\left( \\frac{1}{1+\\exp(-y_iw^Tx_i)} \\right) = \\sum_{i=1}^n \\log(1 + \\exp(-y_iw^Tx_i))$$\n\nLast part is true because of log rules ($-\\log(\\frac{1}{x}) = \\log(x)$).\n\n## Overfitting\nConceptually, MLE is saying that we should find the $w$ that makes $D$ have the highest probability given $w$. From [[thoughts/No Free Lunch Theorem]], we know that there is always a model that performs well for some unlikely $w$. This is overfitting!\n\nWe actually want to find the $w$ that has the highest probability given the data $D$. For this, we need [[thoughts/maximum a posteriori estimation|MAP]]","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/meaning":{"title":"Meaning","content":"\n\u003e If code is law, then are programmers the governors?\n\nA less philosophical discussion of [semantics](thoughts/semantics.md)\n\n[Source: Meaning in *Kernel*](https://kernel.community/en/learn/module-1/meaning)\n\n\"The fight for liberty is not conducted with natural language in the form of political rhetoric: it is **hashed out in technical protocols**.\"\n\nInteresting quote by Buckminster Fuller (who did a lot of pioneering work on geodesic domes): \"You never change things by fighting the existing reality. To change something, build a new model that makes the existing model obsolete\"\n\nWith respect to the argument that 'the fight for liberty' being a fight fought with technical protocols and not natural language is interesting. I think natural [[thoughts/language|language]] is absolutely necessary and that discourse is pretty similar to change itself. Shared [terminology](thoughts/terminology.md) and [labels](thoughts/quantization.md) for discourse is important for both. Change can happen based off of perceived improvement which is correlated with how well that improvement is communicated.\n\nSeems similar to [praxis](thoughts/praxis.md) debate, too many layers of abstractions on theory that is no longer grounded in practice becomes useless unless applied. The arguments then occur in the abstract definitions of the labels and less so how they actually apply. ","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/mechanism-design":{"title":"Mechanism design","content":"\n*Distributed Algorithmic Mechanism Design: Recent Results and Future Directions*. Joan Feigenbaum and Scott Shenker \n\nMechanism design asks how one can design systems so that agents’ selfish behavior results in the desired system-wide goals (similar to [[thoughts/incentives|incentive]] design)\n\nThe mechanism designer’s task is to find a formula for the payments that causes agents to be no worse off by revealing their true costs than they would be by lying about their costs\n\nMechanisms in which agents are asked to directly reveal their [[thoughts/utility|utility]] functions are call direct mechanisms\n\nA *dominant strategy* is one where agents only choose strategies that regardless of how other agents play, never result in lower payoffs than any other strategy.","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/meditation":{"title":"Meditation","content":"\n## A Traditional Account[^1]\n- bhāvanā = “bringing into being” certain types of mental states, qualities, and traits through repeated practice\n- śamatha(calm, tranquility): a state of sustained and stable attention, concentration.\n- Classical [mindfulness](thoughts/mindfulness.md), attempting to achieve states of\n\t- Remembering/recollecting (smṛti): holds an object in mind so as to prevent the mind from drifting away from it.\n\t- Clear comprehension (samprajanya): clear knowing through alert awareness of experience.\n- Nondual mindfulness\n\t- present-centred open awareness with \"mere nondistraction\"\n\n## A Cognitive Science Approach[^1]\n- Focused Attention\n\t- Directing attention towards an object (e.g. breathing)\n\t- Detecting mind wandering/distractions\n\t- Disengagement of attention from distractors\n\t- Leads to effortless sustained attention and ability to monitor attention and notice mind-wandering\n\t- [Study](https://pubmed.ncbi.nlm.nih.gov/15936259/) showing that focussed attention led to extreme increases in perceptual dominance both during and after meditation\n- Open Awareness\n\t- No explicit focus on objects\n\t- Nonreactive\n\t- Leads to acute awareness of phenomenal qualities of experience without ‘grasping’ (approach/avoidance).\n\n[^1]: This content is sourced from Professor [Evan Thompson](https://evanthompson.me/)'s course materials for PHIL451A at UBC. All rights to this content is retained by Evan Thompson.","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/memex":{"title":"Memex","content":"\n[Source](https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881) by Vannevar Bush\n\n\u003e device in which an individual stores all his books, records, and communications, and which is mechanized so that it can be consulted with exceeding speed and flexibility.\n\nBush envisioned the memex behaving like an “intricate web of trails” similar to the function of the human mind, which he believed works by a method of “association” and not via an alphabetical index. According to Levy (2008, 508), the most “innovative feature” of Bush’s memex system was the establishing of associative indices between portions of microfilmed text—what we now call [[thoughts/hypertext|hypertext]] links—so that researchers could follow trails of useful information through masses of literature.\n\n\u003e Tapping a few keys projects the head of the trail. A lever runs through it at will, stopping at interesting items, going off on side excursions. It is an interesting trail, pertinent to the discussion.\n\n## The web is not the memex\nSee also: [[thoughts/the garden and the stream]]\n\n1. A memex contains both original materials and the materials. Unlike the web, there is no read-only version of the memex. Anything you read you can link and annotate. Not just reply, but change\n2. Links are associative (read: backlinks)\n3. Links and annotations are made by readers as well as writers. A stunning thing that we forget, but the link here is not part of the author’s intent, but of the reader’s analysis. On the world wide web of course, only an author gets to determine links. What would it be like to have Curius-like annotations by default?\n\n","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/memory-palace":{"title":"Memory Palace","content":"\n## Method of Loci\n[Source: Method of Loci in *Wikipedia*](https://en.wikipedia.org/wiki/Method_of_loci)\n\nCan we create associations between digital/physical space and concept space? Create a digital library of our concepts and ideas?\n\n## Better ways to browse/discover ideas and concepts\n[More from Bret Victor and DynamicLand](http://worrydream.com/cdg/ResearchAgenda-v0.19-poster.pdf)\n\nRelated to better [interaction design](thoughts/interaction%20design.md). How do we better browse [information at different scales](thoughts/information%20scales.md)\n\nMaterial is dynamic and multi-medium\n\nConceptual connections between pieces of knowledge and branches can be visually seen and explored\n\nCan we bring together representations *across fields* so ideas can cross-pollinate?\n\nSupports\n1. Generalization: going from specific examples to an abstracted pattern\n2. Instantiation: going from abstraction to specific examples\n3. Analogy: diverse examples of the same pattern","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/mental-model":{"title":"Mental Models","content":"\nMental models (cognitive frameworks) help us understand how people reason and react to interface experiences. They provide predictive and explanatory power for understanding user behaviour.\n\nIt is an inner [representation](thoughts/representation.md) of a system.\n\n2 types:\n1. Internal frameworks: about the mental process inside user's head\n2. External frameworks: account for interactions with technologies, environment, and [context](thoughts/context.md)\n\nCharacteristics:\n-   constantly evolving\n-   not always an accurate representation (can contain errors and uncertainty measures)\n-   provide a simple representation of a complex phenomena\n\nModels are runnable. We use Norman's seven stage model\n1.  **Establish the goal** to be achieved\n2.  **Form the intention** for action (what should I do?)\n3.  **Specify the action** sequence (how do I do that?)\n4.  **Execute** the action sequence (let's see how it goes)\n5.  **Perceive** the system state (what am I seeing and hearing?)\n6.  **Interpret** the perceived system state (what's actually happening?)\n7.  **Evaluate** the system state (is this right?)\n\n(realistically, this model is only good for exploratory learning when a user is learning a system for the first time or for encountering error cases)\n\nIf a breakdown occurs on the **left** (2-4), we call that the **gulf of execution**: the difference between the intentions and allowable actions\n\nIf a breakdown occurs on the **right** (5-7), we call that the **gulf of evaluation**: the difference between the actual system state and user's understanding\n\n## Mental model vs Conceptual model\n-   mental models: something the **user has (forms)**\n    -   users **\"see\"** the system through mental models\n    -   users **rely** on mental models during usage\n    -   mental models can support or impede user's interaction\n-   [conceptual model](thoughts/conceptual%20model.md): something the **designer creates**\n\t-   essentially a high level description of how a system *should* work\n    -   to foster good mental model formation by the user\n\n![](/thoughts/images/mental-vs-conceptual.png)\n\n## Interface Types\nPrimarily concerned with:\n-   a function\n-   interaction style used\n-   input/output device used\n-   platform it's being designed for\n\nE.g.:\n-   command\n-   graphical\n-   multimedia\n-   virtual reality\n-   web\n-   mobile","lastmodified":"2023-02-15T01:38:21.501821358Z","tags":null},"/thoughts/message-broadcast":{"title":"Message broadcast","content":"\n## Ordering\n### Total order broadcast or Atomic broadcast\nGlobally consistent broadcast, agreement from all nodes (hard but can be done with consensus algorithms like [[thoughts/Raft Consensus Algorithm|Raft]]!)\n\nIn [[thoughts/State Machine Replication (SMR)|state machine replication]], total order broadcast assumes the state update function is **deterministic**. That is, whenever two replicas are in the same state, giving them the same input, they will transition to the same next state. The main limitation is that total order broadcast cannot update state immediately, have to wait for delivery through broadcast\n\nExamples: [[thoughts/HoneyBadgerBFT|HoneyBadgerBFT]]\n\n### Causal Broadcast\nObeys happens-before ([[thoughts/causality|causal]]) relationships.\n\nIn [[thoughts/State Machine Replication (SMR)|state machine replication]], assumed state update function is **deterministic and concurrent updates are commutative**. Replicas can process updates in different orders and still end up in the same state\n\n### FIFO (reliable) Broadcast\nMessages sent by the **same** node must be delivered in the order they were sent \n\nAssumes state update function is **deterministic + all updates are commutative**.\n\n### Best-effort\nNo ordering guarantees.\n\nAssumes state update function is **deterministic + commutative + idempotent + tolerates message loss**\n\n## Reliability\nNodes can die mid-transmission!\n\nTwo strategies for mitigating node-death:\n1. Eager reliable broadcast: first time a node receives a message, re-broadcast to each other node (reliable but expensive! $O(n^2)$ messages for $n$ nodes)\n2. Gossip: first time a node receives a message, forward it to $k$ other nodes, chosen randomly (reliable with high probability)\n\n## Retry semantics\n- At-most-once: send request, don't retry, update may not happen\n- At-least-once: retry request until acknowledged, may repeat update\n- Exactly-once: retry + [[thoughts/idempotence|idempotence]] / deduplication","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/metalabel":{"title":"Metalabel","content":"\n[Source: Metalabel.xyz](https://metalabel.xyz/)\n\n\u003e A group of people using a collective identity to communicate a perspective through a series of distinct releases that contribute to a greater whole\n\n## Elements\n1.  A core perspective or mission. That could be advocating for a certain perspective, aesthetic, region, idea, or about solving a problem and changing the world.\n2.  A principle (or group of principles) curating the output. Labels are ultimately trying to communicate an idea, incrementally, with each release. That means they need a consistent vision to successfully put an idea in the mind of the public. This means a level of creative leadership is required to curate what releases and artists are invited to be a part of the project.\n3.  Discrete releases. A label exists to put culture into the world, whether that’s music, ideas, a way of living, words, or something else. What makes a label unique from a person’s personal creative practice is that different people are invited to release work under the same banner. By constructing an umbrella under which multiple artists can sit, the label can generate more dialogue and “heat” because disparate nodes in the network are reflecting back similar ideals. What makes a label unique from a brand is that all of a brand’s efforts result in the promotion of a single product. In the case of a label, its efforts are always promoting different products that all relate to the same core aesthetics or ideals. \n4.  Information architecture. Record labels use catalogue numbers to sequence their releases. A similar sequencing or contextualizing of works is a key element of the label. It helps clue t he audience into the larger context of the work. This is already common in the new worlds of drop commerce and Web3, where concepts like “Seasons” have become used to conceptually organize content and community, bringing the language of fashion and television into broader cultural creation. This mixing is a hallmark of meta labeling.\n5.  A scene it participates in. Labels are at their best when they represent or are in dialogue with a thriving, organic scene or community. To truly be valuable, it must create value for the larger scene it’s a member of.\n6. A source of funding. Without funds to put into projects, any label is limited in its output. Previous labels used sales from their products to fund new releases, or someone’s existing personal wealth. In the world of Web3 and meta labels, these sources of funding are evolving","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/metaphysics":{"title":"Metaphysics","content":"\n\u003e _meta ta physika_ (\"after the things of nature\")\n\nIdeas that can't be reached through objective studies of material reality. Common areas of study are [[thoughts/ontology|ontology]] and [[thoughts/epistemology|epistemology]]","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/mimetic":{"title":"Mimetic","content":"\n[Source: Mimetic by *Brian Timar*](https://www.briantimar.com/notes/mimetic/mimetic/)\n\n[...There was a] positive feedback loop that encouraged me to spend ever-increasing amounts of time on my work. Humans inherit convictions [mimetically](https://en.wikipedia.org/wiki/Ren%C3%A9_Girard#Mimetic_desire) from each other — we learn what to value by imitating our peers. Maybe this is why we tend to want to conform to ingroup expectations in [communities](/thoughts/communities) so much?\n\nDangers of groupthink as these feedback loops loop into themselves and repeat: \n[collaborative-thinking](/posts/collaborative-thinking)\n\nAmong experimentalists, it’s not hard to find graduate students who can tell you every detail about how a particular machine operates, and almost nothing about why it should be built.\n\n## [Reading](thoughts/reading.md)\nSpeaking with authors through their written work triggers the same neural circuits that produce imitation of desire. By stocking a bookshelf judiciously, you can express a preference over preferences — “what should I value? What do I want to spend my waking hours thinking about?” — and act on it through careful, honest reading. This engineering is safe: most authors exert their influence slowly, over hundreds of pages, and if the effect turns out to be undesirable, you need only put the book down. It’s cheap and reliable — if you want to emulate someone, start by reading what they read. Most importantly, it’s _powerful_, because authors form a large part of the meta-peer group that determines which communities and games you engage with.","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/mind-body-problem":{"title":"Mind-Body Problem","content":"\nConcerned with how the mind and body are connected to one another\n-   are we just entirely made up of matter or is there something more?\n-   two points of doubt\n\t-   we know a bit about minds without knowing anything about brains\n\t-   are minds different from brains\n\t-   not true, they still might be the same thing\n\nApproaches\n-   [Materialism](thoughts/Materialism.md) (physicalism) → minds and brains are identical (identity theory)\n    -   nothing magical about minds, just the brains activity\n-   dualism → minds are distinct from the brain\n-   [[thoughts/idealism|idealism]] → everything is mental/in the mind\n\n## Considering other minds\n-   for own mind → introspection works, more or less\n-   for other minds → must rely on behaviour of others (what they say and do)\n-   two possible ways of understanding how this way of knowing other minds works\n    -   behaviourism → behaviour is all there is to mentality\n        -   seems inconsistent w introspection\n        -   we have thoughts that are never reflected in our behaviour\n        -   can have multiple thoughts that correspond with a behaviour → umbrella example\n            -   a man looks out of a window, goes to a closet and takes an umbrella before leaving his house\n            -   what is he thinking?\n            -   there are multiple possible thoughts that could've lead to his taking the umbrella\n    -   common-sense psychology (C-SP) -\u003e understand most likely correct interpretation\n        -  common-sense knowledge of other minds rests on knowledge of some general principles of the characteristic behaviour of people\n\t        -   He sees pretty much what we see when we look.\n            -   He doesn’t like most stuff that people don’t like (getting soaked).\n            -   He minimizes costs when possible.\n            -   In general, we attribute normal perceptual and reasoning abilities.\n        -  \"We attribute thoughts to him that it is reasonable for him to have, given those abilities.\"\n\n## Causal pictures\n-   thoughts are not directly perceivable, they lie behind and cause behaviour. as a result,\n\t1.  certain counterfactuals are true\n\t\t1.  if the thought never occurred, the behaviour would not have happened\n\t2.  thoughts _explain_ the behaviour\n\t3.  there are regularities (natural laws) that govern the connection\n-   someone performs an action for a reason when their reason is a cause of their action\n\t-   A did B for a reason C when C caused A to do B\n-   arguments for the causal picture\n\t-   when we try to explain why someone did something, only citing the causes seem adequate\n-   arguments against the causal pictures\n\t-   some behaviours seem to be more than just a symptom or effect of inner factors like thoughts","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/mindfulness":{"title":"Mindfulness","content":"\nWhat do I do when I am stressed or overcome with anxiety about the future? What about a terrible decision I feel like I've made or some [failure](posts/a-failure-resume.md)?\n\nI've found regular mindfulness sessions to be extremely helpful in easing my 'always-overthinking' brain.\n\nRelated: how can we be more [digitally mindful?](thoughts/digital%20mindfulness.md)\n\n## Self-guided Mindfulness\nI've tried guided meditions like the ones on YouTube and Headspace and such but find they don't work super well for me. I really like being intentional with what I want out of the meditation session and I find it helps me focus and stay present. Here is the process I find works best for me:\n\n1.  Start with focusing on breathing and bodily sensations. Are you comfortable? Is your head clear? Is your breath and heartbeat regular and relaxed?\n2. Ask an additional level of 'why's if anything feels out of the ordinary. Reflect on life situation + most current feelings.\n\nThen, if I am feeling stressed/anxious about anything in particular:\n1. Perspective and timescales. How will current events play out a month from now? A year? A decade?\n2. What doors can this open? We can choose to believe everything happens for a reason when looking back on it. Everything will play out regardless of what failures happens your way. The best I can do is make the most of my hand and make that the best possible future.\n3. How can I minimize regret? How do I avoid the [optionality](thoughts/optionality.md) fallacy?\n\nOr if things are going well:\n1. What is going well right now?\n2. Who am I grateful for?\n3. What was beautiful today?\n\n## Designing for busy-by-default\n[Source: Fools and their time metaphors by *Aaron Z. Lewis*](https://aaronzlewis.com/blog/2019/02/11/fools-and-their-time-metaphors/)\n\n\"The subjective quality of time—how it feels from the inside—is missing entirely. If the idea of a “subjective calendar” sounds too far-out, consider the [alternative maps](https://www.theatlantic.com/entertainment/archive/2011/05/human-cartography-maps-that-define-the-mind/238416/) made by creative cartographers. They add new meaning by distorting conventional representations of geography. Why can’t our calendars follow suit?\"\n\nSee also: [desire paths](thoughts/desire%20paths.md)","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/money":{"title":"Money","content":"\n\u003e Money is a form of shared truth\n\nSources: [Money Language *in Kernel*](https://kernel.community/en/learn/module-0/money-language) and [Shelling Out *in Kernel*](https://kernel.community/en/learn/module-2/shelling-out)\n\nMoney is old. \"We have yet to discover a civilization that didn't have money. So, we know it's at least as old as civilization.\"\n\nMoney is a [[thoughts/language|language]] through which to communicate value. Then, was does this mean for [decentralization](thoughts/decentralization.md)? No one should control the expression of economic value in exactly the same way that no one controls the meaning of words: they are arrived at consensually through common use.\n\nWhat money is, how it is created, and who gets to distribute it goes to the very heart of the ways in which we are all incentivised to act\n\n[Incentives](thoughts/incentives.md) can be thought of as the [social, political and neurobiological primitives](thoughts/social%20contracts.md) which define what kinds of behaviours we express.\n\n\u003e Programmable money provides [[thoughts/utility|utility]] which makes it much more than just money for the internet: **it turns it into the [internet](thoughts/Internet.md) of money**.\n\nMoney allows specialization, allowing goods and services to be transformed into a intermediary representation that is accepted by society.\n\n## Master-slave vs [Peer-to-peer](thoughts/peer-to-peer.md)\nDifference between hierarchical and [decentralized](thoughts/decentralization.md) methods.\n\nQuestion is \"who is the slave\"? Supposedly the those that need to follow the interfaces that the master dictates, there is no 'ownership'.\n\nWhat does this mean in the context of efficiency in systems? [Consensus](thoughts/consensus.md) takes a long time. Decentralized methods are hard to get right. Is the tradeoff worth it? At what point do we trade good user experience with rights of data ownership?\n\n## Money and Speech\n\n\u003e Free as in beer or free as in speech? -- Richard Stallman\n\nFreedom of speech means that our *ability to speak* is free, but that doesn't mean we can say whatever we want (e.g. hate speech and defamation).\n\nSimilarly for [web3](thoughts/web3.md), access to the network is unrestricted (you only need a connection), but saying anything meaningful (e.g. state changing on the shared public record) has an associated cost. Thus certain behaviours we agree to be malicious (like creating fake transactions) are not disallowed, but just economically unsustainable.\n\nWouldn't this favour the rich? Well yes, but we can mitigate this by using weighting like [quadratic voting/funding](thoughts/quadratic%20funding.md) which values number of unique contributions more than dollar amounts.\n\n### Taxes\nLaffer curve: as the tax rate increases, the rate at which revenue increases slows down due to increased avoidance, evasion, and disincentive to engage in the taxed activity.\n\nThis can be applied to the rise and fall of empires: \"governments that overburdened their taxpayers, such as the Soviet Union and later Roman Empire, ended up on the dust-heap of history, while governments that collected below the optimum were often conquered by their better-funded neighbors.\"\n\n(Although, might not be [100% valid](https://qz.com/895785/laffer-curve-everything-trump-and-republicans-get-wrong-about-trickle-down-economics-and-reaganomics/amp/))\n\n### Dispute Resolution\n\u003e Most pre-modern cultures, ranging from the Iriquois in America to the pre-Christian Germanic peoples, decided that payment was better than punishment\n\nCurious if the main reason is that you need to keep track of whether someone has served their punishment or not and memory historically has been unreliable. On the contrary, you don't need to remember whether you were paid because you can just count your money.\n\nThe question applied to [web3](thoughts/web3.md): **can we advance the aims of rehabilitative justice using a shared and common historical record for better [accountability](thoughts/accountability.md)?**\n\n## Engineering Money\n\u003e Money-as-a-[protocol](thoughts/Protocol.md) really allows us to do is program incentives at scales never before possible\n\nMoney, in this context, is not a concrete thing, its an abstraction to communicative values, as a language, and as a technology. It is a classifier for things that exhibit behaviour that lets us use it for\n1. Store of Value\n2. Medium of Exchange\n3. Unit of Account\n\nMore importantly, there are tradeoffs in the above properties.\nGold is a great store of value but sucks as a medium of exchange (interesting tangent, the traditional heuristic that money *should* have inherent intrinsic value which is separate from the money but the truth is almost the opposite. If the medium used to express transactional relationship has its own value, its not a very functional abstraction).\n\nHistorically, like physical materials, we've just accepted properties the way they are and just built what we could with them. However, also like physical materials, we've found ways to engineer the fundamental properties that we want.\n\nHowever, it feels liek we run into a weird [catch 22](thoughts/catch%2022.md) here where it is debatable whether the new 'engineered money' actually does have the properties we claim to have so it holds us back from developing/accepting it any more. I think this is in large part due to money being a combination of both **technical protocols and [social contracts](thoughts/social%20contracts.md)**\n \nAndreas' argument is that we can use abstract monetary protocols which we can engineer to change gradually higher-order social contracts.","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/monism":{"title":"Monism","content":"\nMonism holds that ultimate reality is *all of one kind and one kind only*.\n\nMore familiar forms of monism:\n- [[thoughts/idealism|Idealism]]\n- [[thoughts/Materialism|Materialism]]\n\n## Neutral Monism\nThe intrinsic nature of ultimate reality is neither mental nor physical (between idealism and materialism)\n\nMuch like interiors and exteriors, in Russel's account the mental and physical imply and necessitate each other as reflection of a single (hence monistic) nature","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/morphology":{"title":"Morphology","content":"\n\u003e The system for combining units of meaning\n\n- Morpheme: the smallest unit of meaning in a language\n\t- Free morphemes can occur alone\n\t- Bound morphemes cannot\n- Order of acquisition of phonemes (Brown 1973)\n\t- Morphemes come in in a consistent order (within a language)\n\t- The order is predicted based on a variety of factors, including the salience and consistency of form-meaning mapping\n\t- Same factors can predict differences between languages (in languages with more salient affixes and consistent form-meaning mappings children learn the morphology earlier)\n- The U-shaped curve\n\t1. Rote memorization (child stores the forms they hear) – higher accuracy\n\t2. Rule acquired and over-applied – lower accuracy\n\t3. Rule acquired but children also know there are exceptions – higher accuracy","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/move-fast-and-break-things":{"title":"Move Fast and Break Things","content":"\n\u003e To slow down is to end up [default dead](http://www.paulgraham.com/aord.html); the rhythm and pace of how technology is supposed to be built does not allow for consideration of social consequences. (Jasmine Wang)\n\n[Samson](https://www.samsonzhang.com/2021/01/19/how-to-innovate-and-create-a-culture-of-innovation.html) and [Engelbart](https://www.dougengelbart.org/content/view/348/000/)\n\nMoving fast but not breaking things\n\nA activity -\u003e core business activity (actual value producing activities)\nB activity -\u003e reduce product-cycle time, make faster, smarter, higher-quality A activities (increase velocity)\nC activity -\u003e reduce improvement-cycle time, make faster, smarter, higher-quality B activities (increase acceleration)\n\nThis is exactly what I mean when I talk about \"bootstrapping.\" It is a very American term – the image is of someone able to perform the wonderful, impossible trick of pulling himself up by pulling up on his own bootstraps – but the idea is one that we put into practice every time that we \"boot up\" a computer. A small bit of code in a permanent read only memory knows how to go out to the disk to get more instructions, that in turn know how do to even more things, such as getting even more instructions. Eventually, this process of using successive steps to lead to ever bigger steps, building on each other, get the whole machine up and running. You start small, and keep leveraging what you know at each stage to solve a bigger and bigger problem.\n\n## The Coming Software Apocalypse\n[Source: The Coming Software Apocalypse by James Somers](https://outline.com/AKHJUv)\n- occasionally shift the pile of sand so it settles in a more stable configuration\n- take time to understand the actual tech youre working on and the problems you're trying to solve\n- talk it out with people\n\n“The problem is that software engineers don’t understand the problem they’re trying to solve, and don’t care to,” says Leveson, the MIT software-safety expert. -\u003e [software and politics](thoughts/software%20and%20politics.md)\n\n","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/multi-class-classification":{"title":"Multi-class Classification","content":"\n## One vs All\nSuppose we only know how to do [[thoughts/probabilistic classifier|probabilistic binary classification]]. But we have $k$ classes we want to distinguish between. We can\n- For each class $c$, train binary classifier to predict whether example is a $c$.\n\t- This creates $k$ binary classifiers\n- On prediction, apply the $k$ binary classifiers to get a “score” for each class $c$.\n- Predict the $c$ with the highest score (argmax)\n\nThis divides the space into convex regions (much like [[thoughts/K-means]])\n\nNotation: $w_{y_i}$ denotes a classifier where $c = y_i$\n\n## Loss\nProblem: how can we define a loss that encourages the largest $w_c^Tx_i$ to be $w_{y_i}^Tx_i$?\n\nBasically, for each $x_i$ we want\n- $w_{y_i}^Tx_i \u003e w_c^Tx_i$ for all $c$ that is not the correct $y_i$\n- We write $w_{y_i}^Tx_i \\geq w_c^Tx_i + 1$ to avoid the strict inequality\n- This is the constraint we use!\n\n\n### Sum\nPenalizes each $c$ that violates the constraint\n\n$$\\sum_{c \\neq y_i} \\max\\{0, 1-w_{y_i}^Tx_i + w_c^Tx_i\\}$$\n\n### Max\nPenalizes the $c$ that violates the constraint the most\n\n$$\\max_{c \\neq y_i} \\{ \\max\\{0, 1-w_{y_i}^Tx_i + w_c^Tx_i\\} \\}$$\n\nAdding L2-[[thoughts/regularization|regularization]] turns both into multi-class [[thoughts/SVM|SVMs]]. Both are convex upper bounds on the 0-1 loss.\n\n## Multi-class Logistic Regression\nSimilarly, we can smooth out the max with the log-sum-exp trick to get something differentiable and convex:\n\n$$f(w) =\\sum_{i=1}^n \\left[ -w_{y_i}^Tx_I + \\log(\\sum_{c=1}^k \\exp(w_c^Tx_i))\\right] + \\frac{\\lambda}{2}\\sum_{c=1}^k\\sum_{j=1}^d w_{cj}^2$$\n\nWe can rewrite the last term as $\\lVert W \\rVert^2_F$ (the Frobenius norm of the matrix $W$).\n\nThis is equivalent to binary logistic loss for $k=2$\n\nSee also: [[thoughts/probabilistic classifier#Multi-class Probabilities|multi-class probabilities]]","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/multiple-realization":{"title":"Multiple Realization","content":"\nAre there multiple ways of realizing intelligence?\n\n[The bitter lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)\n-   a bitter lesson\n    -   reframing data?\n        -   speech data → audio features / mfcc\n        -   inadvertently taking away the ability to make new insights based of restrictions\n    -   how do we explore more of the solution space\n        -   feedforward → linear relationships\n        -   sigmoid → non-linear\n        -   what other solution spaces are we missing\n-   do we necessarily need human intelligence for machine intelligence?\n* Are we constraining solution space with human heuristics?","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/neural-networks":{"title":"Neural networks","content":"\nSee also: [[thoughts/convolutional neural networks]]\n\n## Shallow Networks\nMany domains require non-linear transforms of the features (see: [[thoughts/change of basis]]). Usually not obvious which transform to use.\n\n**Neural network models try to learn good transformations**. Whereas [[thoughts/latent-factor model]]s train the embedding and model separately, neural networks learn both features and the model at the same time.\n\nLet $k$ be the number of hidden units. Generally, $\\hat y_i = v^Th(Wx_i)$ (or, with bias, $\\hat y_i = \\sum_{c=1}^k v_ch(w_c^Tx_i + \\beta_c) + \\beta$)\n\n![[thoughts/images/single-layer-ann-diagram.jpg|500]]\n\nArtificial neural network:\n- $x_i$ is measurement of the world\n- $z_i$ is internal representation of world\n\t- Each $h(z_i)$ can be viewed as binary feature: do we care about it or not?\n\t- Use sigmoid as a smooth approximation\n- $y_i$ is output of neuron for classification/regression\n\nParameters: the (k,d) matrix $W$, and (k) vector $v$. To turn this into [[thoughts/multi-class classification]], we modify $v$ into a (k', k) matrix (where k' is the number of classes) and convert to probabilities by computing the softmax of the $\\hat y_c$ values\n\nLosses:\n- [[thoughts/binary classification|Binary Classification]]: $f(W,v) = \\sum_{i=1}^n \\log(1+\\exp(-y_iv^Th(Wx_i)))$\n- [[thoughts/linear regression|Regression]]: $f(W,v) = \\frac{1}{2} \\sum_{i=1}^n (v^Th(Wx_i)-y_i)^2$\n\n### Training\nGenerally non-convex as W and v are both variables. As such, finding the global optimum is NP-Hard. We can use [[thoughts/gradient descent#Stochastic Gradient Descent (SGD)]] but this is not guaranteed to reach a global optimum due to non-convexity.\n\n### Implicit Regularization\nOften, increasing $k$, the number of hidden units, improves test error. This seems at odds with the [[thoughts/fundamental tradeoff|fundamental tradeoff]], doesn't it?\n\n\nHowever, learning theory (trade-off) results analyze global min with worst test error. The actual test error for different global minima will be better than worst case bound. Among the global minima, SGD is somehow converging to “good” ones! Empirically, using SGD is like using L2-Regularization, but the regularization is “implicit”.\n\nWith small models, “minimize training error” leads to unique (or similar) global mins. With larger models, there is a lot of flexibility in the space of global mins (gap between best/worst).\n\nWe get results that look like the following: \n\n![[thoughts/images/double-descent curves.png]]\n\n## Deep Learning\nInstead of a single layer of hidden units, we can stack them.\n\n$$\\begin{aligned}\n\\hat y_i \u0026= v^Th(W^{(m)}h(W^{(m-1)}h(\\dots W^{(1)}x_i))) \\\\\n\u0026= v^T(I_{l=1}^mh(W^{(l)}x_i)) \u0026 \\textrm{Where } I \\textrm{ is repeated function composition}\n\\end{aligned}$$\n\n### Vanishing Gradient Problem\nThe gradient of the sigmoid function away from the origin is nearly zero. This is worse when you take the sigmoid of a sigmoid of a sigmoid...\n\nIf these are numerically set to 0 because of how small they are, [[thoughts/gradient descent#Stochastic Gradient Descent (SGD)]] will not make progress\n\nThis is partially solved by replacing the sigmoid activation with the ReLU activation. Alternatively, can also use skip connections that 'shortcuts' between layers\n\n### Philosophy of Deep Learning\n-  No universally accepted explanation as to why they work so well, just really a form of [classification](thoughts/object%20classification.md)\n-  The \"Golden age network\" had 3 main properties\n\t1.  shallow → no more than three or four layers between input and output\n\t2.  uniform → only one type of node deploying a sigmoidal activation\n\t3.  fully connected → each node from a lower layer connected to each other in the next layer\n-   Depth, hierarchy of parts intuition\n    -   Analogy of assembly line mass production of automobiles\n        -   One person is skeptical of the significance of assembly lines → \"any thing that can be made by the assembly line could, in theory, be made by a team of skilled machinists\"\n        -   Other person believes that the assembly line is more efficient, specialized, and reusable\n            -   Each unit can grow increasingly specialized and better at a small range of simpler tasks reliably and efficiently\n            -   Standardization of units across automobiles\n    -   sum-product network example\n        -   simple device for computing polynomial functions\n        -   shallow networks → must compute the expanded expressions of that function (skilled but inefficient machinists)\n        -   deep networks → can compute the factorized expression of the polynomial function\n            -   show that they can compose simple operations\n-   heterogeneity\n    -   different types of operations composed together\n    -   dccns → conv layer followed by relu followed by max pooling\n        -   good at detecting features in a variety of different locations/poses\n    -   combining all three operations means we can product a simplified, transformed representation of the source image\n        -   can get more complex/abstract as you move deeper through the layers\n-   sparse connectivity\n    -   heuristic → only local pixels matter\n    -   dramatically reduces number of learned parameters\n-   [[thoughts/regularization]]\n    -   input preturbations\n        -   rotations/scaling/transformations\n        -   noise\n    -   dropout\n    -   L1 regularization → favours simpler/sparser solutions by causing weights to fall to 0 if a large gradient is not maintained\n\n#### So why are they so effective?\n-   hierarchical feature composition\n-   vector space separation\n\t-   input can be realized as a feature space\n\t-   output can be realized as manifolds or regions in the feature space\n\t-   training is just then learning the manifolds/regions that create desired categories\n-   most commentators agree that current deep learning methods fall short of implementing general intelligence, and it remains an open question as to whether some modification of current deep learning methods will be able to do so -\u003e question of [intelligence](/thoughts/intelligence)\n-   self-learning algorithms like AlphaZero (which learns from self-play) seem to disprove/vindicate the empiricist approach (need real world experience to learn)\n    -   counterargument is that systems like AlphaGo have built in knowledge about the rules of Go and mechanisms to explore possible outcomes one at a time (e.g. Monte Carlo Tree Search for the solution space)\n\n#### Cognition and [Intelligence](/thoughts/intelligence)\n[Potemkin village](thoughts/potemkin%20village.md) analogy for approximating intelligence.\n\n#### Brain-like networks\n-   biological similarities\n\t-   CNNs have high sensitivity to spots, edges, and bars in specific orientations\n\t-   echoes the work of hubel and wiesle (1962) which found similar patterns in the feline visual cortex\n-   can record a single neuron but very difficult to record patterns\n-   functional vector → vector that corresponds to one of the output classes\n-   speech example, network managed to recover phonetic hierarchical information\n-   both systems have created a system of internal representations that corresponds to important distinctions and structures in the outside world\n-   theories → representations that allow networks to \"make sense\" of their corpus and respond in a fashion that reduces error\n-   how do we explain 'conceptual change'?\n\t-   knowing a creature's vector-space partitions may suffice for short-term prediction of behaviour but inadequate to predict or explain the evolution of those partitions over the course of time\n\t-   just knowing output space partitions is not enough, but connection weights seems to provide a level that meets all of these conditions\n-   neural networks have decently high [[thoughts/fault tolerance|fault tolerance]] (some redundant neurons)\n\t-   may help to explain functional persistence of brains in the face of minor damage\n\t-   in a large network, a loss of a few neurons will not make a huge impact, but the quality of its computations will progressively degrade\n\n#### Differences\n-   real neural networks arent fully connected like ANNs\n-   real neural networks have horizontal cell-to-cell connections within a given layer which are not present in ANNs\n-   real brains don't use backprop via generalized delta rule\n\t-   back prop requires\n\t\t1.  computing partial derivates to minimize error\n\t\t2.  propagating deltas through the network back to relevant connections\n\t-   little empirical evidence for this in biological brains\n-   real brains show a progressive reduct in reaction time as one learns\n\t-   not seen in ANNs where error decreases but prediction time remains constant\n-   ANNs require a 'global truth' or teacher\n\t-   these 'perfect' signals are not present in the real world\n-   Hebbian learning\n\t-   those who 'vote with winners, become winners'\n\t-   can be used to produce learning in ANNs but not nearly as effective as backprop","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/neutrality":{"title":"Neutrality","content":"\n## Net Neutrality\n*The Neutrality Pyramid: A Policy Framework to Distribute Power Over the Net* by Juan Ortiz Freuler\n\n\u003e Neutrality: “It is fundamental to our right to freedom of expression that any and all parties who exercise control over any layer of our channels of communication respect the integrity of the message that is being delivered.”\n\nNet neutrality: separating the content layer from the connectivity layer. The rhetoric was that if we kept layers separate, it creates more value for everyone\n1. More users mean more clients for ISPs\n2. Better quality of internet service provided by ISPs is a win for users\n\nTo protect the virtuous circle, **we can and should apply the core principles of net neutrality to other layers.** (see [[thoughts/Rhizome Proposal|Rhizome proposal]])\n\n![[thoughts/images/neutrality pyramid.png]]\n\nWe currently have device and net neutrality (mostly) but we should push for platform and data neutrality.\n\nLeveraging the pyramid:\n1. Seeing the pyramid: Users should be aware of who the intermediaries are at each layer. If intermediaries do not respect our rights, we should shift to more decent providers.\n2. Observing behaviours within each layer: we need to promote enforceable rules to ensure that each level of the pyramid will be kept from abusing its gatekeeping powers. This requires open standards for [[thoughts/interoperability|interoperability]]\n3. Observing dynamics between layers: we need to promote enforceable rules that ensure intermediaries do not illegitimately discriminate between the actors operating in the other layers of the pyramid","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/niche-at-scale":{"title":"Niche at scale","content":"\n\"Tokyo, a city where a number of unusual stores exist: Stores that only sell vinyl records from the 1970s, or that only sell whisky from the 1980s.\n\nPut those stores in a Des Moines suburb and they will obviously fail. But in Tokyo, where 20 to 30 million people can reach the city by train, there are likely to be a few thousand people who love 1970s albums or 1980s whiskey.\n\nThe internet is Tokyo.\" ([Source](https://www.inc.com/jeff-haden/small-business-ideas-startup-ideas-start-a-business-entrepreneur-mark-cuban-how-to-decide-which-side-hustle-to-start.html))\n\n\"In the future, everyone will be world-famous for 15 minutes.\" -- [Andy Warhol](https://en.wikipedia.org/wiki/15_minutes_of_fame)\n","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/object-classification":{"title":"Object Classification","content":"\n## Data to Model\n### Random Sample Consensus (RANSAC)\n1. randomly choose minimal subset of data points necessary to fit model\n2. points within some distance threshold of model are a consensus set, the size of the consensus set is the model's support\n3. repeat for N samples, model with biggest support is most robust fit\n\nChoosing number of samples $k$\n1. let $\\omega$ be the fraction of inliers\n2. let $n$ be the number of points needed to define hypothesis (e.g. $n=2$ for a line)\n3. suppose $k$ samples of $n$ points are chosen. then\n\t1. the probability that all $n$ in a sample are correct is $\\omega^n$\n4. the probability that all $k$ samples fail is $(1-\\omega^n)^k$, thus we choose a $k$ large enough to keep this below a targe failure rate\n\nAdvantages\n- general method\n- easy to implement and calculate failure rate\nDisadvantages\n- only handles a moderate percentage of outliers without cost blowing up\n- many real problems have high rate of outliers (e.g. noise)\n\n### Hough Transform\n- For each token, vote for all models to which the token could belong\n- Return model with most votes\n\ne.g. for each point, vote for all lines that *could* pass through it; true lines will pass through many points and thus receive many votes\n\nTurning image space into parameter space. Rearranging $y = mx + b$ into $y - mx = b$ where $b$ and $m$ are the variables instead of $y$ and $x$.\n\nWe can alternative transform it using Book's Convention: $x\\sin(\\theta) + y\\cos(\\theta) + r = 0$. Then, $x\\sin(\\theta) + y\\cos(\\theta) = \\rho$\n\nAdvantages\n- Can handle high percentage of outliers: each point votes separately\n- Can detect multiple instances of a model in a single pass\nDisadvantages:\n- Complexity of search time increases exponentially with the number of model parameters\n- Can be tricky to pick a good bin size\n\n## Classification\nClassifier is a procedure that accepts as input a set of features and outputs a prediction for the class label.\n\n### Standard Bag-of-Words pipeline\n1. Dictionary Learning: learn visual words using clustering\n2. Encode: build Bags-of-words vectors for each image\n3. Classify: train and test data using BOW ([[thoughts/KNN|KNN]], [[thoughts/Naive Bayes|naive Bayes]], [[thoughts/SVM|SVM]])\n\n### Bayes Rule\nSee: [[thoughts/probability#Bayes' Theorem|Bayes' Theorem]]\n\nDecision boundary, the location where one class becomes more probable than the other (e.g the point where the probability classes are equal). \n\nThe Bayes' risk is the shaded region where one class's probability is still non-zero beyond its decision boundary.\n\n![](/thoughts/images/bayes-risk.png)\n\nSee also: [[thoughts/probability|probability]]\n\n### ROC Curve\nTrade-off between true positive rate and false positive rate. A random classifier will always have 1:1 true positive and false positive rate\n\n![](/thoughts/images/roc-curve.png)\n\n### Parametric vs Non-parametric\n- Parametric classifiers rely on a model\n\t- fast, compact\n\t- flexibility and accuracy depend on model assumptions\n- Non-parametric classifiers are data driven (rely on comparing to training examples directly)\n\t- slow\n\t- highly flexible decision boundaries \n\n### Spatial Pyramid\nHave multiple scales of the input image to compute histograms across. Train a classifier for each scale along with a combined weight to combine each classifier.\n\n### VLAD (Vector of Locally Aggregated Descriptors)\nInstead of incrementing the histogram bin by a single count, we increment it by the residual vector $x - c(x)$ (diff between cluster center and feature vector)\n\nDimensionality is $Kd$ where $K$ is number of codewords and $d$ is the dimensionality of the local descriptor (128 for SIFT)\n\n## Decision Tree\nSee notes on [[thoughts/decision tree|decision trees]]\n\n### Classifier Boosting\n- Train an [[thoughts/Ensemble method|ensemble]] of classifiers sequentially\n- Bias subsequent classifiers to correctly predict training examples that previous classifiers got wrong\n\n## CNNs\nSee notes on [[thoughts/convolutional neural networks|CNNs]]","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/object-detection":{"title":"Object Detection","content":"\n## Template Matching\nLinear filtering is also known as template matching. Convolution/correlation can be thought of as comparing a template (the kernel) with each section of the image.\n- Consider the filter and image section as vectors\n- Applying the filter can be interpreted as computing the dot product between the filter and the local image patch\n\nThe correlation is then normalized to between -1 and 1 using cosine similarity, where 1 is the value when the filter and image region are identical. This process is essentially finding the cosine similarity between template and local image neighbourhood\n\n$$\\cos\\theta = \\frac{a \\cdot b}{|a||b|} = \\frac{a \\cdot b}{\\sqrt{(a \\cdot a)(b \\cdot b)}} = \\frac{a}{|a|} \\frac{b}{|b|}$$\n\nThen, we can map over the image and create a correlation map. Thresholding this gives us detections.\n\nGood:\n1. Robust against noise\n2. Relatively easy to compute\nBad:\n1. Scaling (we can address this using scaled representations like a Gaussian image pyramid)\n2. Rotation\n3. Lighting conditions\n4. Sensitive to viewing direction and pose (in 3D worlds)\n\n### Gaussian Image Pyramid\nCollection of representations of an image. Typically, each layer of the pyramid is half the width and half the height of the previous layer. In the Gaussian version, each layer is smoothed by a Gaussian then resampled to get the next layer.\n\nDetails get smoothed out (are completely lost) as we move to higher levels, only large uniform regions of colours in the original image are left.\n\n![Upsampling Process](https://miro.medium.com/max/1016/1*Q9UKqUC6OqpR3KL1yRrXxA.png)\n\n### Laplacian Pyramid\nTo do this, create a Gaussian pyramid and take the difference between one pyramid level and the next after smoothing but before subsampling. \n\nAt each level, retain the residuals (difference between smoothed image and normal image) instead of the blurred images themselves.\n\nConstructing the pyramid, we repeat until min resolution reached:\n1. Blur\n2. Compute Residual\n3. Subsample\n\nReconstructing, we repeat until original resolution reached:\n1. Upsample\n2. Blur\n3. Sum with residual\n\n## Local Feature Detection\n\u003e Moving from global template matching to local template matching (e.g.edges and corners)\n\nAs differentiation is linear and shift invariant, we can implement it as a convolution.\n\nThe discrete approximation is $\\frac{\\partial f}{\\partial x} \\approx \\frac{F(X+ \\Delta x, y) - F(x,y)}{\\Delta x}$ where $\\Delta x$ is usually $1$. This is equivalent to a convolution $F$ is a $1 \\times 2$ filter with the first element is $-1$ and the second element is $1$. Note that the derivatives go up for the Y direction and the right for the X direction.\n\nWe usually smooth the image prior to derivative estimation. Increased smoothing\n- eliminates noise edges\n- makes edges smoother and thicker\n- removes fine detail\n\nWeights of a filter for differentiation should sum to 0 as a constant image should have derivative 0.\n\n### Edge Detection\nThe goal here is to identify sudden changes in image brightness as this encodes the vast majority of shape information.\n\nAn edge is a location with high gradient.\n\nMainly caused by\n- Depth discontinuity\n- Surface orientation discontinuity\n- Reflectance discontinuity (e.g. change in material)\n- Illumination discontinuity (e.g. shadows)\n\nAs we usually smooth prior to derivative calculation and convolution is associative, we can combine both steps and use derivatives of Gaussian filters.\n\n$$D \\otimes (G \\otimes I(X,Y)) = (D \\otimes G) \\otimes I(X,Y)$$\n\n#### Sobel (Gradient Magnitude)\nLet $I(X,Y)$ be an image. Then, we let $I_x(X,Y)$ and $I_y(X,Y)$ be estimates of the partial derivatives in the $x$ and $y$ directions, respectively. Then, the vector $[I_x, I_y]$ or $\\nabla f = [\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}]$ is the gradient and $\\sqrt{I_x^2+I_y^2}$ is the gradient magnitude.\n\nThe gradient points in the direction of most rapid increase of intensity. The direction is then $\\theta = \\arctan{\\frac{\\frac{\\partial f}{\\partial y}}{\\frac{\\partial f}{\\partial x}}}$. The strength of the edge is then the magnitude $||\\nabla f|| = \\sqrt{\\frac{\\partial f}{\\partial x}^2 + \\frac{\\partial f}{\\partial y}^2}$.\n\n#### Marr/Hildreth (Laplacian of Gaussian)\n**Design Criteria**\n1. localization of space (find where the edge is)\n2. localization in frequency (identify high frequency and low frequency edges)\n3. rotationally invariant (rotation shouldn't affect edges)\n\nFind the zero-crossings (intercepts) of the Laplacian of the Gaussian. This is $\\nabla^2 G(x,y) = \\frac{-1}{2\\pi\\sigma^4}[2-\\frac{x^2+y^2}{\\sigma^2}]\\exp{(-\\frac{x^2+y^2}{2\\sigma^2})} = 0$\n\nAlternatively, we can say that subtracting the delta function from the Gaussian gives you an approximation of the Laplacian\n\n#### Canny (Local Extrema of 1st deriv)\n**Design Criteria**\n1. good detection (reduce missed edges, reduced edges where edges don't exist)\n2. good localization (accurate edge detection)\n3. one (single) response to a given edge\n\nFind the local extrema of a first derivative operator.\n\nSteps\n1. Apply directional derivatives of Gaussian\n2. Computer gradient magnitude and gradient direction\n3. Perform non-max suppression\n\tNon-max suppression allows us to suppress near-by similar detections to obtain one \"true\" result. In images, we select the maximum point across the width of the edge (following the direction of the gradient).\n \n\tIn implementations, the value at a pixel $q$ must be larger than its interpolated values at $p$ (the next pixel in the direction of the gradient) and $r$ (the previous pixel in the direction of the gradient). Interpolate as needed.\n4. Linking and thresholding\n\tTrying to fix broken edge chains by linking separate edge pixels through taking the normal of the gradient and linking it if the nearest interpolated pixel is also an edge pixel. Accept all edges over low threshold that are connect to an edge over high threshold.\n\t\n|Author|Approach|Detection|Localization|Single Resp|Limitations|\n|--|--|--|--|--|--|\n|Sobel|Gradient Magnitude Threshold|Good|Poor|Poor|Thick edges|\n|Marr/Hildreth|Zero-crossings of 2nd Derivative|Good|Good|Good|Smooths Corners\n|Canny|Local extrema of 1st Derivative|Best|Good|Good||\n\n### Boundary Detection\nHow closely do image edges correspond to boundaries that humans perceive to be salient or significant? \n\nOne approach is using circular windows of radii $r$ at each pixel $(x,y)$ cut in half by a line that bisects the circle in half. Then, compare visual features on both sides of the cut and if the features are statistically different, then the cut line probably corresponds to a boundary.\n\nFor statistical significance:\n1. Compute non-parametric distribution (histogram) for left side\n2. Compute non-parametric distribution (histogram) for right side\n3. Compare two histograms, on left and right side, using statistical test\n\nExample features include\n- Raw Intensity\n- Orientation Energy\n- Brightness Gradient\n- Color Gradient\n- Texture gradient\n\nFor this implementation, we consider 8 discrete orientations ($\\theta$) and 3 scales ($r$)\n\n### Features\nCorners are locally distinct 2D image features that (hopefully) correspond to a distinct position on a 3D object of interest in the scene.\n\nCannot be an edge as estimation of a location along an edge is close to impossible (the aperture problem)\n\n### Autocorrelation\nCorrelation of the image (distribution of pixel values) with itself. At each pixel, compute its partial derivative w.r.t. either the $x$ or the $y$ axis, $I_y = \\frac{\\partial I}{\\partial y}, I_x = \\frac{\\partial I}{\\partial x}$.\n\nWindows on an edge will have autocorrelation that falls of slowly in the direction of the edge but rapidly orthogonal to the edgge. Windows on a corder will have autocorrelation that falls off rapidly in all directions.\n\n#### Harris Corner Detection\nAs a stats reminder, covariance is the *direction* of the correlation. The closer the covariance is to 1, the closer it is to a perfect positive correlation. -1 implies perfect negative correlation.\n\nWhen drawing distrubtion, draw normals to edges going from low values (dark) to high values (white).\n\n1. Compute image gradients over small region\n2. Compute covariance matrix $$\\begin{bmatrix}\\sum_{p \\in P}I_xI_x \u0026 \\sum_{p \\in P}I_xI_y \\\\ \\sum_{p \\in P}I_yI_x \u0026 \\sum_{p \\in P}I_yI_y\\end{bmatrix}$$ (essentially fitting a quadratic to the gradients over the small image patch $P$)\n4. Computer eigenvectors and eigenvalues of the covariance matrix.\n5. Use threshold on eigenvalues to detect corners ($\u003e0$ is a corner)\n\nWe can visualize the covariance matrix $C$ as an ellipse whose axis lengths are determined by the eigenvalues and orientation determined by $R$ (the rotation matrix). It tells us the dispersion of the gradients nearby.\n\nAs $C$ is symmetric, we have the covariance matrix as the ellipse equation\n\n$$f(x,y) = \\begin{bmatrix}x \u0026 y\\end{bmatrix}\\begin{bmatrix}1 \u0026 0 \\\\ 0 \u0026 1\\end{bmatrix}\\begin{bmatrix}x \\\\ y\\end{bmatrix} = \\textrm{const}$$\n\nWhere the minor axis is $\\lambda_{max}^{-1/2}$ and the major axis is $\\lambda_{min}^{-1/2}$\n\nThen, this is what the eigenvalues tell us:\n- Case 1 (both $\\lambda_1$ and $\\lambda_2$ are close to zero): flat region\n- Case 2 ($\\lambda_2$ is much greater than $\\lambda_1$): horizontal edge\n- Case 3 ($\\lambda_1$ is much greater than $\\lambda_2$): vertical edge\n- Case 4 ($\\lambda_1$ are both rather large $\\lambda_2$): corner\n\nTo threshold, we can pick a function\n1. Harris \u0026 Stephens: $\\lambda_1 \\lambda_2 - \\kappa (\\lambda_1 + \\lambda_2)^2$ which is equivalent to $\\det(C) - \\kappa \\textrm{trace}^2(C)$. $\\kappa$ is usually 0.4 or 0.6.\n2. Kanade \u0026 Tomasi: $\\min(\\lambda_1, \\lambda_2)$\n3. Nobel: $\\frac{\\det(C)}{\\textrm{trace}(C)+\\epsilon}$\n\n#### Linear Algebra Aside/Review\nGiven a square matrix $A$, a scalar $\\lambda$ is called an **eigenvalue** of $A$ if there exists a nonzero vector $v$ that satisfies\n\n$$Av = \\lambda v$$\n\nThe vector $v$ is called an eigenvector for $A$ corresponding to the eigenvalue $\\lambda$. The eigenvalues of $A$ are obtained by solving $\\det(A-\\lambda I) = 0$\n\n## Keypoint Description\n### Scale Invariant Features (SIFT)\nDavid Lowe\n\nInvariant to translation, rotation, scale, and other imaging parameters. (Generally works for about ~20% change in viewpoint angle)\n\nAdvantages:\n- Locality: features are local (robust to occlusion and clutter)\n- Distinctiveness: individual features can be matched to a large database of objects\n- Quantity: many features can be generated (even for small objects)\n- Efficiency: fast (close to real-time performance)\n\nDescribes both a **detector** and **descriptor**\n1. Multi-scale local extrema detection\n\t- Use difference of gradient pyramid (3 scales/octave, down-sample by a factor of 2 each octave)\n2. Keypoint localization\n\t- We then remove low constrast or poorly localized keypoints. We can determine good corners by using the covariance matrix! (Threshold on magnitude of extremum, ratio of principal curvatures)\n3. Orientation assignment\n\t- Create histogram of local gradient directions computed at selected scale multiplied by the gaussian kernel at the center\n\t- Assign canonical orientation at peak of smoothed histogram (mode)\n4. Keypoint description (SIFT Descriptor)\n\t- histogram of local gradient directions\n\t\t- (8x(4x4)) = 128 dims\n\t\t- 4x4 = 16 histograms\n\t\t- 8 orientations each\n\t- Normalized to unit length to reduce the effects of illumination change\n\tRobust to affine changes (rotation and scaling)\n\t\n### Histogram of Oriented Gradients (HOG)\n- uses 8x8 cells and blocks which consist of 2x2 cells\n- then for each cell, create a histogram of 'unsigned' gradients\n\t- perform soft binning (adding to one bin also adds to neighbour bins)\n- concatenate then L2 normalize\n- 15x7x4x36 = 3780\n\n### 'Speeded Up' Robust Features (SURF)\n- 4x4 cell grid of 5x5 cells\n- each cell is represented by 4 values\n\t1. sum of all x derivatives\n\t2. sum of all y derivatives\n\t3. abs of 1\n\t4. abs of 2\n- use Haar wavelets filters (simple derivative filters where all black on one side and all white on the other, weighted by gaussian)\n- 4x4x4 = 64 dims\n\n## Object Recognition\n1. Match each keypoint to the database of keypoints\n\tTo find out probability of correct match, we can compare the ratio of distance between nearest neighbour and 2nd nearest neighbour. A threshold of 0.8 provides great separation.\n2. identify clusters of at least 3 features that agree on an object and pose\n\tLowe uses a generalized Hough transform\n3. check each cluster found by performing detailed geometric fit of affine transformation to the model\n4. accept/reject interpretation accordingly\n\t\n### Approximate Nearest Neighbour\n- generally, finding nearest neighbour in high-dimensional data is linear in time (even for KD trees)\n\n### Transformations\nDegrees of freedom (DOF)\n1. translation: 2\n2. rigid (euclidean): 3\n3. similarity: 4\n4. affine: 6\n5. projective: 8","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/ontology":{"title":"Ontology","content":"\n\u003e Ways of being\n\nThe nature of being and structures of objects. Ontology seeks the classification and explanation of things. A branch of [[thoughts/metaphysics|metaphysics]].\n\n## Heidegger\nConcept of dasein, which literally means 'Being-there'. Through the use of this expression, Heidegger calls to attention the fact that a human cannot exist or be taken into account without existing in [context](thoughts/context.md) of a world with other things -- \"to be human is to be fixed, embedded, and immersed in the physical, literal, tangible day to day world\"\n\n### Near-ness\n- Heidegger observes that because of technology, “all distances in time and space are shrinking” and “yet the hasty setting aside of all distances brings no nearness; for nearness does not consist in a small amount of distance.”\n- See also [[thoughts/Tools for Conviviality|Tools for Conviviality]]\n\n### Essence\n- The essence of technology is not something we make; it is a mode of being, or of revealing. ... To consider technology essentially is to see it as an event to which we belong: the structuring, ordering, and “requisitioning” of everything around us, and of ourselves.\n\n## Technology\nTechnology as it relates to ontology.\n- technology is not just neutral: [[thoughts/Do Artifacts Have Politics|artifacts have politics]]\n- artifacts shape and create ways of being\n- \"design is ontological\"\n\t- civic design + [[thoughts/urban planning|urban planning]] are also importantly ontological\n\t- designing spaces of dwelling + being\n\nThe train changed the way we exist -- it expands the vista of existence. We are betting on new means of technology for new ways of being, ones attuned to interdependence, mutuality, etc. Emphasizing the ontology of interdependence over the ontology of separation.\n\nMy understanding of Heidegger on technology is that it is about a _reorganization_ of the world, both spatially and temporally. It is this same reorganization or framing that “orders” all things we know (e.g. point 2) — see modern theories of God and consciousness referring to [[thoughts/Primary of Consciousness#The Blind Spot|quantum microtubules]] to try to explain them. Technology then, is a way of ‘challenging’ existing means of knowledge in a way that reframes it.\n\nHeidegger sees technology as potentially dangerous in that it instrumentalizes the human and the subjective and “displaces” things from their unmediated existence.\n\n\u003e \"how do we reconcile technology with conviviality + care for the web of life?\"\n\nSee also: [[thoughts/prefigurative politics|prefigurative politics]]","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/optical-flow":{"title":"Optical Flow","content":"\nDetermine how objects (and/or the camera itself) move in the 3D world\n\nDifficulty comes as motion is geometric whereas optical flow is radiometric (about an origin)\n\nSee also: [aperture problem](thoughts/aperture%20problem.md)\n\n### Constraint Equation\nLet image intensity be denoted by $I(x,y,t)$. Then, applying chain rule, we obtain $\\frac{dI(x,y,t)}{dt} = I_x\\frac{dx}{dt} + I_y\\frac{dy}{dt} + I_t$.\n\nLet $u = \\frac{dx}{dt}$ and $v = \\frac{dy}{dt}$. Then $[u, v]$ is the 2D velocity space.\n\nIf we set $\\frac{dI(x,y,t)}{dt} = 0$, then we get the **optical flow constraint equation**: $I_xu+I_yv + I_t=0$.\n\nWe assume constant brightness for this, meaning $I(x(t), y(t), t) = C$.\n\nWe measure each of the following:\n- Spatial Derivative: $I_x = \\frac{\\partial I}{\\partial x}$, $I_y = \\frac{\\partial I}{\\partial y}$\n\t- Forward difference\n\t- Sobel filter\n\t- Scharr filter\n- Optical Flow: $u = \\frac{dx}{dt}$, $v = \\frac{dy}{dt}$\n\t- We need to solve for this! (the unknown in the optical flow problem)\n- Temporal Derivative: $I_t = \\frac{\\partial I}{\\partial t}$\n\t- Frame difference\n\n### Lucas-Kanade\nA dense method to compute motion $[u,v]$ at every location in an image.\n\nWhere can you see movement that can be effectively computed? A corner!\n\nSolve for $\\mathbf v$ in $\\mathbf v = (A^TA)^{-1}A^Tb$ where $\\mathbf v$ is the 1-by-2 column matrix of $u$ and $v$. $A$ is the $n$-by-2 column matrix of $I_x(q_i)$, $I_y(q_i)$ partial derivatives evaluated at point $q_i$ ($A$ is actually the same matrix $C$ used in Harris corner detection). $b$ is the 1-by-$n$ matrix consisting of the negative of the temporal partial derivative for each point.\n\n$$A = \\begin{bmatrix}I_x(q_1) \u0026 I_y(q_1) \\\\ I_x(q_2) \u0026 I_y(q_2) \\\\ \\vdots \u0026 \\vdots \\\\ I_x(q_n) \u0026 I_y(q_n)\\end{bmatrix} \\qquad v=\\begin{bmatrix}V_x \\\\ V_y\\end{bmatrix} \\qquad b = \\begin{bmatrix}-I_t(q_1) \\\\ -I_t(q_2) \\\\ \\vdots \\\\ -I_t(q_n)\\end{bmatrix}$$\n*Lucas-Kanade Method*\n\nAssumptions\n- Motion is slow enough that partial derivatives $I_x$, $I_y$, and $I_t$ are well-defined\n- The optical flow constraint equation holds ($\\frac{dI(x,y,t)}{dt} = 0$)\n- Window size is chosen so that motion $[u,v]$ is constant in the window\n- Window size is chosen so that the rank of $A^TA$ is 2 for the window (required inverse exists)\n\n## Stereo\nComputing depth from multiple images. Formulated as a correspondence problem: dtermine match between location of a scene point in one image and its location in another.\n\nDisparity: $d = x - x' = \\frac{bf}{Z}$ where $b$ is baseline, $x$ is distance from $O$ to epipolar line, and $x'$ is distance from $O'$ to epipolar line. $Z$ is distance from $b$ to target $X$. \n\nSimple stereo algorithm\n1. Rectify images (make epipolar lines horizontal)\n\t1. Rectified images have these properties:\n\t\t1. Image planes of cameras are parallel\n\t\t2. Focal points are at same height\n\t\t3. Focal lengths are the same\n\t\t4. Epiolar lines fall along the horizontal scan lines\n2. For each pixel\n\t1. Find epipolar line\n\t2. Scan line for best match\n\t3. Compute depth from disparity\n\nNaive approach, pixel-based often lacks content. What we can try is min SSD-error of a window-based approach.\n\nAnother approach is to match the edges (the zero-crossings) at different scales.\n\nNote: Sum squared differences (SSD) is the same as Normalized Cross Correlation (NCC)","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/optionality":{"title":"Optionality","content":"\n\u003e \"I can never be all the people I want and live all the lives I want. I can never train myself in all the skills I want. And why do I want? I want to live and feel all the shades, tones and variations of mental and physical experience possible in my life.\" -- Sylvia Plath\n\nOptionality: the nature of accepting the possibilities of the unknown, to give every fractal self a chance to live.  _I’d much rather know, but then again, not-knowing keeps all the possibilities open. It keeps all the worlds alive._ [Source](https://reading.supply/@jessica/some-comfort-for-the-time-being-64k4Ml)\n\n\u003e \"This individual has merely acquired stamps of approval and has acquired safety net upon safety net. These safety nets don’t end up enabling big risk-taking—individuals just become habitual acquirers of safety nets. The comfort of a high-paying job at a prestigious firm surrounded by smart people is simply too much to give up. When that happens, the dreams that those options were meant to enable slowly recede into the background. For a few, those destinations are in fact their dreams come true—but for every one of those, there are ten entrepreneurs, artists, and restaurateurs that get trapped in those institutions.\" -- [Mihir Desai on Optionality](https://www.thecrimson.com/article/2017/5/25/desai-commencement-ed/)\n\nAs humans, we tend to love 'exploring' our possibilities more than 'exploiting' and diving deep/committing to what we already have -- we lean heavily toward explore in the [exploit explore](thoughts/exploit%20explore.md) tradeoff curve.\n\nThis is the [optionality fallacy](https://nesslabs.com/optionality-fallacy).\n\nIn a life like the one we live in where cause and consequence is extremely hard to distinguish due to the huge number of confounding variables, trial and error reigns supreme. Though, this doesn't mean trying everything really quickly and abandoning things if results don't manifest (ahem, talented kid burnout syndrome)\n\n\u003e Tinkering and experimenting is a more efficient investment of your time than following a set path of learning which assumes an intrinsic value in specific skills and ignores the non-linear way life works.\n\n\"Accumulate optionality through differentiation, not conformity\" [recommends](https://twitter.com/eriktorenberg/status/1244857973383421954) Torenberg\n\nMaybe why humans constantly chase [prestige](thoughts/prestige.md): to keep doors open as a means of cross-disciplinary recognition.\n\n## Paradox of Choice\nIndividuals are *more* likely to be stressed from a larger number of options as considering more choices requires more mental effort.\n\n## Requiem for a Dream\n[New Yorker on Aaron Swartz](https://www.newyorker.com/magazine/2013/03/11/requiem-for-a-dream)\n\n“I’ve hired a lot of very talented programmers, and one of the things I discovered was that the people who didn’t graduate from college couldn’t finish projects,” his father says. “Because when you go to college, there’s all sorts of stupid stuff you have to do in order to get through.”\n\n\u003e It is a vertiginous thing to have so much freedom—to be always self-skeptical, always testing the reasons for your beliefs, always prepared to abandon them for something better. If you can do anything you want, then every day becomes an existential problem—an empty space of possibility that has no ceiling but also no walls and no floor.\n\n## Making the Decision Right\n[Sarah on Substack](https://limminal.substack.com/p/making-the-decision-right)\n\nWhat I’ve come to learn over the past year is that there are two types of people: people who make the right decision and people who make the decision right.\n\n*Optimizing for optionality seems like the rational thing to do, until I really looked at my life. I had all these “options,” but I hadn’t done any of them.*\n\nI choose the next thing and make it the best.","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/organizing-system":{"title":"Organizing Systems","content":"\n_Organizing System_: an [intentionally](thoughts/intentional%20arrangement.md) arranged collection of resources and the interactions they support. It has authoritative description and standard classification. \n\nIt should enable interactions that allow users to achieve their [goals](thoughts/design%20goals.md).\n\nWe organize\n- physical things (objects/artefacts)\n- information about physical things\n- digital things\n- information about digital things (metadata)\n\nGood organizing systems are\n1. Skimmable at different levels. Is there a 5s version? A 60s version?\n2. Transformable. Can the user transform the data into different representations without having to explicitly define these ahead of time?\n3. Context-sensitive. Not one size fits all, can we create unique content for every reader/reading depending on their prior understanding and current needs?\n4. Interrogable. Can we get clarifications and answers from the text without having the author having to anticipate those questions?\n\nThe document as an 'information container', but also a 'thing' which documents a thing. Data can be seen as 'elementary observations about properties of objects, events, and their environments'\n\nA set of resources is then transformed by an organizing system when the resources are described or arranged to enable interactions with them.\n\n### Tradeoffs\n\u003e The effectiveness of a system for accessing information is a direct function of the intelligence put into organizing it (Svenonius, 2000)\n\nThere are inherent tradeoffs in an organizing system, what is the goal? What are we optimizing for?\n\nSimilar to [research debt](thoughts/research%20debt.md) where there is no effort put into the initial organizational process so the mental burden of retrieving information is much higher.\n\n### Goals\n1. Storing\n2. Retrieving\n3. Minimizing effort to find (increased scale means increased difficulty of finding things)\n\nNot all users have the same goals! How do we address this?\n\n### Three Tiers of Organizing Systems\n1. User interface or presentation components where users or other applications interact with the data\n2. Business logic or functions that use the data\n3. Storage of data itself\n\n![Presentation, Logic, and Storage Tiers](https://berkeley.pressbooks.pub/app/uploads/sites/121/2020/04/Figure-1.2.jpg)\n\n### Design Heuristics\nSensemaking: organizing to derive meaning from experience by fitting new events of observations into what they already know\n\nQuestions to ask\n1. What? What is orgnaized, what type of resource or information object?\n2. Why? What are the goals of the system?\n3. How Much? How many different organization schemes are used?\n4. When? When is the organization of the resource imposed? At the creation of the resource?\n5. How, and by whom? Who is doing the organizaiton? Professional indexers? Algorithms?\n6. Where? Can be abstract ideas like the cloud or physical loike infrastructures and build environments.\n\nSimilar to the questions in the HCI [design requirements](thoughts/design%20requirements.md). When designing an organizing system, it is important to consider domain, scope, and scale.\n\n#### What\n1.  the scope and scale of the collection\n2.  the number and nature of users\n3.  the time span or lifetime over which the organizing system will operate\n4.  the physical or technological environment in which the organizing system is situated\n5.  the relationship of the organizing system to other ones that overlap with it in domain or scope\n\n### General organizing principles\n1. We organize collections of resources using the properties that are easiest to perceive, or whose values vary the most among the items in the collection\n2. We group together resources that we often use together\n3. We put rare or unique resources where we can protect them\n\nExamples of these are 1. alphabetical ordering or 2. chronological ordering\n\nThis scoping process is similar to the [double-diamond design](thoughts/design%20requirements.md) in [HCI](thoughts/human%20computer%20interaction.md).\n\n## The Filing Cabinet\n[Source](https://placesjournal.org/article/the-filing-cabinet-and-20th-century-information-infrastructure)\n\nThe shift from bound volumes (sets of books) to filing systems was extremely significant in the history of classification.\n\nThe currently accepted version of the filing cabinet is attributed to the Library Bureau, the Boston-based company founded in 1876 by Melvil Dewey (the guy who invented the Dewey decimal system)\n\nStill reinforced gendered division of labour though -- \"female file clerks were expected to handle papers, but not to understand their contents; in contrast, it was male managers and executives who read the files, performing jobs that purportedly required thought\"\n\nMostly made popular by efficiency, exploitation of gendered labour, anxiety over information loss, and granular certainty (wanting to break more and more of life into discrete, [quantized, and labelled](thoughts/quantization.md) parts)\n\n[Information](thoughts/information.md) then, was seen as something that could be standardized atomized, and stripped of context.\n\nNow though, the filing cabinet is \"no longer an exemplar of productivity and speed, the file cabinet now embodies the facility of bureaucracies to produce paper, to delay, to leave us waiting\" -- it can create an alternative paper-based reality to which officials reflexively defer.\n\nCuriously enough, piles of paper on a desktop can be both symbols of \"overwhelmed white collar worker confronted with information processing long coded as clerical\" but also \"exemplary information management practice\". In fact, a well-kept pile of papers can be more efficient than a linear index (very similar to the ethic of grab what you need and rely on internal organization than some explicit organizational system). Does this apply to the [Desktop Metaphor](thoughts/interaction%20design.md)?\n\nIs Google search the 21st century filing cabinet?","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/originality":{"title":"Originality","content":"\nIs anything ever new? Is everything derivative\n\nLavoisier once said: \"Rien ne se perd, rien ne se crée, tout se transforme\" — meaning \"Nothing is lost, nothing is created, everything is transformed.\" (when applied to fundamental physics)\n\nIdeas are mostly recombination, does this imply that everything comes from one 'original' idea? ","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/outlier-detection":{"title":"Outlier detection","content":"\nFind observations that are unusually different from the others (aka anomaly detection).\n\nWhy? We may want to remove outliers, or be interested in the outliers themselves (security)\n\n**Generally does not work**. It can be hard to decide when to report an outlier. There are always new ways to make outliers!\n\n5 Types of outlier detection\n1. Model-based methods\n\t- See if z-score is past a certain threshold\n\t- Unfortunately, z-score assumes uni-modal data\n2. Graphical approaches\n\t- Look at a plot, human decides if data is an outlier\n\t- Unfortunately only in max 2-3 dimensions\n3. Cluster-based methods\n\t- Cluster the data\n\t- Find points that do not belong to clusters\n4. Distance-based methods\n\t- How many points lie in a radius $\\epsilon$?\n\t- Global outliers\n\t\t- For each point, compute the average distance to its KNN\n\t\t- Outliers are points that are far from their KNNs\n\t- Local outliers\n\t\t- Outlierness ratio of example $i$ is the average distance of $i$ to its KNN over the average distance of neighbours of $i$ to their KNNs\n5. Supervised-learning methods\n\t - Use [[thoughts/supervised learning]]: $y_i = 1$ if $x_i$ is an outlier, $y_i - 0$ if $x_i$ is a regular point\n\t - Needs supervision: we need to know what outliers look like\n\n## Local vs global outliers\nIt’s hard to precisely define “outliers”\n\n![[thoughts/images/outlier example.png]]\n\n- In the first case it was a “global” outlier.\n- In this second case it’s a “local” outlier:\n\t- Within normal data range, but far from other points.","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/pace-layers":{"title":"Pace Layers","content":"\n![Pace Layers image from Stewart Brand in The Clock of the Long Now](/thoughts/images/pace-layers.png)*The order of civilization. The whole combines learning with continuity.*\n\nCoined by Stewart Brand in 1999.\n\nSee: [[thoughts/Mangrove Theory of the Internet|Mangrove Theory of the Internet]], [[thoughts/Bentoism|Cross-time-scale planning (Bentoism)]]\n\nYou can't have a healthy forest of all old-growth and towering canopies. You can't have a healthy forest of only weeds, bushes, and saplings.\n\nDiversity is resilience.\n\nAll complex systems have different 'paces' at which they operate. Some near the top are faster changing, learning with the trends and the movements of the day to day, others are slow and methodical, remembering and holding power. \n\nThe six Pace Layer levels in descending order from the highest \u0026 fastest to the lowest \u0026 slowest are Fashion, Commerce, Infrastructure, Governance, Culture, Nature.\n\n\u003e Working down from the fast and attention-getting to the slow and powerful... Note that as people get older, their interests tend to migrate to the slower parts of the continuum. Culture is invisible to adolescents but a matter of great concern to elders.  Adolescents are obsessed with fashion while elders are bored by it.\n\n## Physics (and trust) as a new pace layer\nProposing a layer even below nature: physics. This are the axioms of the universe that seem unchanging (at least in the real world) but are actually configurable in the digital. (see: [Lattice](https://twitter.com/latticexyz))\n\n[Trust](thoughts/trust.md) is enabled through consistent accessibility\n-   You can't trust if you don't know if something will be available\n-   Thus [blockchain](thoughts/blockchain.md) is a means of enabling trust, re: trusting objects and [Extended Mind Hypothesis](thoughts/Extended%20Mind%20Hypothesis.md)\n-   physics has infinite availability\n-   legitimacy is a pattern of higher order acceptance (vitalik)\n-  blockchains as digital physics (the bottom layer of trust)\n\n## Internet Pace Layering\n[Gordon Brander on Substack](https://subconscious.substack.com/p/layered-protocols)\n\n\u003e The pace layering is partial—evolved layering is relaxed layering—but we can definitely see chronological shearing reflected by the cycle times of different layers of the stack. Hardware and programming languages tend to evolve on the decades timescale. Operating systems tend to release every few years. Apps, every month. Content is instant.\n\n","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/page-layout":{"title":"Page Layout","content":"\nPage layout is the art of manipulating a user's attention on a page to convey meaning, sequence, and point of interaction.\n\n## Visual \nMechanisms\n-   upper-left-corner preference\n-   whitespace\n-   contrasting fonts\n    -   the bigger and bolder, the more important the info\n-   contrasting foreground and background colours\n    -   eg. putting white text on a black background\n-   positioning, alignment, and indenting\n    -   indented text is subordinate to whatever's above it\n-   graphics like lines, boxes, coloured bars\n    -   things in a box or group go together\n\nFlow\n-   remember tendency to read top-to-bottom and left-to-right (at least, in the west)\n-   **focal point:** spots your eyes can't resist going to\n    -   tend to follow them from strongest to weakest\n    -   better pages only have a few — having too many dilutes the importance\n-   meaning and context play a big part in visual flow → perceived meaning of page content will change where the user chooses to look\n\n## Placement\n-   **proximity:** put things close together, and viewers will associate them with one another\n-   **similarity:** if two things are the same shape, size, color, or orientation, then viewers will also associate them with each other\n-   **continuity:** our eyes want to see continuous lines and curves formed by the alignment of smaller elements\n-   **closure:** want to see simple closed forms, like rectangles and blobs of whitespace, that aren't explicitly drawn for us","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/pain":{"title":"Pain","content":"\n## Belief that pain is the unit of effort\nSource: [alkjash on LessWrong](https://www.lesswrong.com/posts/bx3gkHJehRCYZAF3r/pain-is-not-the-unit-of-effort)\n\n\u003e With this belief, the injunction \"actually try\" means \"put yourself in as much pain as you can handle.\" Similarly, \"she's trying her best\" translates to \"she's really hurting right now.\"\n\nPeople with this belief optimize for the appearance of suffering. Wait until you meet someone for whom _telling them about opportunities actively hurts them_, because you've just created another knife they feel pressured to cut themselves with.\n\nAntidotes\n1. If it hurts, you're probably doing it wrong. That's just bad form.\n\t1. So much of this applies to the physical (e.g. working out) why don't we apply this to our emotional and mental selves?\n2. You're not trying your best if you're not happy.\n\n**Motivation in Hard Times**\n[John in vlogbrothers](https://www.youtube.com/watch?v=oAEewFj_-dg)\n\n\"[worked fuelled by resentment and pain] may burn bright, but it also burns dirty\"","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/paperclip-optimizer":{"title":"Paperclip optimizers","content":"\nOn [LessWrong](https://www.lesswrong.com/tag/paperclip-maximizer)\n\nThe paperclip maximizer is the canonical thought experiment showing how an artificial general intelligence, even one designed competently and without malice, could ultimately destroy humanity. The thought experiment shows that AIs with apparently innocuous values could pose an [existential threat](https://www.lesswrong.com/tag/existential-risk).","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/pattern-matching":{"title":"Pattern Matching","content":"\n[*Science as Seeing* in Aeon](https://aeon.co/essays/seeing-is-not-simple-you-need-to-be-both-knowing-and-naive)\n\nIf prior patterns are essential for making sense of things, how can we avoid falling into well-worn channels of perception? And most importantly, how can we learn to see in genuinely new ways?\n\nTo say that we construct idealised categories is not to say that patterns in the world don’t already exist, but that we must learn how to see them in the world around us.\n\nIf the brain is a taxonomising (see: [[thoughts/terminology#Terminological anchoring|terminological anchoring]] and [[thoughts/language of thought|Language of thought]]) engine, anxious to map the things and people we experience into familiar categories, then true learning must always be disorienting. Learning shifts the internal constellation of the firings of our nerves, the star by which we set our course, the spark of thought itself.\n\nSeeing is a multipartite process, requiring a comparison between noisy signals and [[thoughts/conceptual model|idealised models]].","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/peer-to-peer":{"title":"Peer to peer","content":"\nIn contrast to client-server models, peer-to-peer systems are [[thoughts/decentralization|decentralized]] [[thoughts/Network Theory|networks]] with no privileged nodes. Each node performs the same roles as any other.\n\nExamples include [[thoughts/BitTorrent|BitTorrent]], [[thoughts/blockchain|blockchains]], [[thoughts/Rhizome Proposal|Rhizome]]\n\n## Databases\n[Source](https://blog.mauve.moe/posts/peer-to-peer-databases)\n\n- Limitations of Operation logs\n\t- \"... scenarios where somebody is following a lot of users with a lot of history in SSB and needing to wait for all the logs to be processed, or when a new database replica is added and needs to fetch all the existing state (whether it's a regular DB or a blockchain full node).\"\n\t- \"One way to get around needing to 'catch up' with a writer is to get 'snapshots' of the current state of the data from trusted peers\"\n\t\t- However, the naive approach does not work in peer-to-peer situations as we can't verify the legitimacy of the whole snapshot\n\t\t- Can we utilize ZK proofs here?\n\t- Overall, unsolved. All of this together leads to either a [[thoughts/inevitability of centralization|centralization]] of power in long-lived nodes that do the replication for you due to preferential attachment\n- Actual databases use indices\n\t- \"For example, instead of an application getting a list of every single post in a database and filtering based on the 'tags', they can say `Get me the first 32 posts with the tag #cats` and the database engine will figure out how to do that for them.\"\n\t- This can heavily optimize reads for client applications\n- Mauve suggests that we can actually solve these using [[thoughts/Prolly Trees]]\n\t- \"Everything that can apply to B+ Trees and database indexes, can now apply to Prolly Trees with the added ability of it being p2p, sparsely loaded, and mergable. In particular, when merging two datasets, you can easily skip over blocks that are the same on both sides without having to traverse into a tree, you can also insert entire ranges that are new into your tree withut having to fully traverse the individual items within.\"\n\t- \"If these apps instead used p2p databases, they could drastically improve the initial load times. Instead of waiting for all of the history to sync, a client can focus on getting the set of most recently active users, and query their indexes for just the messages that are needed to render the current view. Detecting notifications like mentions or \"new messages\" can also be done by comparing your last seen state of somebody's index with the latest one. The app can then pull just the notifications since the last load (or last \"marked read\") or ignore those indexes entirely if a user has notifications turned off for that channel.\"\n- This enables multi-tenant peer-to-peer [[thoughts/search]]\n\t- \"Another place where p2p search indexes would be useful is for indexing institutional data for text search. Specifically, it could be useful for projects doing archiving of data using [WebRecorder](https://webrecorder.net/) to build up large datasets of crawled data. At the moment, it's possible to index data from these sources using traditional centralized databases like [Elasticsearch](https://www.elastic.co/elasticsearch/), but this requires running centralized infrastructure and doesn't allow for sharing indexes between groups easily.\"\n\t- \"With p2p databases we can begin to build up search indexes collaboratively with community members, where individuals or smaller groups can participate in generating indexed data, and larger indexes being formed from combining the smaller ones.\"","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/people-as-lighthouses":{"title":"People as lighthouses","content":"\n*written in a note once*\n\nSimilar to [A love letter to virtual community care](https://www.kernelmag.io/pieces/a-love-letter-to-community-care) by Theresa Gao\n\nRelated: [[thoughts/friendship|friendship]]\n\n## Community Care\nLighthouses are beacons for ships at night, identifying the shoreline when everyone else in the town is sleeping.\n\nWhat happens when the lighthouse stops working? Do the ships crash against the shoreline, oblivious to the jagged rocks beneath the waves?\n\nNo, the community comes out at night to light their lamps and bonfires. What was once a singular beacon of light is now a coast awash in light! Ideally, this is what community care -- supporting the beacons of our communities until they are well again.\n\nA goal of life is harmony with others, to see people and understand them, make people feel heard.","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/petname":{"title":"Petname","content":"\n[Petnames](http://www.erights.org/elib/capability/pnml.html) are potentially a method of achieving all 3 properties by having \"names with each of the three pairs of properties, and [building] a naming system involving several of these kinds of names, in order to make use of all three properties.\"\n\nWe are already familiar with this concept actually: the contact list on your phone! Each contact in your phone doesn't actually represent that person, but rather your *relationship* with that person. `John (neighbour)` could be `Dad` in someone else's phone, even though they refer to the same physical person.\n\nSupposes that we have three names:\n1. Keys (global and unique): no one has the same key as you\n2. Petnames (unique and memorable): specific to a *relationship* between two entities\n3. Nicknames (global and memorable): self-proclaimed\n\nThen, keys and petnames are interchangeable with each other. Nicknames are suggestions by users for petnames that others can set for them.\n\nMaybe another version of [[thoughts/Arrow's Impossibility Theorem]]?","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/phenomenology":{"title":"Phenomenology","content":"\nIn phenomenology, the source of all meaning and value is through the subjective lived experience of conscious beings.\n\nThis is the argument *against* independent origination or svabhāva, the very thing [Buddhist](thoughts/Buddhism.md) texts claim that *everything* we perceive is [empty](thoughts/emptiness.md) of.","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/philosophical-realism":{"title":"Philosophical Realism","content":"\nCertain features of reality (like objects, selves, etc.) exist independently of consciousness (that is, do not depend on conscious observation to exist). Keyword here is that not everything we encounter is real, but rather much of the world we experience consists of mind-independent realities that are categorized into certain fundamental types.\n\n## 3 views of realism[^1]\n1. Radical Realism: [qualia](thoughts/qualia.md) are real and cannot be explained by science without radical changes in scientific theory\n3. Conservative Realism: qualia are real and can be explained using current understandings of science or extensions of it\n4. Frankish' Illusionism: qualia do not actually exist but seem to exist\n\t1. We have limited introspective access to the contents of our mental but not the neural medium of those contents\n\t2. Mental content misrepresent non-phenomenal, physical properties as phenomenal (qualia) -- Frankish refers to these as \"quasi-phenomenal\"\n\t3. This is like the [Desktop Metaphor](thoughts/desktop%20metaphor.md), a [fiction](thoughts/fiction.md) created for the benefit of the user. In reality, there are no actual files, folders, etc. in its hardware representation. Dennet states that we use phenomenal properties as a sort of interface for the underlying reality\n5. Blackmore's Delusionism: extension of illusionism\n\t1. Looking into consciousness reveals only what it’s like when we look\n\nRelated: [Hard problem of consciousness](thoughts/Hard%20problem%20of%20consciousness.md)\n\n[^1]: This content is sourced from Professor [Evan Thompson](https://evanthompson.me/)'s course materials for PHIL451A at UBC. All rights to this content is retained by Evan Thompson.","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/philosophy-of-mind":{"title":"Philosophy of Mind","content":"\n*Notes for Philosophy 451A - Philosophy of the Mind* with Professor Evan Thompson [(see all notes)](/tags/PHIL451A).\n\nGuiding Questions\n- What is [consciousness](thoughts/consciousness.md)?  \n- What is [the self](thoughts/the%20Self.md)?  \n- How are consciousness and the self related to the brain, the whole body, and the world?\n\nSubjects of discussion\n- [Consciousness](thoughts/consciousness.md)\n- [Awareness](thoughts/awareness.md)","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/philosophy-of-science":{"title":"Philosophy of science","content":"\n## Karl Popper\nThe aim of scientific inquiry is to find the truth. Yet, some of the greatest scientific theories in the history of science are actually false (e.g. early models of the atom, Newtonian physics). \n\nCloseness to the truth is a function of two factors\n1. Truth\n2. Content\n\nThus, the more truths a theory entails, the closer it is to the truth.\n\n\u003e Even two true theories can have differing degrees of verisimilitude, depending on how much true information they deliver. For example, the claim \"it will be raining on Thursday next week,\" if true, seems closer to the truth than the true yet logically weaker claim \"it will either be raining next Thursday or it will be sunny\".\n\nSimilarly, the concept of a [lie-to-children](https://en.wikipedia.org/wiki/Lie-to-children): creating a simplified world model to explain a system because the real one is too complex to grasp\n\n## Verificationist View\n- rejecting that the idea of certain facts are objective\n    -   For example, a verificationist about height would say that how tall you are depends on what evidence there is about how tall you are.\n    -   The only height you can have is a height that in principle, discoverable or verifiable that you have\n    -   if its true from one's perspective, its their truth → \"If all my evidence says that there is a tall mountain there, then in my personal picture of the world there is a tall mountain there. That's all it can mean, for me, to say that there's a tall mountain there. The mountain really is there, for me, so long as it appears real, and fits my conception of a tall mountain.\"\n    -   \"if tree falls and nobody hears it, did it really fall?\"\n-   \"pursuing our own ends, and trying to satisfy our own desires\" ≠ \"acting for a selfish motive.\"\n    -   psychological egoism (PE) → people always act in their own self-interest\n    -   If my motive is to make me better off, then my motive is a selfish one. If my motive is to make you better off, then my motive is not selfish.\n-   are bad things bad if you don't know about it?\n    -   most people would agree yes\n    -   why is that?","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/phonetics":{"title":"Phonetics","content":"\n\u003e How to produce/pronounce sounds or signs, how we hear sounds\n\n## Sounds\n- Phones: different sounds a language uses\n- Phonemes: meaningfully different sounds in a given language\n- Allophones: phones that do not differentiate meaning\n- Phonotactic knowledge: knowledge of constraints on the sequencing of sounds \n- Phonological idioms: words the child produces in a very adultlike way, while still incorrectly producing other words that use the very same sounds\n\n## Variations in phonetics\n- Voicing: whether vocal folds vibrate (e.g. /s/ is voiceless, /z/ is voiced)\n- Place of articulation: where the vocal tract is closed\n- Manner of articulation: how the vocal tract is closed\n\t- Stops: completely stop the airflow\n\t- Fricative: not completely stopped\n- Articulatory phonetics: describing speech sounds in terms of how they are produced\n- Phonetic features: axes of different features for sounds (e.g. voicing, place of articulation, etc.)\n\n","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/phonology":{"title":"Phonology","content":"\n\u003e Which sounds are used in language, how sounds are combined to form words\n\n## Phonological processes\n- Systematic ways in which to alter the sounds of the target language so that they fit within the repertoire of sounds they can produce\n- Canonical form: preexisting whole-word sound pattern (e.g. consonant + vowel + /j/ + vowel + consonant)\n- Articulatory complexity: types of sounds (or sound sequences) that lead individuals with articulatory deficits to make errors\n\n## Listening\n- Functional load: importance of certain features in making distinctions\n- Phonological awareness: awareness of and ability to work with sounds in spoken language\n- Phonological memory: the ability to remember a sequence of unfamiliar sounds\n- Speech segmentation problem: how do children find word boundaries in a stream of speech","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/play":{"title":"Play","content":"\nFull post on play: [Play to Win: A Post-Work Society](posts/play.md)\n\n\u003e Play: the intentional activity of doing the thing you would want to do. \n\n[Source: Joyful Subversion in *Kernel*](https://kernel.community/en/learn/module-1/joyful-subversion)\n\n\"Play allows us to create and share ownership of spaces in ways which competition cannot. Have as much fun as possible along the way. Turn life into a canvas, rather than a graph with checkpoints. Welcome everyone.\"\n\nIn a world were we seem to be locked behind these little rectangles, how can we escape? Embedded computing experiments like DynamicLand by Bret Victor (more in [interaction design](thoughts/interaction%20design.md))\n\nPlay is adoption of strong rules and beliefs, loosely held.\n\n## Creating spaces not products\n\"Creating a space for change does not necessarily mean you're doing it yourself; you're just making it possible for others.\" (a lot of similar ideas in [Design Justice](thoughts/Design%20Justice.md) and [a new DARPA](thoughts/research%20institutions.md))\n\n## Shifting the nature of work/education\nCan we shift education system away from just assessing students to letting them explore the magical worlds themselves? A more [Mindstorms](thoughts/Mindstorms.md)-esque [constructionist](thoughts/constructionist.md) view on education.\n\n## Magic Circles\n[Source: Magic circles by *Gordon Brandler*](https://subconscious.substack.com/p/magic-circles)\n\nA “magic circle” is the space in which a game takes place. When we step into the magic circle, the we suspend the rules of ordinary life, and allow the rules of the game to mediate our interactions.\n\nWe often mark the boundaries of a magic circle through ceremonies:\n-   Playing the [THX deep note](https://www.youtube.com/watch?v=uYMpMcmpfkI) before a movie\n-   Singing the national anthem before a game\n-   Ringing a gong before yoga practice\n-   Walking down the aisle at a wedding\n\nA lot of concepts similar to [The Grasshopper, Games, Life and Utopia](thoughts/The%20Grasshopper,%20Games,%20Life%20and%20Utopia.md), the lusory attitude as a [boundary](thoughts/boundary%20object.md)\n\n## Animals and Play\n[Graeber on *What's the point if we can't have fun?*](https://davidgraeber.org/articles/whats-the-point-if-we-cant-have-fun/)\n\n\u003e Why does the existence of action carried out for the sheer pleasure of acting, the exertion of powers for the sheer pleasure of exerting them, strike us as mysterious? What does it tell us about ourselves that we instinctively assume that it is?\n\n- the neo-Darwinists assumed not just a struggle for survival, but a universe of rational calculation driven by an apparently irrational imperative to unlimited growth.\n\t- neo-Darwinism: the view that animals were simply trying to maximize the propagation of their own genetic codes\n\t- However, once you reduce all living things to the equivalent of market actors, rationally calculating and optimizing machines trying to propagate their own genetic code, how do we understand how anything even remotely like self-[consciousness](thoughts/consciousness.md), freedom, or moral life arises?\n- animal cooperation often has nothing to do with survival or reproduction, but is a form of pleasure in itself\n- \"Man plays only when he is in the full sense of the word a man\" (Friedrich Schiller, 1795)\n- but what would happen if we agreed to treat play not as some peculiar anomaly, but as our starting point, a principle already present not just in lobsters and all living creatures, but also on every level of [emergent behaviour](thoughts/emergent%20behaviour.md) of self-organizing systems?\n- free will of electrons maybe?\n\t- \"Is it meaningful to say an electron “chooses” to jump the way it does? Obviously, there’s no way to prove it. The only evidence we _could_ have (that we can’t predict what it’s going to do), we do have. But it’s hardly decisive.\"\n\t-  \"If an electron is acting freely—if it, as Richard Feynman is supposed to have said, “does anything it likes”—it can only be acting freely as an end in itself. Which would mean that at the very foundations of physical reality, we encounter freedom for its own sake—which also means we encounter the most rudimentary form of play.\"\n\t- Interesting implications for [materialism](thoughts/Materialism.md) -- consciousness does not *arise* as it is already present? Potential application of [Gall's law](thoughts/Gall's%20law.md)\n- Philosophy as a form of play :)) see also [[thoughts/Jestermaxxing|Jestermaxxing]]\n\n## Against Irony\n\u003e The playful person is neither dogmatist or ironist, but, as Lugones puts it, an easy traveller between, and an explorer of, different normative worlds.\n\nPlay involves lightness with rules -- the ability to lightly step away from but also the ability to lightly adopt.\n\nTo be serious about a game is to play it under the idea that its goals are really and genuinely important -- as an Olympic athlete does. \n\nAn ironist -- a spoilsport -- by openly refusing that shared commitment, destroys the communal development of shared moods in play.\n\nTo be playful about games is neither to be utterly serious, or utterly ironic, but to move easily into and out of commitments to rule-sets. To be playful is to bring oneself to care, for a time, about the specified goals of the game, and to adopt, for a time, a temporary but absolute obedience to a set of rules.\n\n**To be playful with a game is to wear the game's cares and norms lightly**\n\n\u003e Consider, for example, the shared mood of tabletop roleplaying games. The players have to commit, temporarily, to the rules of the game and a kind of (absurd) sincerity of purpose. The players have to really go all-in in pretending to be in character -- of really being, say, fantasy elves and dwarves on a quest to save a village. As is often remarked by dedicated role-players, this shared mood is often wrecked by the pure ironist -- who mocks the activity, who follows the rules mechanically but without real commitment, who breaks the illusion by calling attention to the arbitrariness of its rules","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/positive-sum":{"title":"Positive Sum","content":"\nAs opposed to [zero sum](thoughts/zero%20sum.md)\n\n[Positive Sum Worlds: Remaking Public Goods in *Other Internet*](https://otherinter.net/research/positive-sum-worlds/)and [Gitcoin on Seeking a New Kind of Public Good: Open Call for Proposals](https://gitcoin.co/blog/seeking-a-new-kind-of-public-good/)\n\nWe govern, share, and maintain [public goods](thoughts/public%20goods.md) as a society. While imperfect in how they are built or administered, these objects draw us together in dialogue, debate, and common concern\n\nHow can we [incentivize](thoughts/incentives.md) creation of public goods? Maybe through [quadratic funding](thoughts/quadratic%20funding.md).\n\n### Agalmics\nEconomics is the study of the allocation of scarce goods. We need a new paradigm, and a new field of study. What we need is agalmics.\n\n\u003e The study and practice of the production and allocation of non-scarce goods. [Source](https://wiki.p2pfoundation.net/Agalmics)","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/potemkin-village":{"title":"Potemkin villages","content":"\nThe \"potemkin village that works well on naturally occurring data, but is exposed as fake when one visits points in space that do not have high probability\"\n-   \"A \"Potemkin village\" signifies any deceptive or false construct, conjured often by cruel regimes, to deceive both those within the land and those peering in from outside.\" -\u003e Potemkin Villages in [AI Systems](/posts/ai-systems)\n-   movie village thing","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/power":{"title":"Power","content":"\n## Social Power\n\u003e a practically socially situated capacity to control others’ actions, where this capacity may be exercised (actively or passively) by particular social agents, or alternatively, it may operate purely structurally.\n\nWherever power is at work, we should be ready to ask who or what is controlling whom, and why.\n\nPower can operate actively or passively. Consider a traffic warden:\n1. Active power is the ability of the traffic warden to actually impose a fine\n2. Passive power is the ability of the traffic warden to influence the behaviour of drivers due to the risk of a fine\n\nThis leads to a few characteristics of power\n1. Passive power tends to dwindle with the dwindling of its active operation\n2. Power is capacity; this capacity does not go away even if it is not being realized in action\n\t1. Counterclaim to Foucault's \"Power exists only when it is put into action\"\n\nTypes of social power\n1. Agential Power: power exercised by a single agent on other agents\n2. Structural Power: no particular agent exercising power (e.g. algorithmic power)\n\nPower only exists due to social relations and inherent [trust](thoughts/trust.md) in the other to uphold the expectations we place of their role.\n\n## Identity Power\nSocial stickiness of identities, people tend to do what is expected of their social roles and [norms](thoughts/social%20contracts.md)\n\ne.g. ‘People like us aren’t political’; and so they do not vote. Conversely, part of what encourages many of us to vote is a social self-conception in the collective imagination such that ‘People like us are politically engaged’.\n\n","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/pragmatics":{"title":"Pragmatics","content":"\n\u003e How do you use the language in communication and conversation\n\nPragmatic principles are principles about how language is used\n- Principle of conventionality: the meaning of a word is determined by convention\n- Principle of contrast: different words have different meanings (different from mutual-exclusivity as dog and animal are valid labels here)\n\n- Linguistic competence: ability to use language in grammatical ways, including in production and comprehension\n- Communicative competence: ability to use languages in manners that are appropriate for a given conversation, communicative goal, or social setting.\n- Intentionality is actually a bigger question with respect to language acquisition: is the child intending to communicate?\n\t- Early vegetative noises are not communicative acts, but they can be for adults (e.g., an intentional yawn to express boredom).\n- Three phases\n\t- Perlocutionary Phase (0;0-0;10): what I do/say has an effect on other people\n\t- Illocutionary Phase (0;10-1;0): I can use what I do/say to communicate with other people\n\t- Locutionary Phase (1;0+): I can use language (words used referentially and within well-formed sentences) in my communication\n- Conversational ability\n\t- Connected discourse: communication involving multiple sentences or utterances in a longer time period\n\t- Grice (1957, 1985): two rules to be a good conversationalist\n\t\t- Take turns\n\t\t\t- Very young children (preschoolers and young school age) have longer pauses between turns and less overlapping speech than adults have. They are not as good (as adults) at using words like and, and then, or um to indicate they are not finished talking.\n\t\t- Be cooperative, optimize for\n\t\t\t- Quantity: Make your contribution as informative as is required; provide neither too much nor too little information\n\t\t\t- Quality: Try to make your contribution one that is true; do not say what you believe to be false or that for which you lack adequate evidence\n\t\t\t- Relation: Be relevant\n\t\t\t- Manner: Be perspicuous (i.e., be clear—brief, orderly, unambiguous)\n- Theories about early conversation\n\t- Piaget: child does not have the skill and will for conversation yet\n\t- Vygotsky: speech serves a different function for children at early stages","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/praxis":{"title":"Praxis","content":"\nThe process in which ideas and theories are realized or embodied as action.\n\nThe argument is that all professions are mixtures of theory and practice. If a job is so simple that it is just a series of steps to carry out (algorithmic), then it is not a profession (counterpoint: can everything be reduced into algorithmic steps? How concrete do the steps need to be?). \n\nThus, Bates distinguishes between discipline (theory) and profession (practice).","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/prefigurative-politics":{"title":"Prefigurative Politics","content":"\n\u003e How do we create the world we want to see in the future?\n\nSee also: [[thoughts/fiction#Fiction as shared visions|shared fictions]], [[thoughts/skyhooks|skyhooks]]","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/prestige":{"title":"Prestige","content":"\n [Source: The Prestige Trap by *Wes De Silvestro*](https://statespace.substack.com/p/the-prestige-trap)\n \n Is this why so many people want to join 'prestigious' places to work like big tech or consulting? To keep doors open?\n \n For lack of a better explanation, a big part of it feels like the go-to cop-out for individuals *unsure* of their larger life direction. Or maybe just lacking general conviction/self-confidence in themselves.\n \n Prestige, as Paul Graham defines it, is just fossilized inspiration. It's what was once new and successful and thus *became* prestigious. \"If you do anything well enough, you'll _make_ it prestigious.\"\n \n A lot of people mistake prestige for excellence. The assumption is that prestige entails excellence but the reality is the opposite: prestige **follows** excellence\n \n ### Ivy League\n\"For the majority of Ivy Leaguers, the most impressive thing they've accomplished is achieving admission to their university. When you're deemed successful because you went to Harvard rather than celebrated for what got you there in the first place, you learn to game the system and just focus on the credentials the next time around.\"\n\nThis 'credentials' grind within these prestigious institutions is very reminiscient of [Goodhart's Law](thoughts/Goodhart's%20Law.md). They saw that their process of scrambling and playing 'the game' for college admissions got them prestige so they continue to optimize for that rather than success.\n\n\u003e Some of the lowest hanging fruit remains unpicked because few smart people are willing to venture down the road not taken.","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/privacy":{"title":"Privacy","content":"\n## Definitions\n- Restricting access to information or property to what you wouldn't willingly give away in a particular context\n\t- Specifically, recognizing that privacy is contextual (Nissembaum)\n\t- The context of your privacy—what’s being revealed to whom and for what reason—utterly changed and you had no say in it.\n- From the point of view of an individual restricting access: privacy is a “zone of inaccessibility” that surrounds a person\n- From the perspective of outsiders seeking access: violating someone’s privacy is an affront to that person’s dignity\n\nHowever, some people take advantage of privacy to plan and carry out illegal or immoral activities\n\nThere is also conflicting needs between companies and users\n- Companies want to use data to improve their products\n- Users want to protect their privacy\n\nData anonymization isn't enough. Even if some of the data is scrambled and personally identifiable information is stripped, it is susceptable to linkage attacks (correlating rows of the anonymized dataset to other known datasets)\n\n~87% of all Americans can be identified using only 3 pieces of information:\n1. zip code\n2. birthday\n3. gender\n\n## Privacy for independent development\nPrivacy is the way in which a social group recognizes and communicates to the individual that he is responsible for his development as a unique person, a separate moral agent\n\nIt's valuable because it lets us be ourselves. In order to have different kinds of social relationships with different people, we need to have some kind of control over who knows what about us (see: [[posts/context-collapse|context collapse]])\n\n## Differential Privacy\ntldr; add randomized noise that maintains distribution of data\n\nWhen submitting a piece of data:\n1. A fair coin is flipped.\n2. If heads: the real data is sent\n3. If tails: we generate a random number to encode the result as random noise (e.g. true for heads, false for tails)\n\nThis way, we can't trust any single record to be accurate (plausible deniability), but the aggregate still remains useful.\n\nAs we know noise distribution, this can be accounted for the in final calculation.\n\nNote that this will only work for larger datasets as injecting noise into a small dataset will likely result in inaccurate data\n\n### Usage\n- Apple for error reporting\n- Google for malware reports and traffic reports in Maps\n\n## Contextual Privacy\nFrom Antonio García Martínez in [*The right to never be forgotten*](https://www.thepullrequest.com/p/the-right-to-never-be-forgotten)\n\nHelene Nissenbaum’s ‘contextual privacy’\n\nAn example she draws in her work is imagining your interactions with your physician when dealing with a medical issue. Even in a world where the right to live as a stranger among strangers reigns supreme, we unquestioningly turn over the most intimate medical details to people we barely know. \n\nNow, let’s imagine you leave your doctor’s office and fire up Instagram to take your mind off the diagnosis he just gave you, which is that you don’t have brain cancer but you simply suffer from chronic migraines and will just have to deal. Scrolling past pictures of friends and celebrities, you see an advertisement for a migraine medication, specifically for the vestibular migraines you suffer from. While two seconds ago you were willing to send images of your brain across the world for medical advice, you now feel horribly violated knowing that everyone from Facebook to a pharma marketing team know about your condition.\n\n**The context of your privacy—what’s being revealed to whom and for what reason—utterly changed and you had no say in it.**\n\nSee also: [[thoughts/GDPR|GDPR]]\n\n### Web3\n- Web2: considers identity public but data private\n- Web3: identity is private, but data public\n\n## Rights to privacy\nDiffering opinions on the status of privacy as a right. General consensus is that privacy is a prudential right. That is, rational agents would agree to recognize some privacy rights because granting these rights is to the benefit of society\n\n- Warren and Brandeis\n\t- People in modern society have a right to privacy and that this right ought to be respected\n\t- \"The intensity and complexity of life, attendant upon advancing civilization, have rendered necessary some retreat from the world, and man, under the refining influence of culture, has become more sensitive to publicity, so that solitude and privacy have become more essential to the individual\"\n\t- Warren and Brandeis argue, there are no adequate legal remedies available to the victims. Laws against libel and slander are not sufficient because they do not address the situation where malicious but true stories about someone are circulated (especially in cases where consent was not attained ahead of time, like through cameras)\n- Thomson\n\t- Every “privacy right” violation is a violation of another right\n- Reiman\n\t- Privacy is needed if people are to be autonomous moral agents able to develop healthy personal relationships and act as free citizens in a democratic society\n\t- Our personal information is private to the extent that we can control who has access to it\n\t- He does not argue that privacy is a natural right, nor does he suggest that a person has complete control over what is held private.\n\n## Taxonomy of Privacy\nProposed by Daniel Solove\n\n1. Information collection refers to activities that gather personal information\n2. Information processing refers to activities that store, manipulate, and use personal information that has been collected\n3. Information dissemination refers to activities that spread personal information\n4. Invasion refers to activities that intrude upon a person’s daily life, interrupt a person’s solitude, or interfere with someone’s decision making\n\n## US Legislation\nRestricting information collection\n\n1. The Employee Polygraph Protection Act of 1988 (EPPA) prohibits most private employers from using lie-detector tests under most situation\n2. The Children’s Online Privacy Protection Act (COPPA) states that online services must obtain parental consent before collecting any information from children 12 years old and younger.\n3. The Genetic Information Nondiscrimination Act of 2008 prohibits health insurance companies and health plan administrators from requesting genetic information from individuals or their family members, and it forbids them from using genetic information when making decisions about coverage, rates, or preexisting conditions\n\nWhat the US collects on its citizens\n\n1. Census Records. In order to ensure each state has fair representation in the House of Representatives, the United States Constitution requires the government to perform a census every 10 years\n2. Internal Revenue Service (IRS) Records\n3. FBI National Crime Information Center 2000 includes such categories as wanted persons, criminal histories, people incarcerated in federal prisons, convicted sex offenders, unidentified persons, people believed to be a threat to the president, foreign fugitives, violent gang members, and suspected terrorists\n4. OneDOJ Database provides state and local police officers access to information supplied by five federal law enforcement agencies: the FBI; the Drug Enforcement Agency; the Bureau of Alcohol, Tobacco, Firearms, and Explosives; the US Marshals Service; and the Bureau of Prisons\n5. Closed-Circuit Television Cameras (CCTV)\n6. License-Plate Scanners\n7. Police Drones. Federal Aviation Administration rules require that drones used by the police weigh no more than 25 pounds, fly no higher than 400 feet, and be flown during daylight within view of the operator\n\nCovert Surveillance in the States\n- Allowed under the Fourth Amendment to the United States Constitution. *But* it has changed over time\n- *Olmstead v. United States* that the Fourth Amendment protected tangible assets alone. The federal agents did not “search” a physical place; they did not “seize” a physical item\n- In 1934 the US Congress passed the Federal Communications Act, which (among other things) made it illegal to intercept and reveal wire communications. Three years later the Supreme Court used the Federal Communications Act to reverse its position on warrantless wiretaps\n- After WWII broke out, President Roosevelt agreed to let the FBI resume wiretapping in cases involving national security, though he asked that the wiretaps be kept to a minimum and limited as much as possible to aliens\n- In 1967, Supreme Court rendered that citizens should also be protected from all electronic surveillance conducted without warrants, including bugs (hidden microphones used for surveillance)\n- Congress passed the Title III of the Omnibus Crime Control and Safe Streets Act of 1968. Title III allows a police agency that has obtained a court order to tap a phone for up to 30 days\n- Operation Shamrock: The Signal Security Agency (predecessor to the NSA) contacted Western Union Telegraph Company, ITT Communications, and RCA Communications who allowed SSA to make photographic copies of all foreign government telegram traffic that entered, left, or transited the United States. Facing hostile congressional and press scrutiny, the NSA called an end to Operation Shamrock in May 1975\n- The Foreign Intelligence Surveillance Act of 1978 (FISA) allows the president to authorize electronic surveillance of foreign nationals for up to one year without a court order, as long as there is little chance that the surveillance will reveal the contents of communications with any US citizens. This required the government to get a court order from the FISA Court\n\t- FISA was amended by the Protect America Act of 2007. This act allows the US government to wiretap communications beginning or ending in a foreign country without oversight by the FISA Court.\n- In 1986, the ECPA was passed which allows police to attach two kinds of surveillance devices to a suspect’s phone line. If the suspect makes a phone call, a pen register displays the number being dialed. If the suspect gets a phone call, a trap-and-trace device displays the caller’s phone number.\n\t- While a court order is needed to approve the installation of pen registers and trap-and-trace devices, prosecutors do not need to demonstrate probable cause, and the approval is virtually automatic\n\t- The ECPA also allows police to conduct roving wiretaps—wiretaps that move from phone to phone—if they can demonstrate the suspect is attempting to avoid surveillance by using many different phones\n\t- Under the Stored Communications Act, part of the ECPA, the government does not need a search warrant to obtain from an Internet service provider email messages more than 180 days old\n\t\t- Many big technology companies have formed an organized called Digital Due Process which is lobbying Congress to update the ECPA\n\t\t- The view of the Digital Due Process coalition is that the government should not be able to obtain an email message, document, or photo from an Internet or cloud service provider without a proper search warrant\n- Congress passed the Communications Assistance for Law Enforcement Act of 1994 (CALEA)\n\t- This law required that networking equipment used by phone companies be designed or modified so that law enforcement agencies can trace calls, listen in on telephone calls, and intercept email messages\n- The FBI developed the Carnivore Surveillance System in the late 1990s to monitor Internet traffic, including email messages. Armed with a search warrant, the FBI would set up its Carnivore system at the suspect’s Internet service provider. An Internet service provider questioned the FBI's authority to do this under the Electronic Communications Privacy Act but a US District Court ruled against it.\n\t- In late 2001 the FBI stopped using Carnivore, replacing it with commercial software capable of performing the same function\n- Post 9/11, President Bush signed a presidential order allowing the NSA to eavesdrop on international telephone calls and international emails initiated by people living inside the United States, without first obtaining a search warrant\n- Congress then passed the USA Patriot Act which amended many existing laws. Four main principal categories\n\t1.  Providing federal law enforcement and intelligence officials with greater authority to monitor communications\n\t2.  Giving the Secretary of the Treasury greater powers to regulate banks, preventing them from being used to launder foreign money\n\t3.  Making it more difficult for terrorists to enter the United States\n\t4.  Defining new crimes and penalties for terrorist activity\n\t\t- Allows courts to authorize law enforcement officers to search a person’s premises without first serving a search warrant when there is “reasonable cause to believe that providing immediate notification of the execution of the warrant may have an adverse effect.”\n\t\t- Officers may seize property that “constitutes evidence of a criminal offense in violation of the laws of the United States,” even if that offense is unrelated to terrorism.\n\t- This had averse effects. In November 2003, the ACLU reported that public apprehension about the Patriot Act had led to a significant drop in attendance and donations at mosques\n\t- The Council of the American Library Association was the first of many to pass anti-Patriot Act resolutions: \"urg[ing] librarians everywhere to defend and support user privacy and free and open access to knowledge and information\"\n- US Department of Defence created the Threat and Local Observation Notices (TALON) database in 2003. The purpose of the database was to collect reports of suspicious activities or terrorist threats near military bases. The TALON database was shut down on September 17, 2007\n- In 2013, Snowden leaked PRISM, which is a program that allowed the NSA gained access to the servers of Microsoft in 2007; Yahoo in 2008; Google and Facebook in 2009; YouTube in 2010; Skype and AOL in 2011; and Apple in 2012. It enabled the NSA to access stored information without obtaining search warrants when the NSA had reasonable suspicion that the person being investigated is a foreigner outside the US\n\t- Edward Snowden and Glenn Greenwald explained XKeyscore as being a system which enables almost unlimited surveillance of anyone anywhere in the world\n\t- \"You could read anyone's email in the world, anybody you've got an email address for. Any website: You can watch traffic to and from it. Any computer that an individual sits at: You can watch it. Any laptop that you're tracking: you can follow it as it moves from place to place throughout the world. It's a one-stop-shop for access to the NSA's information. ...\"\n\n## Code of Fair Information Practices\nIn the early 1970s, a group convened to recommend a set of policies often dubbed the \"bill of rights\" for the Information Age\n\n1.  There must be no personal data record-keeping systems whose very existence is secret.\n2.  There must be a way for a person to find out what information about the person is in a record and how it is used.\n3.  There must be a way for a person to prevent information about the person that was obtained for one purpose from being used or made available for other purposes without the person’s consent.\n4.  There must be a way for a person to correct or amend a record of identifiable information about the person.\n5.  Any organization creating, maintaining, using, or disseminating records of identifiable personal data must assure the reliability of the data for their intended use and must take precautions to prevent misuses of the data.\n\nThe Privacy Act of 1974 represents Congress’s attempt to codify the principles described in the Code of Fair Information Practices. However, in most respects, it has fallen short of the desires of privacy advocates:\n1. The Privacy Act applies only to government databases. Far more information is held in private databases, which are excluded. This is an enormous loophole, because government agencies can purchase information from private organizations that have the data they want.\n2. The Privacy Act only covers records indexed by a personal identifier.\n3. No one in the federal government is in charge of enforcing the provisions of the Privacy Act. Federal agencies have taken it upon themselves to determine which databases they can exempt.\n4. The Privacy Act allows one agency to share records with another agency as long as they are for a “routine use.”\n\n## Against Predictive Policing\nSocial contract theory posits that we have surrendered some of our natural rights in order to form a society, with the understanding that this society will protect our remaining rights[^1]. One of the key rights we have surrendered is the right to use violence, as we have delegated this authority to the state through law enforcement so that they may afford us the right to privacy and safety. Using social contract theory, I argue that Canada should enact a total ban on predicting policing algorithms. The use of these algorithms is ineffective at affording us the right to safety and actively harms countless marginalized groups.\n\nThose who advocate for the use of these algorithms argue that they enable law enforcement to better prevent terrorist incidents and crimes. For example, the Chicago police force used these algorithms to identify shooters. Yet, the reality is that these systems have a very negligible impact on improving public safety. In the wake of the 9/11 attacks in the United States the government introduced mass surveillance programs in the name of public safety. However, a study by the New America Foundation found that these programs had neither prevented acts of terrorism nor found evidence of planned terrorist acts. [^6]\n\nThe use of these algorithms also violates the social contract which states that we should impose only as many rules as we need in order to have a functioning society. In a proper social contract, no community members would want to put unfair burdens on others because that would mean putting unfair burdens on themselves. In other words, we would like a minimum viable set of rules that the government is able to enforce.\n\nImagine an extreme world where you are guaranteed all of your absolute rights but have no rights of any other kind (e.g. freedom of speech, freedom of free media, etc.). While this may be a perfectly safe society, you literally cannot do anything but exist. This example serves to illustrate the tradeoff between personal liberties and personal rights; you cannot have your cake and eat it too. It is a basic expectation that individuals have a right to privacy and trading that for a negligible increase in personal safety is not one that most people would make.\n\nWhen we delegate the role of enforcing these roles to the government, we assume that they act impartially on our behalf, without bias or discrimination. However, predictive policing algorithms do not adhere to this standard: they are biased against marginalized groups, and their use often leads to police violence against these groups.\n\nPredictive policing algorithms rely on historical data from police databases, which contain disproportionately high numbers of interactions with people from marginalized groups. As a result, these algorithms are likely to label members of these groups as “high risk” and target them for extra surveillance even when they have not done anything wrong. Under Rawl’s theory of justice, we quickly see that its use is unfair. \n\nIn a study from 2016, ProPublica found that COMPAS, a policing algorithm, overestimated the rate of reoffending for Black individuals by almost twice as much as those for Caucasians [^4]. This meant that Black individuals were disproportionately given longer and harsher sentences. Race isn’t the only feature that these algorithms discriminate on. Any category of people who have been unfairly represented historically (e.g. gender minorities, PoC, immigrants) continue to be systematically harmed by these systems[^3]. This can lead to a self-fulfilling prophecy where people from marginalized groups are more likely to be arrested and jailed because they are being targeted by predictive policing algorithms[^2]. Clearly, this is a system that does not benefit those who are the least-advantaged in this society.\n\nLastly, we have an expectation for the right to explanation in any social contract. Especially when we delegate the responsibility for upholding and reforming rules to the government we expect explanations decisions that significantly affect an individual. Most predictive policing algorithms operate using large troves of data and in a way which is opaque to its operators[^2]. If governments use these policing algorithms, they cannot explain how they made the decisions they did. The public will be left without much recourse to challenge the decisions of automated systems. Alkhatib[^3] explains that these systems without explanation or feedback loops quickly diverge from reality and can lead to increasingly unfair and discriminatory decisions.\n\nIn light of all this evidence, I believe that Canada should enact a total ban on predictive policing algorithms. The social contract theory dictates that we have a responsibility to protect the rights of all individuals in our society equally; predictive policing violates this principle by discriminating against already marginalized groups[^1].\n\n[^0]: Ethics for the Information Age, 8th Edition., Quinn, Michael\n[^1]: https://www.wired.com/2017/04/courts-using-ai-sentence-criminals-must-stop-now/\n[^2]: https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm\n[^3]: https://ali-alkhatib.com/papers/chi/utopia/utopia.pdf\n[^4]: https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm\n[^5]: https://www.science.org/doi/10.1126/sciadv.aao5580\n[^6]: https://www.newamerica.org/international-security/reports/terrorism-america-18-years-after-911/what-is-the-threat-to-the-united-states/\n","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/probabilistic-classifier":{"title":"Probabilistic Classifier","content":"\nWe want a model of $P(y_i = \\textrm{important} | x_i )$ for use in [[thoughts/Decision theory|decision theory]].\n\n- Predictions generally map $w^Tx_i$ to labels for classes (for binary prediction, we used $\\textrm{sign}(x)$)\n- Probabilities we want to map $w^Tx_i$ to the range $[0,1]$\n\nThe most common choice is to use the sigmoid function:\n\n$$h(z_i) = \\frac{1}{1+\\exp(-z_i)}$$\n\n## Multi-class Probabilities\nSee also: [[thoughts/multi-class classification]]\n\nThe softmax function allows us to map $k$ real numbers $z_i = w_c^Tx_i$ to probabilities\n\n$$P(y | z_1, z_2, \\dots, z_k) = \\frac{\\exp(z_y)}{\\sum_{c=1}^k \\exp(z_c))}$$","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/probability":{"title":"Probability","content":"\n## Kolmogorov Axioms\n1. The probability of an event is a non-negative real number\n2. The probability that at least one of the possible events happen is 1\n3. Given a set of mutually exclusive events, the probability of all of them happening is the probability of each event happening summed up\n\n### Consequences\n- $0 \\leq P(A) \\leq 1$\n- $P(\\lnot A) = 1 - P(A)$\n\n## Joint probability\nProbability of both A and B happening. Intersection of the areas of the two events.\n\n### Marginalization Rule\nFor some random variable X\n\n$$P(A) = \\sum_{x \\in \\mathcal{X}}P(A \\cap X = x)$$\n\nFor example, to roll some even number,\n\n$$P(\\textrm{even}) = \\sum_{i=1}^6 P(i \\cap \\textrm{even}) = 0 + \\frac 1 6 + 0 + \\frac 1 6 + 0 + \\frac 1 6$$\n\n## Union of Events\nGiven an event A and B, the probability of both occurring is\n\n$$P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$$\n\n## Conditional Probability\nThe probability of A given B has occurred is\n\n$$P(A|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(B|A)P(A)}{P(B)}$$\n\nDeriving from this, we get,\n1. $P(A \\cap B) = P(A|B) P(B)$\n2. $P(A \\cap B) = P(B|A) P(A)$\n\n## Independence\n$$P(A \\cap B) = P(A)P(B)$$\n\nor \n\n$$P(A|B) = P(A)$$\n\n## Expected Values\nIf we have a random variable $X$ that can takes values $x \\in \\mathcal{X}$, we define the expectation of X:\n\n$$\\mathbb{E}[X] = \\sum_{x \\in \\mathcal{X}} P(X=x)x$$\n\nAdditionally, \n1. For functions that depend on a random variable: $\\mathbb{E}[f(X)] = \\sum_{x \\in \\mathcal{X}} P(X=x)f(X)$\n2. $\\mathbb{E}[\\alpha f(X) + \\beta g(X)] = \\alpha \\mathbb{E}[f(X)] + \\beta \\mathbb{E}[g(X)]$\n3. $\\mathbb{E}[f(X)g(X)] \\neq \\mathbb{E}[f(X)] \\mathbb{E}[g(X)]$\n4. $\\mathbb{E}[X|Y=y] = \\sum_{x \\in \\mathcal{X}} P(X=x|Y=y)f(X)$\n5. $\\mathbb{E}[\\mathbb{E}[X =x | Y=y]] = \\mathbb{E}[X]$ (tower property, law of total expectation, iterated expectation rule)\n\n## Bayes' Theorem\nSee also: [[thoughts/Naive Bayes|Naive Bayes]]\n\nLet $c$ be the class label and $x$ be the measurement (evidence)\n\n$$P(c|x) = \\frac{P(x|c)p(c)}{P(x)}$$\n\n- $P(c|x)$: the posterior probability is the probability of $c$ given $x$ (after the measurement). \n- $p(c)$: prior probability\n- $P(x|c)$: class-conditional probability (likelihood of $c$ on $x$)\n- $P(x)$: unconditional probability (a.k.a. marginal likelihood or expectedness of evidence)\n\nAlternate formulations:\n\n### Expanded\n$$P(c | x) = \\frac{P(x|c)P(c)}{P(x|c)P(c)+P(x|\\lnot c)P(\\lnot c)}$$\n### Multiple Hypotheses\nSuppose $c_1, \\dots, c_n$ is an exhaustive and mutually exclusive set of possibilities\n\n$$P(c_i | x) = \\frac{P(x|c_i)P(c_i)}{P(x|c_1)P(c_1)+\\dots+P(x|c_n)P(c_n)}$$\n\n## Interpretations of Probability\nA = draws from a normal deck, B = draws of a face card.\n$P(B | A) = \\frac 3 {13}$ means:\n\nObjective interpretations: Probability values are determined by factors independent of our beliefs.\n\nSubjective interpretations: Probability values reflect individual degrees of belief, and vary from person to person.\n\nWe can evaluate these interpretations as follows (Wesley Salmon)\n1. Admissible. Probability values must satisfy the axioms of the probability calculus (the Kolmogorov axioms). This is also called coherence.\n2. Ascertainable. Probability values must be values that we can determine (or else they are useless).\n3. Applicable. Probability values must be reliable as a “guide to life”. They must be values that we can justifiably use to make decisions.\n\n1. Classical: number of B over number of A is 3/13\n\t1. Problem: assumes cases of A are equipossible (equal probability)\n\t2. This seems circular\n\t3. Fails ascertainability, admissibility, and applicability\n2. Finite frequency: The proportion of B in a long series of draws is exactly 3/13.\n\t1. Is admissible and ascertainable\n\t2. Not applicable: how does this work for single case probabilities?\n3. Limiting frequency: The limiting frequency in an infinite series of draws would be 3/13.\n\t1. Is admissible and applicable\n\t2. Not ascertainable: there may be no limiting frequency\n\t3. Again, does not work for single case probabilities\n4. Long-run propensity: The set-up A has a disposition to produce long sequences in which B happens with frequency 3/13.\n\t1. Assumes that long-run frequencies have an underlying cause through an experimental arrangement/set-up\n\t2. Not ascertainable: no improvement on the limiting frequency interpretation\n\t3. Not explanatory: the tendency or disposition adds nothing to our udnerstanding\n\t4. Not all probabilities can be interpreted as propensities. (no causal relation)\n5. Logical: B partially entails A, with degree of entailment 3/13.\n\t1. P(B/A) measures the “proportion” of A that overlaps with B\n6. Epistemic: The evidence that A happened provides objective support of degree 3/13 that B happened.\n\t1. Logical and epistemic probabilities might only exist in some cases\n\t2. Very unlikely that we know some of the priors/likelihoods can be computed a priori (from pure logic)\n7. Subjective (actual degree of belief):  Somebody believes with degree 3/13 that A will produce B.\n\t1. Credences can be measured (or even defined) by studying your actions, especially your betting behaviour\n\t2. Problem: actual degree of belief is not admissable, people commit probabilistic fallacies all the time\n\t3. This can lead to bad betting combinations (see [[thoughts/Dutch Book|Dutch Book]] examples) in which you are guaranteed to lose money\n\t4. Key assumption: EU and EMV are equivalent for small but non-trivial amounts of money\n8. Subjective (idealized credence): An idealized version of someone – with coherent probabilities – believes with degree 3/13 that A will produce B.\n\t1. Fixes admissibility as we require it\n\t2. Not applicable: how can we justify using personal probabilities to make decisions if there are no constraints on one’s prior probabilities? \n\t3. Another problem\n\t\t1. The meaning or concept of probability does not essentially involve desires or preferences\n\t\t2. For example, an enlightened Zen Buddhist monk can have probabilities but no desires\n\t\t3. Thus, by Peterson, any theory that creates a necessary (definitional) link between probability and preference/desire must be wrong.\n\n","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/program-analysis":{"title":"Program Analysis","content":"\n1. Concerns what a program does: analysis aim is to check statically/dynamically something about execution behaviours\n2. Is flow-sensitive: what the analysis does with a statement is dependent on control flow of the program\n\nSoftware analysis falls into many categories\n1. Metaproperty analysis: anything else except for what the code actually does (e.g. style checkers)\n2. Program analysis: analysing what a (part of a) program will do / does / can do\n\t1. Static program analysis: without running the program. This requires considering all executions of the code of interest which requires context about the execution up to this point\n\t\t1. Value-agnostic\n\t\t2. Value-sensitive ([[thoughts/symbolic execution]])\n\t2. Dynamic program analysis: analyzes the program while running it\n\t3. Automatic (Concolic) test-case generation\n\n3 main properties about code\n1. How the code is written (fairly simple static meta-property analysis)\n2. What the code does (program analysis - cannot be done precisely)\n3. What the author intended (impossible for fully automatic analysis, not available from the code)\n\nRice's Theorem: All program analysis problems that are non-trivial are undecidable. There is no program analysis that achieves all of the following for all input problems:\n1. Is fully automatic (no user input/interaction other than the program)\n2. Always terminates (the analysis itself, not program being analysed)\n3. On termination: always says “yes” when the answer should be “yes”\n4. On termination: always says “no” when the answer should be “no”\n\n## Designing a Static Analysis\n1. Define the goal: what is the property (of all executions) of a program? What problem is the analysis supposed to help?\n2. Abstract states $\\sigma$: type of information analysis tracks through program\n3. Error/output information $E$: type of information returned by analysis\n4. Analysis function: define a function $\\textrm{analyze}(\\sigma,s)$ for analysis steps where\n\t1. $\\sigma$ is an abstract state\n\t2. $s$ is a program state\n\t3. returns a pair $(\\sigma',E)$ of resulting abstract state plus any errors \n\t4. typically defined per-case of type of (supported) statement s\n5. Concretisation function: maps abstract states to sets of program states  or sets of program executions - this defines what abstract states mean. What does the analysis \"think\" is a possible state at this point?\n\t1. (D, A) maps to set of all states in which at least D are declared and A are initialized\n\t2. (D, A) maps to set of all states in which at most D are declared and A are initialized\n\t3. (D, A) maps to set of all states in which exactly D are declared and A are initialized\n6. (Optionally) termination strategy: for recursive control flow (e.g. loops)\n\nWe can do this by instrumenting (changing) the program. We have two places where this can happen\n1. Instrumenting source code (e.g. grab AST and modify it)\n2. Instrumenting executable (e.g. grab bytecode and modify it)\n3. Instrumenting runtime (e.g. modify JVM)\n\nThere's also a choice to be made about how/when to perform the analysis\n1. Online dynamic analysis: run the analysis as part of / alongside the program\n2. Offline dynamic analysis: make the program produce a log; analyse it separately\n\n## Program Slicing Example\nNB: We never delete variable declarations, just their initializations. Similarly, we keep flow constructs if they have at least one line inside of them.\n\n### Static\n1. Define abstract state $\\sigma$ as $(M, L)$ where\n\t1. $M$ is a map from variable names to what line numbers may have affect that variable at that point\n\t2. $L$ is a list of control flow dependencies at that point\n2. For assignment of `x=e` at line $n$ where `e` is an expression that can contain multiple variables\n\t1. `M[x]` becomes the union of\n\t\t1. The line number `n`\n\t\t2. `M[y]` for every `y` in the expression `e`\n\t\t3. Unions of all sets in `L`\n\t2. `L` remains unchanged\n3. For if-then-else statements\n\t1. Push to `L`: the union of `M[y]` for every `y` in the if-condition check\n\t2. Copy the map `M` to start of the then and else blocks\n\t3. Continue normally...\n\t4. At the end of each block, union the `M`s at the end of each block\n\t5. Pop from `L`\n4. For loops\n\t1. Add loop variable to `M`\n\t2. Push to `L`: the union of `M[y]` for every y in the loop condition\n\t3. Continue normally...\n\t4. When we hit end of loop body, we go back to start of the loop and rewrite. Stop when neither `M` nor `L` update\n\t\t1. Each variable in `M` to be union of its old value and the value at the end of the loop\n\t\t2. Head of `L` is the union of itself and `M[y]` for every y in the loop condition\n\t5. Pop from `L`\n\n### Dynamic\n1. We add two extra objects to the program state, `m` and `l` which are functionally equivalent to $M$ and $L$ from previously\n2. For assignment of `x=e` at line $n$, we update `m` to store\n\t1. $n$\n\t2. `m[y]` for each `y` in `e`\n\t3. `l` flattened\n3. For if-then-else statements\n\t1. Before the statement, we calculate `s` by taking union of all the dependencies in the condition and push this to `l`\n\t2. We pop `l` after the statement\n4. Loops are the same as if-then-else statements but we do steps 1. and 2. inside the loop instead of outside the statement","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/progress":{"title":"Progress","content":"\nFrom *21 Lesson for the 21st Century* by Yuval Noah Harari:  \"Did we domesticate wheat or did wheat domesticate us?\" So much of technological progress is conflated as a good thing. Is it necessarily so?\n\nProgress, loosely defined by [Tyler Cowen and Patrick Collison](https://www.theatlantic.com/science/archive/2019/07/we-need-new-science-progress/594946/), is \"the combination of economic, technological, scientific, cultural, and organizational advancement that has transformed our lives and raised standards of living over the past couple of centuries\"\n\n**Progress implies direction. Progress towards what?** Does this require alignment of values? Is progress enabling us to better express our [identities](thoughts/introductions.md)?\n\nProgress isn't equal, it's multiplicative. It's \"a mixed blessing—one that resulted in technologies that have allowed many people to live longer, safer lives, but that has, simultaneously, destroyed global ecosystems, caused the extinction of many living species, facilitated rampant population growth, and wreaked havoc on climate systems, the effects of which will be an increase in droughts, floods, storms, and erratic weather patterns that threaten most global societies.\" [Source](https://www.theatlantic.com/business/archive/2014/09/the-industrial-revolution-and-its-discontents/379781/)\n\nThere are no 'thought leaders' in bleeding tech, only in established fields. Everyone at the edge of a field is a 'pioneer' in a sense. \n\nAfter a subject gets established, how do we continue to make progress through research? [A new DARPA](thoughts/research%20institutions.md) perhaps?\n\n## History of Progress\nhttps://www.theatlantic.com/business/archive/2016/11/progress-isnt-natural-mokyr/507740/\n\n\u003e   Why might people in the past have been hesitant to embrace the idea of progress? The main argument against it was that it implies a disrespect of previous generations.\n\nIs progress a result of a more creation focused lens rather than a [maintenance](thoughts/creation%20vs%20maintenance.md) focused one? Finding answers through working on new things rather than what was revealed in the past\n\nSo many historically 'truthful' sources like the Church and classical science were wrong about fundamental aspects of the universe (e.g. Earth being the centre of the universe). \"By 1600, much of ancient wisdom had crumbled.\"\n\nSkepticism as the taproot of all knowledge, heavily [Cartesian](thoughts/virtual%20worlds.md)\n\nHowever, [[thoughts/writing|writing]], the printing press, and other tools allowed us to [extend our mind](thoughts/Extended%20Mind%20Hypothesis.md) and conceive of knowledge as **cumulative**.\n\n## Progress Studies\nThe study of the *how* and *why* of progress.\n\nThere are ecosystems that are better at generating progress than others, perhaps by orders of magnitude. What do they have an in common?\n\nWhat enables progress? \"Why did Silicon Valley happen in California rather than Japan or Boston? Why was early-20th-century science in Germany and Central Europe so strong? Can we deliberately engineer the conditions most hospitable to this kind of advancement or effectively tweak the systems that surround us today?\"\n\nHow can we enable useful progress in the future? \n\nFrom a more epistemlogical standpoint, how much of progress just comes down to good:\n1. pedagogy (re: [Mindstorms](thoughts/Mindstorms.md))\n2. networks (re: [social graphs](thoughts/social%20graphs.md))\n3. chance and circumstance\n\n\"Organizations as varied as Y Combinator, MIT’s Radiation Lab, and ARPA have astonishing track records in catalyzing progress far beyond their confines. While research exists on all of these fronts, we’re underinvesting considerably.\" -\u003e [a new DARPA](thoughts/research%20institutions.md) to catalyze progress?\n\nJasmine has a really good [potential curriculum outline](https://jasminew.me/post/progress):\n1. History and causes: How do we make progress?\n\t1. History of science and technology: How were useful discoveries made? What was the relationship between [funding](thoughts/funding.md) and knowledge?\n\t2. Philosophy of technology / technological progress: How, why, and when do particular technologies emerge?\n\t3. Meta-science / science of science / social [epistemology](thoughts/epistemology.md) of science: How do we educate, train, and incentivize scientists?\n\t4. Mechanism design + incentive design: How do we design [incentives](thoughts/incentives.md) to elicit certain behaviours and aggregate specific information?\n\t5. Cultural components of change-making: How have humans organized change in the past around ideas and processes?\n\t6. Cause prioritization: How do we decide what to focus on?\n2. Definition and measurement: What sort of world(s) should we be we building towards?\n\t1. Visions of the future: What type of future/utopia do we want to live in? **Is progress to one person necessarily progress to the collective?** rel: [The ones who walk from Omelas](thoughts/The%20ones%20who%20walk%20away%20from%20Omelas.md)\n\t2. Progress definition and measurement: How do we define progress and metrics?\n3. Drawbacks of progress: What are the risks incurred by progress? How do we make differential progress?\n\t1. Costs of progress: Can progress be too fast? How do we mitigate risks (esp those that are irreversible and existential)?\n\t2. Robust decision-making and better prediction under uncertainty: How can we better predict the impacts of our actions?\n\t\t1. (re: [catch 22](thoughts/catch%2022.md) and the collingridge dilemma)\n\n## What type of Progress?\n\nDo we care more about technological progress or social progress? We can measure social progress via, maybe, [Gini coefficient](https://en.wikipedia.org/wiki/Gini_coefficient) (measuring income/wealth inequality). Technological progress might be measured by our ability to impact the universe, the physical world around us.\n\n### Happiness\nHappiness isn’t necessarily highest in the places with the most technological progress\n\nIs it wrong to try to measure progress in terms of people's happiness? What about the [hedonic treadmill](thoughts/hedonic%20treadmill.md), will we eventually just regress to a new 'normal'?\n\n## A humanistic take\n[Source: How does progress happen? by *Kelsey Piper*](https://www.vox.com/future-perfect/22652782/roots-of-progress-jason-crawford)\n\n\u003e Progress is anything that helps human beings live better lives: longer, happier, healthier, in mind, body, and spirit. And more choices about how we want to live our lives: our careers; where we live; if, when, and who we marry; whether to have kids or not. Fundamentally, I judge progress by humanistic standards.","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/proof-of-stake":{"title":"Proof of Stake","content":"\nUses 'stake' tokens to earn the right to become a validator of the blockchain. Users are chosen to become validators pseudo-randomly depending on various factors like size of stake, age of stake, etc. Validators check for validity of transactions, signing the block, and adding to the chain. Reward for the validator is the transaction fees.\n\nThe stake is a financial motivator for users not to validate or create fraudulent transactions (i.e. if you care about the chain, you should hope that members of the chain are also honest, mutual [trust](thoughts/trust.md)) \n\nThis validation is known as attesting. You can think of attesting as saying \"this block looks good to me.\" If you attest to malicious blocks, you lose your stake. 128 validators are required to attest to a block to achieve finality on it -- this 128 is known as the committee. The committee works on 32 blocks or 'slots' before disbanding -- this duration is known as an epoch.\n\n[Source: Ethereum Wiki](https://eth.wiki/en/concepts/proof-of-stake-faqs)\n\nTLDR; a set of validators take turns proposing and voting on the next block, and the weight of each validator’s vote depends on the size of its deposit (i.e. stake)\n\nOne of the alternatives to [PoW](thoughts/proof%20of%20work.md)\n\n\u003e Security comes from putting up economic value-at-loss rather than straight up burning energy (however, this doesn't take into account collusion)\n\n## Losing Stake\nFor example, a user can lose a portion of their stake for things like going offline (failing to validate) or their entire stake for deliberate collusion.\n\n## Disadvantages\n- Greater chance of [51% attacks](thoughts/fault%20tolerance.md)\n\t- Though this is questionable, 51% means you need to control 51% of the staked ETH which would probably cause ETH's value to drop significantly. There's very little incentive to destroy the value of a currency you have a majority stake in.\n- Incentive to hoard tokens and not use them","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/proof-of-work":{"title":"Proof of Work","content":"\nMiners solve cryptographic problems in order to earn the right to add a new block to the chain where the fastest miner gets the rights to add along with token rewards.\n\n## Basis\nCryptocurrencies use a distributed ledger (blockchain) to track all transactions in a publicly agreed upon manner.\n\nAll transactions are hashed. Hashing in general is a trivial function. To make it 'work', the network sets a difficulty for how much work can be expected to \"mine\" a new block. Mining is essentially just working to find a valid hash for a batch of transactions. A 'block' is a set of transactions.\n\nBecause the 'winner' is randomly-chosen proportional to the work done, it incentivizes everybody on the network to act honestly and record only true transactions.\n \n\u003e Proof of work makes it extremely difficult to alter any aspect of the blockchain, since such an alteration would require re-mining all subsequent blocks.\n\n## Finality\n[Source: Ethereum Wiki](https://ethereum.org/en/developers/docs/consensus-mechanisms/pow/)\n\n\u003e A transaction has \"finality\" on Ethereum when it's part of a block that can't change.\n\nFinality in proof of work is probabilistic, meaning you cannot be 100% certain a transaction in a block is legitimate, only *statistically certain*. Finality, in this probabilistic sense, refers to the time you should wait before considering a transaction irreversible\n\n## Disadvantagaes\n- Operates on the logic of massive power (hashing power) incentivized into existence by massive rewards (block rewards). Only defense attacks is just scale of the network (attackers of size less than $x$ are discouraged from appearing by having the network constantly spend $x$ every day)\n- [Extremely electricity intensive](https://digiconomist.net/bitcoin-energy-consumption)","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/prototyping":{"title":"Prototyping","content":"\nThe point is to make ideas real. They are (limited) representations of conceptual designs for users to interact with.\n\nSketching for [interaction design](thoughts/interaction%20design.md)\n\n![](/thoughts/images/prototype.png)\n\n### Why prototype?\n-   **save time and money** → don't waste time coding/building the wrong thing\n-   **communication** → discuss ideas with stakeholders\n-   **evaluate** interface effectiveness for communicating conceptual model\n-   further develop **conceptual and physical design**\n\n### Before prototyping\nIdentify:\n-   **questions** that your prototype(s) need to answer\n-   **requirements** you need to address\n-   **users and tasks** that your prototype(s) will support\n\n## Acquiring [mental models](thoughts/mental%20model.md)\n1. Using the system (hands-on learning)\n2. Observing others using the system\n3. Reading about a system (documentation)\n\n## Interaction Types\nDeciding upon which of the interaction types to use, and why, can help designers formulate a conceptual model before committing to a particular interface\n\n1. Instructing: users issue instructions to a system\n2. Conversing: users have a dialog with a system\n3. Manipulating: users interact with objects in a virtual or physical space by manipulating them\n4. Exploring: users move through a virtual environment or a physical space\n5. Responding: system initiates the interaction and the user chooses whether to respond\n\n## Fidelity\nFidelity is partly a matter of completeness. As you get more hi-fi it become more close to the actual deployment platform\n\n6 dimensions to fidelity → fidelity is a spectrum. It is *complicated* to prototype multiple dimensions at once, so don't!\n-   **visual realism:** how real it _looks._ polish, graphic imagery\n-   **physical realism:** shape and form for 3D objects; feel\n-   **scope:** how many features/functionalities included; horizontal vs. vertical\n-   **data:** operates on real vs. faked data\n-   **autonomy:** requires \"supervision\" vs. operates alone\n-   **platform:** interim vs. final implementation\n\n### Lo-fi\nRough (but flexible) proof-of-concept of interface design. Useful for generating or narrowing down requirements.\n\nBenefits\n- cheap/easy to make -\u003e intended to be thrown away\n-   lack of polish → less intimidating for users (surprisingly important!)\n    -   avoids nitpick feedback\n    -   inspires more creative feedback\n    -   more willingness to criticize\n\n### Mid/hi-fi\nIncreasing in **completeness** and **detail**\n- higher degree of functionality\n- higher degree of polish\n\n## Vertical vs Horizontal\n**Vertical prototype**:\n-   includes in-depth functionality for only a few selected features\n-   key design ideas can be tested in depth\n\n**Horizontal prototype**\n-   surface layers only: includes the entire user interface with no underlying functionality\n-   a simulation; no real work can be performed\n\n### Wizard of Oz\nMethod of testing a system that does not yet exist\n\n-   human simulates system's intelligence and interacts with user\n-   user\n    -   uses real or mock interface as expected\n    -   \"Pay no attention to the man behind the curtain\"\n-   \"wizard\" (sometimes hidden):\n    -   interprets subject's input according to a **preset algorithm**\n    -   has computer/screen behave in appropriate manner\n\nPossible downside is that the human can over-/under-estimate the quality of the actual technology being simulated.","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/pseudonymity":{"title":"Pseudonymous Web","content":"\n\u003e \"Despite my suburban liberal upbringing in Canada, on VRChat, I have listened to people who want gun rights, who refuse vaccination, and who reject taxation. My worldview has become more open to every strand of human experience.\" On [Life in the Metaverse](https://reboothq.substack.com/p/metaverse)\n\n[Source: The Future of Social Media is Pseudonymous by *Kyle Qian*](https://qualiaspace.substack.com/p/the-future-of-social-media-is-pseudonymous)\n\nAn identity-based [social graph](thoughts/social%20graphs.md) is fundamentally limited. Your Facebook identity and social graph are mere digital shadows of their physical counterparts, and little more.\n\nBy attaching our real-world identities to everything we do, these platforms feel suffocating and unsafe. Is there any way we can construct fully [virtual worlds](thoughts/virtual%20worlds.md) not tethered to reality? I'm not sure we can.\n\n\"In real life and on Facebook, you’re always signaling information about yourself which may not have anything to do with the context you’re in.\" -\u003e [context-collapse](posts/context-collapse.md)\n\nIn this sense, Facebook’s social graph is a [crutch](thoughts/crutch%20and%20shoe%20metaphor.md) that imitates real-world relationships. Platforms which 1) require or encourage using your real identity or 2) rely on existing social graphs (contacts, classmates, mutuals) merely imitate “being there.” By mirroring the real world, platforms like Facebook are ultimately limited by the very physical connections they seek to transcend.\n\nTogether, these platforms form digitally native social graphs based on what people choose to emphasize about themselves, rather than on legal identity or physical proximity. These social graphs are difficult to create on identity-based platforms, as well as in real life, and are the result of meaningful connections between people who otherwise would never have met.\n\n## Decentralized Identities\n[Source: How Identity Emerges in Crypto Networks by *Graeme*](https://g.mirror.xyz/17-QuzdJJ0n-WGtuFiSXpH13-F3XCBgiPYCRtKANwc8)\n\nIs it possible to have pseudonymous identities in decentralized [web3](thoughts/web3.md) systems? Or does it rely purely on natural human recognition of user handles? What about wallet addresses?\n\nWeb3 promises participants 'persistant pseudonyms' that  have protective functions (e.g. not revealing offline identities, but also allows holders to participate in economic activity and  hold goods while allowing them to hide undesirable traits that may lead to oppression)\n\nWe can then use on-chain transactions to hypothesize and analyze possible affiiliations and cultural attitudes. For example, owning an [NFT](thoughts/NFT.md) whose profits will go towards a charity may signal values similar to that charity/cause.\n\nCan we use these web3 packed pseudonymous identities as a tool for social liberation?","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/public-goods":{"title":"Public Goods","content":"\nOne important advantage of startups over public goods is the possibility of an _exit_. Exits create [incentives](thoughts/incentives.md) for upfront funding, hiring, motivation and alignment through equity, a share in the exit. However, for nonprofits, FOSS, and public goods projects, this “light at the end of the tunnel” does not exist.\n\n[Source: Retroactive Public Goods Funding by *Optimism*](https://medium.com/ethereum-optimism/retroactive-public-goods-funding-33c9b7d00f0c)\n\nHow do we incentivize people to contribute to the [stone soup](thoughts/stone%20soup%20metaphor.md) that is public goods [funding](thoughts/funding.md)?\n\n## Definitions\n### Defining 'public'\n\u003e The vernacular term \"public\" is understood to be _something of the people, freely available for use_—such as parks, roads, and common lands.\n\n\"**A public can be identified and classified by** **_shared problems_**, the extent to which they are aware of such problems, and the extent to which they do something about it.\" Similarly, how do we define a [community](thoughts/communities.md)?\n\nCrypto and [web3](thoughts/web3.md) overcome a lot of the bariers of web1 and web2, namely the inability to satisfy inalienable access to 'public' resources. The internet's so-called \"[public spaces](thoughts/digital%20commons.md)\" are nothing like our cities' public parks. They are merely someone else's private server, where access can be revoked at will.\n\nPublic also means creating venues in which people could begin to identify themselves as part of a collective whole.\n\n\u003e To publish a web document or software application is more than making _something_ public: it's an act of making _a_ public (Warner, 2002)\n\n### Defining 'good'\n\"_Why_ are public parks more desirable than public parking lots? This brings us to an important realization: any definition of public goods presupposes a shared understanding of what is in the public's benefit, and why.\"\n\nThese 'goods' exemplify a set of shared values within the 'public'.\n\nAre there concepts of 'free riders' with public goods? What about [tragedy of the commons](thoughts/tragedy%20of%20the%20commons.md)? \"It is clearly in the interest of society to promote the creation and consumption of public goods—be they vaccines, public libraries, or open source code\"\n\n### Economical\nPublic goods are\n1. non-excludable: it’s extremely difficult to stop someone from using the good, like roads and bridges\n2. non-rivalrous:  it’s abundant, and one person’s use of the good doesn’t substantially reduce the amount left for someone else (e.g. there’s more than enough air to go around)\n\nStatic [open source](thoughts/Making%20and%20Maintenance%20of%20OSS.md) (code that anyone can copy off the internet) is an example of a public good. Another example of these are public [infrastructure](thoughts/infrastructure.md) like roads (although not necessarily, if you have your drivers license revoked you may not be able to make use of the roads in the first place).\n\nIt seems only natural that online media archives and open digital [infrastructure](thoughts/infrastructure.md) should qualify as well.\n\nYet, no matter their claim to universality, instantiations of public goods are always _local_. The public cannot contain everyone. Locality is created and felt through [shared space, time, or experience]. It requires synchronicity of experience, rel: [group limits](thoughts/group%20limits.md)\n\nClub goods are excludable but non-rivalrous. A lot of more recent app launches (e.g. Dispo and Clubhouse) used waitlists to create 'fake scarcity' to transition from a public good to a club good.\n\nRelated: [positive sum worlds](thoughts/positive%20sum.md)\n\n## [Web3](thoughts/web3.md)\nhttps://otherinter.net/research/positive-sum-worlds/\n\nCrypto protocols are one of the most compelling novel institutional forms, specifically deriving from their \"public\" qualities\n1. unrestricted membership + participation\n2. open APIs\n3. transparent allocation of resources and pwoer\n\nYet not perfect\n* Ownership of these resources are concentrated in a precious few (whales)\n* The 'public' that this infrastructure serves is mostly decentralized finance\nBoth of these main tokeholders share one common concern: price\n\n### 'Voice' in web3\n\"The equivalence of stake and voice in crypto is reminiscent of early American democracy, in which political representation was conditioned on property ownership. Under this regime, only 6% of the total US population was eligible to vote—a laughably exclusionary idea of the body politic by today's standards (Ratcliffe, 2013)\"\n\n\"The most consequential members of the crypto-public today are those who hold the most tokens, meaning even small holders are effectively removed from the conversation about what's in their benefit.\" Same concepts as [design justice](thoughts/Design%20Justice.md), we need to talk with and consider the marginalized peoples under existing systems of power so we can gain a deeper understanding of the public that we are building for and how to best serve them.\n\n## Obessions with profit\nWeb3 supposed allows us to 'codify' the set of values that a public goods represents. Yet, in practice in web3, \"little space has been made for different values to be discussed or enacted. Which is why, in the absence of ways to enact our shared values, we default to the lowest common denominator: profit.\"\n\nThe United States Dollar does not have a responsibility to profit its holders. A cryptocurrency is a monetary instrument, not a business.\n","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/quadratic-funding":{"title":"Quadratic Funding","content":"\n Sources: [RadicalxChange](https://www.radicalxchange.org/concepts/quadratic-funding/) and [Vitalik](https://vitalik.ca/general/2019/12/07/quadratic.html)\n \n \u003e Quadratic Funding (QF) is a more democratic and scalable form of matching funding for public goods, i.e. any projects valuable to large groups of people and accessible to the general public.\n\nMatching funding is where governments or other institutions match individual contributions to a project. \n\nIn the QF model, the total funding is the square square root of each contribution summed and then squared. This empowers smaller individual contribution and make sure that a broad public benefits. This supposedly solves the [tragedy of the commons](thoughts/tragedy%20of%20the%20commons.md) problem.\n\n\u003e _Your $N$-th unit of influence costs you $N$_\n\nHow do we get around anonymous identities (or rapid creation of new identities) that abuse the system? Similar with collusion or vote-buying? How dowe get around collusion (if we don't, QF just collapses into one-dollar-one-vote)? \"Quadratic payments do not solve every problem. They solve the problem of governing resources that affect large numbers of people, but they do not solve many other kinds of problems.\"\n\n## Pairwise QF\n[Pairwise-bounded QF](https://ethresear.ch/t/pairwise-coordination-subsidies-a-new-quadratic-funding-design/5553) is a partial solution to collusion.\n\nPairwise-bounded QF computes the total subsidy to a project by looking through all pairs of contributors, and imposes a maximum bound on the total subsidy that any given pair of participants can trigger (combined across all projects). This also means that projects that otherwise would have gotten less money in QF could gain more because of the diversity of supporters garnered.\n\nPairwise-bounded QF generally penalizes projects that are dominated by large contributors.\n\n## Traditional Models\n### One-dollar-one-vote\n![Influence vs Value](https://vitalik.ca/images/qv-files/Market8.png)\n\nTraditional funding model with platforms like [Ghost knowledge](https://www.ghostknowledge.com/) really only fund articles that would be published because some individual would pay for it for themselves (essentially just patronage).\n\n\u003e Phrased less mathematically, either you value the article enough (and/or are rich enough) to pay, and if that's the case it's in your interest to keep paying (and influencing) quite a lot, or you don't value the article enough and you contribute nothing. [Source](https://vitalik.ca/general/2019/12/07/quadratic.html)\n\nBut the problem in this case is that smaller contributors have too little influence and the larger contributors have too much\n\n### One-person-one-vote\n![Influence vs Value](https://vitalik.ca/images/qv-files/Market9.png)\n\nEach person gets a singular vote on whether a good gets produced. There is no 'incentive' or 'room' to contribute beyond that.\n\nThe problem here is that smaller contributors or people who have very *little* stake in the good have an outsized influence relative to those who have *large* stakes.","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/qualia":{"title":"Qualia","content":"\nQualia is the Latin plural for the singular “quale” (quality). Often known as the subjective, conscious experience, or phenomenal properties.\n\n\u003e Examples of qualia include the perceived sensation of _pain_ of a headache, the _taste_ of wine, as well as the _redness_ of an evening sky\n\nTraditionally have second-order properties\n- Ineffable (indescribable)\n- Intrinsic (atomic, unanalyzable, cannot be split into constituent observations)\n- Private (no interpersonal comparisons)\n- Directly apprehended (not mediated by thought, inference)\n\n## Vibes\n[Source: Nameless Feeling in *Real Life Mag*](https://reallifemag.com/nameless-feeling/)\n\n[[thoughts/neural networks|Neural networks]] just assess vibes, they are the literal technical implementation of \"no thoughts, just vibes\".\n\nVibes are very similar to the approximations [machine learning systems](thoughts/machine%20learning.md) use. Both suffer from [Goodhart's Law](thoughts/Goodhart's%20Law.md)\n\nOn context-less data: Like vibes, these metrics carry no context or narrative; they can tell you nothing about how or why something might be desirable\n\nIs [intentionality](thoughts/intentionality.md) derivative with vibes/qualia too?\n","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/quantization":{"title":"Labels and Quantization","content":"\n\u003e \"Where is the knowledge we have lost in the information?\" -- T.S. Eliot's \"The Rock\"\n\nOur obsession of applying labels to everything extends to even whether a [hot dog is a sandwhich or not](https://www.hot-dog.org/culture/hot-dog-sandwich)\n\n\"Accuracy is more useful in entry-level jobs and for novices, because as skill increases, quantification of skill becomes harder.\"\n\nWhy do we have labels in the first place?\n- they help us to communicate complex ideas between each other without having to explain our entire mental models\n- they are attached to societal connotations and perceptions of certain concepts\n- they give legitimacy in the form of social proof to concepts\nMore on this in [terminology](thoughts/terminology.md)\n\nAre overloaded terms still useful? (e.g. [hacker](thoughts/Hackers.md) has so many connotations attached to it) At that point, do we need to create new [terminology](thoughts/terminology.md)? See: [hermeneutical injustice](thoughts/hermeneutical%20injustice.md)\n\n## [Qualia](thoughts/qualia.md)\nIs there any anyway to label or quantify the subjective human experience? Probably not.\n\nIf the same apple sends two very different signals to two different people's brains, how is it that we decipher it to be [semantically](thoughts/semantics.md) identical?\n\nNot sure if there's any way to easily do this\n\n## Non-semantic Information\n\"[the] shadows, wind, rust, in the signs of wear on a well-trodden staircase, the creaks of a battered bridge — all the indexical messages of our material environments\" From [A city is not a computer](thoughts/A%20City%20is%20not%20a%20Computer.md)\n\n## Concepts\n- [Goodhart's Law](thoughts/Goodhart's%20Law.md)\n* McNamara Fallacy: Also known as the quantitative fallacy: making a decision involving purely quantitative observations (ignoring all others) is often wrong. [Source](https://en.wikipedia.org/wiki/McNamara_fallacy)\n* Procrustean: an arbitrary standard is used to measure success, while completely disregarding obvious harm that results from the effort\n\n## Are labels helpful? \nIn a data-driven world, can we and should we try to quantize everything?\n\nSome metrics that are inherently v difficult to quantize (e.g. quality of engagement) and others that are more easy to quantize and thus optimize for (like engagement)\n\n## On Algorithmic decision making\n[Source: Can you make AI fairer than a judge? Play our courtroom algorithm game in *MIT Technology Review*](https://www.technologyreview.com/2019/10/17/75285/ai-fairer-than-judge-criminal-risk-assessment-algorithm/amp/)\n\nNo matter how much data we collect, two people who look the same to the algorithm can always end up making different choices.\n\nWe gave you two definitions of fairness: keep the error rates comparable between groups, and treat people with the same risk scores in the same way. Both of these definitions are totally defensible! But satisfying both at the same time is impossible.\n\nrelevant bit on algorithms and algorithmic decision making -\u003e [To Live in their Utopia](thoughts/To%20Live%20in%20their%20Utopia.md), [Algorithms of Oppression](thoughts/Algorithms%20of%20Oppression.md)","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/questions":{"title":"Questions","content":"\n[Source: Asking Better Questions in *Kernel*](https://kernel.community/en/learn/module-2/better-questions)\n\n\u003e Good questions must come from a sincere desire to learn, rather than as a veiled means of stating your own opinion.\n\nAsking better questions is a skill, which means it can be honed and practiced.\n\nNo one likes feeling indept so many claim to know more than they actually do. Don't lie about what you don't know, and instead celebrate a state of not-knowing, \"for therein lies both truth and liberation\". \n\nThe hope is to genuinely enjoy never knowing what you're going to learn next\n\n### Socratic Method\nA method of hypothesis elimination, where better hypothesis are found by eliminating ones that lead to contradictions.\n\nA Socratic Circle is an approach to understanding texts. It is based off of the assumption that all knowledge is connected to prior knowledge, all thinking comes from asking questions, and that one question should lead to asking further questions.\n\nUsually two 'circles' of students, where the inner circle explores and analyzes the text through questioning and answering while the outer circle observes. The outer circle gives feedback upon the first circle finishing and the two swap positions.\n\n","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/quorum":{"title":"Quorum","content":"\n## Read/Write Quorum\nIn a system with $n$ replicas, we can ensure [[thoughts/consistency|consistent]]\n- writes if a write is acknowledged by $w$ replicas (write quorum)\n- reads if we request reads from $r$ replicas (read quorum)\n\t- e.g. send 3 requests, only 2 have to come back. Choose most up to date based on timestamp\n\nKey thing to note is that $r + w \u003e n$, typically, $r = w = \\frac{n+1}{2}$. This means that quorum is generally majority. Thus, reads can tolerate $n-r$ unavailable replicas and writes can tolerate $n - w$ unavailable replicas.\n\nThen the read will see the previously written value (as the read and write quorum share $\\geq 1$ replica). Client can then 'repair' the servers by sending its most up to state to servers that are out of date (with original logical timestamp! this is an [[thoughts/idempotence|idempotent]] operation, should be fine) -- this is called **read repair.**\n","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/quotes":{"title":"Quotes","content":"\nSome quotes to live by.\n\n1. \"**Choose joy.** Choose it like a child chooses the shoe to put on the right foot, the crayon to paint a sky. Choose it at first consciously, effortfully, pressing against the weight of a world heavy with reasons for sorrow, restless with need for action.\" [Source](https://www.themarginalian.org/2020/10/21/14-years-of-brain-pickings)\n2. \"In science, if you know what you are doing, you should not be doing it. In engineering, if you do not know what you are doing, you should not be doing it.\" [Richard Hamming: The Art of Doing Science and Engineering]\n3. \"We tend to wear our ability to get by on little sleep as some sort of badge of honor that validates our work ethic. But what it really is is a profound failure of self-respect and of priorities. What could possibly be more important than your health and your sanity, from which all else springs?\" [Source](https://www.themarginalian.org/2019/10/23/13-learnings-13-years)\n4. \"Who are the people, ideas, and books that magnify your spirit? Find them, hold on to them, and visit them often.\" (re: [friendship](thoughts/friendship.md))\n5. \"Our maps are still maps, approximating the landscape of truth from the territories of the knowable — incomplete representational models that always leave more to map, more to fathom, because the selfsame forces that made the universe also made the figuring instrument with which we try to comprehend it.\" [Source](https://www.themarginalian.org/2019/10/23/13-learnings-13-years)\n6. \"Forgiveness is the alchemy by which the shame transforms into the honor and privilege of being invited into another’s darkness and having them witness your own with the undimmed light of love, of sympathy, of nonjudgmental understanding. Forgiveness is the engine of buoyancy that keeps the submarine rising again and again toward the light, so that it may become a lifeboat once more.\" [Source](https://www.themarginalian.org/2019/10/23/13-learnings-13-years)\n7. \"If an architect believes for a moment that there are hooks in the sky to hang his creations from, he may be able to conceive of structures that he would otherwise not dare to think about. Once the design starts to take shape, he may then begin to see ways in which the essence of it can still be achieved without the need for sky-hooks at all. Maybe this will work for us, too.\" (Source: Steve Grand, Creation: Life and How to Make It) (re: [skyhooks](thoughts/skyhooks.md))\n8. \"People need to be able to shape, extend, reconfigure, and repair their environment to feel truly at home within it... And when there's no space to call your own, there's no opportunity to take refuge in quiet and solitude, and it's more difficult to share space with others.\" [Source](https://kmcgillivray.github.io/a-web-pattern-language/a-domain-of-ones-own/) \n9. \"**You must be completely awake in the present to enjoy the tea.** Only in the awareness of the present, can your hands feel the pleasant warmth of the cup. Only in the present, can you savor the aroma, taste the sweetness, appreciate the delicacy.\" [Source](https://theteacupoflife.com/2014/03/thich-nhat-hanhs-tea-meditation.html)\n10. “Even if it’s not your ideal life, you can always choose it. No matter what your life is, choosing it changes everything.” [Source](https://perell.com/essay/the-price-of-discipline/)\n11. “We're all just walking each other home.” ― Ram Dass\n12. \"磨刀不誤砍柴功\" -- Chinese Proverb. Taking a break to sharpen your saw will not delay you from cutting wood more\n13. Never be ashamed to let your feelings, smiles and tears shine a light in this world.\n14. Be humble at the mountaintops, be strong in the valleys, and be faithful in between. [Source](https://www.marcandangel.com/2022/01/18/19-great-truths-my-grandmother-told-me-on-her-90th-birthday/?curius=1417)\n15. \"Anything new is by nature without precedent — meaning, without data to know whether it will work or not. So when we approach building new things, we don’t optimize for metrics. We optimize for feelings.\" [Source](https://browsercompany.substack.com/p/optimizing-for-feelings?s=r)\n16. \"Yet I live earnestly, building the most beautiful sandcastles I can, knowing they will be washed away. And getting others on the beach to build with me, at times even suspending our belief of the fact that it will disappear; letting ourselves be fooled for a moment that it will last.\" [Source](https://altered.substack.com/p/dust)\n17. \"Time is not linear, but a series of concentric circles, like the rings of a tree. Ourselves today, our newest selves, are the outermost rings of a tree. We are comprised also of every person we were in the years leading up to today, even if those layers have compressed into the past.\" [Source](https://katiewav.substack.com/p/a-personal-syllabus-2022)\n18. \"You can’t build railroads before it is railroad time.\" _(Chuck Thacker)_\n19. “Genius is no more than childhood recaptured at will.” *(Charles Baudelaire)*\n20. “In place of occasional experiences of depth that renew and satisfy us, we are simply given an infinite surface upon which to skim indefinitely.” ([Source](https://theconvivialsociety.substack.com/p/what-you-get-is-the-world))\n21. \"Many a failure of love follows on the—usually false—opinion that we have exhausted the other person’s inside, that there is no further promise of depth.\" ([Source](https://theconvivialsociety.substack.com/p/what-you-get-is-the-world))\n\t- Deep attention as diversification: gaining access to a bit more of the world.","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/r-K-Selection-theory":{"title":"r/K Selection theory","content":"\n\u003e In ecology, r/K selection theory relates to the selection of combinations of traits in an organism that trade off between quantity and quality of offspring\n\n|r-selected|K-selected|\n|--|--|\n|many offspring, low investment| few offspring, high investment|\n|thrive in unstable habitats|thrive in stable habitats|\n\n## r-selection\n_r_-selected species are those that emphasize high growth rates, typically exploit less-crowded ecological niches, and produce many offspring, each of which has a relatively low probability of surviving to adulthood\n\nExamples include dandelions, insects, rodents, etc.\n\n## K-selection\n_K_-selected species display traits associated with living at densities close to carrying capacity and typically are strong competitors in such crowded niches, that [invest](https://en.wikipedia.org/wiki/Parental_investment \"Parental investment\") more heavily in fewer offspring, each of which has a relatively high probability of surviving to adulthood\n\nExamples include elephants, humans, whales, etc.\n\n","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/rationality":{"title":"Rationality","content":"\nAn act is rational (roughly) if it is most likely to maximize satisfaction of the agent’s preferences or [[thoughts/utility|utility]].\n\n**Bounded rationality:** the choices that people make attempt to maximize benefit and minimize cost are imperfect: humans have a hard time precisely estimating benefit and cost and thus use imperfect heuristics to pick the most promising choices.\n\nInteresting argumental ties to [effective altruism](thoughts/effective%20altruism.md), especially w.r.t. optimizing for benefit and minimizing cost.","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/reading":{"title":"Reading","content":"\n1. getting back into reading\n2. Books, with some effort, can help you learn to walk, but only people can help you orient where to walk. In other (equally vague yet obvious) words, I can’t know (through books), if I don’t know what to know (through people). (quote from eva)\n3. organizing thoughts\n\nI used to think that to be a productive member of society, one just had to put their head down and try to churn out as much output as possible. I very much subscribed to the belief that if I just kept constantly producing new things, I would eventually learn from my mistakes and improve rapidly. I found that while, yes, this approach allowed me to build my technical skills really quickly, I applied it to everything — even things that didn't need it. I held a metaphorical hammer in my hands and everything seemed like a nail.\n\nOver the summer, I began to read again. I started with technical write-ups, fiction novels, traversed into self-help, and to memoirs. I started to read more about the state of the world and critically discuss these with family and friends. Reading helped me colour in the lines as to [*why* we need to build](thoughts/value%20setting.md) in the first place. I realized that the problems we try so hard to solve with technology are not tech problems, but human ones.\n\nI've started to write more about these ideas, at first to help me organize my own thoughts, but eventually segued into an excuse for me to talk to people about interesting ideas and get their perspective. It's started a sort of chain reaction in a sense, with an observation from a book leading to a conversation with a friend to a blog post ad infinitum — leading me to be a more informed and curious individual.\n\n","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/recommendation-system":{"title":"Recommendation System","content":"\n## *Captivating algorithms: Recommender systems as traps*\n\nMason’s definition of a trap: ‘an invention for the purpose of\ninducing animals to commit incarceration, self-arrest, or suicide’ (p. 657) -- this is exactly what recommender systems get users to do: trap themselves in a viscous cycle.\n\nTraps operate through 'scripted roles' -- the ability of the hunter to construct a mental model of its prey. It is not taking its [free will](thoughts/freedom.md) to make decisions, but rather manipulating it to its own demise. Recommender systems, Seaver posits, are thought-traps.\n\nCold Start Problem: when one has no data yet. Without data, data driven recommendations do not work (see: [stone soup metaphor](thoughts/stone%20soup%20metaphor.md))\n\nTemporarily taking off the veil of abstraction and seeing them for what they really are - pieces of human engineering: \"Placing algorithmic systems alongside tripwires and trapdoors not only takes the shine off, reminding us that they, too, are products of ordinary human engineering; it also helps us think about how they work, the ways of thinking they depend on, and how they might be critiqued.\"\n\n\"Successful companies like Facebook have become successful, Eyal writes, by becoming ‘first-to-mind’: their users ‘feel a pang of loneliness and before rational thought occurs, they are scrolling through their Facebook feeds’... We can use 'captology' to designate this understanding of people in behaviourism inflected terms, as habitual minds with tendencies and compulsions that make them susceptible to persuasion and targets for capture.\"\n\nOptimization metrics (see [quantization](thoughts/quantization.md))\n1. RMSE (root mean squared error) - how accurate the recommender systems were\n\t1. RMSE just doesn't work up to a point because user preferences are inherently unstable or 'noisy' signals. These vary significantly with time/setting and posed a serious challenge to predictive accuracy\n2. Transitioned to 'captivation metrics' - ability of a system to capture user [attention](thoughts/attention%20economy.md) or 'engagement'\n\t1. Moving towards interpreting behaviours (ex. skipping a video, clicking away, watch time, etc.) rather than explicit ratings (ex. asking users to give feedback on accuracy)\n\t2. 'Dwell time': length of individual user sessions\n\n## Approaches\n### Content-based Recommendation\n1. \"more things like this...\"\n2. Compare the content of an item to user's preferred items\n3. A form of [[thoughts/supervised learning]]\n\n### Collaborative filtering\n1. \"users like you looked for...\"\n2. Based on identification of similar users and their patterns of activity\n3. A form of [[thoughts/unsupervised learning]]\n\nOne way of doing this is using a technique called matrix factorization, which is a [[thoughts/latent-factor model]] for entries in matrix $Y$.\n\nLoss function:\n$$f(Z,W) = \\lVert ZW - Y \\rVert_F^2 + \\frac{\\lambda_1}{2}\\lVert Z \\rVert_F^2 + \\frac{\\lambda_2}{2}\\lVert W \\rVert_F^2$$","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/regularization":{"title":"Regularization","content":"\nA method for controlling [[thoughts/complexity|complexity]]. Our main tools:\n1. Model averaging (e.g. [[thoughts/Ensemble method|ensemble methods]])\n2. Regularization (this)\n\nWhen we have multiple models with the same training models, we should pick models that are *more conservative* (e.g. in [[thoughts/linear regression|linear regression]], pick smaller slope)\n\nWe should regularize $w_j$ so that they don't explode.\n\nMakes the tangent to the level curves of the gradient point towards the global minimum\n\n![[thoughts/images/l1-vs-l2-regularization.png]]\n\n### L0-Regularization\n- Adds penalty on number of non-zeros to select features\n\n$$f(w) = \\mathcal L + \\lambda \\lVert w \\rVert _0$$\n\n### L2-Regularization (Ridge Regression)\n- Generally decreases overfitting\n\n$$f(w) = \\mathcal L + \\frac{\\lambda}{2} \\lVert w \\rVert ^2$$\n\nThis *almost always* decreases test error. Bigger $\\lambda$ also means gradient descent converges faster.\n\nTo help with this, we can standardize continuous feature by replacing it with its z-score.\n\n### L1-Regularization (LASSO)\n- Like L2-regularization, it’s convex and improves our test error\n- Like L0-regularization, it encourages elements of $w$ to be exactly zero (though not as sparse)\n\n$$f(w) = \\mathcal L + \\lambda \\lVert w \\rVert _1$$\n\n\n\nWe can actually combine this using an [[thoughts/Ensemble method]] + bootstrapping (BoLASSO):\n- Create bootstrap samples\n- Run feature selection on each sample\n- Take the intersection of selected features\n- Reduces false positives\n\n#### How is this different from L2?\nThe penalty stays is proportional to how far away $w_j$ is from zero. There is still something to be gained from making a tiny value exactly equal to 0.\n\nWith L2, the penalty gets smaller as you get closer to zero. The penalty asymptotically vanishes as $w_j$ approaches 0 (no incentive for “exact” zeroes).\n\nL1-Regularization sets values to exactly 0, basically removing features from the model","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/religious-authority":{"title":"Religious authority","content":"\nAs it pertains to [epistemic authority](thoughts/epistemic%20authority.md)\n\n## Debates from Classical South Asia\n- Right and wrong aren’t directly perceptible to humans\n- But some traditions in CSA say yes: revelation/sacred texts\n- The source must be āpta with regard to what’s right and wrong; must have:  \n\t- perfect knowledge of right and wrong\n\t- the ability to communicate this knowledge\n\t- at least lack the intention to lie, if not have the intention to communicate honestly\n- Vedas are author-less so can have no faults or biases -- uniquely trustworthy \n- Dharmakīrti against authority of the Vedas\n\t- Even if there was a flawless revealed source, it wouldn't help as the the revealed source still has to be interpreted and this necessarily happens through human interactions mediated by language\n- Partiality makes communication possible, words are meaning-laden (see: [terminology](thoughts/terminology.md)) because of conventions and usage\n\t- No one, then, can know the meaning of an 'authorless' word: \"it is not possible in the case of words that lack an [original] expounder\"\n\t- Common usage is partial and *not* an independent source of knowledge\n\t- \"Since the meaning of authorless words [can] be known neither from tradition, nor from reason, nor from the [ordinary] world, it is [only] proper [to say] that there is no cognition [of the meaning] in this case\"\n\t- See also: derived [intentionality](thoughts/intentionality.md)\n- Cannot trust other humans who are also flawed\n\t- \"Indeed, a blind [person] does not find the way when led by [another] blind [person]!\"\n\t- Since no human being has overcome the confusion which is due to [moral] defects, as an expositor [of the Veda] he does not know the supersensible restriction [of Vedic words] to a particular meaning by himself","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/rendering":{"title":"Rendering","content":"\n## Projective Rendering\n1. For each triangle of the object/mesh\n\t1. Project its vertices onto the screen\n\t2. For each pixel in the triangle on the screen\n\t\t1. Compute the colour\n\nUtilizes parallelism to take advantage of SIMD (GPUs are fast at this!)\n- Vertex shader: run for every vertex to transform it to normalized screen space\n- Fragment Shader: run for every pixel to compute the pixel colour\n\n## Raytracing\n1. For each pixel in the image\n\t1. Generate a ray\n\t2. For each triangle\n\t\t1. Test intersection of triangle and ray\n\t3. Compute colour based on closest object\n\n## Coordinate Systems\nWhich way is up?\n1. Y is up\n2. Z is up\n\nCan also either be (imagine both of the following where X is thumb, Y is pointer, Z is middle)\n1. Left-handed\n2. Right-handed","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/replication":{"title":"Replication","content":"\n\u003e A node that has a copy of the data is called a *replica*\n\nReplication is the act of ensuring [[thoughts/consistency|consistency]] of data across replicas. If one replica is faulty, others are ideally still accessible\n\nOf course, if data doesn't change, this is an easy problem: just copy it. Hard problem is when the data changes.\n\nCan take inspiration from hardware systems! RAID (Redundant Array of Independent Disks) which is used to replicate within a single computer fills a similar role but RAID has a single controlled whereas distributed systems have nodes that act independently.\n\nAn important concept in replication (and [[thoughts/message broadcast|message broadcast]]) is making sure that we avoid cases where losing an ACK could lead to users doing an action multiple times (e.g. pressing the like button)?\n\nThis can be done by ensuring [[thoughts/idempotence|idempotence]] in our actions.\n\n## [[thoughts/State Machine Replication (SMR)|State machine replication]]\nCan be done by FIFO-[[thoughts/message broadcast#Total order broadcast|total order broadcasting]] every update to all replicas. Whenever a replica delivers an update message, it applies it to its own state\n\nThis is what underlies a lot of [[thoughts/blockchain|blockchains]], distributed ledgers, smart contracts, etc. ([[thoughts/ethereum|Ethereum]] is just one big state machine)\n\n","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/representation":{"title":"Representation","content":"\n## Symbolic Representation\n-   Dretske just kinda doesn't agree w/ the pioneer 10 space probe plate lmao\n    -   symbols will not mean anything to any alien life\n    -   we find it easy to understand because we have the context and we live on this planet\n-   what sort of things can be representations\n    -   words/pictures/numbers/diagrams\n    -   state of mind, can represent almost anything at all\n-   what sort of things can be objects of representations\n    -   almost anything (physical objects, sentences, numbers, moods, feelings, emotions, non-existent things)\n    -   pictures represent by resemblance → derivative [intentionality](thoughts/intentionality.md)\n        -   ‘resemblance theory of pictorial representation’, or the 'resemblance theory'\n-   X represents Y → suggests that representation is a relation between two things\n-   is there a basic type of representation underlying everything else?\n    -   Crane says mental representations are the most basic level\n    -   pictures dont work\n        -   represent by resemblance\n        -   When we try to represent the difference between … and …, if … then …, and either … or … in pictures, we draw a complete blank. There just seems no way of doing it.\n    -   words don't work either\n        -   represent by convention (see [terminology](thoughts/terminology.md))\n        -   same words in same context mean the same thing to different people\n    -   all other kinds of representation all depend on mental representations in order to work\n        -   many things that we take for granted cannot be represented in terms of pictures → e.g. relations between ideas like \"if it doesn't rain this afternoon, we will go for a walk\"\n- Mental representations are either naturalistic or conceptual\n\t-   naturalistic → matter of correlation, \"these spots mean measles\", spots are a reliable indicator of measles\n\t\t-   teach us about the term, they appeal to natural laws and science\n\t-   conceptual → \"this read light means stop\", matter of convention, connection is arbitrary\n\t\t-   what a competent speaker knows when he/she knows the term\n\nRelated thought experiments: [Brains in a Vat](thoughts/Brains%20in%20a%20Vat.md), [Twin Earth Argument](thoughts/Twin%20Earth%20Argument.md)","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/research-debt":{"title":"Research Debt","content":"\n[Source: Research Debt in *Distill Pub*](https://distill.pub/2017/research-debt/)\n\nPartly works because we can utilize [collaborative thinking](/posts/collaborative-thinking). Related: [knowledge distillation](thoughts/knowledge%20distillation.md), [teaching](thoughts/teaching.md)\n\nThinking about understanding knowledge as climbing a mountain. Every time novel work happens, the mountain gets a little bit taller.\n\n\u003e Mathematics is a striking example of this. For centuries, countless minds have climbed the mountain range of mathematics and laid new boulders at the top. Over time, different peaks formed, built on top of particularly beautiful results. Now the peaks of mathematics are so numerous and steep that no person can climb them all.\n\nYes, the climb is hard but it could be easier. Let's build staircases for the mountains.\n\nHow do we reduce [interpretive labour](thoughts/interpretive%20labour.md) for learners?\n\n## Debt in research\n* Poor exposition -\u003e no good explanation of ideas and concepts\n* Undigested ideas -\u003e it takes effort to polish ideas, developing the right analogies, language, and ways of thinking\n* Bad abstractions and notation -\u003e abstractions and notation are the user interface of research. To have bad notation is to have bad ways to interact with the underlying knowledge\n* Noise -\u003e there's *too* much new progress being made each day. How do we choose what to focus on?\n\nNot just about poorly explained ideas, but rather the lack of ideas being digested and worked through in public (communal messiness of thought). How can we create better abstractions, notations, and visualizations to improve how we interact and interface with ideas?\n\n\u003e Part of thinking is having a conversation with ourselves.\n\n## Distillation\n\"Distillation is also hard. It’s tempting to think of explaining an idea as just putting a layer of polish on it, but good explanations often involve transforming the idea. This kind of refinement of an idea can take just as much effort and deep understanding as the initial discovery.\"\n\nSo who should distill knowledge?\n* Needs to be more than one person: too much knowledge to polish every idea from scratch\n* Cannot be less skilled non-experts: refining and explaining ideas requires creativity and deep understanding\n\nIs distillation a form of [maintenance](thoughts/creation%20vs%20maintenance.md)?\n\n### Where are the Distillers?\nThe research distiller is an integral role for a healthy research community, yet almost no one is filling it right now.\n\nIs it because people want their work to look hard? Do people not enjoy distillation? While both of these may play a small part, the biggest part is malalignment of [incentives](thoughts/incentives.md) (relevant to [incentives in open source maintenance](posts/paid-open-source.md)).","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/research-institutions":{"title":"Research Institutions","content":"\n\u003e Great hackers tend to clump together (PG, 2004)\n\n[Money](thoughts/money.md) is power. It dictates what type of research and work gets [funded](thoughts/funding.md), and who gets to do it. \n\nIt's important to be aware of the incentive structures in place wherever you work (e.g. academia, industry): 80k hours of work in your life, it matters a lot where that goes (voting with labour). \n\nOne of the reasons we're not seeing another Xerox Parc/Bell Labs, it feels like there is too *much* [perception in globalized communities](thoughts/communities.md). Intimacy is destroyed when the balance of internal/external balance skews too far towards external. Without intimacy, there is no [trust](thoughts/trust.md). Without trust, there is no exploration. (rel: [group limits](thoughts/group%20limits.md))\n\nAs of now, there are no good spaces to work on long-term (think 10+ years in the future) research to enable the visions of the future. Also, is long-term innovation just [infrastructure](thoughts/infrastructure.md)?\n\nLimitations of private companies and startups\n- You spend less than what you make (for sake of profit)\n- Trade-off between intellectually interesting and profitable (? debatable but generally true)\n- Not as much funding of [public goods](thoughts/public%20goods.md). Arguably, \"predicting future public goods is as important a social function as predicting future private goods\"\n\nCan we move away from depending completely on only one of \n1. Government funding\n2. Market Influence\n3. [Academia](thoughts/academia.md)\n\n\u003e The best predictor of success in innovation is the number of other people they come into contact with\n\nSome thoughts. Already have been thinking about this in relation to [hackathons](posts/hackathons.md), [paid open source](posts/paid-open-source.md)\n\n## 3rd Spaces\nFor people wanting to create change, why do we choose to do that through innovation rather than policy? (is this due to [creation vs maintenance](thoughts/creation%20vs%20maintenance.md) approaches to thinking?)\n\nProcurement services: finding a business application of research (specifically government funded)\n\nWe're not building a utopia of research, this is more about finding a relationship/group of people you can be yourself with. It doesn't need to be permanent, recognizing people have different stages in their lives. Once youre done, you can move on.\n\nRelated: reinventing [hackathons](posts/hackathons.md) as 3rd spaces\n\n## PARPA and alternative [funding](thoughts/funding.md) models\nhttps://benjaminreinhardt.com/parpa / https://benjaminreinhardt.com/wddw / https://www.nber.org/system/files/working_papers/w24674/w24674.pdf\n\nFrom the [Atlantic](https://www.theatlantic.com/science/archive/2019/07/we-need-new-science-progress/594946/): \"In a recent paper, Pierre Azoulay and co-authors [concluded](https://www.nber.org/papers/w15466) that Howard Hughes Medical Institute’s long-term grants to high-potential scientists made those scientists 96 percent more likely to produce breakthrough work. If this finding is borne out, it suggests that present funding mechanisms are likely to be far from optimal, in part because they do not focus enough on research autonomy and risk taking.\"\n\nAnother potential method is research labs becoming sustainable by bringing products to market\n\n## Orgs\n### New Science\nhttps://newscience.org/\n\n\u003e New Science will create a network of new scientific institutes pursuing basic research while not being dependent on universities, the NIH, and the rest of traditional academia and, importantly, not being dominated culturally by academia.\n\nTheir plan is to not replace traditional academic institutions, but to develop alternative/complementary ones to provide 'competitive pressures' on existing ones. New Science is to research as Silicon Valley was to entrepreneurship.\n\nIncentive and organizational structures are not everything.  You can copy all of the US’s laws and structures of government and this will absolutely not lead to your country’s GDP per capita suddenly (or ever) jumping to $60k/year. Similar things can be said about research organizations.\n\n\"Instead, I believe that the most promising way to achieve large-scale improvement in the way basic scientific research is organized is to start small, help individual scientists, and to make [small steps towards a much better world](https://marginalrevolution.com/).\" Is this potentially good justification for [minigrants](thoughts/idea%20list.md)?\n\n### Santa Fe\nhttps://www.santafe.edu/\n\nThemes of research generally surround complex systems and a more system-based approach to analyzing and learning about the world: https://www.santafe.edu/research/themes\n\n\u003e Computers were becoming more powerful, and some scientists began to dream of a day when they might simulate highly complex systems, even living systems, in silico.\n\n\"We weren’t disillusioned,\" [Pines, the SFI Co-founder] says. \"But we recognized that [universities](thoughts/academia.md) were ill-equipped to nurture emerging new fields, and we were thinking about how we could help them grow. If we could create an institution where they could flourish, we thought we could make a difference.\"\n\n\u003e All we needed was a few million dollars, a building, a staff, and a great deal of luck... The key was simply to create a refuge for brilliant scholars to interact in an environment that was free from boundaries – what one collaborator many years later called “a spa for the brain.”\n\n","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/resource-interaction":{"title":"Resource Interaction","content":"\nInteractions arise naturally from the affordances of resources or are purposefully designed into [organizing systems](thoughts/organizing%20system.md). Intersects with [interaction design](thoughts/interaction%20design.md)\n\nThe most common interactions are\n1. Accessing resources\n2. Merging resources\n\nDistinguishing interactions means looking at user requirements, resource properties used, and the legal, social and organizational environment.\n\nTo enable interactions, it is necessary to identify, describe, and sometimes transform resources.\n\nOne approach to resource transformation is to use a *crosswalk* which are equivalence tables that relate resources from one organizing system to another\n\nAnother is to use *data mapping*, in which descriptions layers are compared and matched using either unidirectional or bidirectional links. This allows us to bridge the vocabulary problem in which different people refer to the same concepts slightly differently.\n\nAs for evaluation criteria, generally the most important aspects are\n1. Efficiency (timeliness and cost)\n2. Effectiveness (accuracy and relevance of results)\n3. Satisfaction (user sentiment)","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/rhizomatic-vs-arborescent":{"title":"Rhizomatic vs Arborescent Systems","content":"\nSee also: [[thoughts/A City is not a Tree|A City is Not a Tree]]\n\n## Arborescent\nHierarchical, tree-like networks.\n\nComes from the way genealogy trees are drawn: unidirectional progress, with no possible retroactivity and continuous binary cuts.\n\nWhenever we have a tree structure, it means that within this structure no piece of any unit is ever connected to other units, except through the its parent (meaning the unit as a whole)\n\nDoes power always need to function top down?\n\n\u003e \"The enormity of this restriction is difficult to grasp. It is a little as though the members of a family were not free to make friends outside the family, except when the family as a whole made a friendship.\"\n\nThe structure of a [[thoughts/blockchain|blockchain]] follows this very closely.\n\n## Rhizomatic\n\u003e  \"a rhizome has no beginning or end; it is always in the middle, between things, interbeing, intermezzo.\" (Deleuze and Guattari in *A Thousand Plateaus*)\n\nA nonlinear and non-hierarchical network with no specific entry or exit points. Defined as a *non-arborescent* network.\n\nAlso what [[thoughts/Rhizome Proposal|Rhizome]] is named after.","lastmodified":"2023-02-15T01:38:21.505821366Z","tags":null},"/thoughts/right-to-be-forgotten":{"title":"Right to be forgotten","content":"\nResistance against [digital permanence](thoughts/digital%20permanence.md)\n\n## Right to be forgotten\n[Denegri Case](https://restofworld.org/2021/argentina-denegri-google-right-forget/) and the [Right to be forgotten](https://en.wikipedia.org/wiki/Right_to_be_forgotten)\n\nRight for individuals to \"determine the development of their life in an autonomous way, without being perpetually or periodically stigmatized as a consequence of a specific action performed in the past\"\n\n\"The public interest, which sometimes stands against the right to deletion and also the right to be forgotten, is the right of the public to know.\"\n\n\"By changing what we were, you change what we are and what we are going to be.\"\n\nBarbra Streisand Effect: efforts to hide information result in even greater publicity\n","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/safety":{"title":"Safety","content":"\n\u003e A promise in [[thoughts/distributed systems|distributed systems]] that claims that \"something bad\" will never happen\n\nThis is obviously broad, but can have multiple flavours including never returning null fields, dead-locks should never happen, etc.\n\nInterestingly, all properties can be expressed as the intersection of safety and [[thoughts/liveness|liveness]] properties","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/scientific-progress":{"title":"Scientific Progress","content":"\nHeavily attached to societal [progress](thoughts/progress.md) and the concept of defining what 'forward progress' even means.\n\nHas the scientific culture of being wrong now vs a few hundred years ago changed? Would Einstein survive in the modern age? Probably not.\n\nHypothesizing that this is leading to small incremental changes rather than monumental new theories/original work from being developed.\n\n\u003e \"Science advances one funeral at a time\"\n\nPeople get too attached to their theories. (e.g Planck and Einstein)\n\n## Sleeping Beauties\nThe \"sleeping beauty\" of science papers are papers that are dormant for 10 years then have a lot of citations.\n\nUsually indicative of work that was too 'out there' or didn't align with existing incentive structures/measures of success when it was first published and got burried, only to be 're-discovered' down the line.\n\nIterative science and Karl Popper's [Philosophy of science](thoughts/philosophy%20of%20science.md)","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/search":{"title":"Search","content":"\n\u003e Search has co-opted the citation, vis-à-vis the hyperlink\n\nThe post-WWII 'information explosion' meant that we have a lot of info and not great means of looking through it to find what we want. This is a form of [information retrieval](thoughts/information%20retrieval.md) and way of answering [questions](thoughts/questions.md).\n\nInefficient search leads to\n1. knowledge gaps\n2. errors\n3. repeating research\n4. times spent searching\n5. knowledge silos\n\nFinding stuff is hard because\n1. theres a lot of things (large haystack, small needle)\n2. semantic meaning and intention is hard to extract/understand\n3. search systems are not complete\n4. individuals have different requirements for what they are looking for (is it possible to create personalized search engines?)\n\nGood way to prototype search system is to analyze the typical dimensions that users search for things along and build those in. There should be support the five interaction strategies\n1. browsing\n2. known item searching\n3. analytical searching on one or more of the facets\n4. empirical searching based on user profiles\n5. similarity searching\n\nSearch is a form of [recommendation system](thoughts/recommendation%20system.md)\n\nA diary of searches: [Search Diary](thoughts/Search%20Diary.md)\n\nEssay on [Bias in Search](thoughts/Bias%20in%20Search.md)\n\n### Queries on [information](thoughts/information.md)\nHow do we convert a query into subject words and then locate these words in the catalogue if people describe things differently? How do we resolve synonyms?\n\nIncreasing number of words that describe an item will increase recall at the cost of precision.\n\n#### Precision/recall trade-off\nThe trade-off between recall and precision decides whether a search finds all relevant documents (high recall) or only relevant documents (high precision).\n\n### [Infrastructure](thoughts/infrastructure.md) is a trap\n\n\u003e Algorithmic recommendation has settled deep into the infrastructure of online cultural life, where it has become practically unavoidable.\n\nSo used to digital extractivism and data mining that it has become hidden to us now.\n\n\"An infrastructure is a trap in slow motion. Slowed down and spread out, we can see how traps are not just devices of momentary violence, but agents of ‘environmentalization’\"\n\nThe boiling frog problem -- we don't notice we're dying until it's too late.\n\n## Boutique Search Engines\n[Source: Re-Organizing the World’s Information: Why we need more Boutique Search Engines by *Sari Azout*](https://sariazout.mirror.xyz/7gSSTJ96SEyvXeljymglO3zN4H6DCgVnrNZq8_2NX1A)\n\nWe've returned to the *curated web* with Notion, Airtable, and Readwise collections, yet we haven't found good ways to make them multiplayer.\n\nStill thinking about this in the context of collaborative digital gardens (e.g. [Quartz](http://quartz.jzhao.xyz/))\n\n\u003e What started as a well-intentioned way to organize the world’s information has turned into a business focusing most of its resources on monetizing clicks to support advertisers rather than focusing on the search experience for people.\n\nThe big thing here is that horizontal/'universal search' sites like Google use the same interface to search everything, relying on natural language to decipher user intentions. Vertical search players like Yelp/Zillow filled the functionality and relevancy gaps by using more structured search formats appropriate to the medium.\n\nCuration, when thought of in the context of sharing bite-sized, isolated bits in feed-like architectures, is predominantly about entertainment, not utility. **How do we move beyond the search bar in an [attention economy](thoughts/attention%20economy.md)?**\n\nBut if we curate, who curates the curators? We then run into a meta-governance problem. Mirror's [Token Race](https://dev.mirror.xyz/dLLIq4Iebg5DLWJbOWa3sU6oQuwbogkmqPnz-ZbzPUg) appears to be a good start to answering this question.\n\n### On Ads\nWhen you monetize via ads, curation takes a backseat to featuring advertisers - there is just less digital real estate available to curate your own recommendations. This creates [trust](thoughts/trust.md) gaps between users and search engines.\n\nThe search box versus the feed\nintentional browsing vs being served by an algorithm\n\nIs it possible to move away from the ‘feed’-based model of browsing the social internet?\n\n\u003e The “feed”–an archaic form of content consumption that is effectively just a direct visual manifestation of the data structure that powers it – is a medium that is effectively designed to be consumed alone. –Humphrey Obuobi\n\n\"I realized that the experience of research is exactly opposite to the way I usually often encounter information online. When you research a subject, you make a series of important decisions, not least what it is you want to research, and you make a commitment to spend time finding information that doesn’t immediately present itself. You seek out different sources that you understand may be biased for various reasons. The very structure of the library… allows for browsing and close attention. Nothing could be more different from the news feed, where these aspects of information—provenance, trustworthiness, or what the hell it’s even about—are neither internally coherent nor subject to my judgment. Instead this information throws itself at me in no particular order, auto-playing videos and grabbing me with headlines. And behind the scenes, it’s me who’s being researched.\"\n\n## Search Engine to Oracle\n[Source: Language models like GPT-3 could herald a new type of search engine in *MIT Technology Review*](https://outline.com/ZhCArb)\n\ntransition from aggregator of information to oracle\n\npagerank -\u003e rank literally whats relevant, asks the user to determine what info they wanna actually use\n\noracle -\u003e tells you the 'right' answer\n\n\"The idea is that instead of searching for information in a vast list of web pages, users would ask questions and have a language model trained on those pages answer them directly. The approach could change not only how search engines work, but what they do—and how we interact with them\"\n\n[epistemological](thoughts/epistemology.md) question: Metzler and his colleagues are interested in a search engine that behaves like a human expert. It should produce answers in natural language, synthesized from more than one document, and back up its answers with references to supporting evidence, as Wikipedia articles aim to do.\n\n## Search Engines as Faith\nThey freely provide, it seems, a sorting of the wheat from the chaff, and answer our most profound and most trivial questions. They have become an object of faith. Many view the results of search as objective.\n\n\"Like gods, these mathematical models were opaque, their workings invisible to all but the highest priests in their domain: mathematicians and computer scientists.\" (Cathy O'Neil)\n\nThey are the database of our intentions. We search for things we are hoping to know, hoping to do, and hoping to become\n\n## Library Search\n- first catalogue was 4000 years ago\n- card catalogue: \"indexing\" each book listed alphabetically by title, author, and subject\n- computerization: online public access catalogues (OPACs) in 1970s, 1980s\n- catalogues move online in 1990s - \"web OPAC\"\n\t- downsides: locked libraries into traditional models of search\n- second generation OPACs - incorporate interactive features and simplified interfaces\n\t- competition from search engines pushed redesign\n- library \"discovery layers\" implemented\n\t- expansion of online collections: articles, ebooks, digital library collections\n\t- gives a search engine appearance and functionality\n- mainly relies on metadata as opposed to internet search engines which rely on full text content and keywords\n\n## Federated Search\nFederated search is a technique used to search multiple data sources at once. With federated search, you can retrieve information from many different content locations with just one query and one search interface.\n\n## Internet topology as shaped by search engines\n[Source: Critical Atlas of the Internet](https://louisedrulhe.fr/internet-atlas/)\n\n![](thoughts/images/internet-atlas.png)\n\n![](/thoughts/images/search%20engine%20space.png)*The first cone represents the loss of distance. As shown in the picture previous hypothesis, terrestrial space converges at a specific point. On Internet, distance is not relevant. Everything is potentially one click away. The second cone reintroduces the notion of non-physical distances. On the Internet, distance has no relevance, but the notion of space nevertheless remains.*\n\nSee also: [internet computing](thoughts/internet%20computing.md), [Internet](thoughts/Internet.md)\n\nSearch engines create an embedding space for the world that maps from physical to digital. Page ranking is the function that maps and remaps the 'location' and relatedness of real concepts.\n\n## The Vocabulary Problem\nIs this a form of [hermeneutical injustice](thoughts/hermeneutical%20injustice.md)?\n\n1. Lexical Ambiguity: the [meaning](thoughts/meaning.md) of human language is not specific\n2. Polysemy: one word has many meanings\n3. Synonymy: many words mean approximately the same thing\n\n### Text Processing\nSimilar to practices in [reflect](posts/reflect.md) NLP processing actually!\n\n- Lexical Analysis: break text into tokens\n\t- Bag of Words\n- Transformations\n\t- Case folding: convert all to lower case\n\t- Stopwords: remove words that contribute semantic meaning/indexing value\n\t\t- e.g. words that don't reduce information entropy\n\t\t- for example, words that appear in *all* documents are not very helpful\n\t\t- zipf's law, first ~5% are stop words, next ~45% are meaning content words and the last ~50% are long tail rare words\n\t- Stemming: grouping of related words (e.g. cats/cattiness -\u003e cat)\n\t- Term Weighting: assigns weights on basis of importance to document\n\t\t- term frequency (TF): occurrences in a\n\t\t- document frequenc (DF): # of docs containing the term\n\t\t- term weight is usually $\\frac{TF}{n}\\frac{1}{DF}$ where $n$ is the total word count\n- Index: unique id to a single document\n- Inverted Index: index which each entry holds list of pointers to all items with a certain property (e.g. title)\n\n## Generations\n1. Pre-1998: keyword frequency and boolean operators\n2. 1998-2010: link structure (page rank), keywords\n3. 2010-2015: user data, personalization, NLP\n4. 2015-now: AI, deep learning\n\n## Ethics\nMajor issues:\n1. Access to information: value of information and knowledge, [democracy](thoughts/democracy.md), gatekeeping, [censorship](thoughts/censorship.md)\n2. Equity, accuracy (truth) and transparency: search-engine bias and the problem of opacity/non-[transparency](thoughts/transparency.md)\n3. [[thoughts/privacy|Privacy]] and freedom: personal privacy and informed consent; monitoring and surveillance\n4. Property rights: how do crawlers/search engines respect property, ownership, free market competition\n\nSearch is a form of [data capitalism](thoughts/Data%20Capitalism.md)\n\n## Regulation\n### Google Books\n- Goal to scan 1 million books in 3 years\n\t- Bypassed copyright, which is highly problematic\n\t- Tried to fix this by partnering with 20 major libraries through their Publisher Program\n\t- Secretive; tried to tell libraries not to tell each other about this partnership\n- Aiming to create a large scale digital [library](thoughts/library.md) that included *historical* knowledge\n- Critiques\n\t- Poor quality of scanning\n\t- [[thoughts/privacy|Privacy]] -- Google would gain access into detailed insights about what people were reading\n\t\t- Historically, librarians focussed heavily on this, sometimes even going to jail due to resisting handing over library records\n- 2005 Class Action Lawsuit by author and copyright holders' organizations: theft of books\n\t- 2008 settlement: Google agreed to pay copyright holders; revenue from orphan works; access through libraries\n\t- 2011 settlement thrown out over concerns of monopoly, privacy, European opposition\n\t- 2013 appealed\n\t- 2016 Supreme Court of US ruled that Google Books was legal under the Fair Use exception (claiming it expands public knowledge and understanding)\n- Competition policies\n\t- Sherman Act (1890): outlaws \"monopolization, attempted monopolization, or conspiracy or combination to monopolize\"\n[Aaron Swartz](https://en.wikipedia.org/wiki/Aaron_Swartz)\n- In 2011, Swartz was arrested MIT police on state breaking-and-entering charges, after connecting a computer to the MIT network in an unmarked and unlocked closet, and setting it to download academic journal articles systematically from JSTOR in the hopes of freer access of information\n- Federal prosecutors, led by Carmen Ortiz, later charged him with two counts of wire fraud and eleven violations of the Computer Fraud and Abuse Act\n- Swartz was found dead supposedly by suicide in his Brooklyn apartment, though this is still disputed \nEU Digital Markets Act\n- Applies to \"gate-keeper platforms\"; fines up to 20% of annual revenue\n- e.g.\n\t- Prohibits use of personal data mined from one service to benefit another service they offer\n\t- Prohibition on requiring users to subscribe to one's service\n\t- Requirements for transparency on advertising prices\n\t- Prohibitions on self-preferencing\n\t- Restrictions on targeted advertising without consent\n\t- Requirements for interoperability with third-party software\n","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/security":{"title":"Security","content":"\n[Source: Playdough Protocols in *Kernel*](https://kernel.community/en/learn/module-1/playdough-protocols)\n\nIntegrity of information is critical to relationships of [trust](thoughts/trust.md) as we saw in the episode on [game theory](thoughts/game%20theory.md).\n\n## Internet\nOn security in [[thoughts/internet computing|the internet]]\n\nMain excuse: \"when $x$ was designed, there were only a few players and they all know and trusted each other\"\n\n\u003e \"Secure\" web servers are the equivalent of heavy armoured cars. The problem is, they are being used to transfer rolls of coins and checks written in crayon by people on park benches to merchants doing business in cardboard boxes from beneath highway bridges. Further, the roads are subject to random detours, anyone with a screwdriver can control the traffic lights, and there are no police. -- Garfinkel, Spafford, \"Web Security and Commerce\"\n\nA lot of the internet is based on good faith and relying on users to be good actors\n\nWhat level of the [[thoughts/internet computing|internet computing stack]] should be responsible for security? Options:\n- New network-layer protocol\n- New transport-layer protocol\n- New 'pseudo-layer' between transport and application (SSL, TLS)\n- Responsibility of the application (SSH)\n\n### Terminology\n- confidentiality: only the sender and the intended receiver should \"understand\" message contents\n- authentication: the sender and receiver want to confirm each other's identity\n- message integrity: the sender and receiver want to ensure that the message is not altered without detection\n- access and availability: services must be accessible and available to users\n- Actors: can be people or entities\n\t- Alice, Bob: want to communicate securely\n\t- Trudy: intruder, may\n\t\t- eavesdrop: intercept messages\n\t\t- delete/add messages\n\t\t- impersonation: can fake source\n\t\t- hijacking: 'take over' ongoing connection\n\t\t- denial of service: prevent service from being used by others\n- Given that Trudy can see all the data, how do we provide confidentiality? [[thoughts/encryption|Encryption]]!\n\n## Block Ciphers\n- Message is broken into blocks (e.g. 64-bits of data)\n- Each block is encrypted/decrypted separately\n- $2^{64}$ combinations for a 64-bit block!\n- Cipher-block chaining\n\t- Do an additional operation with the plaintext\n\t- E.g.\n\t\t- XOR first block with arbitrary (randomly chosen) number known by both parties\n\t\t- Following blocks are XOR'ed with previous block\n- DES\n\t- 56-bit symmetric key, 64-bit plaintext input\n\t- No longer considered secure, 56-bit key can be brute forced in \u003c1 day\n\t- 3DES is more secure, do it 3 times with 3 different keys\n- AES\n\t- Also symmetric, replaced DES as NIST standard in 2001\n\t- 128-bit block cipher\n\t- 128-, 192-, or 256-bit key\n\t- Way more secure than DES\n\t\t- Brute force decryption that takes 1 second for DES would take 149 trillion years for 128-bit AES\n\n## Certification Authorities (CA)\n- Authority of who own's what public keys\n- When Bob wants Alice's public key\n\t- Alice provides a certificate\n\t- Certificate is signed by CA\n\t- Bob applies CA's public key to confirm certificate's authenticity\n\t- Certificate contains Alice's public key\n\n## Preventing Replay Attacks\n- Nonce - value that will only ever be used once (usually derived from clock time)\n- A sort of challenge, Alice wants Bob to prove they have received the nonce by sending them back that same nonce\n- Ensures this is a new conversation between Alice and Bob\n\nSee also: [[thoughts/hash function|hash functions]]","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/self-knowledge":{"title":"Self-knowledge","content":"\n## Reflexivity vs Reflectivity\nSelf-illumination/reflexivity  \n- Every conscious experience is directly revealed to itself.  \n- \"In seeing blue, you experience seeing\"\n- Problems: Reflexivity as a concept is weird though\n\t- \"A knife cannot cut itself, an acrobat can’t stand on their own shoulders.\"\n\t- \"How can one and the same awareness be both of an object/content and of itself?\"\n\nOther-illumination/reflectivity  \n- For a state to be a conscious state is for it to be the object of a higher-order mental state (an inner perception or inner thought).\n- \"I see blue, I'm aware that I see blue\"\n- Problems: how could two states that are nonconscious in themselves come together and make one of them conscious?\n\t- Curious how this applies to [emergent behaviour](thoughts/emergent%20behaviour.md)\n\t- By having a higher layer that enables the reference of a lower layer, this is essentially a two-way recursive relation that opens the door to much more composable and perhaps complex behaviour\n\nNagarjana's Argument\n- Infinite regress, you cannot use a fact to establish itself\n- Summarized in terms of reflectivity\n\t- argues against reflexivity\nOpponents Argument\n- Can use recursive definition\n\n## Paper #2 for PHIL240A\n\n\u003e Śiva and God are hanging out, binge-watching a Cosmicflix series called “The Greatest Hits in Philosophy.” It’s the Descartes episode. Descartes says: “To begin with, I acknowledge that it is impossible for God ever to deceive me, for trickery or deception is always indicative of some imperfection” (p. 36) Śiva leans back and smirks. “Now THAT,” he says, “is impressive. I’ve managed to so thoroughly deceive myself that I think I can’t be a deceiver!” God looks sideways at Śiva and responds, “What are you on about? This is one of the greatest moments of insight that one of my creatures has had! Because Descartes clearly and distinctly perceives that I am not a deceiver, he opens himself to all knowledge!” “Oh really?,” Śiva responds. “I thought Descartes already had the key to all knowledge just in the realization ‘I exist.’ He just needs to understand what that means about his own nature!” God pushes pause on the Cosmicflix show and, with a sweep of his arm, transforms their surroundings to a formal debate platform. “OK,” God says, “Time to get to the bottom of what self-knowledge even is. Do you accept the challenge?” “Bring it,” says Śiva, with a grin.\n\n---\n\n- **G:** God, the Creator of all things\n- **S:** Śiva, the Ultimate Reality, the consciousness from which all else springs\n\n**G:** Wonderful. Now, let us first set the ground and define some terminology.\n\n**S:** As one should always do when debating.\n\n**G:** I posit that self-knowledge is the knowledge of one's own mental states. This means that one should be able to know what the 'self' constitutes, and to know one's experiences, propositional attitudes, etc.\n\n**S:** This sounds reasonable but hinges on how you define \"one's own\". What does it mean to distinguish between one consciousness and another? I posit that, well, Descartes is actually me.\n\n**G:** I am confused.\n\n**S:** You must remember that, outside of Cosmicflix binging series, I am Śiva, the ultimate reality. I am a sculptor of sorts as I can create and carve worlds from myself. Conventional reality is created through my act of *apoha* or exclusion. So all of the world that Descartes lives in, including himself is actually something I have created. Descartes' conventional sense of personal identity is also conceptual and made through this process of exclusion as well (Torella, p. 132).\n\nLet me rephrase my question. Seeing as you are also the Creator of all things, did you not consider all of your creations extensions of your self?\n\n**G:** Ah I see your question. Though I too have sculpted Descartes in my image, I do not see him as a part of myself.\n\n**S:** But doesn't his existence depend on you creating him? My ascertainment of something being a 'jar' is brought about by the free knowing subject and existence of the polarization of 'non-jar' things (Torella, p. 129-131). This act of chiselling is just sculpting the world from the same block of marble -- the same body of consciousness -- is it not?\n\n**G:** No. Creation, to me, does not imply me carving them out of my consciousness. Just as I can create mountain and forest who are not part of my conscious being, so too can I create other conscious beings.\n\nDescartes is this own conscious being. He has actually ascertained this himself through his Second Meditation.\n\n*[G presses play on the show and continues talking.]*\n\nFor Descartes, [the self](thoughts/the%20Self.md) is the thinking being. This was what his statement *“cogito, ergo sum”* posits (Descartes, p. 18-19). Existence must necessarily be true whenever it is put forward by me or conceived in my mind. In this second meditation, Descartes explores the concept of the \"I\" quite clearly, eventually resolving that both soul and body can be deceptions (p. 18-19) and only thought, above all else, is inseparable from the existence of the self (p. 20).\n\n*[S pauses the show once again.]*\n\n**S:** Okay, even if you don't subscribe to the fact that Descartes is actually a subset of the ultimate reality, how can Descartes be so certain that he cannot be deceived? If you have endowed him with infallible judgment, how is it that he can be mistaken, as he undoubtedly is from time to time?\n\n**G:** Well, this is not something I can control. I give humans free will to think and judge and that is what allows them to err. Descartes himself also came to this conclusion in his mediations. \"The will is free to affirm or deny whatever it wishes – as such, free will is the source of error... If there was no free will, we would never make mistakes.\" (Descartes, p. 39-40).\n\nThe idea of God (me) exists as an idea in Descartes' mind and he clearly and distinctly perceives all of my qualities. \n\nOne of these qualities of perfection is existence, then God would not be God if he did not exist -- just as a triangle only exists if it has the property of being three-sided (Descartes, p. 46-47).\n\nThus, he concludes, I must exist and have these perfect qualities. In doing so, I cannot deceive him (as deception is evil) so his perceptions are accurate. Any missteps he makes are due to overstep in judgement.\n\n**S:** Ah see now that Descartes does not have the key to *all knowledge* but rather just the ability to know that one must exist and the freedom to be able to judge the world for themselves. Hmm, this seems ok... for now. Let us return to the show.\n\n*[S presses play on the Cosmicflix show again.]*\n\n---\n\n## Week 6 Short-answer for PHIL240A\n\nAnswer this question from the perspectives of both Descartes and Pratyabhiñā thinkers.\n\n\u003e What, if anything, about self-knowledge is trustworthy?\n\nFrom the perspective of Cartesian thinkers, both soul and body are not necessarily trustworthy, but thought is. A Cartesian thinker is one who understands the Meditator, who is in turn sure of their own thoughts. To even have doubts or to be deceived, one must first exist. Thus, above all else, thought is inseparable from being. Then, the 'self' is only a thing that thinks (Descartes, p. 18-19) and thus is a trustworthy indicator of the self existing.\n\nThen, Descartes goes on to extend this by attempting to prove the existence of God. The rationale here surrounds the fact that God is *infinitely* perfect and has infinite substance (the most real) -- necessary existence cannot be separated from the essence of a supremely perfect being. As no effect can have a greater amount of reality than its cause combined with the fact that you can’t actually get the idea of infinity just from endlessly increasing what’s finite, the infinite must independently exist (Descartes, p. 32).\n\nThus, Cartesian thinkers conclude, if deception is imperfect and God exists and is perfect, God cannot deceive. The things I perceive \"clearly and distinctly\" must be true and cannot be deceiving us about basic universal truths (e.g. a square has four sides) and methods of logical deduction (if p then q).\n\n---\n\nPratyabhiñā thinkers on the other hand, believe that *all* knowledge is self-knowledge as everything is carved from the ultimate reality Śiva. They posit that only consciousness can present itself as precisely what it’s not while still remaining itself. Contrary to insentient objects,\" consciousness is capable of changing without perishing\" (Ratie p. 441).\n\nExternality, then, is made on the basis of differentiating internal appearances, in order for Śiva to be able to experience the effects of the created objects (Torella p. 149). This creates a basic divide between self and world. Even the mere appearance of an external world to an embodied subject is the result of this exclusion (*apoha*). My ascertainment of something being a 'jar' is brought about by the free knowing subject and existence of the polarization of 'non-jar' things (Torella, p. 129-131)\n\nAs all objects and subjects rest in Siva, there is one underlying unitary consciousness.\n\n[^1]: This content is sourced from Professor [Evan Thompson](https://evanthompson.me/)'s course materials for PHIL451A at UBC. All rights to this content is retained by Evan Thompson.","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/selfish":{"title":"Selfish","content":"\nAre selfishness and selfcare the same thing?\n\n\u003e To be able to provide care, you need to take care of yourself\n\nselfcare → more [altruism](thoughts/effective%20altruism.md) → create a better environment for self → betterment of the self\n\nIs there a difference between genuine altruism vs egoistic altruism?\n\nIs [play](thoughts/play.md) even self-care?\n\nReverse machiavellianism\n-   machiavellian is like you do the good thing for a selfish ends\n-   opposite would be you do the selfish thing for a good ends\n\nGeneral thoughts:\n1. in scarce situations - try to align yourself with ppls selfish reasons to get them to do things. its ok to be selfish in scarce situations if it enables you to better help others in the future (hill exploration analogy, its ok to be selfish if it means we can reach a better local max)\n2. try to make situations of abundance\n\nIs there a label for someone who prioritizes themselves so that they can best help others in the long term? \n\nI think I'm realizing that I am selfish in the sense that I will only help others if it is something I will enjoy doing and obviously that depends on who it is I'm helping, what I'm doing, my state of self, etc.\n\nThe catch is that I just really enjoy helping others in pretty much all situations (with a few exceptions, like when my own personal well-being is in jeopardy or the person I just an asshole)\n\nHow do I unlearn the negative connotations associated with being selfish?\n\n\"We tend to wear our ability to get by on little sleep as some sort of badge of honor that validates our work ethic. But what it really is is a profound failure of self-respect and of priorities. What could possibly be more important than your health and your sanity, from which all else springs?\" [Source](https://www.themarginalian.org/2019/10/23/13-learnings-13-years/)\n\nSee also: [pain](thoughts/pain.md)\n\n## In Tech\n[Source: the technofuturist's oath by *Priya*](https://priyaghose.io/2021-09-03-the-technofuturists-oath/)\n\n*If we don’t make our numbers, we won’t get the next round of funding. And without that funding, we won’t ever fulfill on our positive-sum, idealistic mission that will benefit everyone.* is a very common thing to hear people working at startups scrounging at money say.\n\nDoes competition always kill positive-sum worlds?\n\n## Intelligently Selfish\n[Source: How to be Intelligently Selfish -- *Dalai Lama*](https://www.skepticspath.org/blog/how-to-be-intelligently-selfish-dalai-lama/)\n\nHis Holiness skillfully _redefines_ selfishness to mean the healthy pursuit of what’s best for yourself: what would bring you genuine happiness -- caring about others.\n\n## Porousness of [the self](thoughts/the%20Self.md)\nSelfishness depends on what the definition of the self is. Expansions on the concept of 'self':\n- [noosphere](https://en.wikipedia.org/wiki/Noosphere) as the extended self\n- [The Egg](https://www.youtube.com/watch?v=h6fcK_fRYaI) by Andy Weir + Kurzgesagt\n- [self-knowledge](thoughts/self-knowledge.md)\n\n## Nice vs Kind\n*From Joice*\n\nBeing nice is doing something you think will people happy. Being kind is doing something because you want to do it for them. The key is agency and boundary of self :))\n\n","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/semantics":{"title":"Semantics","content":"\n\u003e What do words or sentences mean\n\nMeanings are public property: the same meaning be grasped by more than one person and by people at different times. Heavily related to [representation](thoughts/representation.md)\n\n## Implications\n- If this argument is correct, then the content of our thoughts partly depends on what is in the world we live in\n- Content determines object\n\t- What about indexical thoughts? Thoughts that depend on context like \"you\", \"me\", \"there\", \"here\"\n- Concept of meaning rests on two unchallenged assumptions\n    - Understanding a word (knowing its intension) was just a matter of being in a certain psychological state\n    -   meaning of a term determines its extension\n        -   extension → actual physical manifestation / what it is\n-   proving these are false → [Twin Earth Argument](thoughts/Twin%20Earth%20Argument.md)\n    -   extension of the term is not a function of the psychological state of the speaker by itself\n        -   water on twin earth vs earth in 1750; both oscars think it to be the same thing\n\n## Sociolinguistic hypothesis\n-   division of linguistic labour\n\t-   some people wear gold rings\n\t-   some people tell the difference between gold and non-gold\n\t-   not everyone needs to tell the difference between gold and non-gold, rely on the judgement of experts\n\t-   formal: \"every linguistic community exemplifies the sort of division of linguistic labour just described; that is, it possesses at least some terms whose associated \"criteria\" a re known only to a subset of the speakers who acquire the terms, and whose use by the other speakers depends upon a structured cooperation between them and the speakers in the relevant subsets\"\n-   two theories → if \"water\" means $H_2O$ in $W_1$ and \"water\" means $XYZ$ in $W_2$\n\t1.  world-relative but constant in meaning, 'water' means the same thing in both world, but water is $H_2O$ in $W_1$ and water is $XYZ$ in $W_2$\n\t2.  water is $H_2O$ in all worlds, but 'water' doesn't mean the same thing in $W_1$ and $W_2$\n- Twin-earth argument implies 2nd one is true\n- Rigidity → if a designator in a particular sentence refers to the same individual in every possible w in W\n\t- Water is rigid in (2)\n- Once we have discovered the nature of water, nothing counts as a possible world in which water doesn't have nature\n\t- i.e. one we have discovered that water (in the actual world) is h2o, nothing counts as a possible world in which water isn't h2o\n- Water at another time or in another place or even in another possible world has to bear the relation same to our \"water\" in order to be water\n- Types of statements\n\t- [[thoughts/epistemology|epistemically]] necessary → rationally unrevisable\n\t- [[thoughts/metaphysics|metaphysically]] necessary → true in all possible worlds\n\n## Lexical Development\n- Mental lexicon: mental dictionary of word knowledge (how it sounds, grammar, definition, etc.)\n- Word: symbol that refers to something\n- Symbol: stands for something without being a part of that something\n- Context-bound word: things tied to particular contexts (word use is more specific than actual meaning)\n- Nominals: names for things\n- Natural partitions hypothesis: the physical world makes obvious the things that take nouns as labels, whereas the meanings that verbs encode have to be figured out from hearing the verb in use\n- Relational relativity hypothesis: possibility that verb meanings will vary from language to language (linguistic work showing that noun meanings are more similar across languages than are verb meanings)\n- Word extension: to what extent is a word valid?\n\t- Underextensions: using words in a more restricted fashion\n\t- Overextensions: using words in a more broad fashion (for related study, see Naigles \u0026 Gelman 1995 study, results showed that overextensions are mistakes, they don’t indicate incorrect understanding of the words)\n\t- Protowords (also known as phonetically consistent forms -- PCFs)\n\t\t- Phonetically consistent: the child uses the same word every time.\n\t- Things that help with accurate word extension:\n\t\t- Taxonomic extension: words to things are actually taxonomies (they are of the same category)\n- Word spurt: see Choi \u0026 Gopnik (1995)\n- Types of language use, two ends of a continuum\n\t- Referential language style: more object labels\n\t- Expressive language style: relatively fewer object object labels and more personal/social words\n- Mapping problem: how do we know what the new word refers to?\n\t- Fast mapping: initial hypothesis about word meaning\n\t- Lexical principles/lexical constraints: guides that limit possible interpretations of new words\n\t\t- Whole-object assumption: words refer to whole objects\n\t\t- Assumption of mutual exclusivity: different words refer to different kinds of things. No category overlap\n\t- Lexical gaps: Sometimes things are not a one-to-one match – your language may not have a lexical item for something\n- Age at which children learn early words (first 50-100) can vary a lot due to\n\t- Environmental Factors\n\t\t- Language experience and input\n\t\t- Socioeconomic status (SES)\n\t\t- Birth order\n\t- Individual Factors\n\t\t- Processing speed\n\t\t- Phonological memory\n\t\t- Personality and temperament\n\n## Deep Learning Semantics\n### Images\nSemantics in [[thoughts/convolutional neural networks]]\n\nHidden units often correlate semantically-meaningful concepts.\n\nInceptionism: what about, instead of weights, use backpropagation to take gradient with respect to $x_i$. i.e., show me what you think a banana looks like\n\nStyle Transfer: loss function matches deep latent representation of content image $C$:\n- Difference between $z_i^{(m)}$ for deepest $m$ between $x_i$ and $C$\n- Intuition, deep layers $z_i^{(m)}$ capture the semantics/concepts in an image, invariant to actual style\n\n- Adversarial Examples: imperceptible noise that changes label/prediction.\n\t- Potentially dangerous! We could repaint a stop sign and fool self-driving cars\n- It can learn bad correlations (e.g. correlating grass with cows so when it sees a cow by a beach it has no idea what it is)\n\t- Related: does the prediction change real-world outcomes?\n\t- i.e., does the doctor *actually* care?\n\t- Does “not trying to overfit” mean we perform badly on some groups?\n\t\t- If you have 99% “Group A” in your dataset, model can do well on average by only focusing on Group A\n\t\t- Treat the other 1% as outliers\n\t\t- Doing well at test-time might mean ignoring outliers and minorities\n\t- See also: [[posts/bias-bug|bias bug]]","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/sequential-games":{"title":"Sequential Games","content":"\nRepresented with a game tree consisting of nodes (representing choices by players) and branches\n(representing different options)\n\nA player has perfect information if her information set has just one node (e.g., chess); imperfect if\nmore than one (e.g., silent auction where you don’t know the other bids)\n\nTwo sequential games are equivalent if they have the same game tree.","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/skyhooks":{"title":"Skyhooks","content":"\nWe should have nondystopian science [fiction](thoughts/fiction.md) -- there's value in reclaiming an optimistic and hopeful future (very Reboot vibes). I love the concept of skyhooks: dream about what you can build as if the sky had hooks you could hang your creations from (a metaphor for unlimited resources) and most of the time, you can still create that with scarce resources.\n\nSteve Grand in *Creation: Life and How to Make It*\n\n\u003e If an architect believes for a moment that there are hooks in the sky to hang his creations from, he may be able to conceive of structures that he would otherwise not dare to think about. Once the design starts to take shape, he may then begin to see ways in which the essence of it can still be achieved without the need for sky-hooks at all. Maybe this will work for us, too.","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/small-technology":{"title":"Small Technology","content":"\n[Source](https://small-tech.org/)\n\n\u003e Small Technology is everyday tools for everyday people designed to increase human welfare, not corporate profits.\n\nPrinciples of small technology:\n1. easy to use\n2. personal\n3. [[thoughts/privacy|private]] by default\n4. share alike\n5. [[thoughts/peer-to-peer]]\n6. [[thoughts/interoperability|interoperable]]\n7. zero knowledge\n8. non-commercial\n9. non-colonial\n10. inclusive\n\nThoughts: not sure I agree with how they say that the small web is single-tenant. Collaboration is important! We use the web not because its easy to own our stuff, but because it should be easy to do stuff with others.\n\nSee also: [[thoughts/digital mindfulness]], [[thoughts/friction]], [[thoughts/Mangrove Theory of the Internet]], [[thoughts/Tools for Conviviality]]","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/social-contracts":{"title":"Social Contracts","content":"\nSocial contracts are implicit agreements among members of social  groups to cooperate for social benefits. They help us form shared cultures and values\n\n[Rousseau](https://plato.stanford.edu/entries/rousseau/) -\u003e everyone forfeits some rights so that they might also impose selected duties\n\ne.g. most democracies today, citizens agree to pay taxes in their shared currencies to fund and maintain basic [infrastructure](thoughts/infrastructure.md) like roads, bridges, and electrical grids\n\nSee also: [[thoughts/Social Contract Theory]]\n\n## Social Rules for [learning](thoughts/learning.md)\n[From Recurse Center's Social Rules](https://www.recurse.com/social-rules?curius=30)\n\n\u003e For example, working at the edge of your abilities requires taking emotional risks, and the social rules help create an environment where it’s safe to do that. Letting someone know that they impacted you by breaking a social rule and accepting that feedback gracefully when you’re the one who messed up are important ways to learn generously. This allows everyone to keep working and growing together.\n\n1. No well-actually’s: correcting someone about something that's not relevant to the conversation or only tangential to what they're actually trying to say. Not helpful and break the flow of conversation\n2. No feigned surprise: acting surprised when someone doesn't know something. Makes people feel bad for not knowing things and less likely to ask questions in the future, which makes it harder for them to learn\n3. No backseat driving: lob advice from across the room without really joining or engaging in a conversation. Even if your advice is correct, it’s rude to bust into a conversation without asking. If you overhear a conversation where you could be helpful, the best thing to do is to ask to join.\n4. No subtle-isms: Subtle-isms make people feel like they don’t belong. We want to create an environment where everyone can focus all their energy on programming.","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/social-graphs":{"title":"Social Graphs","content":"\n## Questions\n- How do social graphs work if users are [pseudonymous](thoughts/pseudonymity.md)? If [cities are not top-down hierarchies](thoughts/A%20City%20is%20not%20a%20Tree.md), then are social graphs a better way to think about them?\n-  Does directness matter in social graphs\n\t-   i.e. facebook is undirected (friend means you are friends with each other) whereas twitter is directed (you can follow someone but doesn't mean they follow you back)\n\n## Social Graph vs Interest Graphs\n-   social graph → who's connected to who\n-   interest graph → online representations of interests\n-   constructing interest graphs from social graphs\n    -   traditional social media apps like facebook/ig\n-   constructing social graphs from interest graphs\n    -   more 'live' apps like tiktok\n-   social graph as infrastructure?\n    -   should we make one centralized social structure and platforms can then build platforms off of that social graph?\n    -   china does this well\n-   focus on being end product rather than infrastructure layer that others build on top of\n-   \"a platform is when the economic value of everybody that uses it exceeds the value of the company that creates it. then it's a platform\"\n-   \"achieving product-market-fit of social is the intersection of a feature and a graph\"\n    -   people keep copying each others features\n    -   but if the underlying graph is different, the intersection might be different too\n-   [search](thoughts/search.md) directed vs feed directed networks\n    -   [https://outline.com/ZhCArb](https://outline.com/ZhCArb) → future of search?\n    -   why feeds exist → more supply than eyeballs to consume it, someone needs to make a decision on what you actually see (no chronological feeds anymore)\n\n[Closing the Loop Podcast Episode](https://www.youtube.com/watch?v=xbnDay35L8I)\n* constructing social graphs from interests (tiktok)\n* constructing interest graphs from social graphs (traditional networks like fb)\n\n","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/sociolinguistics":{"title":"Sociolinguistics","content":"\n\u003e How children learn to use their languages in socially appropriate ways that reflect their status in the community and the social context\n\n## Variation\n- Constrained variation: distribution of a variant is not random or free, there are systematic correlations with independent factors.\n- Free variation: accounts for cases where some variants seem to alternate with each other without any reliable constraints in a particular context or when used by a certain speaker\n- Interspeaker: variation occurs between different speakers within or across speech communities\n- Intraspeaker: variation occurs between within a single speaker, but might depend on interlocutors and context (= inherent variability)\n- Group differentiation: social/regional varieties index (mark) group boundaries\n- Variation factors\n\t- Speaker-driven factors\n\t- Audience-driven factors\n\t- Task-related factors\n\t- Linguistic factors\n\n## Language vs Dialect vs Accent\n- Language: not mutually intelligible communication systems\n- Dialect: mutually intelligible, but have differences in sentence structure ([[thoughts/syntax|syntax]]), how words are made ([[thoughts/morphology|morphology]]), or word choice (lexicon)\n- Accent: mutually intelligible, only have differences in [[thoughts/phonology|phonology]] (sounds)\n\n## Rate and Time\n- Ochs (1985)\n\t- How are phonological registers, word order, and ergativity acquired by children learning Samoan (and how does their speech compare to adult patterns)?\n\t\t- Children use features of both registers even at one word stage, but do not show recognition of appropriate contexts until multi-word stage (2- 2.5 years), children start producing tautala lelei first and then tautala leaga\n\t- Ergativity acquired relatively late, appears to match a sociolinguistic norm in the community\n- Types of time\n\t- Real Time: chronological time based on year\n\t- Apparent Time: an estimate of time based on speaker age or date of birth\n\t- When we look at a speaker age as a proxy for time, we must make assumptions what things are stable in language and at what ages.","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/software-and-politics":{"title":"Software and Politics","content":"\n\u003e \"Computers play a fundamental role in making the world — and above all the built structure of the world — alive, humane, ecologically profound, and with a deep living structure\"\n\u003e \n\u003e -- Christopher Alexander to a room of \n\n[Do Artifacts Have Politics](thoughts/Do%20Artifacts%20Have%20Politics.md)? Yes, they do.\n\n## Politics for Software\n[Source: Politics for Software Engineers by *Steven Buss*](https://sbuss.substack.com/p/politics-for-software-engineers-part-2)\n\n\"Blockchain voting addresses how to vote in a trust-less society, but a trust-less society cannot have a functioning [democracy](thoughts/democracy.md).\" (see: [trust](thoughts/trust.md))\n\nPotential use of [Merkle Trees?](https://en.wikipedia.org/wiki/Merkle_tree) (but also, [A City is not a Tree](thoughts/A%20City%20is%20not%20a%20Tree.md))\n\n## Simplicity is more important that provably correct\n\"I think where most software engineers fail at politics, it's in understanding that key point. We tend to over engineer our systems and never need to explain the inner workings to anyone who is non-technical. This isn't restricted to just software engineers, of course. Any sufficiently advanced technology is difficult to explain in terms a non-expert can understand. But we do, at least, understand that we need to tailor the front-end user experience to the target demographic.\"\n\nCurious how this ties into the [over simplification of user interfaces](/thoughts/books/mindstorms#Microworlds and simplification)\n\n\"Blockchain voting fails at the most basic test of social technology: can you explain how it works to someone skeptical of the people in power in a way that makes them trust the system?\"\n\n## Values and Technology\n\u003e \"Technology is the result of human imagination – of human beings envisioning alternatives to the status quo and acting upon the environment with the materials at hand to change the conditions of human and non-human life. As a result of this human activity, all technologies to some degree reflect, and reciprocally affect, human values.\" (Friedman and Hendry, 2019)","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/software-principles":{"title":"Software Principles","content":"\n\u003e A Pattern Language for developing software\n\nInspired by [Urbit Precepts](https://urbit.org/docs/development/precepts)\n\n1. [[thoughts/local-first software|Local first]]. Decentralized/[[thoughts/distributed systems|distributed systems]] second. Avoid hosting like the plague. Make self-hosting easy\n2. Apps should be treated like queries -- stateless. Local state should be avoided as much as possible, database is the source of truth.\n3. There is a latent cost to new features: [maintenance](thoughts/maintenance.md)\n4. Design with the goal of making atomic and reusable libraries\n5. Heuristics should only be used where determinism is infeasible\n6. Code courageously. \"It's natural to feel fear of code; however, you must act as though you are able to master and change any part of it. To code courageously is to walk into any abyss, bring light, and make it right.\"\n\n## On programming advice\nJamie Brandon's [Reflections on a Decade of Coding](https://www.scattered-thoughts.net/writing/reflections-on-a-decade-of-coding)\n\nProgramming practices are mostly tacit knowledge. Tacit knowledge isn't easy to share. An expert will relate some simple-sounding rule of thumb, but then grilling them on specific cases will quickly uncover a huge collection of exceptions and caveats that vary depending on the specific details of the situation.\n\nIt's so easy to think that simple solutions exist. But if you look at the history of ideas that actually worked, they tend to only be simple from a distance. The closer you get, the more you notice that the working idea is surrounding by a huge number of almost identical ideas that don't work. Take bicycles, for example. They seem simple and obvious, but it took [two centuries](https://en.wikipedia.org/wiki/History_of_the_bicycle) to figure out all the details and most people today [can't actually locate the working idea](https://link.springer.com/content/pdf/10.3758/BF03195929.pdf) amongst its neighbours. Even when old niche ideas make a comeback (eg [[thoughts/neural networks|neural networks]]) it's not because they were right all along but because someone recognized the limitations and found a new variation on the idea that overcame them (eg deep learning). Finding the idea that actually works amidst the sea of very similar ideas that don't work requires staying curious long enough to encounter the fine-grained detail of reality and humble enough to recognize and learn from each failure.\n\nMainstream is mainstream for a reason. The frontier is the place to go mining for new ideas, but it's 1% gold and 99% mud.","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/soulbound":{"title":"Soulbound","content":"\n[Source: Soulbound by *Vitalik*](https://vitalik.ca/general/2022/01/26/soulbound.html)\n\n## Non-transferability\n\u003e A soulbound item, once picked up, cannot be transferred or sold to another player.\n\nIf you take the proverb that \"those who most want to rule people are those least suited to do it\" (Douglas Adams, *The Restaurant at the End of the Universe*) seriously, then you should be suspicious of transferability, precisely because transferability makes governance power flow away from the meek who are most likely to provide valuable input to governance and toward the power-hungry who are most likely to cause problems.\n\n## [Game design](thoughts/game%20design.md)\nSoulbound in the context of video [games](thoughts/games.md) (specifically Realm of the Mad God). I think this is such an interesting case study because the game itself is perma-death, meaning that items on characters are permanently deleted/lost on a character death.\n\nSoulbound is an interesting mechanic that has had a lot of implications for gameplay and in-game economy:\n\n- Players cannot trade these items. This incentivizes participation for actual gameplay loops + events\n\t- For example, when the game decides to host an event by boosting item drop rates for certain dungeons, people actually just play the game more rather than accumulating wealth and just buying the items off of farmers seeking to make a profit\n- However, this enables a secondary (illicit) market that trades *accounts* rather than items. This only accounts for a very small minority of trades as the average user does not use more than a single account\n- There is certain prestige that comes with owning certain items (e.g. \u003c1% drop rate from one of the most difficult dungeons in the game)\n\t- This is a visual signifier for one of three things: skill, veterancy, or dedication\n- As a result, organized groups for running hard and dangerous dungeons have emerged, with highly coordinated Discord servers with bots for managing headcount and role distribution (we need 2 healers! 5 people who can boost our damage!)\n\t- Some of the more elite groups actually have very strict requirements for entry (need to have 3 characters at the strongest stat cap, activity requirements, etc.)\n\t- All of these are volunteer run\n\nBy keeping the most prestigious items *untradeable*, it incentivizes more community involvement and recognition/prestige around the activities that yield those items. A lot of these items are extremely powerful and enable incredibly unique capabilities for characters. But as the game is permadeath, not a lot of individuals have the guts to use these regularly.","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/state-channels":{"title":"State Channels","content":"\nState channels are a very broad and simple way to think about [[thoughts/blockchain|blockchain]] interactions which could occur on the blockchain, but instead get conducted off of the blockchain, without significantly increasing the risk of any participant.\n\nSimilar to the concept of payment channels in [[thoughts/bitcoin|Bitcoins]]’s Lightning Network and [Raiden Network](https://raiden.network/) on Ethereum, but instead of only supporting payments, they also support general ‘state updates.’\n\nWork by\n1. Locking up some portion of state into a contract through a deposit of some amount of token\n2. Channel participants then communicate off-chain to sign valid transactions without submitting them to the chain. Each new update \"replaces\" the old one\n3. Participants choose to close the channel and submit the state back to the blockchain, unlocks state\n\nProperties\n- Near-instant finality: after all parties sign a state update, it can be considered final. Not instant because of dispute window\n- Strong privacy properties: every intermediate transaction happens 'within' the channel and doesn't need to be published to chain (which isn't true for sidechains for example)\n- Requires all parties to be available\n- Requires all participants to be hardcoded in the contract\n\n### Preventing fraud\nIf a party attempts to fraudulently close a channel, other parties in the channel have a period of time in which they can submit a more recent state, proving that fraud was attempted. Once an infraction is proven, the contract handles the resolution process, (e.g punishing the guilty party by slashing their deposited funds)","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/stone-soup-metaphor":{"title":"Stone Soup metaphor","content":"\n### Stone Soup Metaphor\n[Source: Stone Soup in *Wikipedia*](https://en.wikipedia.org/wiki/Stone_Soup)\n\n\u003e Some travelers come to a village, carrying nothing more than an empty cooking pot. Upon their arrival, the villagers are unwilling to share any of their food stores with the very hungry travelers. Then the travelers go to a stream and fill the pot with water, drop a large stone in it, and place it over a fire. One of the villagers becomes curious and asks what they are doing. The travelers answer that they are making \"stone [soup](https://en.wikipedia.org/wiki/Soup \"Soup\")\", which tastes wonderful and which they would be delighted to share with the villager, although it still needs a little bit of garnish, which they are missing, to improve the flavor.\n\u003e \n\u003e The villager, who anticipates enjoying a share of the soup, does not mind parting with a few carrots, so these are added to the soup. Another villager walks by, inquiring about the pot, and the travelers again mention their stone soup which has not yet reached its full potential. More and more villagers walk by, each adding another ingredient, like potatoes, onions, cabbages, peas, celery, tomatoes, sweetcorn, meat, milk, butter, salt, and pepper. Finally, the stone (being inedible) is removed from the pot, and a delicious and nourishing pot of soup is enjoyed by travelers and villagers alike. Although the travelers have thus tricked the villagers into sharing their food with them, they have successfully transformed it into a tasty meal which they share with the donors.\n\n\nProperly seeding new initiatives to set the expectations for future potential contributors.\n\nPreventing the [cold-start problem](https://en.wikipedia.org/wiki/Cold_start_(recommender_systems))","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/supervised-learning":{"title":"Supervised learning","content":"\n- Input: take features of examples and corresponding labels as inputs\n- Output: a model that can accurately predict the labels of new examples\n\nGenerally, the most successful machine learning technique (with the exception of games)\n\nExamples:\n- [[thoughts/decision tree|Decision trees]]\n- [[thoughts/Naive Bayes]]\n- [[thoughts/KNN|KNN]] (to fit an appropriate $k$)\n- [[thoughts/Ensemble method|Ensemble Methods]]\n- [[thoughts/linear regression]]\n\nTradeoffs:\n| |Decision trees|Naive Bayes|\n|-|-|-|\n|# Features used|Sequences of rules based on 1 feature|All features|\n|Training|$O(dn)$, one pass per depth|$O(n)$, just counting|\n|New data|May need to recompute tree|Just update counts|\n|Accuracy|Good if simple rules based on individual features work|Good if features almost independent given label|\n|Interpretability|easy to see how decisions are made|easy to see how each feature influences decision|\n\n## Notation\n- $X$ is the input\n- $y$ are the class labels\n- $n$ is the number of examples (generally idnex is denoted by subscript)\n- $d$ is the number of features (generally index is denoted by superscript)\n- $\\hat y$ are the predictions\n\n## Parametric vs Non-parametric\n- Parametric models: have fixed number of parameters w.r.t. $n$\n- Non-parametric models: number of parameters grows with $n$\n\n## General Rules\n- We care far more about testing error than training error\n- Golden Rule: the test data cannot influence training the model in any way\n- Independent and Identically Distributed (IID) assumption\n- [[thoughts/fundamental tradeoff|Fundamental trade-off]] between getting low training error and having training error approximate test error\n\t- We can mitigate this by penalizing model complexity (e.g. for [[thoughts/linear regression#Penalizing Model Complexity]])\n\t- See also: [[thoughts/regularization]]\n- Optimization bias\n\t- How biased is an \"error\" that we optimized over many possibilities?\n\t- Is large if you compare lots of different models, small if you only compare a few.\n\n## Decision Theory\nAre we equally concerned about each potential outcome? Usually not! Sometimes, false negatives or false positives have outsized impact -- the cost of mistakes might be different\n\n- Letting a spam message through (false negative) is not a big deal.\n- Filtering a not spam (false positive) message will make users mad\n\nWe can look to [[thoughts/Decision theory|decision theory]] to help us here. Denote $cost(\\hat y_i, \\tilde y_i)$ as the cost of predicting $\\hat y_i$ instead of the actual label $\\tilde y_i$.\n\nThen, instead of predicting the most probable label, compute all possible actions and take the action with the lowest expected cost: $\\mathbb E [cost(\\hat y_i, \\tilde y_i)]$\n- We assign the probability of each state to be the confidence of the predicted class (e.g. predicting 'spam' with 0.6 likelihood means we set the probability of true 'spam' to 0.6)\n\n","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/symbolic-execution":{"title":"Symbolic Execution","content":"\nHelps with analysis where there are infinitely many initial states / executions. A (terminating) [[thoughts/program analysis]] can’t precisely explore them all!\n\n**All-executions property: are there any executions of the program which violate the desired condition?** Equivalently, is there any way to reach a statement such that its Failure Condition is true?\n\nQuestions that value-dependent all-executions correctness analysis tries to answer:\n1. `assert x == 42;` Can assert statements in this code ever fail?\n2. `x = a[y];` Can execution of this code ever raise exceptions?\n3. `throw new RuntimeException(...);` is this ever reached?\n4. Will my function always satisfy its intended postcondition? etc.\n\n1. We will input/unknown values as symbolic values; we give names to these unknowns.  \n    We track a symbolic state in our analysis, mapping program variables to symbolic expressions.\n2. We will additionally track a set of path conditions: constraints representing the conditions which must be true in order to reach the current program point.\n\nWe can do something similar for loops by doing bounded unrolling.\n\n## Program Reachability Example\n- For loops\n\t- Find the set of variables assigned to in the loop body\n\t- Copy symbolic state before the loop, updating each assigned-to variable to map to a fresh symbolic value\n\t\t- Do this once for the start of the loop and once for right after the loop\n\t- Inside the loop, set the path condition to the loop condition\n\t- Outside the loop, set the path condition to the inverse of the loop condition\n\t- Continue both analyses\n","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/symbolic-system":{"title":"Symbolic Systems","content":"\n## Convergence of CS and Philosophy\n-   newell and simon claimed that both digital computers and the human mind could be understood as physical symbol systems\n\t-   using strings of bits or streams of neuron pulses as symbols representing the external world (formal symbol manipulation)\n-   intelligence (as claimed by newell and simon) required making the appropriate inference from these internal representations\n\t-   \"a physical symbol system has the necessary and sufficient means for general intelligent action\"\n-   turning rationalist philosophy into a research program\n\t-   hobbes → reasoning was calculating\n\t-   descartes → mental representations\n\t-   leibniz → \"universal characteristic\" — a set of primitives in which all knowledge could be expresse\n\t-   kant → concepts are rules\n\t-   russell → logical atoms as the building blocks of reality\n\n## Symbolic AI as a degenerating research program\n-   problem of representing significance and relevance → how do you transfer the learnings to the real world\n-  [Heidegger](thoughts/embedded%20AI.md)\n\t-   values are just meaningless facts (hammer is for hammering), leaves out information defining the relation of hammers to nails and the rest of the environment (readiness-to-hand)\n-   Commonsense knowledge problem → how do we represent 'common sense' in a way that is accessible to AI systems that use natural language\n\t-   problem isnt curating those facts, it's knowing which facts are relevant in any given situations (the [frame problem](thoughts/frame%20problem.md))\n\t\t-   should be able to ignore something without having to figure out that it should ignore it\n\t-   if the computer is running a representation of the current state of the world and something in the world chances, how does the program determine which of its represented facts can be assumed to have stayed the same, and which would have to be updated?\n\t\t-   if a certain proposition is true (e.g. there are no empty spots in a parking lot) will it stay true? for how long?","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/syntax":{"title":"Syntax","content":"\n\u003e How are words combined, is a sentence grammatical\n\n## Child-directed Speech\n- Motherese/infant-directed speech (IDS)/child-directed speech (CDS), when talking to babies, adults use a higher-pitched voice, a wider range of pitches, longer pauses, and shorter phrases. Vowels are not only longer in duration, but also are more prototypical examples of the particular vowel being produced\n\t- Generally more straightforward - focused on here and now, directs joint attention, and connects to real world referents\n\t- Lots of repetition for new lexical items\n\t- Helps with language acquisition\n\n## Learning Syntax\n- Syntactic bootstrapping hypothesis: knowledge of language structure is generally useful for learning new verbs\n\t- If we know what the syntactic structure of the language is, it is easier to figure out the meaning of a new word\n- Negative evidence: correcting overgeneralizations\n\t- There is no negative evidence in the speech stream without explicit feedback\n- Cross-situational learning: computing correlations between hearing a word and experiencing its referent (see Smith \u0026 Yu 2008 for related study on whether cross-situational learning is a possible explanation for how children learn words)\n- Measurables\n\t- Longest utterance\n\t- Average utterance (mean length of utterance or MLU)\n\t- Kinds of sentences the child can produce\n- Stages of development\n\t- Stage I (MLU 1.01 to 1.99): earliest word combinations\n\t- Stage II (MLU 2.00 to 2.49): grammatical morphemes start showing up\n\t- Stage III (MLU 2.50 to 2.99): varied simple sentences\n\t- Stage IV (MLU 3.00 and up): varied complex sentences\n\t- Stage V: new complex sentences\n\n## Types of Grammars\n- Prescriptive grammar: dictates how people should speak, gives rules and grammar based around a “standard” or “correct” way of speaking, ignoring variation between dialects or between different demographics of people\n- Descriptive grammar: we want to describe how people actually speak, not how we think they should speak\n- Open-class words: nouns, verbs, adjectives (can be added to)\n- Closed-class words: auxiliaries, prepositions, complementizers, determiners (usually fixed in language)\n- Sentence types\n\t- Declarative (statement): “that’s a doggie”\n\t- Imperative (command): “look at the doggie”\n\t- Interrogative (question): yes/no questions\n\t- Negative sentences: contain negation\n\t- Complex sentences: contain more than one main verb\n- Hirsch-Pasek and Golinkoff (1996): word order comprehension study. Do children know about subjects vs. objects and word order? \n\n## Two theories of syntax\n- Innate/generative: children do not \"learn\" anything specific for a given language, they already have a universal grammar (UG), they learn language-specific parameters to the UG\n- Experience-based/constructivist: grammatical knowledge comes completely from experience\n","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/system-model":{"title":"System model","content":"\nHow do we capture assumptions in a system model for [[thoughts/distributed systems|distributed systems?]]\n\n### Network behaviour (e.g. message loss)\n- Reliable: message is received if and only if it is sent, messages may be reordered\n- Fair-loss: messages may be lost, duplicated, or reordered. A message eventually gets through if you keep retrying (can be upgraded to reliable using retry + packet deduplication)\n- Arbitrary: active adversary, may interfere with messages (can be upgraded to fair-loss using TLS)\n- Network partition: some links dropping/delaying all messages for an extended period of time\n\n### Node behaviour (e.g. crashes)\n- Crash-stop: node is faulty if it crashes. After it crashes, it stops executing forever\n- Crash-recovery: node may crash at any moment, losing in-memory state. It may resume executing sometime later (sometimes call omission fault)\n- Byzantine: a node is faulty if it deviates from the algorithm. Faulty nodes may do anything, including crashing or malicious behaviour\n- Correct: not faulty\n\n### Timing behaviour (e.g. latency)\n- Synchronous: message latency no greater than a known upper bound\n- Partially synchronous: asynchronous for some finite (but unknown, possibly arbitrarily large) periods of time, synchronous otherwise\n\t- Like synchronous model, assumes a shared global clock with bounded drift $\\Delta$\n\t- There is an unknown transition point GST (global stabilization time) where the system goes from asynchronous to synchronous.\n\t\t- All messages sent in an asynchronous period $t \\leq GST$ are delivered by time $GST + \\Delta$\n\t\t- All messages sent in the synchronous period $t \\geq GST$ arrive by time $t + \\Delta$\n\t- The key difference is that we can wait for a sufficiently long delay ($\\Delta$) after the start of a round that if the network has reached synchrony you're guaranteed to receive all messages from all non-Byzantine nodes\n- Asynchronous: messages can be delayed arbitrarily, no timing guarantees\n\n### Identity and Messages\n- Authenticated: a Byzantine node cannot forge a message or change the contents of a received message before it relays the message to other nodes\n- Non-authenticated: nodes have no way of verifying the authenticity of a received message\n\n### Permissioning\n- Permissioned: all nodes in the cluster are known ahead of time\n- Permissionless: anyone can join the cluster","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/systems-design":{"title":"Systems Design","content":"\n## Software Systems\nSystem design in this context means defining the architecture, product design, modules, interfaces, and data for a system according to given requirements. The purpose of system design is to architect a system that can effectively support the functionality of a product or service.\n\nSee also: [[thoughts/system model]]\n\n- Requirements\n\t- Functional: what does the system need to do?\n\t- Non-functional: what properties does it need?\n- 4 things to ask clarifications on\n\t1. Users: who will use the system? how will they use it?\n\t2. Scale: how will our system will handle a growing amount of data?\n\t3. Performance: how fast must our system be?\n\t4. Cost: what are our budget constraints?\n\n## Latency Numbers\n```\nLatency Comparison Numbers\n--------------------------\nL1 cache reference                           0.5 ns\nBranch mispredict                            5   ns\nL2 cache reference                           7   ns                      14x L1 cache\nMutex lock/unlock                           25   ns\nMain memory reference                      100   ns                      20x L2 cache, 200x L1 cache\nCompress 1K bytes with Zippy            10,000   ns       10 us\nSend 1 KB bytes over 1 Gbps network     10,000   ns       10 us\nRead 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSD\nRead 1 MB sequentially from memory     250,000   ns      250 us\nRound trip within same datacenter      500,000   ns      500 us\nRead 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memory\nHDD seek                            10,000,000   ns   10,000 us   10 ms  20x datacenter roundtrip\nRead 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSD\nRead 1 MB sequentially from HDD     30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSD\nSend packet CA-\u003eNetherlands-\u003eCA    150,000,000   ns  150,000 us  150 ms\n\nNotes\n-----\n1 ns = 10^-9 seconds\n1 us = 10^-6 seconds = 1,000 ns\n1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns\n```\n\nBased off of the above:\n-   Read sequentially from HDD at 30 MB/s\n-   Read sequentially from 1 Gbps Ethernet at 100 MB/s\n-   Read sequentially from SSD at 1 GB/s\n-   Read sequentially from main memory at 4 GB/s\n-   6-7 world-wide round trips per second\n-   2,000 round trips per second within a data center\n\n## Real-time\n- WebRTC\n\t- Fast message propagation (no relaying)\n\t- Encryption and authorization over untrusted signaling servers\n\t- No setup required, public signaling servers are available\n\t- Not suitable for a large number of peers (quadratic explosion of complexity)\n\t\t- Browser have a max on connectivity: ~100 diff connections but varies per browser\n- WebSockets\n\t- Clients connect to a single endpoint over Websocket. The server distributes document updates and awareness information among clients.\n\t- Solid choice if you want a central source that handles authentication and authorization\n\t- Also send header information and cookies, so you can use existing authentication mechanisms with this server\n- Hypercore/Dat\n\t- Uses a [[thoughts/DHT]] + [[thoughts/NAT]] traversal utilities\n\t- Low latency\n\t- Medium reliability\n\n## 4+1 Architectural Model\n1. Logical view: The logical view is concerned with the functionality that the system provides to end-users (usually uses UML)\n2. Process view: The process view deals with the dynamic aspects of the system, explains the system processes and how they communicate, and focuses on the run time behaviour of the system (usually sequence diagram, communication diagram, activity diagram)\n3. Development/Implementation view: The development view illustrates a system from a programmer's perspective and is concerned with software management. (usually package/component diagram)\n4. Physical/Deployment view: The physical view depicts the system from a system engineer's point of view. It is concerned with the topology of software components on the physical layer as well as the physical connections between these components\n5. (+1) Scenarios: The description of an architecture is illustrated using a small set of use cases, or scenarios. They also serve as a starting point for tests of an architecture prototype","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/task-centered-design":{"title":"Task-Centered System Design","content":"\n-   articulate concrete descriptions of real-world people doing their real-world tasks\n-   use these description to determine which users and what tasks the system should support\n-   prototype an interface that satisfy these requirements\n-   evaluate the interface by performing a task-centred walkthrough\n\nStrengths\n-   practical way to ground designs to real user tasks\n-   finding requirements at pre and early design stages\n\nLimitations:\n-   tasks almost always embody a process even if they are not specific to a specific technological implementation\n-   may not encourage consideration of alternate ways to do tasks\n-   may be hard to produce pure system- or process- independent tasks\n\n## Understanding Tasks\nEstablishing requirements starts with identifying and understanding **task examples** (users and their tasks).\n\n## Personas\nPersonas are rich descriptions of typical users of the product under development on which the designers can focus on in designing products.\n\nBased off of user profiles, they include description of user's behaviour, attitudes, activities, environment\n\nA persona has 2 goals:\n-   to help the designer make design decisions\n-   reminds the team that real people will be using the product\n\n## Scenarios\nScenarios show how tasks are handled by design:\n-   what the user would see / do step-by-step when performing the task\n-   task + design = scenario\n\nScenario is design-specific; task is design-independent\n\nNatural way to explain what people are doing and stakeholders relate easily","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/teaching":{"title":"Teaching","content":"\nKierkegaard's instructional advice in his *Journals* (from [In Over Our Heads](thoughts/In%20Over%20Our%20Heads.md))\n\n\u003e \"If real success is to attend the effort to bring a person to a definite position, one must first of all take pains to find him where he is and begin there. This is the secret of helping others... In order to help another effectively I must understand what he understands. If I do not know that, my greater understanding will be of no help to him... Instruction begins when you put yourself in his place so that you may understand what he understand and in the way he understands\"\n\n## [Constructionist](thoughts/constructionist.md) Teaching Style\nThe fundamental issue may then be that there's too many tools and too much space: the large space should start small and widen (scaffolding), rather than having everything available at game-start.\n\nHowever, in a siloed world, communication is not exercised. A major component of a lot of subjects seems to be able to communicate effectively with another programmer. If the novice comes out of this experience unable to verbalize and communicate, is it even of use?\n\nA lot of similar questions to [game design](thoughts/game%20design.md). Important learnings in [Mindstorms](thoughts/Mindstorms.md)","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/telerobotics":{"title":"Telerobotics","content":"\n## Dennett's 1981 \"where am I\" story\n-   Secret experiment, Dennett's brain is remove, kept alive in a tank of nutrients, and equipped with a multitude of radio links by means of which it executes all of its normal bodily control functions (very related to [Brains in a Vat](thoughts/Brains%20in%20a%20Vat.md) example)\n-   Dennet's body is then equipped with receivers and transmitters so that it can use its built-in sensors (eyes, ears, etc.) to relay info back to Dennet's brain\n-   stretching of the nerves\n-   “here I am, suspended in a bubbly fluid, being stared at by my own eyes …” — still can't manage to convince himself to place himself in the tank\n-   dennetts body is then trapped under a rockslide, as radio links slowly give away, a shift in point-of-view occurs\n\t-   Is Dennett really in the tank of nutrient, really trapped beneath the soil, or really no-place at all (or both places at once)?\n-   point of view is a construct grounded in the brain's experiences of control, communication, and feedback\n    -   this leaves it open to rapid and radical reconfiguration\n\n## Telepresence\n- literally remote presence\n-   telephone line → thin, narrow [bandwidth](thoughts/bandwidth.md) of aural telepresence\n-   far end, dennets experiment → leave brain and body joined and intact, but wrap the body in a kind of additional sensory cocoon\n-   if this is achievable, would seemingly require a high-[bandwidth](thoughts/bandwidth.md) multi-sensory bath of information with local sensory stimulation\n-   \"But as soon as a distant camera responds to your controls, and especially if the mode of control is either ‘natural’ (the helmet rig) or highly practiced (a video-gamer with a joystick), you begin to feel relocated, as if you are in the distant scene\"\n-   human vision involves a complex process of intelligent search and just-in-time information retrieval\n-   upside-down world example\n    -   people can readapt to upside-down world after a period of sustained use\n    -   however, if it is passive (wheeled around in a wheelchair), the adaption does not occur\n-   the notion that our perceptual experience is determined by the passive receipt of information is misleading\n    -   the whole point of seeing and perceiving our world is so that we can intervene and act upon it\n\n## Telerobotics\n- communication on a higher level of abstraction in which the human communicates goals and the robot comes up with the plan to achieve it\n-   diagnosis that telerobotics are unlikely to generate any real shift in perspective\n    -   example of going to a shop\n        -   never think of each individual muscle movement or thought\n        -   more of a general \"i need a soda, i'm gonna go to the store\"\n        -   most of what ‘I’ did, ‘I’ seemed to have very little to do with\n        -   The vast bulk of neural activity leading both to, and away from, this tip of the metaphorical 'I'berg is unconscious.\n    -   example of picking up tichener circles (circle size illusion but with poker chips)\n        -   it is the conscious (illusory) perception of one circle as larger than the other that causes the autopilot-like subsystem to reach for a specific disc\n        -   Our conscious high-level decisions thus serve as the impetus for the other systems to do their stuff, while still devolving substantial sub-problems to other internal agencies.\n        -   this is what T. Sheridan (1992) originally dubbed “Supervisory Control”: a type of control in which only goals and high level commands are communicated to the slave robot.\n        -   how is this different from telerobotics?\n    -   in principle, telerobotics systems need not feel more alien than teleoperated systems to the conscious users, however this is not the case in practice. closely coupled teleoperated systems seem to much better induce the feeling of actual telepresense more effectively\n        -   what seems to be important is the presense of some kind of local, circular [feedback loop](thoughts/feedback%20loops.md) in which neural commands, motor actions, and sensory feedback are closely and continuously correlated\n            -   temporal disruptions (like lag) may break this 'illusion'\n    -   the brain uses a special piece of neural circuitry known as a motor emulator\n        -   This is a little circuit that takes a copy of the motor signal to the hand (say) and feeds it into a neural system which has learned about the typical responses from the bodily peripheries which are likely to ensue. The emulator is thus like a little local scale model of the real circuit. It rapidly outputs a prediction of the signals that should soon be arriving from the bodily peripheries, and these are then used instead of the real thing. This emulator-based feedback is then used for ongoing error-connection and smoothing\n    -   explaining why the apparent telerobotics that we as humans actually perform seem to not suffer from the sensation that our body, while performing the action sequences, we are somehow less than fully in control of ourselves\n        -   one possible explanation is that own detailed bodily motions retain a sense of unfolding and possible intervention\n            -   unfolding → rich array of sensory feedback as the action is ongoing\n            -   potential intervention → i can just consciously stop","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/terminology":{"title":"Terminology","content":"\n## Orwell on Language\n[Source: *Orwell* on Politics and the English Language](https://www.orwell.ru/library/essays/politics/english/e_polit/)\n\n\"In prose, the worst thing one can do with words is surrender to them. When you think of a concrete object, you think wordlessly, and then, if you want to describe the thing you have been visualising you probably hunt about until you find the exact words that seem to fit it.\"\n\n## A tangent on language\nlanguage as an abstraction for concepts\n\nneed to communicate and refer to objects that are not spatially/temporally local\n\nabstraction involves compression -\u003e detail is lost\nthe way we make up for that detail is through having a shared consensus over meaning and intent\n\nthis meaning and intent is baked into the meaning of the word through how the word is used \n‘In most cases, the meaning of a word is its use’, Wittgenstein claimed, in perhaps the most famous passage in the Investigations. It ain’t what you say, it’s the way that you say it, and the [context](thoughts/context.md) in which you say it. Words are how you use them.\n\nyet usage changes over time\nno one person or institution decides how language works: it is one of the few logically decentralized aspects of humanity\n\nold meanings may no longer make sense. new groups try to co-opt old terminology. we accrue a plurality of definitions\n\nwhen do we need new words?\n\n## Terminological anchoring\nnatural meaning 'drift'\n\n- hesitant to 'root' new terms, terminology evolves in a decentralized way, centralizing meaning often concretizes meaning (which is good in the case of dictionaries but i dont think web3 is at that stage yet)\n- naming as power, but naming also anchors meaning\n\n## Definition overloading\n- term overloading\n\t- i think my worry with a 'standard library' is that there is no one 'unified' interpretation of a single concept, how will it adapt to usage overtime? wouldnt this anchor thought patterns to a shared 'truth'?\n\t- \"By changing what we were, you change what we are and what we are going to be.\" erasure through terminology change -\u003e essentially just cooptation?\n\t- \"Thus potential sources of uncertainty and misunderstanding arise in the form of homonyms (i.e. words that are used to denote more than one concept) and synonyms (i.e. more than one word for the same concept).\" [Source](https://philosophyforchange.wordpress.com/2014/03/11/meaning-is-use-wittgenstein-on-the-limits-of-language/?curius=1294)\n\ndo we need new words?\ne.g. hacker, metaverse\n\nat nwplus, we have a slide on all our promo materials that explains that hackers don't actually 'hack devices' at hackathons\n\n## Right to be forgotten\n- right to be forgotten but for terminology\n\t- rel: [digital permanence](thoughts/digital%20permanence.md)\n\nhard for things ingrained within society\nmeaning is not dictated by some central organization\nit needs to be collectively forgotten, and/or overwritten\n\neither hard-fork it within a subcommunity\nor create an entirely new word\n\n## Terminological [Feedback Loops](thoughts/feedback%20loops.md)\n1. Practice creates new terminology as a way to communicate complex ideas without needing to rexplain each time\n2. Terminology then shapes how we think about the world: [Sapir-Whorf](thoughts/language%20of%20thought.md)\n3. Some terminology becomes outdated as practice changes\n4. Arguments ensue over updating shared terminology (esp as language is decentralized, this can cause fracturing)\n5. Two camps emerge\n\t1. People who want to use terminology mainly as a means to more efficiently communicate practice\n\t2. People who like the theory behind terminology or those who are attached to tradition\n6. Camps argue over who has the 'right' definitions but for their own goals\n\t1. Camp 1 repeats this loop\n\t2. Camp 2 continues to argue over definitions","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/testimony":{"title":"Testimony","content":"\nForming a belief based on the [trust](thoughts/trust.md) of another's written or spoken word.\n\nThree main positions of validity of knowledge gained through testimony\n1. Skepticism (e.g. John Locke): one cannot gain knowledge on the basis of testimony alone. Cannot ensure reliability of other actors\n2. [Reductionism](thoughts/Reductionism.md): one can gain knowledge through testimony, but only if one has independent, inductive reason for believing that the speaker is reliable\n3. Non-reductionism (e.g. [Nyāya](thoughts/Nyāya.md)): one can gain knowledge through testimony simply by trusting the speaker (provided that the speaker knows what they assert). Testimony is a trust-worthy [epistemic](thoughts/epistemology.md) instrument, knowledge is communal\n\nRelated: [consensus](thoughts/consensus.md)\n\n## Experts: Which Ones Should You Trust?\n*by Alvin I. Goldman (2001)*\n\nCentral Question: the Novice/2-Expert Problem\n- An expert\n\t- Knows a lot about the domain (first order material)\n\t- Knows about the literature concerning the domain (second order material)\n\t- Able to draw on this knowledge to produce answers about the domain\n- Two experts disagree, as a novice, which expert do you trust as more credible? 5 kinds of evidence\n\t1. Arguments presented by the contending to support their own views and critique their rival's views\n\t2. Agreement from additional putative experts on one side or other of the subject in question\n\t\t1. Counterpoint: Copernican heliocentrism, most 'experts' believed that the Earth was the middle of the solar system, not the sun\n\t\t2. Goldman steel-mans his argument through Bayesian analysis, experts should think for themselves and should be 'conditionally independent' -- they will not invariably parrot the claims of others when those claims are wrong\n\t\t3. What about discoverability of experts? If a tree falls but nobody hears it, did it still happen?\n\t3. Appraisals by \"meta-experts\" of the experts' expertise\n\t4. Evidence of the expert's interests and biases vis-a-vis the question at issue\n\t5. Evidence of the expert's past track-records\n- Important to note that all of these depend on *human* knowledge, not [religious authority](thoughts/religious%20authority.md)\n- Not fool-proof either, e.g. differences in communication medium, language, smooth-talking, etc.\n- How does the novice avoid cognitive [biases](thoughts/bias.md) of their own?","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/the-Self":{"title":"The self","content":"\n1. Me (self-as-object)\n\t1. Some feature is the object of my awareness\n\t2. I recognize this feature as mine or ascribe it to myself\n2. I (self-as-subject)\n\t1. I experience myself as subject of perception/cognition/emotion\n\t2. Body anchored\n\nValid in dreams, but also [games](thoughts/games.md)?\n\n## Autoscopic Phenomena[^1]\n- Autoscopic Hallucination: you see a double of yourself but do not feel like you have ownership or agnecy over it\n- Heautoscopy: visual perspective switches back and forth between yourself and double and you feel ownership of both\n- Out-of-body experience: you identify the body seen from the outside as yours but have no feeling of agency for it\n\t- Direct electrical stimulation at the temporoparietal junction induces out-of-body experiences\n\n## Views of the self[^1]\n1. Neuro-nihilism\n\t- There is no self\n\t- The self is an illusion created by the brain\n\t- \"I\" does not refer to anything so all references are errors (false)\n2. Enactive View\n\t- The self is a process\n\t- Enacted through social cognition and language, rooted in the life of the body immersed in the environment\n\t- \"I\" functions performatively, not referentially\n\t- I-making (ahamkāra): the sense of being an \"I\" who endures through tiem and who is a thinker of thoughts and a doer of deeds\n\t\t- dancing is a process that enacts a dance in the dance itself is no different from dancing\n\t\t- similarly, the self is a process that enacts an \"I\" and the \"I\" is no different from the self\n\t\t- The self is self-specifying ([autopoietic](thoughts/autopoiesis.md)) and also [interdependent](thoughts/interdependence.md) (dependently originated process)\n3. Absolutism\n\t- There exists a real independent self\n\n## Identity\nEssay by Jenny Odell and in [Kopi Chats on Substack](https://kopiclub.substack.com/p/letter-37-loneliness-vs-being-alone)\n\n\u003e _“When I examine my [[thoughts/identity|identity]], I do see an inalienable spirit grasping for infinity. But in the very same place, I also see an intersection of historical and cultural vectors, held up by **a web of countless reliances**.”_\n\nReminds me of Indra's Net, that everything is [interdependent](thoughts/interdependence.md), [empty](thoughts/emptiness.md) of dependent origination.\n\n\"Connective vulnerability is so frightening because sometimes we will be let down by others, unmoored from [friendships](thoughts/friendship.md) and relationships we thought were our anchors in life. But that doesn’t mean we shouldn’t try. (see: [nothing-stops](posts/nothing-stops.md))\"\n\n[^1]: This content is sourced from Professor [Evan Thompson](https://evanthompson.me/)'s course materials for PHIL451A at UBC. All rights to this content is retained by Evan Thompson.","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/the-garden-and-the-stream":{"title":"The Garden and the Stream","content":"\n[Source](https://hapgood.us/2015/10/17/the-garden-and-the-stream-a-technopastoral/)\n\n## The Garden\nA garden is a metaphor for a lot of things: growth, persistence, and the constant battle against entropy.\n\nThe Garden is an old metaphor associated with [[thoughts/hypertext]].\n\n\u003e The Garden of Forking Paths from the mid-20th century. The concept of the Wiki Gardener from the 1990s. Mark Bernstein’s 1998 essay Hypertext Gardens.\n\nThe Garden is the web as [[thoughts/search#Internet topology as shaped by search engines|topology]]. Every walk through the garden creates new paths, new meanings, and when we add things to the garden we add them in a way that allows many future, unpredicted relationships.\n\nThere is no *right* or canonical way to view it\n\nA hard part of this is The Navigation Problem: how do we give web users just enough guidance to freely explore the web, without forcing them into pre-defined browsing experiences?\n\n## The Stream\nIn the stream metaphor you don’t experience the Stream by walking around it and looking at it, or following it to its end. You jump in and let it flow past. You feel the force of it hit you as things float by.\n\nIn other words, the Stream replaces topology with serialization. Rather than imagine a timeless world of connection and multiple paths, the Stream presents us with a single, time ordered path with our experience (and only our experience) at the center.\n\nWe live in a shallow web. Not of actual trails, but of sign posts.\n\n\u003e A web of “hey this is cool” one-hop links. A web where where links are used to create a conversational trail (a sort of “read this if you want to understand what I am riffing on” link) instead of associations of ideas... A web seen as a tool for self-expression rather than a tool for thought.","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/tools-for-thought":{"title":"Tools for Thought","content":"\n\u003e \"When designing new tools for thought, let’s think not just in terms of features, but materials – _what software laws of physics do we want embodiments of our thoughts to obey?_\"\n\nRelated: [Extended Mind Hypothesis](thoughts/Extended%20Mind%20Hypothesis.md), [Networked thought](posts/networked-thought.md), [interaction design](thoughts/interaction%20design.md), [[thoughts/memex]]\n\nQuestions:\n1. How can we create tools that aid our thinking? How can we extend the range of thoughts we can think?\n2. As an extension, how do we organize the abundance of [information](thoughts/information.md) we have today so that it is both accessible and useful?\n3. How do we distill all the [research debt](thoughts/research%20debt.md) so that our ideas are easily useful to others?\n4. How can we make mixed media first-class? Allow drawing, images, and video? Bring back the overhead projector!\n\nCan we do this on a browser-level rather than just a standalone app? Building in curius.app-esque support, annotations, note-taking, etc. Minimize context switching\n\n## Capture-organize-synthesize loop\n[Source](https://subconscious.substack.com/p/unconscious-r-and-d)\n\n-  Why do file systems force you to name a file (_synthesize_), and place it in a folder (_organize_) before you can write in it (_capture_)?\n-  Why do Word Processors present you with a blank page (_synthesize_) instead of offering scratch notes (_capture_) that are relevant (_organize_) to your writing goals?\n-  Why do we expect ourselves to create good ideas from nothing (_synthesize_)? It’s much easier to generate ideas when you have lots of material (_capture_) clustered by themes and relationships (_organize_)\n\nMixing up the order of _capture-organize-synthesize_ causes friction. It forces us to make decisions before we’re ready.\n\nSee also: [reverse outlining](https://maggieappleton.com/reverse-outline)\n\n## Thought as a technology\n[Source](https://cognitivemedium.com/tat/index.html)\n\n- How can we invent new elements of cognition?\n- How can we reify internal mental models?\n- Not all visualization is good\n\t- There is a cargo cult mentality which embraces visualization for the sake of visualization. In fact, there is no _a priori_ reason a visual approach is superior\n\n## Word Charcuterie Board\nIs there any way to rearrange the fuzzy cloud of ideas in our head easily on paper/screens?\n\nHow can we 'cut' text without being afraid of it being lost forever? Even with tools like the undo button and [[thoughts/git|Git]] revision history, the actions of the past are by default hidden. Time is not first class.\n\n## On memory and [lost knowledge](thoughts/lost%20knowledge.md)\n\u003e If a tree fell and nobody remembered, did it really happen?\n\nVery 1984-line-of-thought but those who control the past, how we remember and what history is, controls the present and thus controls the future.\n\nOur tools of memory should be democratized and public. These tools are a [public good](thoughts/public%20goods.md). They are, quite literally, the [infrastructure](thoughts/infrastructure.md) for mental representations and operations. These are the patterns the dictate our very mental processes.\n\n## Kernel\n[Source: Remember in *Kernel*](https://kernel.community/en/learn/module-3/remember)\n\nWe live in an [information](thoughts/information.md) age. The amount of data we produce far outweighs what we consume, so much so that its extended far beyond our ability to make meaningful use of it. \n\n\u003e \"There is a growing mountain of research [but we] cannot find time to grasp, much less to remember, all the conclusions of others as they appear. Yet specialization becomes increasingly necessary for progress, and the effort to bridge between disciplines is correspondingly superficial [...]\n\nA record should be able to be\n1. continuously extended\n2. stored\n3. consulted (e.g. through search)\n\nRight now, most [organizing systems](thoughts/organizing%20system.md) are really good at 1) and 2) but suck at 3).\n\nWe're trying to build tools that allow association between ideas easily, relying on relations and relatedness [without forcing hierarchies or classification straight away](thoughts/A%20City%20is%20not%20a%20Tree.md). Then, the path through these ideas can be thought of as 'user trails'. \n\n### Chunking\nWe naturally group things into patterns and chunks and allow us to think on and rationalize at higher levels of abstraction, descending into lower levels only when we need to.\n\nThis was demonstrated by chess masters in the 1970's: \"Players learn to recognize somewhere between 25,000 and 100,000 **patterns of chess pieces**. These much more elaborate 'chunks' are combinations of pieces that the players **perceive as a unity**, and are able to reason about at a higher level of abstraction than the individual pieces\"\n\nIs it possible to automatically pick up repeated digital [desire paths](thoughts/desire%20paths.md) of user trails and pull them into [workflows](thoughts/workflows.md)? take advantage of natural spaced repetition to identify saliency\n\nThe focus of modern information systems is moving from \"data-processing\" towards \"concept-processing\", meaning that the basic unit of processing is less and less an atomic piece of data and is becoming more a semantic concept which caries an interpretation and exists in a [context](thoughts/context.md) with other concepts.\n\n[Source: Automated knowledge discovery in advanced knowledge management](https://www.researchgate.net/publication/220363565_Automated_knowledge_discovery_in_advanced_knowledge_management)\n\nAre there ways to 'breadcrumb' how we navigate? Even something as simple as option+click to leave a crumb and when finishing a session, you can save parts of the trail as a flow.\n\n### Spatial\nCan we create spatial reminders that adhere to their contexts? Sticky notes for our mind? A reminder in certain notes to come back later and add to it, etc. Can we build [memory palaces](thoughts/memory%20palace.md)? Spatial representations of information? (See https://nototo.app/)\n\n### Emotion\nVideo is incredibly expressive. You can *feel* the passion of people who really care about the things they study, build, and work on.\n\nIs it possible to create mediums for thought that convey 'awe and mystery and surprise and beauty'? I really hope so.\n\n### Execution\nCan we embed computation into our notes? Create APIs out of our thoughts and concepts? Compose theorems just as easily as we chain function calls?\n\n## Activism\n[Source: On Gathering, *Mindy Seu*](https://www.shiftspace.pub/on-gathering-mindy-seu)\n\nMemory work of this sort is also a form of activism. Whose memories are saved and retold to future generations?\n\nAfter a conversation, all parties maintain ownership of what transpired, and they continue to hold ties to one another. This form of storytelling is not predetermined, but develops through its unfolding.\n\n## Mediums versus Tools\nLinus Lee on [Browsers as Tools of Thought](https://thesephist.com/posts/browser/)\n\n\u003e A tool is something that takes an existing workflow, and makes it more efficient. A nail is an efficient way of holding pieces of wood together; a to-do app is an efficient way of remembering your responsibilities. A medium, on the other hand, gives us new agency or power by which we can do something we couldn’t do before.\n\n**The best mediums are instead collections of generic, multi-purpose _components_ that mesh together well**\n\n\n## Tasting Notes\n[Robin Sloan shares his recipe for taking notes that spark novels](https://every.to/superorganizers/tasting-notes-with-robin-sloan-25629085)\n\n\u003e But the interesting thing about Robin is he doesn’t look at these things as bricks exactly. They don’t combine together in predictable, linear ways.\n\u003e \n\u003e Instead, Robin’s notes are more like ingredients—deep yellow saffron, Ceylon cinnamon, black garlic, and white truffle—bits of the world that he throws together into a pot and covers with a heavy lid. He turns up the heat, he adds salt to taste—until out comes a story. \n\n### On inventing new containers\nI describe myself as a ‘media inventor’, which I know sounds like a strange label. To me, it means that a lot of my work – not really my novels, but almost everything else – involves inventing a format or container at the same time that I’m writing or imagining what goes into it.","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/traditional-knowledge":{"title":"Traditional Knowledge (TK)","content":"\n*Strategic translation: pollution, data, and Indigenous Traditional Knowledge* by Sarah Blacker\n\nWe look to 'Water is a living thing' as a case study. Here, two First Nations communities \"*chose* to partially translate their knowledge into data because doing so enabled them to enter into dialogue with policy-makers -- with data as the lingua franca - to participate in science, and to retain control over their own data.\"\n\nThis is an act of protest against the settler colonial state.\n\nData as a form of partial translation which serves as a [boundary object](thoughts/boundary%20object.md)\n\nScience is not apolitical, nor measurement neutral.\n- \"The practices through which data is collected are informed by the social and political context where the science is being carried out as well as by the assumptions and positionality of the scientists themselves.\"\n- \"Because government metrics of contamination are framed as objective and politically neutral (Hoover 2013), they are difficult to challenge, particularly for economically marginalized and racialized communities that are disproportionately affected by environmental contamination\"\n\t- This is also not always true either (e.g. lobbying, strategic funding of specific outcomes in research, etc.)\n\t- tldr; Who is to say the government is objective?\n\t- e.g. 'science muzzling' (read: censorship) under the Harper government\n\nMcLachlan's three-track method\n- used in a collaboration between the two First Nations communities and non-Indigenous scientists in order to produce a document that could be circulated in the form of data\n- Tracks\n\t1. Narrative: Articulates TK about environmental environmental contamination\n\t2. Numerical: Provides measurements of contamination levels using current industry standards\n\t3. Synthesis: combination of the above\n\nSome argue that \"local knowledge is altered when it is removed from ‘its embeddedness in a holistic cultural and political context’ so that it can be made comparable, classifiable, and commensurable\"\n\n\u003e [S]cientists look at very thin slices of stuff. They don’t look at the whole book, they look at one word on a page and try to define. Somebody’s got to put the book together. But if you can’t see the whole book, you can’t do it. That’s the trouble with scientists. Where the traditional knowledge is like you have the whole book. You may not be able to say exactly why, what causes this, what causes that. But you can sure see the changes.\n\nSeems to mutual distrust between First Nations groups and government + industry\n1. First Nations groups don't trust govt + industry as the data they collect is not holistic and doesn't incorporate TK\n2. Government + industry doesn't trust First Nations as they doubt their scientific abilities and incapability of producing 'objective' data\n\nDid not end up working under Harper government, but First Nations communities were undeterred.\n\n## Open Access\nFrom Kimberly Christen’s “Does Information Really Want to be Free?” and Salomé Viljoen’s “A Relational Theory of Data Governance”\n\nContests over access to knowledge arise because of the historical conditions that meant that indigenous people lost control over how and what knowledge was to be circulated\n\nData and information should only be common use *after* voluntary communication to others. This is not the case for the vast majority of traditional knowledge.\n\nPublic domain instead violates indigenous peoples’ rights by defining their collective works as “folklore” and excluding their protection via copyright system","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/tragedy-of-the-commons":{"title":"Tragedy of the Commons","content":"\n\n\u003e The more accessible a good is, the less people want to pay for it. --[Scott Moore](https://scott.mirror.xyz/7nKKV4x17rVkZL9_C0vVL3Vax2rv1H1ciigleEgBAOw)\n\nA government only has interest in [funding](thoughts/funding.md) its own roads, companies like Facebook only have interest in funding their own infrastructure. Very prevalent in [open-source](posts/paid-open-source.md), some of the most used software in the world often goes unpaid and unfunded.\n\nCommons in the modern economic context is any open-access and unregulated resource (e.g. atmosphere, ocean, rivers, etc.)\n\n\u003e How we might focus less on speculation and more on participation?\n\nDoes this impact [digital commons](thoughts/digital%20commons.md) too? What about for [climate tech](thoughts/climate%20tech.md)?\n\nWould be solved if people acted according [[thoughts/Kant]]'s Categorical Imperative (tldr; only act in a certain way if it is possible and desirable for everyone in the world to act in that way)\n\n## Without Tragedy\nElinor Ostrom defines 7 requirements to govern a commons without tragedy:\n\n-   Clear boundaries (private)\n-   Managed by locals\n-   Community makes its own rules\n-   Community can monitor behavior\n-   Graduated sanctions for those who violate community rules\n-   Cheap, accessible means of conflict resolution\n-   Self-determination\n\nIn a small community, everybody knows everybody, and can keep track of what they do. This makes small groups [[thoughts/game theory|iterated games]] which rewards trust and penalizes sociopathic behaviour","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/transformers":{"title":"Transformer Models","content":"\n![[thoughts/images/transformer supremacy.png]]\n\n## Attention\nEach decoding can use hidden state from each encoding step. Used to re-weight during decoding to emphasize important parts. Can be seen as a variant of skip-connections.\n\nAt each time step:\n1. Prepare inputs (encoder hidden states from previous input)\n2. Score each hidden state\n3. Softmax the scores and multiply each input by its score\n4. Sum up all the vectors\n\nContext vector is usually appended to decoder’s state when going to next layer\n\nThis is a single-head attention mechanism. Most transformers use multiple heads to attend to different aspects of the input (e.g. for text, one focuses on grammar, another may focus on counts of things)\n\n## Transformers\nCNNs are less sequential, but take multiple steps to combine distant information. “Attention is all you need”: keep the attention, ditch the RNN/CNN. Uses “self-attention” layers to model relationship between all words in input\n\n![[thoughts/images/transformers.png]]","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/transitive-closure":{"title":"Transitive Closure","content":"\n![[thoughts/images/transitive closure.png]]\n\nLet:\n- $X$ be the set of elements\n- $\\mathcal R$ be the set of relations\n- $\\mathcal R^2$ be the set of relations which can be reached from two hops of relations in $\\mathcal R$\n\t- For example, `(a,c)` is reached by going through `(a,b) -\u003e (b,c)`\n- $\\mathcal R^*$ is the entire transitive closure over $\\mathcal R$","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/transparency":{"title":"Transparency","content":"\n[Source: What’s in a Category: Definitions of Authenticity, Transparency, and the Social-Bot by *Eseohe Ojo*](https://digitaltattoo.ubc.ca/2020/03/30/guest-post-whats-in-a-category-definitions-of-authenticity-transparency-and-the-social-bot/)\n\nThe process of identifying users is how social media platforms monetize their operations\n\nBig companies avoid fully detailing how they identify and categorize uses, claiming that the information is \"proprietary\".\n\n\"They argue, this surveillance allows them ways to minimize the gamification of the social media system by disruptive actors, and by segmentation and differentiation, they may better protect the authentic user from the inauthentic.\"\n\n## Algorithmic Transparency in the News Media\n[PDF in Digital Journalism](http://www.nickdiakopoulos.com/wp-content/uploads/2016/07/Algorithmic-Transparency-in-the-News-Media-Final.pdf)\n\n- Deuze (2005, 455) defines transparency as the “ways in which people both inside and external to journalism are given a chance to monitor, check, criticize and even intervene in the journalistic process.”\n- Similarly, defines *algorithmic transparency*: what we define as the disclosure of information about algorithms to enable monitoring, checking, criticism, or intervention by interested parties.\n- Even though transparency is not a new concept for holding governments and institutions accountable, its recent renaissance has been accompanied by changes in communication technologies (Fung, Graham, and Weil 2007)\n\t- Digital technologies have changed the access to and scrutiny of information by anyone with internet access, which Meijer (2009) broadly described as “computer-mediated transparency.”\n- Transparency is generally considered a means to see the truth and motives behind people’s actions (Balkin 1999) and to ensure social accountability and trust (Breton 2006). On a very basic level, transparency allows access to more information which can influence power relationships between governments and citizens, business and customers, and in our case between news outlets and audiences (Bennis 2013). The access to more information also reduces uncertainty in social relations and theoretically increases trust (Cotterrell 1999), which is crucial in the maintenance of a functional society (Fukuyama 1995).\n- But while transparency can be seen as beneficial to engendering trust, seeing the inner workings of a government, business, or newsroom can result in negative implications such as undermining competitive advantages or creating costs without concomitant gains (Granados and Gupta 2013).\n- Challenges\n\t- what would motivate a news or media organization to disclose details about their algorithms? Costs identified in producing transparency information included: data preparation, documentation writing, source code polishing, and benchmark testing. “How does being transparent offset loss of revenue?\"\n\t- Participants also suggested that disclosing aspects of how a proprietary algorithmic system works may hurt an organization’s technological competitive advantage, or open the system to manipulation by third parties. Yet it was recognized that people will game the system no matter what, and that by disclosing information publicly it would level the playing field or, as one participant (CS2) put it, “everybody has the same chance now because we all know the rules of the game.”\n\nCited as:\n\n\u003e Diakopoulos, N., \u0026 Koliska, M. (2017). Algorithmic transparency in the news media. _Digital journalism_, _5_(7), 809-828.\n\n## Explanations as Mechanisms for Supporting Algorithmic Transparency\n[PDF in CHI 2018](https://dl.acm.org/doi/pdf/10.1145/3173574.3173677)\n\n* Transparency involves encountering non-obvious information that is difficult for an individual to learn or experience directly, about how and why a system works the way it does and what this means for the system’s outputs.\n* Greater transparency allows people to question and critique a system in order to develop appropriate reliance, rather than blind faith\n* Methods for transparency\n\t* algorithm audits, which investigate both how an algorithmic decision making system works, and what its impacts are\n\t\t* some have argued that platforms are intentionally opaque regarding details about their operation as a form of self-protection from competitors or others who attempt to “game” the system\n\t* providing explanations, a common approach in recommender systems that may help solve problems caused by lack of transparency in algorithmic decision-making systems\n* How explanations are \"white box descriptions\"\n\t* They provide information about how a system produces a recommendation, particularly focusing on the system’s reasoning and data source\n* Why explanations are \"black box descriptions\"\n\t* providing justifications for a system and its outcomes and explaining the motivations behind the system, but not disclosing how the system works.\n\t* These explanations fill an intention gap between a user’s needs and interests and the system’s goals, but do not provide any visibility into how the system works\n* Transparency of mechanism vs outcome\n\nCited as:\n\n\u003e Rader, E., Cotter, K., \u0026 Cho, J. (2018, April). Explanations as mechanisms for supporting algorithmic transparency. In _Proceedings of the 2018 CHI conference on human factors in computing systems_ (pp. 1-13).\n\n## ACM Principles for Algorithmic Transparency and Accountability\n- Awareness: stakeholders of analytic systems should be aware of the biases + risks + potential harms their design, implementation, and use could cause\n- Access and redress: encourage the adoption of mechanisms that allow questioning by and remediation for groups adversely affected by algorithmic decision making systems\n- Accountability: institutions should be held responsible for decisions made by their algorithms, even if how the model arrived at its results is inexplicable\n- Explanation: systems are encouraged to produce explanations of model output (regarding both procedures followed by algorithm as well as decisions made)\n- Data Provenance: describe how the data was collected and should be maintained, along with an exploration of the potential biases induced by the data gathering process\n- Auditability: models, algorithms, data, and decisions should be recorded so that they can be audited in cases where harm is suspected\n- Validation + Testing: institutions should routinely use rigorous methods to validate their models (against discriminatory harm for example) and documents those methods.","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/tribe-flourishing":{"title":"Tribe Flourishing","content":"\nRelated: [collaborative-thinking](posts/collaborative-thinking.md), [communities](thoughts/communities.md), [friendship](thoughts/friendship.md), and [context-collapse](posts/context-collapse.md)\n\nWhy are we more ourselves in small group chats than our posts? Why are we more comfortable trying new things and working on projects in these smaller groups?\n\nIs it because of bureaucratic friction at scale? [Group limits](thoughts/group%20limits.md)? \n\nHow do we move away from the 'other' and towards the 'us'? Towards collectivism and interdependence rather than individualism?\n\n## On Building with a Squad\nBy [Jon Borichevskiy](https://jon.bo/posts/squad/)\n\n\u003e It is not a startup, nor an organization with a mission statement, nor a non-profit, nor a consultancy... Our calls are space we hold in which we invite one other to explore and create what wants to be built at the intersection of all our interests and diverse perspectives and past experiences. **A squad is a collective identity in which I can participate to create something more intricate, comprehensive, and wonderful than with just myself.**\n\nIt’s [[trust|trusting]] everyone else in the group is committed to upholding a high-openness, high-trust, [[thoughts/play|playful]] mode of co-creating and exploration. It’s having the confidence that whatever comes up – we will make space for the collective group wisdom to work through it and come out on the other end stronger, together. \n\nTakeaways\n- Shared knowledge graph tooling is a common pain point and one no one has solved well\n- Frictionful onboarding can be good! \"What does work is having people join our open calls, playing with ideas and tasks they resonate with, and progressively getting more involved\"\n\n## 'Back to the Land'\nA lot of similar concepts to [FCTC](thoughts/From%20Counterculture%20to%20Cyberculture.md) around digital communalism and back-to-the-land movements\n\n## Squad Wealth\n[Source: *Other Internet* on Squad Wealth](https://otherinter.net/research/squad-wealth/)\n\n\"Squad culture is the antithesis of neoliberal individualism. Millennials are healing from decades of irony poisoning, rediscovering what it's like to have generative, exploratory relationships with one another.\"\n\n_The squad economy primarily yields non-monetary forms of value_\n\n## Friends \u003e Communities\n[Source: friends \u003e communities, *Sari Azout*](https://sariazout.substack.com/p/58-friends-communities)\n\n\"This is about building the picks and shovels for intimate, intentionally small groups of friends and Internet friends to build things together, live together, and create wealth together. Unlike the Discord communities you’re part of, the small groups I’m thinking of have to stay small to survive — they’re small by design. Can you really be yourself in group chats with 50+ people?\"\n\n## [Mutual Aid](thoughts/Mutual%20Aid.md)\n[Chama](https://en.wikipedia.org/wiki/Chama_(investment))'s for the modern age, [Communities of Fate](thoughts/Community%20of%20Fate.md)\n\n## Small Group\n[Source: James Mulholland](https://jmulholland.com/small-group/)\n\n\u003e The SMALL GROUP offers a private, close-knit environment in which members can share ideas freely.\n\nBenjamin Franklin had the Junto Club, Tolkien and C.S. Lewis had The Inklings, Jobs and Wozniak had Homebrew. The Bloomsbury Group was integral to the success of Virginia Woolf, Clive Bell, and John Maynard Keynes, while MIT’s Model Railroad Club spawned much of modern hacker culture.\n\nAround a dozen members is the sweet spot of social motivation: small enough to know everyone, yet large enough that the group won’t collapse if one or two members’ enthusiasm wanes; small enough that you are not daunted by competing with the whole world, yet large enough that you still need to be on your toes to keep up.\n","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/trust":{"title":"Trust","content":"\n\u003e In an empire of lies, telling the truth is a revolutionary act. In a fearful society; love and trust are the primary tools of resistance.\n\n[Source: *Kernel* on Trust](https://kernel.community/en/learn/module-0/trust)\n\n\u003e Trust is only meaningful once we have fully understood how people can lie.\n\nHaving clearly defined and encoded rules means that there is an *implicit shift* from trusting those who own the medium to those who are transacting. In essense, trusting peers rather than a regulatory power.\n\nThis feels like its missing an important step in the process: trusting the medium. If people don't understand how the medium works to facilitate transactions, how can they trust it? Not only is **access** important, but how easily people understand why it works.\n\nCurious whether this has relations to [philosophy of science](thoughts/philosophy%20of%20science.md) and [Cartesian skepticism](thoughts/Descartes'%20Meditations.md)\n\nRelated: [game theory and trust](thoughts/game%20theory.md), [[thoughts/PHIL240A Final Paper|PHIL240A Final Paper]]\n\n\u003e To dream up important ideas you must think like an idealist; to build systems that will live up to those dreams, you must think like an adversary.\n\n### [Money](thoughts/money.md) as Faith\nWhat you believe informs what you pay attention to and how you act, which define what you vest value in.\n\n## Web3\n\"Because [blockchain](thoughts/blockchain.md)s allow us to define succinctly our shared truths, **and because the record itself is shared** across all participants, there is a whole new \"trust space\" we can explore, searching for more valuable kinds of transactions impossible within merely legal fictions.\"\n\n## Trust as an Unquestioning Attitude\n*C. Thi Nguyen*\n\n\"We inhabit trust like we inhabit the air, and we only notice it when it has departed.\"\n\n\u003e Most theories of trust presume that trust is a conscious attitude that can be directed at only other agents. I sketch a different form of trust: the unquestioning attitude. What it is to trust, in this sense, is not simply to rely on something, but to rely on it unquestioningly. It is to rely on a resource while suspending deliberation over its reliability\n\n### Baier's Goodwill Theory\nColloquial use of \"trust\" blurs together two very distinct concepts\n- Mere reliance: depending on something\n- Attitude of trust: depend in some more normatively loaded manner\n\t- E.g. failing to show up after having promised to do so: \"I had trusted you and you let me down\"\n\t- Generally applies to things/people within our integrative stance -- things we take to be part of us and towards things with which we are supposed to be integrating to form some larger whole\n\t- The normativity here arises, not from there being any moral commitments in play, but from teleological integration: \"The external objects that evoke the strongest sense of betrayal are those whose functions are most tightly integrated into our own thinking and functioning\"\n\nQuestion: can objects be trusted in the normative sense? Can we feel betrayed by objects?\n\nThis involves ascribing goodwill to the trusted and the sense of betrayal comes from discovery that there is no such goodwill after all.\n\n### Responsiveness Theories\nThinking that the fact that you trust in them/it will give a reason to fulfill that trust.\n\n\u003e a trustworthy person “takes the fact that they are counted on to be a reason for acting as counted on” (Jones 2012, 66)\n\nBetrayal of trust here is failure to be properly responsive\n\nHawley's definition of trust is that \"to trust somebody is to take them to have made a commitment to do something and to rely on them to fulfill that commitment. Hawley's account grounds the sence of betrayal in the trusted person's failure to live up to their commitments\"\n\n### Non-agent based theories\nYet all of these theories share the presumption of agent-directedness or [intentionality](thoughts/intentionality.md).\n\nRelated, [agential gullibility and the Extended mind Hypothesis](thoughts/Extended%20Mind%20Hypothesis.md)\n\n\u003e \"The veteran also suffers from a problem of trust, a building block on which all of social life is erected. The everyday, taken-for-granted reality of civilian life ignores much; civility assumes the nonlethal intentions of others. In war, however, all such assumptions evaporate: one cannot trust the ground one walks on, the air one breathes, nor can one expect with full assuredness that tomorrow will come again.\" (Kearl 1989, 353)\n\u003e ...\n\u003e The fact that many philosophers find it odd to speak of being betrayed by their environment is perhaps best explained by the fact that most philosophers have lead, by and large, pretty cushy lives.\n\nInteresting to distinguish between what we are trusting when we trust designed (e.g. search engines, devices, websites, etc.) and non-designed objects (the ground, physics, etc.)\n\nTo lose trust is to shift from the unquestioning state to the endlessly skeptical and suspicious mood.\n\nPHIL 240A Assignment 1: [Trust as Unquestioning Attitude](thoughts/Trust%20as%20Unquestioning%20Attitude.md)\n\n## Partiality and prejudice in trusting\n*By Katherine Hawley*\n\n\u003e Is it reasonable to trust your [friends](thoughts/friendship.md)?\n\nCommon definition of trust:\n- involves relying on them to do it\n- an extra factor which distinguishes genuine trust from the attitude of mere reliance we take to inanimate objects\n\nInterestingly, there is a gap between relying on someone to do something and believing that they will do it\n- Trust is a choice -- so \"trusting someone to do something need not involve belief that she is trustworthy, nor belief that she will do what she is trusted to do, nor even belief that it is likely she will do it\"\n- You can trust someone to do something without relying on them to do it\n\t- I can trust my friends to keep my secrets by not believing that they *won't* keep my secrets\n- You can rely on them without trusting them\n\t- I can rely on my neighbour to tidy the garden we share but I don't trust her to do so (nor distrust) -- I would feel disappointed but not resentful if she didn't do the job\nTrust doesn't require *active knowledge* -- checking whether $x$ will $p$ is unnecessary when I already *know* whether $x$ will $p$\n\nStroud (2006) and Kelly (2004) argue that we *should* have partiality towards friends not only in actions but beliefs as well, though this isn't always the right thing to do. As Stroud says, 'friendship requires epistemic irrationality'\n- Confirmation [bias](thoughts/bias.md): tendency to notice evidence which confirms our existing beliefs (that our friends are indeed good people)\n- May resist bad news that undermines a shared history of friendship (sunk cost fallacy)\n\t- \"should we quietly drop the friend, provoke a confrontation, or accept a continuing friendship contaminated with doubts?\"\n\nThe considerations are all in some sense selfish—they play on our wish to be right, to have been right, to be a good judge of character, and to avoid difficult situations.\n\nExploring potential conflicts between different types of trust\n1. Epistemic Trust: trust in someone as a speaker or source of knowledge\n2. Practical Trust: trust in someone as an actor\n\nIn fact, there is often a two-way [[thoughts/causality|causal]] interaction between friendship and trustworthiness. Roughly, people are more likely to behave in a trust-worthy manner towards their friends, and we are more likely to form friendships with people we consider trustworthy. Clearly, there are exceptions\n1. Friend might let you down instead of disappointing someone else as your friend hopes you will understand and forgive them\n2. Might find it more tempting to lie about some matters because they are concerned about maintaining a good image of themselves in your mind\nBut if she takes these liberties too often, you will feel you have been taken for granted, and come to resent your friend. **Friendship requires mutual respect and openness as well as forgiveness.**\n\nStroud's 4 demands of friendship\n1. Serious scrutiny: scrutinize negative claims about our friends\n2. Different conclusions: draw different conclusions and make difference inferences than they otherwise would about non-friends given the same information\n3. Interpretive Charity: interpret evidence against friends more charitably than with non-friends\n4. Reason: treat the fact someone is a friend as a reason when we believe about them\n\n## Trust Circles\nFrom [Buzzard](https://buzzard.life/posts/kristen/buzzard-squad-as-cell/)\n\n![Trust circles](thoughts/images/Trust%20Circles.png)\n\n## Trust between human and non-human systems\n\nTrust has historically distinguished from *mere reliance* (Baier, 1986, p. 242) through an attitude of trust or extra factors which distinguish genuine trust from mere reliance (Hawley, 2014, p. 1) that we take to inanimate objects. However, algorithms and computerized decision making systems are beginning to play larger roles in our society -- deciding jail time for criminals, giving medical diagnoses, and many more. How should we weigh the epistemic authority or trustworthiness of human versus non-human expert systems?\n\nI posit that, until these algorithmic systems are able to reliably be held accountable for their decision making, they should not be epistemologically load-bearing. These systems should *supplement* human decision making rather than be considered an epistemic authority in and of itself. Let us construct a case study to examine this in more detail.\n\nSuppose you are a hiring manager at a tech company. There is a potential candidate in the pipeline for you company that you are very on the fence about whether to hire or not. She has an incredibly strong 'yes' recommendation from a more senior hiring manager. You don't know this higher up very well but you know that her and this candidate are close friends already. On the other hand, the company uses an internal AI-powered candidate ranking system. This system is quite complex and the original engineers who designed it have since long left the company. This system gives this candidate a strong 'no' hire recommendation.\n\nIn this situation, both systems are 'authorities', having been approved by the company for use in the hiring process. The more senior hiring manager is clearly an expert, having been working in this company and hiring many stellar employees in the past. The algorithm can also be considered an expert here, having scored extremely highly on tests of accuracy in predicting based off of historical data whether candidates will do well in the company. It has been vetted for internal use.\n\nHowever, it is important to note here that in the case example, while *both* systems are potentially biased, it is far more likely that the algorithmic system is biased.\n\nThe senior hiring manager could potentially be doxastically partial towards her friend but not because it is normative to be always partial to our friends. Notably, Crawford defines being a good friend constitutively involving forming attitudes about one’s friends that are appropriately responsive to the features that one’s friends have that appear to warrant those attitudes (2019, p. 1). It is unknown to you whether the senior hiring manager has any state-given reason to highly recommend her friend, so we cannot assume this to be the case as it is an unbased claim (as we have no evidence to believe so). Thus, we have solid reason to assume that the manager's friend actually *does* have those features that she believes makes them such a good candidate.\n\nHowever, there is one clear detail in this case that makes the algorithmic expert far more likely to be biased: it is trained on historical data that has been sanitized and decontextualized. In fact, historical data shows that in the past there have been more men in the women in the workforce. The *forbidden base rate* (Gendler, 2011) here is the statistical information about the relative number of male and female employees in the tech industry. If the data was sampled at random, then it is *statistically optimal* for the algorithm to prefer male applicants to female applicants rather than purely on the basis of qualification for the position. This, while *epistemically* rational, may not be the correct choice of action for moral reasons.\n\nLastly, I put forth the concept of epistemic accountability, a measure of whether there are ways to holding the agent in question accountable for their doxastic claims. Accountability here refers to the ability to reduce the epistemic trust in an authority after violating an epistemic norm (e.g. being incorrect). I argue that the algorithmic authority cannot be held accountable for its actions as it does not have capacity as an epistemic agent on its own -- it cannot be held accountable for its decisions. As the algorithm itself is a *designed object* we can instead attribute it forms of *derived* trust whereas the trust is not only in the algorithm itself, but its designer (the engineers who created the algorithm, the data engineers who sourced and cleaned the data) or experts who know how to operate it. As both types of progenitors of this type of trust are absent, it would be epistemically irrational to trust this algorithm.\n\nIn conclusion, it is clear that despite potential biases from both parties, the algorithmic authority has clear flaws in its ability to be held accountable as an epistemic agent and highly likely to be partial *against* the female candidate due to the forbidden base rate in this case study. It is much more likely that the senior hiring manager is a trustworthy epistemic agent.\n\n### References\n1.  Baier A. 1986. Trust and antitrust. *Ethics* 96:231–60.\n2. Hawley, K., 2014. Partiality and prejudice in trusting. _Synthese_, _191_(9), pp. 2029-2045.\n3. Crawford, L., 2019. Believing the best: on doxastic partiality in friendship. *Synthese*, 196(4), pp. 1575-1593.\n4. Gendler, T. 2011. On the Epistemic Cost of Implicit Bias. *Philosophical Studies* 156(57), pp. 33-63\n\n","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/truth":{"title":"Truth","content":"\nIs there a hard truth to anything in the universe? Can we truly know anything?\n\n\"The word “axiom” means self evident truth. All of mathematics are models based on frameworks of axioms and postulates. We develop proofs and theorems from these. All facts and axioms in mathematics are fundamentally flawed.\n\nare ideas inherently different from facts?\nwhat are the universal axioms of the universe?\ndescartes\n* solipsism -\u003e we can only know that we exist\n\n## Gödel's incompleteness theorem\n[A great explanation video](https://www.youtube.com/watch?v=HeQX2HjkcNo)\n\nThere will always be statements that are true that **cannot** be proven\n\nIt basically states that if math is consistent, it cannot be complete. And if it is not complete, it must not be consistent.\"\n\nRelated to Conway's Game of Life and whether we can tell a program can halt or not.\n\n## Verisimilitude\nTruth is not binary, but rather a spectrum. Some propositions are closer to being true than other propositions.\n\nVery related to the work of Karl Popper and his [philosophy of science](thoughts/philosophy%20of%20science.md).\n\nSee: [Descartes' Meditations](thoughts/Descartes'%20Meditations.md)","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/unsupervised-learning":{"title":"Unsupervised learning","content":"\nIn [[thoughts/supervised learning|supervised learning]], we have features $x_i$ and class labels $y_i$. Write a program that produces $y_i$ form $x_i$\n\nIn **unsupervised learning**, we only have $x_i$ values, but no explicit target labels. We can\n- [[thoughts/outlier detection|Outlier detection]]: is this a normal $x_i$?\n- Similarity/[[thoughts/clustering|Clustering]]: which examples look like this $x_i$\n- Which $x_i$ occur together\n- Latent-factors: what 'parts' are the $x_i$ made from\n- Data visualization: what does the high-dimension $X$ feature space look like?\n- Ranking: what are the most important $x_i$?\n","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/urban-planning":{"title":"Urban Planning","content":"\nSee also: [[thoughts/Arcosanti|Arcosanti]]\n\nBrand argues that many great buildings achieved their greatness by gradual stepwise evolution over time. New buildings need to be designed with the expectation that they will evolve, because they usually outlive their initial use. Even if a building does not change its use (e.g. it remains the same university department), the needs of its users will change and the building will need to adapt. This should be done, for example, by making sure that changing the space layout in the building is possible without changing the structure.\n\n## Housing Crisis\n[Why Housing Is So Expensive — Particularly in Blue States](https://www.nytimes.com/2022/07/19/opinion/ezra-klein-podcast-jenny-schuetz.html?showTranscript=1)\n\n- The five states in the U.S. with the highest rates of homelessness are New York, Hawaii, California, Oregon and Washington. Some of the bluest states in the country, not one red state on that list.\n- Housing is fundamental. When you fail to provide it, that failure reverberates throughout society, it lays waste to all your other carefully laid policy plans and ideals\n\t- That means a state like California — that prides itself on all the green energy infrastructure it’s building — is pricing people who would want to live in that infrastructure into states where they use more fossil fuels\n- Two housing affordability problems\n\t- Supply hasn't kept up with the demand: high-cost metros, places with great job markets haven’t been building enough housing to accommodate population growth and job growth for something like the last 30 years.\n\t\t- Democratic places have very strong demand for housing so a lot of high-income people who bid up the housing prices\n\t\t- Democratic administrations have imposed a lot of rules on construction processes (sometimes for progressive reasons like protecting the environment or giving voice to community)\n\t\t\t- But in some senses, it’s now been — the impulse to give communities control has been weaponized by wealthy white communities, which then used this to say you can’t build apartments and low-income housing in our wealthy neighborhoods\n\t- Housing cost is too high relative to low incomes: the poorest households everywhere in the country spend more than half of their income on housing costs, and that leaves them too little money left over to pay for things like food and transportation and health care.\n\t\t- If you spend more than 30 percent, HUD says that you are cost-burdened. And if you spend more than 50 percent, they say you are severely cost-burdened\n- Federal housing vouchers!\n\t- *Housing vouchers are actually one of the most effective anti-poverty programs we have.*\n\t- They can rent an apartment on the private market. They spend 30 percent of their income, whatever dollar value that is, and the federal government picks up the tab for the rest of this.\n\t- Critique: if you just give everybody a voucher, or a check, or a subsidy, all that’s going to happen is that landlords or other kinds of housing suppliers are going to pocket that\n\t\t- Response: works well for housing-abundant but highly priced areas. For supply-constrained places, we need to also build more homes.\n- Democratic process\n\t- Small-d democratic processes where people get to engage in their local government and make their voice heard, are not actually that democratic.\n\t- It’s not representative. And we know this, in part, from the work of political scientists who have looked at the characteristics of people who show up to a neighborhood meeting.\n\t- Actually seems to *disallow* experimentation\n\t\t- In theory: democracy allows compared to other systems is a lot of different kinds of systems to flourish and we can see what works best.\n\t\t- But what is really striking reading your work and looking at housing is actually how little experimentation is possible. And this estimate you make, really, really is wild. That it is illegal to build anything except single-family detached houses on roughly 75 percent of land in most cities today.\n\t- If most of the houses that already exist in your city are currently illegal under zoning, it raises questions about what the zoning is trying to do.\n\t\t- Cambridge, Massachusetts is a perfect example. The vast majority of parcels in Cambridge, Massachusetts have what are called nonconforming uses. So the structure there is in violation of current zoning laws. Either it’s too tall or too close to the street or a structure that’s illegal.\n\t- We've made communes illegal in a lot of places\n\t\t- So the boarding house that had one communal kitchen, and meals got cooked, and everybody had, essentially, a bedroom, but you all ate your meals together or ate out at a restaurant all the time, that was very typical. And certainly earliest cities — workers moved from farms to cities, and they all just rented a room in a boarding house and that was pretty much the option. It was much, much cheaper.\n\t\t- But what we’ve essentially done is say middle class preferences for having nuclear families and having your own kitchen and bath, that’s the only housing structure that’s allowed. \n\t- What about the resurgence of co-living arrangements?\n- Homes as investment\n\t- We’ve really pushed housing as the engine of middle class wealth. We have really pushed people to stock a ton of their money and wealth and long-term financial security or intergenerational financial security in homes.\n\t- And so that also creates a politics where people are very, very nervous about anything that might negatively affect their home values\n- Environmental\n\t- We think a lot about \"Are there going to be any negative consequences to anybody from building here\" — without thinking about the flip side, \"if we don’t build here, what are the negative consequences?\"\"\n\n## Notes from *A people-centric smart city for racial justice*\n-   cities are the backbone and hope of social change\n-   either great benefit but also digital cages of surveillance and control\n-   what is the role of cities in the post-pandemic phase?   \n    -   laboratories for democratic and sustainable innovations\n    -   smart, equitable, democratic cities\n-   tech has market AND social power \n    -   9T market cap, more than the entirety of european stock market\n- IMPORTANT QUESTIONS\n    -   smart for whom?\n    -   cities for whom?\n-   types of cities\n    -   big tech first → e.g. toronto (sidewalk labs)\n    -   turn data into common good and infrastructure\n    -   SHOULD be people first → make digital transformation work for all\n        -   reduce inequalities\n        -   affordable housing\n        -   health care\n        -   sustainable mobility\n        -   ecological transition\n        -   green public psaces\n        -   reduce carbon emissions\n    -   THEN see how we can apply tech\n    -   **avoid techno-solutionism** -\u003e [maintenance of existing systems](thoughts/creation%20vs%20maintenance.md)\n-   involves citizen decision making\n    -   [Making and Maintenance of OSS](thoughts/Making%20and%20Maintenance%20of%20OSS.md) tech + tech that preserves privacy\n-   zero carbon cities of the future (energy transition)\n    -   electrify our mobility, shift to renewables\n    -   creating green spaces\n    -   super blocks → make larger blocks, reclaim some roads for public use\n-   agile digital transformation\n    -   ethical digital standards for cities\n    -   open source, open standards, [interoperability](thoughts/interoperability.md)\n    -   _reproducibility_\n    -   public money ↔ public code\n    -   data is the raw material of the digital economy\n        -   ML will increase ROI by anywhere from 10 to 30 percent\n    -   data extractivism\n        -   [surveillance capitalism](thoughts/Data%20Capitalism.md) → you are not the customer or even the product, you are the raw material\n        -   black box society → strong need for public engagement\n            -   what are the social, ethical, racial \u0026 geopolitical implications of automated decision systems ([software is political](thoughts/software%20and%20politics.md))\n            -   latent costs of externalities related to manipulating data\n        -   new deal on data → data as digital public goods\n            -   data sovereignty, data portability, data trusts (data commons)\n            -   privacy + security by design\n            -   data infrastructure at city-scale\n            -   open standards, open APIs\n            -   access to historical, anonymized, and aggregated data which minimized privacy risks\n            -   assess automated decision systems and ensure accountability (make algorithms public)\n-   questions\n    -   how do you have mass citizen participation if there's mass inequalities in the city?\n        -   how do you include the traditionally excluded?\n        -   participitary populations → ohh this would only be digitally native citizens\n            -   actually not necessarily true, lots of more senior citizens and more impoverished people\n            -   not a 'facebook democracy' → click here to sign a petition to solve a problem\n            -   hybrid process, physical participation, digital part just enhances participation\n        -   people of marginalized communities trust the government less (theyve failed them in the past)\n            -   make public institutions more transparent and accountable too, not just a citizen problem\n\n","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/user-involvement":{"title":"User Involvement","content":"\nThe underlying aim is to involve members of the public in helping them make a change in their lives where technology is often viewed as an integral part of the process. This is the point of [participatory design](thoughts/Design%20Justice.md).\n\nThe main principles of [user centered design](thoughts/human%20centered%20design.md) (Gould and Lewis) are as follows:\n1. Early focus on users and tasks: Understanding who users will be (cognitive, behavioural, anthropomorphic, and attitudinal characteristics) and observing users doing normal tasks, studying nature of normal tasks, involving users in design process.\n2. Empirical measurement: early in development, get reactions and performance of intended users to scenarios/manuals/etc. Then, later in development, get reactions and performance of users to simulations and prototypes. Where possible, specific usability and UX goals should be identified, clearly documented and agreed upon at the beginning of the project which can help designers choose between alternative designs and check on progress.\n3. Iterative design: when problems are found in user testing, they are fixed, then more tests and observations carried out to see effects of fixes. This allows the design to be refined based on feedback\n\nBenefits:\n1. Expectation management: ensuring that the users' expectations of the new product are realistic and no surprises for users when the product arrives.\n2. Ownership: users who are involved and feel that they have contributed to a product's development are more likely to feel a sense of ownerships toward it and support its user\n\nThe process of this is the [double diamond design](thoughts/design%20requirements.md).\n\n### Participation\nWide participation helps bring different perspectives to the process, which enhances design itself, produces more user satisfaction with the final product, and engenders a sense of ownership.\n\n**Participatory/cooperative/co-design** is an overarching design philosophy that places stakeholders as central actors in creation activities. A stakeholder is anybody who is affected by the item\n","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/utility":{"title":"Utility","content":"\nUtility is the tendency of an object to produce happiness or prevent unhappiness for an individual or a community. \n\nHow can we assign utilities to represent preferences?\n\n## Interval Scales\n- Assign to each outcome $x$ a value $v(x)$ such that $v(x) \\geq v(y) \\iff x \\geq y$ and $v(x) = v(y) \\iff x \\sim y$\n- Transformation is linear\n- Called an ordinal transformation\n\nOrdinal Scales must satisfy the following properties:\n1. Completeness: $x \\succ y$ or $x \\sim y$ or $y \\succ x$\n2. Asymmetry: if $x \\succ y$ then it is false that $y \\succ x$\n3. Transitivity: if $x \\succ y$ and $y \\succ z$ then $x \\succ z$\n\n## Infinite Utility\nAn agent values A infinitely relative to B and C if we deny Continuity: $[\\lambda A, (1-\\lambda)C] \\succ B$ for any $\\lambda \u003e 0$\n\nThe agent is willing to trade B for any gamble that offers a positive chance of A, when the ‘losing outcome’ is C.)","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/utopia":{"title":"Utopia","content":"\n## What is a utopia?\n[[thoughts/Utilitarianism|Utilitarian]] perspective: a society where everyone can fully maximize their [[thoughts/utility|utility]] function\n\n## Is one even possible?\nIn a scarce world with infinite wants, no. Our concept of utopia is related to our concept of abundance, and most believable forms of utopia depend on being able to leave Earth, thereby providing us with near-infinite resources.\n\nUtopia might only be a useful concept for people in higher resourced countries, it’s very difficult for people who are worried about day-to-day survival to imagine a utopia that is the same as first-world countries. Maslow's hierachy of needs?\n\nDoes the concept of utopia requires a common definition of 'good'? If so, how do we decide what good is in a maximally beneficial way? Utilitarianist approach of maximizing everyone's utility function? Related to thoughts in [The Ones Who Walk From Omelas](thoughts/The%20ones%20who%20walk%20away%20from%20Omelas.md)\n\n## Protopia\n\n\u003e I think our destination is neither utopia nor dystopia nor status quo, but protopia. Protopia is a state that is better than today than yesterday, although it might be only a little better (Kevin Kelly)\n\nWe don't have much desire for life one hundred years from now. Many dread it. That makes it hard to take the future seriously. So we don't take a generational perspective. We're stuck in the short now instead of the [[thoughts/fiction#The Big Here and Long Now|long now]].","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/value":{"title":"Value","content":"\n[Source: *Kernel* on Value](https://kernel.community/en/learn/module-1/value)\n\nInteresting approach to taking a negative-space approach to defining values: the *negation* of what destroys value is then what must give it value.\n\nI'm not sure I fully agree, I don't think values follow the contrapositive (e.g. A implies B is true does NOT necessarily mean that not A implies not B)\n\n## Shared [truth](thoughts/truth.md)\nCreating shared truth *through [fiction](thoughts/fiction.md)* by dreaming the world we want to see come to fruition. I really like this, helps to explain why we need a collective vision. Reminds me of a big reason [contests like this exist](https://medium.com/@yishan/solarpunk-art-contest-2021-da9474c9722e).\n\nIn essence, these are just [social contracts](thoughts/social%20contracts.md) (which are just shared truths that we all believe in)\n\nLegal fiction is one that has huge influence today (enforced by the threat of violence which relies on the asymmetric power of a nation state). But it feels like we can create other fictions that we as a society can believe in (e.g. the mathematical [consensus](thoughts/consensus.md) fiction)\n\nUnfortunately, social capacity of humans mean we hit the [group limit](thoughts/group%20limits.md) of ~150 people pretty quickly. Thus, writing and then the shared record (see: [blockchain](thoughts/blockchain.md)) was invented to hold societies larger than a single tribe together.\n\n","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/value-setting":{"title":"Value Setting","content":"\n\u003e \"I’ve noticed that many people compete in games they don’t understand because they are modeling the behavior of people around them. Most common is the competition for wealth as a proxy for happiness.\" —Michael Seibel\n\nTook on a large number of commitments in the past year, not everything was something I enjoyed. Been thinking about what makes work enjoyable \n\n Ask yourself, and listen closely to your answer: “What do I like about this world? What pains me about this world?” Spend time developing your taste for what is beautiful, as well as your sensitivity to what is discordant, unjust, ugly, wrong.\n \n \u003e Aim to be fulfilled—not excessively rich. There's a reason why lottery winners are just as miserable as they were before. Hedonistic adaptation is inescapable.\n\nSome insightful pieces of writing\n* https://thesephist.com/posts/play/\n* https://www.julian.com/blog/life-planning\n* https://paukowee.wordpress.com/2021/03/06/values-setting/\n\nMaybe a part of the [exploit explore](thoughts/exploit%20explore.md) curve and the obsession with [optionality](thoughts/optionality.md)\n\n## What do I value\n\n\u003e Creating the shovels for the next generation to build their sand castles\n\n## What type of work I don't like doing\n  * could've spent that time doing other stuff\n  * didnt feel intellectual stimulating\n  * too much context switching\n\n## What I love doing\n  * learn cool new stuff\n  * solve problems\n  * SHIP STUFF\n  * amazing community\n  * independence, ability to lead\n\n## Must haves\n* intellectually challenging\n  * does the work challenge how I think?\n  * will i get to deep dive and do focused work on certain topics?\n  * am i learning new things?\n* tight feedback loop: [feedback loops](thoughts/feedback%20loops.md)\n  * are there mechanisms to tell me if I'm doing well or not?\n  * is feedback immediate, present, and clear?\n* creative freedom\n  * do i get freedom to choose (at least in part) what I work on?\n* being able to share my work with others: [building in public](thoughts/building%20in%20public.md)\n  * fun team to work with\n  * can i tell my family and friends what i do without shame\n  * are real people going to be using what i build?\n* balance\n  * can I afford to take this on without compromising my ability to pay rent and tuition?\n  * do I have still have personal time to just enjoy life?\n  ","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/virtual-worlds":{"title":"Virtual Worlds","content":"\n## Bridging the real and the virtual\n-   moving away from personal computing\n    -   started off with timeshare\n    -   personal computing\n    -   now streaming EVERYTHING to the cloud\n    -   devices will just be viewing places\n\nNo matter how hard we try, our virtual selves will inevitably be tethered to our physical selves. Interface with these virtual worlds through looking at our screens, typing on our keyboards, etc. even with a [pseudonymity](thoughts/pseudonymity.md) that is not supposedly tied to anything in the physical realm.\n\n\u003e The web is not only an intangible space; it is also a physical space made of brick, mortar, metal trailers, electronics containing magnetic and optical media, and fiber infrastructure. (Safiya Noble)\n\nRelated to: [digital commons](thoughts/digital%20commons.md) and [VR](thoughts/vr.md)\n\nIn a world where scarcity is constructed, do we even need to use it? Can we rely on manipulating abundance ([agalmics](thoughts/positive%20sum.md)) through [incentives](thoughts/incentives.md)?\n\n\u003e I realized I had become used to better digital goods being gated and inaccessible to the public when I felt weird taking all the digital goods without pay. (**[Nancy](https://nancyzuo.substack.com/p/capitalism-in-virtual-worlds)**)\n\n### Crypto\nCrypto still needs to be converted to fiat? Can we have a fully crypto economy?\n\nCrypto has managed to build infrastructures that exist outside the nation state, but we still live our lives embedded in places, communities, and nations. How do we bridge that gap?\n\nRelated: [Web3](thoughts/web3.md)\n\n## Physical Touch\n\n\u003e \"One concern, though, is that some social skills may not develop as effectively when so many interactions exist online. We learn how we are and aren’t supposed to act by observing others and then having opportunities to act out our observations ourselves.\"\n\n\"On the internet, you can pull the plug and walk away. There’s no forcing mechanism that makes us have to learn\" -\u003e how do we keep people digitally accountable?\n\n[Dunbar](thoughts/Dunbar's%20Number.md) and his colleagues demonstrated that very light touch triggers a cascade of endorphins that, in turn, are important for creating personal relationships. Can this be replicated virtually?\n\nWhat about [Nozick's Experience Machine](thoughts/Nozick's%20Experience%20Machine.md) and the Matrix?","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/virtue-ethics":{"title":"Virtue ethics","content":"\nThe notion of virtue or excellence refers to reaching one's highest potential. According to Aristotle, happiness derives from living a life of virtue.\n\nThere are two kinds of virtues:\n1. intellectual virtues: associated with reasoning and truth\n2. moral virtues: habits and dispositions formed through repetition (e.g. telling the truth)\n\t- not simply a disposition to act in a particular way, it is also a disposition to feel in a particular way\n\t- \"We may even go so far as to state that the man who does not enjoy performing noble actions is not a good man at all\"\n\nA morally right action then, is a right action is an action that a virtuous person, acting in character, would do in the same circumstances.\n\nVirtue ethics pays particular attention to the agent as well as the action and the consequences of the action. A good person does “the right thing at the right time for the right reason”\n\nWhat are the virtues humans need in order to flourish and be truly happy? Commonly, they are\n1. honesty\n2. justice\n3. loyalty\n\nA vice is the opposite of a virtue. It is a character trait that prevents a human being from flourishing or being truly happy.","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/visualization":{"title":"Visualization","content":"\nMostly from *Envisioning Information* by Edward R. Tufte\n\n## High density visualization\n\n\u003e High-density designs allow viewers to select, to narrate, to recast and personalize data for their own uses.\n\nThe control of information is given over to *viewers*, not to editors, designers, or decorators\n\nThin data prompts suspicions: \"What are they leaving out? Is that really everything they know? What are they hiding? Is that all they did?\"\n\nIt is not how much information there is, but rather how effectively it is arranged.\n\n**Clutter and confusion are failures of design, not attributes of information**\n\n### Colour\nFundamental uses of colour in information design\n- To label (colour as noun)\n- To measure (colour as quantity)\n- To represent or imitate reality (colour as representation)\n- To enliven it decorate","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/vr":{"title":"VR","content":"\nPhysical bodies perceive the senses that are input from the VR machine. [Brains in a Vat](thoughts/Brains%20in%20a%20Vat.md) experiment? question of [representation](/thoughts/representation) and whether we need [embedded systems](thoughts/embedded%20AI.md)\n\nMore on this from Anthony Tan in their piece [Life in the Metaverse](https://reboothq.substack.com/p/metaverse).\n\n## Expression of Self\nLGBT community – exploring gender identity. Super easy to express this online, and flexibility to do this more safely in an online space.\n\n\u003e When form is fluid, stereotypes, beauty, body standards, and gender norms become less restrictive. It’s harder to judge people’s appearances when you can choose exactly how you look.\n\n## Reality privilege\n-   Can explore things, can get fully immersed in a virtual world safely\n-   Don’t have the same privilege online\n-   Is the concept of [utopia](thoughts/The%20ones%20who%20walk%20away%20from%20Omelas.md) only a reality for those who can afford to not worry about physiological health? Maslow's hierarchy of needs\n\n## Money and Corporations\nWhat about economies within these metaverses? These feel important for compensating creators (via [monetary](thoughts/money.md) incentives) and running underlying infrastructure.\n\n\"Financialization is only a means to better interactions, lives, and communities — and it should never limit or exploit those ends.\" [Source](https://reboothq.substack.com/p/metaverse)\n\nHow related is this to all of the financial incentives within [web3](thoughts/web3.md) in particular and how rooted in money the whole crypto world is?","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/web3":{"title":"Web3","content":"\n\u003e **Web3 is the open-source ethic extended beyond code as static artifacts but rather as live organisms.**\n\nCrypto systems are interesting, they are \"decentralized, jurisdictionless entities that exist entirely in cyberspace, maintained by a combination of [[thoughts/cryptography|cryptography]], economics and [social consensus](thoughts/social%20contracts.md)\" However, blockchain as a technology only *enables* [decentralization](thoughts/decentralization.md), it doesn't guarantee it.\n\n\u003e “The point isn’t ‘web3’, it isn’t ‘decentralization’ for the word’s sake. The point is developing tools that allow us to leverage computers to collaborate more effectively. It’s about accountability and choosing for ourselves what to trust. It’s about withholding trust from strangers on the internet but holding out the belief that we can build a better way.” ([Dan Finlay](https://medium.com/@danfinlay/what-moxie-missed-on-web3-wallets-8dc572e7f39b))\n\nThe cyberpunk spirit: the basic property of which adversarial conflict continues to heavily favour the defender. **It should be much more expensive to destroy or disrupt than they are to use and maintain** -- [Vitalkik Buterin](https://medium.com/@VitalikButerin/a-proof-of-stake-design-philosophy-506585978d51)\n\nOf course, this is not perfect technology. I do have a few [hesitations/critiques](thoughts/web3%20critique.md) on it as well.\n\n## Index\n- [Blockchain](thoughts/blockchain.md)\n- [Decentralization](thoughts/decentralization.md)\n- [Public Goods](thoughts/public%20goods.md)\n- [DAOs](thoughts/dao.md)\n- [Quadratic Funding](thoughts/quadratic%20funding.md)\n- [Proof of stake](thoughts/proof%20of%20stake.md)\n- [Proof of work](thoughts/proof%20of%20work.md)\n- [Consensus](thoughts/consensus.md)\n- [Play](thoughts/play.md)\n- [NFTs](thoughts/NFT.md)\n- [Arweave](thoughts/Arweave.md)\n\nNotes on [Kernel](https://kernel.community/en/) curriculum: [Kernel](thoughts/kernel.md)\n\n## Web History\n[Ethereum article](https://ethereum.org/en/developers/docs/web2-vs-web3/ )\n\nWe are in the process from changing platforms to _protocols_; the difference being that, in protocols, there is no central appeal.\n\n### Web1,  Information Economy [1980s to 2000s]\n[Internet](thoughts/Internet.md) services were built on open [protocols](thoughts/Protocol.md) that were controlled by the internet community. Develops could generally rest assured that these protocols wouldn't change much because they were commonly agreed on by the community. \n\n### Web2, Platform Economy [2000s to 2020s]\nInternet as we know it today, companies that provide services in exchange for your personal data. Web2 enabled us to enjoy [P2P](thoughts/peer-to-peer.md) interactions on a global scale, but always with a middleman: a platform acting as a trusted intermediary between two people who do not know or trust each other.\n\nGeneral migration from open services to more sophisticated, centralized services\n\nEffects include frequent incursions on personal [[thoughts/privacy|privacy]], the spread of misinformation, and the ‘attention economy,’ all of which have fundamentally changed how we relate to one another, and destabilized civic engagement and labor across industries. [Source](https://gitcoin.co/blog/seeking-a-new-kind-of-public-good/)\n\n### Web3, Token Economy [2020s to present]\nDecentralized apps (usually running on the blockchain).\n\nMajor benefits:\n1. Anyone on the network can use the service (no one can block/deny you access to the service)\n2. Payments are built in (ether or ETH)\n3. Turing complete\n4. Require no personal data\n5. High reliability: runs on decentralized network rather than a single backend\n\nLimitations\n1. Scalability/Speed: change to state need to be processed and propagated\n2. UX: lots of information, not a lot of good ways to interface with it\n3. Fracturability: can happen when there are disagreements about [protocol](thoughts/Protocol.md) changes\n4. Cost: gas fees \n\nVerifiability is the atom of web3. It is what the hyperlink was for Web1.\n\n## Cool Applications\n### [Gitcoin](https://gitcoin.co/)\nHow do we incentivize [open source software](posts/paid-open-source.md)? Gitcoin approaches this through decentralizing [funding](thoughts/funding.md) (away from corporations and toward individuals).\n\nNot just providing funding, 4 main value adds\n1. Earn -\u003e get paid to do maintenance work and upkeep of public goods!\n2. Learn -\u003e mentorship from industry leaders and peers\n3. Connect -\u003e creating a community of builders and support network\n4. Fund -\u003e making it easy for developers to support each other\n\nSee also: [[thoughts/decentralized marketplace|marketplaces]]\n","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/web3-critique":{"title":"Web3 Critique","content":"\nReally good piece by [Moxie on web3](https://moxie.org/2022/01/07/web3-first-impressions.html?curius=1294).\n\n- Web3 lacks [infrastructure](thoughts/infrastructure.md)\n\t- By definition, infrastructure does not need to be rebuilt every time they are used. To ask people to throw away their infrastructure is rather stupid.\n\t- Servers are infrastructure! Nodes are infrastructure! People won't want to run these themselves. Until we reach a point where enough web3 platforms are able to provide this same level of infrastructure, we're going to still end up with centralization.\n\t- \"If there’s one thing I hope we’ve learned about the world, it’s that people do not want to run their own servers. The companies that emerged offering to do that for you instead were successful, and the companies that iterated on new functionality based on what is possible with those networks were even more successful.\"\n- [Decentralization](thoughts/decentralization.md) is not always good. The more I get involved with the space, the more I am certain that the main value add of [blockchain](thoughts/blockchain.md) and [web3](thoughts/web3.md) is not decentralization but rather [interoperability](thoughts/interoperability.md) and [transparency](thoughts/transparency.md).\n\t- Decentralization also ends up making progress very difficult. See: [Vanilla Ice Cream effect](thoughts/Vanilla%20Ice%20Cream%20effect.md)\n\t- \"This isn’t a funding issue. If something is truly decentralized, it becomes very difficult to change, and often remains stuck in time.\"\n- Blind [trust](thoughts/trust.md). Crypto folks don't necessarily trust the people but some just blindly trust the medium. If people don't understand how the medium works to facilitate transactions, how can they trust it? Transparency also involves transparency into its inner workings.\n\t- Similarly, \"Almost all dApps use either Infura or Alchemy in order to interact with the blockchain.\"\n\t- We just rely on these two pieces of critical (centralized!) pieces of infrastructure to produce the correct results and not be bad actors.\n- [Degraded Blockchain problem](thoughts/Degraded%20Blockchain%20problem.md)\n\n### Vitalik Response\n[Source: Vitalki's Reddit Response](https://www.reddit.com/r/ethereum/comments/ryk3it/my_first_impressions_of_web3/hrrz15r/)\n\nLevels of connecting to the blockcahin\n1.  Use a Binance account.\n2.  Run a piece of code that asks the Infura API endpoint what the blockchain state is, trust the answer. However, keys are still kept locally; the code signs transactions locally and sends them to the Infura API endpoint to be re-broadcasted.\n3.  Same as (2), but the code also runs a [light client](https://github.com/ethereum/consensus-specs/blob/dev/specs/altair/sync-protocol.md) to verify the signatures on the block headers and uses Merkle proofs to verify individual account and storage data.\n4.  Same as (3), but the code talks to N different API endpoints run by N different companies, so only 1 of them need to be providing honest answers for the connection to be reliable.\n5.  Same as (4), but instead of pre-specifying N API endpoints the code connects directly to a [p2p](thoughts/peer-to-peer.md) network\n6.  Same as (5), but the code also does data availability sampling and accepts fraud proofs, so it can detect and refuse to accept blocks that are invalid.\n7.  Run a fully verifying node.\n8.  Run a fully verifying node that also participates in mining/staking.","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/workflows":{"title":"Workflows","content":"\nCreating modular tools for users to [build their own workflows](https://thesephist.com/posts/tools/) and [interactions](thoughts/interaction%20design.md)\n\n\u003e \"Each person’s mind works a little differently, and each person remembers and processes information a little differently. I think we all work at our best when we work with tools that fit how our minds work.\"\n\nWhen other people build tools for us to use, they either design tools after their own workflows and mental models, or worse, they design it for a mass market of millions of people who all sort-of-but-not-really work and think in similar ways.\n\nBuilding tools for others usually means the creator builds for their own workflow/mental models: [universal design](thoughts/Design%20Justice.md). We create tools that work OK for the majority, but great for no one.\n\ntools you build yourself can grow and change as your workflow changes over time: less of a sense of [digital permanence](thoughts/digital%20permanence.md)\n\nAre our tools extensions of who we are? At what point does it just become a part of our mind? Relevant: [the extended mind hypothesis](thoughts/Extended%20Mind%20Hypothesis.md)\n\nCan we kill the [desktop metaphor](thoughts/desktop%20metaphor.md)?\n\n## Cool Approaches\n### [Mercury](https://uxdesign.cc/introducing-mercury-os-f4de45a04289)\n\nDefining everything around workflows rather than applications.\n\nVerb-noun-modifier approach (e.g. *Find mentions of Dogs in my notes*)\n\nExtensive use of the command palette, smart context-based dropdown filling\n\n\u003eIn conventional App-driven operating systems, functions are segregated within different Apps. The process of moving from App to App generates friction that takes you out of flow, and distracts you from your intentions.\n\nNotifications are off by default unless you specific your availability in the rules of the space (really valuable esp in an [attention economy](thoughts/attention%20economy.md))\n\n","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/writing":{"title":"Writing","content":"\nWhy write?\n\nWriting as crystallized thought, a way of expressing the labyrinth of interconnected, messy, and many time incoherent ideas in my mind. It is a form of [[thoughts/knowledge distillation|knowledge distillation]].\n\n\u003e The thing I like about writing is that it’s quite literally _thinking_—a way for me access my own interiority and construct something from it. What I write is all mine, it’s a living thing, it’s an extension of me that wanders out into the world. (Ava in [How To Avoid Half-Heartedness](https://ava.substack.com/p/how-to-avoid-half-heartedness))\n\nIt is a form of [[thoughts/bandwidth#Lossiness as Mutation|lossiness as mutation]], a way to re-interpret and adapt the thoughts into a new form -- to breathe it new life. Whether [[posts/networked-thought|networked]] or linear, molding it into new forms through [[thoughts/language|language]] and [[thoughts/terminology|terminology]] can give it a new perspective. A mental unflattening.\n\n\u003e What I am doing right now, writing this essay, is, technically, a linear walk through the network of my ideas. That is what writing is: turning a net into a line. (Henrik Karlsson, [Reader-generated Essays](https://www.lesswrong.com/posts/ZtMsyMP5F7zzP8Gvc/reader-generated-essays))\n\nIt is the form almost universally understood by all, a sort of [[thoughts/contact language|contact language]] that enables people from vastly different backgrounds and [[thoughts/context|contexts]] to build [[thoughts/fiction#Fiction as shared visions|shared fictions]].\n\nIt is the contribution of the radical intellectual, a sort of gift and offering. From David Graeber, ‘Fragments of an Anarchist Anthropology’:\n\n\u003e One obvious role for a radical intellectual is to do precisely that: to look at those who are creating viable alternatives, try to figure out what might be the larger implications of what they are (already) doing, and then offer those ideas back, not as prescriptions, but as contributions, possibilities — as gifts [...] Such a project would have to have two aspects: one ethnographic, one utopian, suspended in a [constant dialogue](https://kernel.community/en/learn/module-0/conversation/#old-gifts-anew).\n\nWriting is a form of autonomous knowledge, something that is [[thoughts/autopoiesis|autopoetic]], self-contained, and self-spreading.\n\nSee also: [[thoughts/idea list#Writing|writing idea list]]\n\n## Art\nWriting as [[thoughts/art|art]]\n\n\u003e I write like the 12 dollar desk salad, the bar that packs 20 grams of protein and plastic into one 200-calorie brick. But good writing, like a good meal, needs fat. It should indulge readers, is meant to be chewed and enjoyed, affording a generous escape from the prosaic and mundane. -- [Jasmine Sun](https://jasmine.substack.com/p/audience-of-one)\n\n*How much time should we spend producing great writing, and how much trying to prove it to the world?* Can we write as if we were Hanya Yanagihara in \"A Little Life\"? To please only ourselves?\n\n## As Thinking\nTed Chiang on the power of written language in *Truth of Fact, Truth of Feeling*:\n\n\u003e Writing was not just a way to record what someone said; it could help you decide what you would say before you said it. And words were not just the pieces of speaking; they were the pieces of thinking. When you wrote them down, you could grasp your thoughts like bricks in your hands and push them into different arrangements. Writing let you look at your thoughts in a way you couldn’t if you were just talking, and having seen them, you could improve them, make them stronger and more elaborate.\n\n## As Claims\n\u003e We write not only to state what we have think but also to show why others might agree with it and why it matters. We also know that whatever it is we think, it is never the entire truth. Our conclusions are partial, incomplete, and always subject to challenge. So we write in a way that allows others to test our reasoning: we present our best thinking as a series of claims, reasons, and responses to imagined challenges, so that readers can see not only what we think, but whether they ought to agree.\n\u003e \n\u003e -- *Writing in College*, by Joseph M. Williams and Lawrence McEnerney\n\nThesis can contain 4 main types of claims\n1. Claims of fact or definition: argue about what the definition of something is or whether something is a settled fact\n2. Claims of cause and effect: argue that one person, thing, or event caused another thing or event to occur\n3. Claims about value: what something is worth, whether we value it or not, how we would rate or categorize something\n4. Claims about solutions or policies: argue for or against a certain solution or policy approach to a problem\n\nThese aim to get the reader to say \"that's interesting, I'd like to know more\"\n\n1. Logos: logic (See also: list of [[thoughts/logical fallacies]])\n2. Ethos: reputational appeal of the writer\n3. Pathos: emotional appeal\n\n## As query\n[Source](https://escapingflatland.substack.com/p/search-query)\n\n**A blog post is _a search query_. You write to find your tribe; you write so they will know what kind of fascinating things they should route to your inbox.**\n\nSee also: [[thoughts/Internet|niche at scale and the internet]]\n\n\u003e Writing for a general public, you need to be broad and a bit bland. I didn’t want a general public. I wanted a specific set of people, the people who could help me along as a human being obsessed with certain intellectual problems. I didn’t know who these people _were_. I only knew that they existed. Hence my writing was a search query. It needed to be phrased in such a way that it found these people and, if necessary, filtered others.\n\nTwo opposing forces to this:\n1. Having idiosyncratic interests that grow in complexity means that _if you pursue_ _them too far you will end up obsessed with things that no one else around you cares about_.\n2.  Humans tend to mimic the interests of those around them (see: [[thoughts/mimetic|memetic thinking]])\n\nWe can reach a sort of equilibrium by writing and doing [[thoughts/building in public|things in public]].","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null},"/thoughts/zero-sum":{"title":"Zero-sum","content":"\nAs opposed to [positive sum](thoughts/positive%20sum.md)\n\n## [Group Limits](thoughts/group%20limits.md)\nIn a local context, relationships may be positive sum. But in the context of all social relationships, they are zero-sum. Social capacity is limited.\n\nRivalrous in nature. Your ability to acquire something excludes someone else from acquiring it.","lastmodified":"2023-02-15T01:38:21.509821373Z","tags":null}}