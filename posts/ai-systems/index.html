<!DOCTYPE html>
<html lang="en">
<head>
  
  <meta charset="UTF-8" />
  <meta
    name="description"
    content="This blog post is adapted from a term paper I wrote for PHIL250: Minds and Machines at UBC. I hope you enjoy the post and learn as much as I did in writing it!"
  />
  <title>
    Machines and Intelligence
  </title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  
  <meta property="og:url" content="https://jzhao.xyz" />
  <meta property="og:title" content="" />
  <meta property="og:description" content="" />
  <meta property="og:image" content="https://jzhao.xyz/res/og-card.png" />
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:creator" content="@_jzhao">
  <meta name="twitter:title" content="">
  <meta name="twitter:description" content="" />
  <meta name="twitter:image" content="https://jzhao.xyz/res/og-card.png" />


  
  
  
  
  
  <link rel="shortcut icon" type="image/png"  href="https://jzhao.xyz//icon.png" />
  

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <link href="https://jzhao.xyz/styles.20d42b17cb9edb3aa5644847edf23ef1.min.css" rel="stylesheet" />

  
  <link href="https://jzhao.xyz/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css" rel="stylesheet" id="theme-link">

   
  
  
  
  
  <script src="https://jzhao.xyz/js/darkmode.f421222dbcb0e89bea7c9ed1d7659d3e.min.js"></script>
  
  
  
  <script src="https://jzhao.xyz/js/util.59b5eb848f398a9b2cf864a089780673.min.js"></script>
  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css" integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"></script>


    
  <script src="https://unpkg.com/@floating-ui/core@0.7.3"></script>
  <script src="https://unpkg.com/@floating-ui/dom@0.5.4"></script>
  
  <script src="https://jzhao.xyz/js/popover.37b1455b8f0603154072b9467132c659.min.js"></script>

  
  
  
  <script src="https://jzhao.xyz/js/code-title.b35124ad8db0ba37162b886afb711cbc.min.js"></script>
  

  
  
  <script src="https://jzhao.xyz/js/clipboard.c20857734e53a3fb733b7443879efa61.min.js"></script>
  

  

  
   
  <script>
    
    const isReducedMotion = window.matchMedia('(prefers-reduced-motion: reduce)').matches
    const lastVisit = localStorage.getItem('lastVisitTime')
    const now = Date.now()
    let show = 'true'
    if (lastVisit) {
      document.documentElement.setAttribute('visited', 'true')
      const minElapsed = Math.ceil((now - parseInt(lastVisit)) / (1000 * 60))
      show = (!isReducedMotion && minElapsed > 5) ? 'true' : 'false'
    }
    document.documentElement.setAttribute('show-animation', show)
    localStorage.setItem('lastVisitTime', `${now}`)

    const BASE_URL = "https://jzhao.xyz/"
    const fetchData = Promise.all([
          fetch("https:\/\/jzhao.xyz\/indices\/linkIndex.76743a4227d14db4d61fb694bcdc5e6f.min.json")
            .then(data => data.json())
            .then(data => ({
              index: data.index,
              links: data.links,
            })),
          fetch("https:\/\/jzhao.xyz\/indices\/contentIndex.1fbfcaabd6f3b1e210dfe221adb0d126.min.json")
            .then(data => data.json()),
        ])
        .then(([{index, links}, content]) => ({
          index,
          links,
          content,
        }))

      const render = () => {
      

      const siteBaseURL = new URL(BASE_URL);
      const pathBase = siteBaseURL.pathname;
      const pathWindow = window.location.pathname;
      const isHome = pathBase == pathWindow;

      addCopyButtons();
      

      addTitleToCodeBlocks();
      

      

      
      const container = document.getElementById("graph-container")
      
      if (!container) return requestAnimationFrame(render)
      
      container.textContent = ""

      const drawGlobal = isHome &&  false ;
      drawGraph(
          "https://jzhao.xyz",
          drawGlobal,
          [{"/moc":"#4388cc"}],
          drawGlobal ? {"centerForce":1,"depth":-1,"enableDrag":true,"enableLegend":false,"enableZoom":true,"fontSize":0.5,"linkDistance":1,"opacityScale":3,"repelForce":1,"scale":1.4} : {"centerForce":1,"depth":1,"enableDrag":true,"enableLegend":false,"enableZoom":true,"fontSize":0.6,"linkDistance":0.8,"opacityScale":3,"repelForce":2,"scale":1}
        );

      


      
      initPopover(
        "https://jzhao.xyz",
         true ,
         true 
      )
      
    }

    const init = (doc = document) => {
      
      addCopyButtons();
      

      addTitleToCodeBlocks();
      renderMathInElement(doc.body, {
        delimiters: [
          {left: '$$', right: '$$', display: true},
          {left: '$', right: '$', display: false},
        ],
        throwOnError : false
      });
      
    };
  </script>
  
  
  <script type="module">
    import { attachSPARouting } from "https:\/\/jzhao.xyz\/js\/router.9d4974281069e9ebb189f642ae1e3ca2.min.js"
    attachSPARouting(init, render)
  </script>
  
</head>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-WDD4K02HML"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-WDD4K02HML', { 'anonymize_ip': false });
}
</script>



<body>
<div id="search-container">
  <div id="search-space">
    <input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search"
      placeholder="Search for something...">
    <div id="results-container">
    </div>
  </div>
</div>


<script defer src="https://jzhao.xyz/js/semantic-search.9c4f636c1b2bfe1cfc3536d5e1d675f6.min.js"></script>



<div id="cursor-chat-layer">
  <input type="text" id="cursor-chat-box">
</div>
<script src="https://unpkg.com/cursor-chat"></script>

<div class="singlePage">
    
    <header class="delay t-3">
    <h1 id="page-title"><a href="https://jzhao.xyz/">jzhao.xyz</a></h1>
    <div class="spacer"></div>
    <div id="search-icon">
      <p>Search</p>
      <svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg>
    </div>
    <div class='darkmode'>
    <input class='toggle' id='darkmode-toggle' type='checkbox' tabindex="-1">
    <label id="toggle-label-light" for='darkmode-toggle' tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35;" xml:space="preserve">
            <title>Light Mode</title>
            <path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z" />
        </svg>
    </label>
    <label id="toggle-label-dark" for='darkmode-toggle' tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'" xml:space="preserve">
            <title>Dark Mode</title>
            <path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z" />
        </svg>
    </label>
</div>

</header>


    <article>
      <h1>Machines and Intelligence</h1>
      <p class="meta">
          Last updated 
Nov 2, 2020

 
          
<a href="https://github.com/jackyzha0/jackyzha0.github.io/tree/hugo/content/posts/ai-systems.md" rel="noopener">Edit Source</a>


      </p>
      <ul class="tags">
    
    <li><a href="https://jzhao.xyz/tags/fruit/">Fruit</a></li>
    
</ul>

      

      




















<p>This blog post is adapted from a term paper I wrote for PHIL250: Minds and Machines at UBC. I hope you enjoy the post and learn as much as I did in writing it!</p>
<hr>
<a href="#introduction"><h2 id="introduction"><span class="hanchor" ariaLabel="Anchor"># </span>Introduction</h2></a>
<p>Historically, development of AI has taken a very specific approach — systems that represent the world through symbols and manipulate those tokens in a systematic way to arrive at a result. This type of AI was coined Good Old-Fashioned AI (GOFAI) by John Haugeland<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>This worked well up until around 1984 when the field entered an &lsquo;AI Winter&rsquo;, a long plateau in progress that was most likely due cynicism in the AI research community that trickled to media and 





<a
  href="/thoughts/funding/"
  rel="noopener" class="internal-link"
  data-src="/thoughts/funding/">funding</a> bodies, halting research and development<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<p>However, with the rise of Moore&rsquo;s Law and the insane amount of compute and data available, a new approach to the development of AI arose — one that focused on statistical methods and connectionist networks like artificial neural networks<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. Haugeland<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> dubbed this approach to AI design New Fangled AI (NFAI).</p>
<p>This paper will examine factors that differentiate GOFAI and NFAI systems, such as their ability to adapt to changes in input, and the explainability of their outputs and internal representations. It will also examine current work in integrating the two approaches to Artificial Intelligence to create an artificial general intelligence.</p>
<a href="#gofai-systems"><h3 id="gofai-systems"><span class="hanchor" ariaLabel="Anchor"># </span>GOFAI Systems</h3></a>
<p>Since the inception of the term GOFAI, the basic idea has remained unchanged: thinking as internal symbol manipulation. Within these GOFAI systems, symbols are representative of aspects of our world. These symbols are manipulated in a systematic and logical matter, performing a series of deterministic steps that results in another sequence of symbols<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>A very common example of GOFAI systems are expert systems, which are computer systems that emulate the decision making ability of a human expert<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. They solve problems via decision-tree reasoning, figuring out whether to perform certain actions based off of if-then rules.</p>
<p>However, just being able to solve a problem shouldn&rsquo;t be sufficient for intelligence. So what qualifies it? At its core, GOFAI can be considered &lsquo;artificially intelligent&rsquo; because of semantic interpretation. If the symbols represent aspects of our world, the result, which is also a symbol sequence, can be <em>translated</em> back into aspects of our world. This is called semantic interpretation, which &ldquo;seeks to construe a body of symbols so that what they mean (&lsquo;say&rsquo;) turns out to be consistently reasonable and sensible, given the situation&rdquo;<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<a href="#nfai-systems"><h3 id="nfai-systems"><span class="hanchor" ariaLabel="Anchor"># </span>NFAI Systems</h3></a>
<p>NFAI, on the other hand, is a diverse and still rapidly evolving set of systems and algorithms. It is more of a grab-bag term, roughly meaning any sort of scientific mind design that is not GOFAI<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Under this umbrella are connectionist networks, which are networks composed of lots of simple units that are interconnected with various strengths. This paper will mostly focus on connectionism as a synecdoche for the greater umbrella of NFAI.</p>
<p>Some classic examples of connectionist networks include convolutional neural networks (CNNs), which are a form of image classifiers<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>. These networks operate by applying filters or kernels to an input between layers of the network. Each of those filters have their own set of strengths that will learn and evolve over time to identify certain &lsquo;features&rsquo; from the input. Similar to cell assemblies in animal perceptual systems, these filters assemble more complex patterns using smaller and simpler patterns<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>.</p>
<p>These connectionist networks are very inspired by the structure of the brain, with its hierarchical patterns and compositional nature<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>, rather than the rational manipulation of symbols that is observed in GOFAI.</p>
<a href="#the-potemkin-village-analogy"><h2 id="the-potemkin-village-analogy"><span class="hanchor" ariaLabel="Anchor"># </span>The Potemkin Village Analogy</h2></a>
<p>While it is obvious that GOFAI and NFAI are very different approaches to constructing AI systems, how do they differ in their resilience to failure? An analogy that may be useful in visualizing this is a 





<a
  href="/thoughts/potemkin-village/"
  rel="noopener" class="internal-link"
  data-src="/thoughts/potemkin-village/">potemkin village</a> — a fake village that is built to resemble and deceive others into thinking it is real. AI systems attempt to build a sort of &lsquo;potemkin village&rsquo; that &ldquo;works well on naturally occurring data, but is exposed as fake when one visits points in space that do not have high probability&rdquo;<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>.</p>
<p>GOFAI systems are excellent at &ldquo;processing syntactical patterns like those characteristic of logical formulae, ordinary sentences, and many inferences&rdquo;<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>, but are also very narrow-minded and vulnerable when it comes to unexpected variations or oddities in the input given. The potemkin village that a GOFAI system may construct will hold up if only seen from the intended angles, but any slight deviation from an intended or expected input would shatter the illusion immediately.</p>
<p>NFAI systems, on the other hand, are &ldquo;adept at finding various sort of similarities among patterns, at recognizing repeated (or almost repeated) patterns and filling in missing parts of incomplete patterns&rdquo;<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. These also happen to be the exact things that GOFAI systems struggle with. The potemkin village that a NFAI system may construct will hold up much more robustly to unexpected patterns or noisy input, but will, at heart, still be a fake village.</p>
<a href="#rationality-and-explainability"><h2 id="rationality-and-explainability"><span class="hanchor" ariaLabel="Anchor"># </span>Rationality and explainability</h2></a>
<p>In GOFAI systems, 





<a
  href="/thoughts/intentionality/"
  rel="noopener" class="internal-link"
  data-src="/thoughts/intentionality/">intentionality</a> — the meaning and semantics behind the tokens — is injected through explicit programming by those who create it. These GOFAI systems are able to process these tokens and make conclusions based off of logic and reason rather than just trial-and-error. Case in point, expert systems. These if-then statements can easily explain decisions by showing which parts evaluated as true or false in its decision making process<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>.</p>
<p>





<a
  href="/thoughts/connectionist-networks/"
  rel="noopener" class="internal-link"
  data-src="/thoughts/connectionist-networks/">Connectionist networks</a>, for the most part, are very hard to explain and are often dubbed black-box models due to the hidden nature of its internal workings. Unlike GOFAI systems, its internal representation model is defined by the state of the entire network rather than that of any single unit — this is commonly referred to as a distributed model of connectionist representation<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> and is often claimed to be one of the distinctive features of connectionism.</p>
<h2 id="models-of-representationthoughtsrepresentationmd">Models of 





<a
  href="/thoughts/representation/"
  rel="noopener" class="internal-link"
  data-src="/thoughts/representation/">representation</a></h2>
<p>To put it in sound terminology, note while in the GOFAI system, the <em>tokens</em> are the objects of formal processing, so the system which manipulates the tokens is the actual vehicle of computation. The tokens themselves are also <em>representations</em> of aspects of the world, so they are also vehicles of mental content. In GOFAI systems, tokens are both the vehicle of computation and the vehicle of mental content.</p>
<p>This is in contrast with connectionist systems, where computation is performed at the level of simple units (unit activations, backpropagation), meaning the units are the vehicles of computation. However, as these systems use a distributed model of representation, it is not a single unit that represents something, but rather the &ldquo;network state as a whole thats interpreted as representing&rdquo;<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>. Thus, in connectionist systems, the vehicles of computation (units) need to be the vehicles of representation (network state).</p>
<a href="#integrating-gofai-and-nfai"><h2 id="integrating-gofai-and-nfai"><span class="hanchor" ariaLabel="Anchor"># </span>Integrating GOFAI and NFAI</h2></a>
<p>Given that GOFAI and NFAI systems seem so vastly different in their approaches to AI, how might one go about reconciling them?</p>
<p>One approach is to combine both into one system. This is used when there’s a rational, known, and algorithmic way to process a subproblem. Systems like AlphaZero, a connectionist based Go playing system, use mixed systems to achieve the level of performance they report. Although at heart, AlphaZero uses a deep neural network to assess new positions, it also uses a Monte Carlo Tree Search (a GOFAI algorithm) to determine its next move based of the assessment of the neural net<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>.</p>
<p>Another, less researched method, are interpretable connectionist systems. As traditional connectionist networks rely on the network state being the vehicle of representation, the complexity, depth, and scale of modern connectionist models means that it is becoming increasingly difficult for humans to interpret the output. The field of 





<a
  href="/thoughts/explainability/"
  rel="noopener" class="internal-link"
  data-src="/thoughts/explainability/">explainable</a> AI (XAI) focuses on incentivizing connectionist networks to develop localist representations (i.e. moving away from having the vehicle of representation be at the network level, but at the unit level). Zhang, Wu, and Zhu of UCLA recently showed that it is possible to train a CNN to use &lsquo;interpretable filters&rsquo;, which encourage networks to group feature detectors into single filters, showing the possibility of moving from distributed representations to more local representations<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>.</p>
<a href="#what-is-agi"><h3 id="what-is-agi"><span class="hanchor" ariaLabel="Anchor"># </span>What is AGI?</h3></a>
<p>While intelligence can be understood in many ways, this paper will focus on examining the prospects of emulating or achieving the capacity to understand or learn anything a human can — the hallmark of an artificial general intelligence (AGI).</p>
<p>Most commentators would agree that current AI systems fall short of implementing general intelligence<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>. These are narrow AI systems, which are used to accomplish or solve specific tasks like the game of Go or language translation, rather than to attempt to create a system capable of AGI. So, what&rsquo;s stopping us from making the transition from domain-specific algorithms to domain-general algorithms?</p>
<p>One problem that stumped earlier attempts at AGI was the <em>common-sense problem</em>: how do we represent common-sense information that is obvious to most humans in a way that is accessible to AI systems that use natural language? Unsurprisingly, the problem of storing all of this information was solved by the massive explosion in compute and data in the past few decades<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. However, the difficult part of this problem, choosing what subset of that huge information bank is relevant in any situation, remains a huge unsolved problem. How do we update our database of knowledge when relationships between symbols change? This is referred to as the 





<a
  href="/thoughts/frame-problem/"
  rel="noopener" class="internal-link"
  data-src="/thoughts/frame-problem/">frame problem</a>.</p>
<a href="#dissolving-the-frame-problem"><h3 id="dissolving-the-frame-problem"><span class="hanchor" ariaLabel="Anchor"># </span>Dissolving the frame problem</h3></a>
<p>Dreyfus<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> posits that any AI systems which attempt to tackle the frame problem through storing relevant frames are bound to failure. He argues that, &ldquo;human beings do not simply store common-sense information,&rdquo; rather they &ldquo;directly perceive and act upon significance in their environment&rdquo;. In his view, a more Heideggerian approach to AI will dissolve this problem.</p>
<p>Heideggerian AI, in its most basic sense, is concerned with
the Heideggerian concept of Dasein, which literally means &lsquo;Being-there&rsquo;<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>. Through the use of this expression, Heidegger calls to attention the fact that a human cannot exist or be taken into account without existing in 





<a
  href="/thoughts/context/"
  rel="noopener" class="internal-link"
  data-src="/thoughts/context/">context</a> of a world with other things — &ldquo;to be human is to be fixed, embedded, and immersed in the physical, literal, tangible day to day world&rdquo;<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>.</p>
<p>Dreyfus believed that, for any AI system to achieve any sort of general intelligence, it must also exhibit Dasein. Thus, &ldquo;a successful Heideggerian AI would need a perfect model of the human body – and by implication, that Dasein must be expressed as a human being, organically as well as existentially&rdquo;<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>.</p>
<a href="#a-non-humanistic-approach"><h3 id="a-non-humanistic-approach"><span class="hanchor" ariaLabel="Anchor"># </span>A non-humanistic approach</h3></a>
<p>However, Steed refutes Dreyfus&rsquo; overly humanistic interpretation of Heideggerian AI, believing that a AI model only needs to be &ldquo;embedded and embodied such that what AI experiences is significant for AI in the particular way that AI is,&rdquo; and thus intelligence would be possible by Heideggerian standards<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>.</p>
<p>The refutation against a purely anthropocentric view of AI brings to light an important concept: the 





<a
  href="/thoughts/multiple-realization/"
  rel="noopener" class="internal-link"
  data-src="/thoughts/multiple-realization/">multiple realization</a> argument. Emulating or copying human intelligence isn&rsquo;t the only way to achieve intelligence that rivals that of humans.</p>
<p>Contemporary AI systems are almost always used as a problem solving tool, a means to tackle uniquely human problems and to convey results that are semantically useful to us. As a result, these approaches are doomed to be constrained by human problems. This is the essense of the 





<a
  href="/thoughts/multiple-realization/"
  rel="noopener" class="internal-link"
  data-src="/thoughts/multiple-realization/">bitter lesson of AI</a>. However, if we look outside the anthropocentric view of intelligence, AI systems may not share these human problems with us and &ldquo;perhaps an authentic, free AI system does not converge to a solution that is interpretable from a human standpoint at all&rdquo;<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>.</p>
<p>AI is already capable of learning, adaptation, and basic Being-in-the-world. Thus, to achieve general intelligence, we should allow AI to contemplate its own problems and existence.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Huageland, John. (1996). <em>What Is Mind Design?</em> Mind Design II, doi:10.7551/mitpress/4626.003.0001.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Hendler, J. (2008). <em>Avoiding another AI winter.</em> IEEE Intelligent Systems, (2), pp. 2-4.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Jackson, Peter (1998). <em>Introduction To Expert Systems</em> (3 ed.). Addison Wesley. p. 2. ISBN 978-0-201-87686-4.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>Buckner, C. (2019). <em>Deep learning: A philosophical introduction.</em> Philosophy Compass, 14(10), e12625.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p>Zhang, Q., Nian Wu, Y., &amp; Zhu, S. C. (2018). <em>Interpretable convolutional neural networks.</em> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 8827-8836).&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6" role="doc-endnote">
<p>Churchland, P. (1990). <em>Thinking: An invitation to cognitive science.</em> Vol. 3., pp. 199-228.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7" role="doc-endnote">
<p>Goodfellow, I., Shlens, J., &amp; Szegedy, C. (2014) <em>Explaining and harnessing adversarial examples.</em> ArXiv Preprint ArXiv: 1412.6572.&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8" role="doc-endnote">
<p>Crane, Tim. (2003). <em>The Mechanical Mind.</em> doi:10.4324/9780203426319.&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9" role="doc-endnote">
<p>Silver, D., Hubert, T., Schrittwieser, J., Antonoglou, I., Lai, M., Guez, A., &hellip; &amp; Lillicrap, T. (2017). <em>Mastering chess and shogi by self-play with a general reinforcement learning algorithm.</em> arXiv preprint arXiv:1712.01815.&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10" role="doc-endnote">
<p>Dreyfus, Hubert L. (2008) <em>Why Heideggerian AI Failed and How Fixing It Would Require Making It More Heideggerian.</em> The Mechanical Mind in History, pp. 331–362., doi:10.7551/mitpress/9780262083775.003.0014.&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11" role="doc-endnote">
<p>Solomon, R. (1972), <em>From Rationalism to Existentialism: The Existentialists and Their Nineteenth Century Backgrounds</em>, Harper &amp; Row, New York.&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12" role="doc-endnote">
<p>Steiner, G. (1978), <em>Heidegger</em>, The Harvester Press Limited, Sussex&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13" role="doc-endnote">
<p>Steed, R. (2019). <em>AI is Heideggerian Enough, But Can It Be Authentic?</em> Unpublished manuscript, Carnegie Mellon.&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>


    </article>
    <hr/>


<div class="page-end">
    <div class="backlinks-container">
        <h3>Backlinks</h3>
<ul class="backlinks">
    
    
    
    
    
    
    
    
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      <li>
        <a href="/thoughts/Mindstorms/" data-ctx="AI systems" data-src="/thoughts/Mindstorms" class="internal-link">Mindstorms</a>
      </li>
      
      
      
      <li>
        <a href="/thoughts/Neural-Correlates-of-Consciousness-NCC/" data-ctx="AI systems" data-src="/thoughts/Neural-Correlates-of-Consciousness-NCC" class="internal-link">Neural Correlates of Consciousness (NCC)</a>
      </li>
      
      
      
      <li>
        <a href="/thoughts/automation/" data-ctx="AI systems" data-src="/thoughts/automation" class="internal-link">Automation</a>
      </li>
      
      
      
      <li>
        <a href="/thoughts/data-distributions/" data-ctx="AI Systems" data-src="/thoughts/data-distributions" class="internal-link">Data Distributions</a>
      </li>
      
      
      
      <li>
        <a href="/thoughts/embedded-AI/" data-ctx="post on AI systems" data-src="/thoughts/embedded-AI" class="internal-link">Embedded AI</a>
      </li>
      
      
      
      <li>
        <a href="/thoughts/potemkin-village/" data-ctx="AI Systems" data-src="/thoughts/potemkin-village" class="internal-link">Potemkin villages</a>
      </li>
      
      
      
</ul>

    </div>
    <div>
        <script
  src="https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js"
  integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI="
  crossorigin="anonymous"
></script>
<h3>Interactive Graph</h3>
<div id="graph-container"></div>
<style>
  :root {
    --g-node: var(--secondary);
    --g-node-active: var(--primary);
    --g-node-inactive: var(--visited);
    --g-link: var(--outlinegray);
    --g-link-active: #5a7282;
  }
</style>

<script src="https://jzhao.xyz/js/graph.afdb02e537635f9a611b53a988e5645b.js"></script>

    </div>
</div>



<div id="contact_buttons">
    <footer>
        <p>Made by Jacky Zhao using <a href="https://github.com/jackyzha0/quartz">Quartz</a>, © 2022</p>
        <ul>
            
            <li><a href="https://jzhao.xyz/">Home</a></li>
            <li><a href="https://twitter.com/_jzhao">Twitter</a></li><li><a href="https://github.com/jackyzha0">Github</a></li></ul>
    </footer>
</div>


</div>
</body>

</html>
