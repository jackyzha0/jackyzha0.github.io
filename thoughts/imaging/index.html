<!DOCTYPE html>
<html lang="en">



<head>
  
  <meta charset="UTF-8" />
  <meta
    name="description"
    content="Image Formation, Cameras, and Lenses Image formation depends on
 Lighting conditions Scene geometry Surface properties Camera optics Sensor properties  Image Processing Pipeline The sequence of image processing operations applied by the camera&rsquo;s image signal processor (ISP) to convert a RAW image into a regular JPG/PNG."
  />
  <title>
    Imaging
  </title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  
  <meta property="og:url" content="https://jzhao.xyz" />
  <meta property="og:title" content="" />
  <meta property="og:description" content="" />
  <meta property="og:image" content="https://jzhao.xyz/res/og-card.png" />
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:creator" content="@_jzhao">
  <meta name="twitter:title" content="">
  <meta name="twitter:description" content="" />
  <meta name="twitter:image" content="https://jzhao.xyz/res/og-card.png" />


  
  
  
  
  
  <link rel="shortcut icon" type="image/png"  href="https://jzhao.xyz//icon.png" />
  

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <link href="https://jzhao.xyz/styles.3f792f95b046b8a6c4dbf66a4412e3d0.min.css" rel="stylesheet" />

  
  <link href="https://jzhao.xyz/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css" rel="stylesheet" id="theme-link">

   
  
  
  
  
  <script src="https://jzhao.xyz/js/darkmode.f421222dbcb0e89bea7c9ed1d7659d3e.min.js"></script>
  
  
  
  <script src="https://jzhao.xyz/js/util.9825137f5e7825e8553c68ce39ac9e44.min.js"></script>
  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css" integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js" integrity="sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A" crossorigin="anonymous"></script>


    
  <script src="https://unpkg.com/@floating-ui/core@0.7.3"></script>
  <script src="https://unpkg.com/@floating-ui/dom@0.5.4"></script>
  
  <script src="https://jzhao.xyz/js/popover.53ad9a087e3feeaaa12b63bfd02d923b.min.js"></script>

  
  
  
  <script src="https://jzhao.xyz/js/code-title.b35124ad8db0ba37162b886afb711cbc.min.js"></script>
  

  
  
  <script src="https://jzhao.xyz/js/clipboard.c20857734e53a3fb733b7443879efa61.min.js"></script>
  

  

  
   
  <script>
    
    const isReducedMotion = window.matchMedia('(prefers-reduced-motion: reduce)').matches
    const lastVisit = localStorage.getItem('lastVisitTime')
    const now = Date.now()
    let show = 'true'
    if (lastVisit) {
      document.documentElement.setAttribute('visited', 'true')
      const minElapsed = Math.ceil((now - parseInt(lastVisit)) / (1000 * 60))
      show = (!isReducedMotion && minElapsed > 5) ? 'true' : 'false'
    }
    document.documentElement.setAttribute('show-animation', show)
    localStorage.setItem('lastVisitTime', `${now}`)

    const BASE_URL = "https://jzhao.xyz/"
    const fetchData = Promise.all([
          fetch("https:\/\/jzhao.xyz\/indices\/linkIndex.7767d7ddacf73642ebd36d59be18fb3d.min.json")
            .then(data => data.json())
            .then(data => ({
              index: data.index,
              links: data.links,
            })),
          fetch("https:\/\/jzhao.xyz\/indices\/contentIndex.8f260f2889f4ace055d9e3372adedebf.min.json")
            .then(data => data.json()),
        ])
        .then(([{index, links}, content]) => ({
          index,
          links,
          content,
        }))

      const render = () => {
      

      const siteBaseURL = new URL(BASE_URL);
      const pathBase = siteBaseURL.pathname;
      const pathWindow = window.location.pathname;
      const isHome = pathBase == pathWindow;

      addCopyButtons();
      

      addTitleToCodeBlocks();
      

      
     
      
      initPopover(
        "https://jzhao.xyz",
         true ,
         true 
      )
      

      
      const footer = document.getElementById("footer")
      if (footer) {
        const container = document.getElementById("graph-container")
        
        if (!container) return requestAnimationFrame(render)
        
        container.textContent = ""

        const drawGlobal = isHome &&  false ;
        drawGraph(
            "https://jzhao.xyz",
            drawGlobal,
            [{"/moc":"#4388cc"}],
            drawGlobal ? {"centerForce":1,"depth":-1,"enableDrag":true,"enableLegend":false,"enableZoom":true,"fontSize":0.5,"linkDistance":1,"opacityScale":3,"repelForce":1,"scale":1.4} : {"centerForce":1,"depth":1,"enableDrag":true,"enableLegend":false,"enableZoom":true,"fontSize":0.6,"linkDistance":0.8,"opacityScale":3,"repelForce":2,"scale":1}
          );

        }
      
    }

    const init = (doc = document) => {
      
      addCopyButtons();
      

      addTitleToCodeBlocks();
      renderMathInElement(doc.body, {
        delimiters: [
          {left: '$$', right: '$$', display: true},
          {left: '$', right: '$', display: false},
        ],
        macros: {
          '’': "'"
        },
        throwOnError : false
      });
      
    };
  </script>
  
  
  <script type="module">
    import { attachSPARouting } from "https:\/\/jzhao.xyz\/js\/router.9d4974281069e9ebb189f642ae1e3ca2.min.js"
    attachSPARouting(init, render)
  </script>
  
</head>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-WDD4K02HML"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-WDD4K02HML', { 'anonymize_ip': false });
}
</script>



<body>
<div id="search-container">
  <div id="search-space">
    <input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search"
      placeholder="Search for something..." dir="">
    <div id="results-container">
    </div>
  </div>
</div>


<script defer src="https://jzhao.xyz/js/semantic-search.9c4f636c1b2bfe1cfc3536d5e1d675f6.min.js"></script>



<div id="cursor-chat-layer">
  <input type="text" id="cursor-chat-box">
</div>
<script src="https://unpkg.com/cursor-chat"></script>

<div class="singlePage">
    
    <header class="delay t-3">
    <h1 id="page-title"><a href="https://jzhao.xyz/">jzhao.xyz</a></h1>
    <div class="spacer"></div>
    <div id="search-icon">
      <p>Search</p>
      <svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg>
    </div>
    <div class='darkmode'>
    <input class='toggle' id='darkmode-toggle' type='checkbox' tabindex="-1">
    <label id="toggle-label-light" for='darkmode-toggle' tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35;" xml:space="preserve">
            <title>Light Mode</title>
            <path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z" />
        </svg>
    </label>
    <label id="toggle-label-dark" for='darkmode-toggle' tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'" xml:space="preserve">
            <title>Dark Mode</title>
            <path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z" />
        </svg>
    </label>
</div>

</header>


    <article>
      <h1>Imaging</h1>
      <p class="meta">
        Last updated 
Dec 24, 2021

 
          
<a href="https://github.com/jackyzha0/jackyzha0.github.io/tree/hugo/content/thoughts/imaging.md" rel="noopener">Edit Source</a>


      </p>
      <ul class="tags">
    
    <li><a href="https://jzhao.xyz/tags/seed/">Seed</a></li>
    
</ul>

      

      






  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  

  
  















<a href="#image-formation-cameras-and-lenses"><h2 id="image-formation-cameras-and-lenses"><span class="hanchor" ariaLabel="Anchor"># </span>Image Formation, Cameras, and Lenses</h2></a>
<p>Image formation depends on</p>
<ol>
<li>Lighting conditions</li>
<li>Scene geometry</li>
<li>Surface properties</li>
<li>Camera optics</li>
<li>Sensor properties</li>
</ol>
<a href="#image-processing-pipeline"><h3 id="image-processing-pipeline"><span class="hanchor" ariaLabel="Anchor"># </span>Image Processing Pipeline</h3></a>
<p>The sequence of image processing operations applied by the camera&rsquo;s image signal processor (ISP) to convert a RAW image into a regular JPG/PNG.</p>
<ol>
<li>Lens</li>
<li>CFA</li>
<li>Analog Front-end -&gt; RAW image (mosaiced, linear, 12-bit)</li>
<li>White balance</li>
<li>CFA demoisaicing</li>
<li>Denoising</li>
<li>Colour transforms</li>
<li>Tone reproduction</li>
<li>Compression -&gt; final RGB image (non-linear, 8-bit)</li>
</ol>
<a href="#examples"><h3 id="examples"><span class="hanchor" ariaLabel="Anchor"># </span>Examples</h3></a>
<a href="#reflection"><h4 id="reflection"><span class="hanchor" ariaLabel="Anchor"># </span>Reflection</h4></a>
<p>Surface reflection depends on viewing $(\theta_v,\phi_v)$ and illumination $(\theta_i,\phi_i)$ direction along with the Bidirectional Reflection Distribution Function: $BRDF(\theta_v,\phi_v,\theta_i,\phi_i) = \frac{\rho_d}{\pi}$</p>
<p>All angles are spherical coordinates w.r.t. the normal line of the surface.</p>
<p>A Lambertian (matte) surface is one which appears the same brightness from all directions. A mirror (specular) surface is one where all incident light is reflected in one direction $(\theta_v,\phi_v)=(\theta_r,\phi_r)$</p>
<a href="#cameras"><h4 id="cameras"><span class="hanchor" ariaLabel="Anchor"># </span>Cameras</h4></a>
<p>


<img src="https://jzhao.xyz//thoughts/images/bare-sensor-imaging.png" width="auto" alt="Bare-sensor imaging"  /><em>All scene points contribute to all sensor pixels</em></p>
<p>As a result, the image is really blurry.</p>
<p>


<img src="https://jzhao.xyz//thoughts/images/pinhole.png" width="auto" alt="Pinhole camera"  /><em>Pinhole camera</em></p>
<p>The image here is flipped, but no longer blurry. Roughly, each scene point contributes to one sensor. Pinhole camera means you need to get the right size of pinhole. If the pinhole is too big, then many directions are averaged, blurring the image. If the pinhole is too small, then diffraction becomes a factor, also blurring the image.</p>
<p>A few perspective &rsquo;tricks&rsquo; arise out of the pinhole</p>
<ol>
<li>Size is inversely proportional to distance</li>
<li>Parallel lines meet at a point (vanishing point on the horizon)</li>
</ol>
<p>Side note, pinhole cameras are really slow because only a small amount of light actually makes it through the pinhole. As a result, we have lenses</p>
<a href="#lenses"><h4 id="lenses"><span class="hanchor" ariaLabel="Anchor"># </span>Lenses</h4></a>
<p>The role of a lens is to capture more light while preserving, as much as possible, the abstraction of an ideal pinhole camera, the thin lens equation</p>
<p>$$\frac{1}{z&rsquo;} - \frac{1}{z} = \frac{1}{f}$$</p>
<p>where $f$ is the focal point, $z&rsquo;$ is the distance to the image plane, and $z$ is the distance to the object.</p>
<p>Focal length can be thought of as the distance behind the lens where incoming rays parallel to the optical axis converge to a single point.</p>
<p>Different effects can be explained using physics phenomena. Vignettes are simply light that reaches one lens but not the other in a compound lens. Chromatic aberration happens because the index of refraction depends on wavelength of the light so not all colours can be in equal focus.</p>
<p>Similarities with the human eye</p>
<ul>
<li>pupil is analogous to the pinhole/aperture</li>
<li>retina is analogous to the film/digital sensor</li>
</ul>
<a href="#weak-perspective"><h4 id="weak-perspective"><span class="hanchor" ariaLabel="Anchor"># </span>Weak Perspective</h4></a>
<p>Only accurate when object is small/distant. Useful for recognition</p>
<p>$$P = \begin{bmatrix}x \\ y \\ z\end{bmatrix} \textrm{projects to a 2D image point} \\ P&rsquo; = \begin{bmatrix}x&rsquo; \\ y&rsquo;\end{bmatrix} \textrm{where} \\ m = \frac{f&rsquo;}{z_0}, x&rsquo; = mx, y&rsquo; = my$$</p>
<a href="#orthographic-projection"><h4 id="orthographic-projection"><span class="hanchor" ariaLabel="Anchor"># </span>Orthographic Projection</h4></a>
<p>$$P = \begin{bmatrix}x \\ y \\ z\end{bmatrix} \textrm{projects to a 2D image point} \\ P&rsquo; = \begin{bmatrix}x&rsquo; \\ y&rsquo;\end{bmatrix} \textrm{where} \\ x&rsquo; = x, y&rsquo; = y$$</p>
<a href="#perspective-projection"><h4 id="perspective-projection"><span class="hanchor" ariaLabel="Anchor"># </span>Perspective Projection</h4></a>
<p>$$P = \begin{bmatrix}x \\ y \\ z\end{bmatrix} \textrm{projects to a 2D image point} \\ P&rsquo; = \begin{bmatrix}x&rsquo; \\ y&rsquo;\end{bmatrix} \textrm{where} \\ m = \frac{f&rsquo;}{z_0}, x&rsquo; = f&rsquo;\frac{x}{z}, y&rsquo; = f&rsquo;\frac{y}{z}$$</p>
<a href="#image-as-functions"><h2 id="image-as-functions"><span class="hanchor" ariaLabel="Anchor"># </span>Image as functions</h2></a>
<a href="#grayscale-images"><h3 id="grayscale-images"><span class="hanchor" ariaLabel="Anchor"># </span>Grayscale images</h3></a>
<p>2D function $I(x,y)$ where the domain is $(x,y) \in ([1, width], [1, height])$ and the range is $I(x,y) \in [0, 255] \in \mathbb{Z}$</p>
<a href="#point-processing"><h3 id="point-processing"><span class="hanchor" ariaLabel="Anchor"># </span>Point Processing</h3></a>
<p>Apply a single mathematical operation to each individual pixel</p>
<a href="#linear-filters"><h2 id="linear-filters"><span class="hanchor" ariaLabel="Anchor"># </span>Linear Filters</h2></a>
<p>Let $I(x,y)$ be an $n \times n$ digital image. Let $F(x,y)$ be the $m \times m$ filter or kernel. For convenience, assume $m$ is odd and $m &lt; n$. Let $k = \lfloor \frac{m}{2} \rfloor$, we call $k$ the half-width.</p>
<p>For a correlation, we then compute the new image $I&rsquo;(x,y)$ as follows:
$$I&rsquo;(x,y) = \sum_{j=-k}^k\sum_{i=-k}^k F(i, j) I(x + i, y + j)$$</p>
<p>For a convolution, we then compute the new image $I&rsquo;(x,y)$ as follows:
$$I&rsquo;(x,y) = \sum_{j=-k}^k\sum_{i=-k}^k F(i, j) I(x - i, y - j)$$</p>
<p>A convolution is just the correlation with the filter rotated 180 degrees. We denote a convolution with the $\otimes$ symbol.</p>
<p>In general,</p>
<ol>
<li>Correlation: measures similarity between two signals. In our case, this would mean similarity between a filter and an image patch it is being applied to</li>
<li>Convolution: measures the effect one signal has on another signal</li>
</ol>
<p>Each pixel in the output image is a linear combination of the central pixel and its neighbouring pixels in the original image. This results in $m^2 \times n^2$ computations. When $m \approx n$, then this is a $\mathcal{O}(n^4)$</p>
<p>Low pass filters filter out high frequences, high pass filters filter out low frequencies.</p>
<a href="#properties-of-linear-filters"><h3 id="properties-of-linear-filters"><span class="hanchor" ariaLabel="Anchor"># </span>Properties of Linear Filters</h3></a>
<ol>
<li>Superposition: distributive law applies to convolution. Let $F_1$ and $F_2$ be digital filters. Then $$(F_1 + F_2) \otimes I(x,y) = F_1 \otimes I(x,y) + F_2 \otimes I(x,y)$$</li>
<li>Scaling. Let $F$ be a digital filter and let $k$ be a scalar. $$(kF) \otimes I(x,y) = F \otimes (kI(x,y)) = k(F \otimes I(x,y))$$</li>
<li>Shift invariance: output is local (doesn&rsquo;t depend on absolute position in image)</li>
</ol>
<p><strong>Characterization Theorem</strong>: Any operation is linear if it satisfies both superposition and scaling. Any linear, shift-invariant operation can be expressed as a convolution.</p>
<a href="#properties-of-convolution"><h4 id="properties-of-convolution"><span class="hanchor" ariaLabel="Anchor"># </span>Properties of Convolution</h4></a>
<ol>
<li>Associative. $G \otimes (F \otimes I(x,y)) = (G \otimes F) \otimes I(x,y)$</li>
<li>Symmetric. $(G \otimes F) \otimes I(x,y) = (F \otimes G) \otimes I(x,y)$</li>
</ol>
<p>Correlation, on the other hand, is generally not associative.</p>
<p>For 1D Gaussians, we note $G_{\sigma_1}(x) \otimes G_{\sigma_2}(x) = G_{\sqrt{\sigma_1^2 + \sigma_2^2}}(x)$. Convolving with $G_\sigma(x) \otimes G_\sigma(x) = G_{\sqrt 2 \sigma}(x)$</p>
<a href="#boundary-effects"><h3 id="boundary-effects"><span class="hanchor" ariaLabel="Anchor"># </span>Boundary Effects</h3></a>
<ol>
<li>Ignore these locations: make the computation undefined for the outsize $k$ rows/columns</li>
<li>Pad with zeroes: return zero whenever of value of $I$ is required at some position outside the image</li>
<li>Assume periodicity: wrap image around</li>
<li>Reflect border</li>
</ol>
<a href="#pillbox"><h3 id="pillbox"><span class="hanchor" ariaLabel="Anchor"># </span>Pillbox</h3></a>
<p>A 2D pillbox is rotationally invariant but not separable</p>
<p>$$f(x,y) = \frac{1}{\pi r^2}
\begin{cases}
1 &amp; \textrm{if} x^2 + y^2 \leq r^2 \\ 0 &amp; \textrm{otherwise}
\end{cases}
$$</p>
<p>An efficient implementation would represent a 2D box filter as the sum of a 2D pillbox and some &ldquo;extra corner bits&rdquo;</p>
<a href="#gaussian-filters"><h3 id="gaussian-filters"><span class="hanchor" ariaLabel="Anchor"># </span>Gaussian Filters</h3></a>
<ul>
<li>Box filter doesn&rsquo;t apply well for lens defocus. A circular pillbox is a much better model for defocus</li>
<li>Gaussian is a good general smoothing model
<ul>
<li>for phenomena</li>
<li>whenever the CLT applies</li>
</ul>
</li>
</ul>
<p>Gaussian filters are rotationally invariant.</p>
<p>We get $G_\sigma(x,y) = \frac{1}{2\pi\sigma^2}\exp^{-\frac{x^2+y^2}{2\sigma^2}}$ where $\sigma$ is the standard deviation</p>
<p>For a 3x3, we then need to quantize and truncate it, evaluating $G_\sigma(x,y)$ wherever in the filter. Increasing $\sigma$ means more blur. Problem with 3x3 is that it truncates too much of the distribution (does not sum up to one), this can cause unintentional darkening.</p>
<p>In general, the Gaussian filter should capture $\pm3\sigma$ for $\sigma = 1$ which gives us a 7x7 filter.</p>
<a href="#efficiency"><h4 id="efficiency"><span class="hanchor" ariaLabel="Anchor"># </span>Efficiency</h4></a>
<p>As both the 2D box filter and 2D Gaussian filter are separable, it can be implemented as two 1D convolutions which convolve each row and then each column separately.</p>
<p>A 2D filter is separable if it can be expressed as an outer product of two 1D filters</p>
<p>A seperable 2D Gaussian only does $2m$ multiplications at each pixel (one for each 1D filter). Considering the image has $n \times n$ pixels, then this is a $2m \times n^2$ multiplications. Assuming $m \approx n$, this is $\mathcal{O}(n^3)$</p>
<a href="#fourier-transform"><h4 id="fourier-transform"><span class="hanchor" ariaLabel="Anchor"># </span>Fourier Transform</h4></a>
<p>The basic building block of the fourier transform is the periodic function.</p>
<p>$$Asin(\omega x + \phi)$$</p>
<p>where $A$ is the amplitude, $\omega$ is the angular frequency and $\phi$ is the phase. Fourier&rsquo;s claim was that you could add enough of these to get any periodic signal!</p>
<a href="#the-convolution-theorem"><h3 id="the-convolution-theorem"><span class="hanchor" ariaLabel="Anchor"># </span>The Convolution Theorem</h3></a>
<p>Let $i&rsquo;(x,y) = f(x,y) \otimes i(x,y)$ be the convolution.</p>
<p>Then, $\mathcal{I}&rsquo;(w_x,w_y) = \mathcal{F}(w_x,w_y)\mathcal{I}(w_x,w_y)$ which is just a simple element-wise multiplication after applying a Fourier transform to each.</p>
<p>At the expense of two Fourier transforms and one inverse Fourier transform, convolution can be reduced to (complex) multiplication. This speeds up the cost of FFT/IFFT for the image and filter to $\mathcal{O}(n^2\log n)$ and $\mathcal{O}(m^2\log m)$ respectively, dropping the total cost of convolution to $\mathcal{O}(n^2)$</p>
<a href="#convolution-sizing"><h3 id="convolution-sizing"><span class="hanchor" ariaLabel="Anchor"># </span>Convolution Sizing</h3></a>
<p>Convolving two filters of size $m \times m$ and $n \times n$ results in a filter of size</p>
<p>$$(n + 2 \lfloor \frac m 2 \rfloor) \times (n + 2 \lfloor \frac m 2 \rfloor)$$</p>
<p>More broadly for a set of $K$ filters of sizes $m_k \times m_k$ the resulting filter will have size</p>
<p>$$(m_1 + 2 \sum_{k=2}^K \lfloor \frac{m_k}{2} \rfloor) \times (m_1 + 2 \sum_{k=2}^K \lfloor \frac{m_k}{2} \rfloor)$$</p>
<a href="#non-linear-filters"><h2 id="non-linear-filters"><span class="hanchor" ariaLabel="Anchor"># </span>Non-linear filters</h2></a>
<ul>
<li>Median Filter (take the median value of the pixels under the filter), effective at reducing certain kinds of noise, such as impulse noise (&lsquo;salt and pepper&rsquo; noise or &lsquo;shot&rsquo; noise)</li>
<li>Bilateral Filter (edge-preserving filter). Effectively smooths out the image but keeps the sharp edges, good for denoising. Weights of neighbour at a spacial offset $(x,y)$ from the center pixel $I(X,Y)$ given by a product $\exp^{-\frac{x^2+y^2}{2\sigma_d^2}}\exp^{-\frac{(I(X+x, Y+y) - I(X,Y))^2}{2\sigma_r^2}}$. We call the first half of the product the <em>domain kernel</em> (which is essentially a Gaussian) and the second half the <em>range kernel</em> (which depends on location in the image).</li>
<li>ReLU. $x$ for all $x &gt; 0$, $0$ otherwise.</li>
</ul>
<a href="#sampling"><h2 id="sampling"><span class="hanchor" ariaLabel="Anchor"># </span>Sampling</h2></a>
<p>Images are a discrete (read: sampled) representation of a continuous world.</p>
<p>An image suggests a 2D surface which can be grayscale or colour. We note that in the continuous case that</p>
<p>$i(x,y)$ is a real-valued function of real spatial variables, $x$ and $y$. It is bounded above and below, meaning $0 \leq i(x,y) \leq M$ where $M$ is the maximum brightness. It is bounded in extent, meaning that $x$ and $y$ do not span the entirety of the reals.</p>
<p>Images can also be considered a function of time. Then, we write $i(x,y,t)$ where $t$ is the temporal variable. We can also explicitly state the dependence of brightness on wavelength explicit, $i(x,y,t,\lambda)$ where $\lambda$ is a spectral variable.</p>
<p>We denote the discrete image with a capital I as $I(x,y)$. So when we go from continuous to discrete, how do we sample?</p>
<ul>
<li>Point sampling is useful for theoretical development</li>
<li>Area-based sampling occurs in practice</li>
</ul>
<p>We also quantize the brightness into a finite number of equivalence classes. These values are called gray-levels</p>
<p>$$I(x,y) \implies \lfloor \frac{i(x,y)}{M} (2^n - 1) + 0.5\rfloor$$</p>
<p>Typically, $n=8$ giving us $0 \leq n \leq 256$</p>
<p>Is it possible to recover $i(x,y)$ from $I(x,y)$? In the case when the continuous is equal to the discrete, this is possible (e.g. a completely flat image). However, if there is a discontinuouty that doesn&rsquo;t fall at a precise integer, we cannot recover the original continuous image.</p>
<p>A bandlimit is the maximum <em>spatial frequency</em> of an image. The audio equivalent of this is audio frequency, the upper limit of human hearing is about 20kHz which is the human hearing bandlimit.</p>
<p>Aliasing is the idea that we don&rsquo;t have have enough samples to properly reconstruct the original signal so we construct a lower frequency (fidelity) version.</p>
<p>We can reduce aliasing artifacts by doing</p>
<ol>
<li>Oversampling: sample more than you think you need and average</li>
<li>Smoothing before sampling: reduce image frequency</li>
</ol>
<p>This creates funky patterns on discrete images called moire patterns. This happens in film too (temporal aliasing), this is why wheels sometimes look like they go backwards.</p>
<p>The fundamental result (Sampling Theorem): For bandlimited signals, if you sample regularly at or above twice the maximum frequency (called the Nyquist Rate), then you can reconstruct the original signal exactly.</p>
<ul>
<li>Oversampling: nothing bad happens! Just wasted bits.</li>
<li>Undersampling: things are missing and there are artifacts (things that shouldn&rsquo;t be there)</li>
</ul>
<a href="#shrinking-images"><h3 id="shrinking-images"><span class="hanchor" ariaLabel="Anchor"># </span>Shrinking Images</h3></a>
<p>We can&rsquo;t shrink an image simply by taking every second pixel</p>
<p>Artifacts will appear:</p>
<ol>
<li>Small phenomena can look bigger (moire patterns in checkerboards and striped shirts)</li>
<li>Fast phenomena can look slower (wagon wheels rolling the wrong way)</li>
</ol>
<p>We can sub-sample by using Gaussian pre-filtering (Gaussian blur first then throw away every other column/row). Practically, for ever image reduction of a half, smooth by $\sigma = 1$</p>


    </article>
    <hr/>


<div class="page-end" id="footer">
    <div class="backlinks-container">
        <h3>Backlinks</h3>
<ul class="backlinks">
    
    
    
    
    
    
    
    
    
      
      
      
    
      
      
      <li>
        <a href="/thoughts/computer-vision/" data-ctx="Images, Cameras, Lenses, Filters, Sampling" data-src="/thoughts/computer-vision" class="internal-link">Computer Vision</a>
      </li>
      
      
      
</ul>

    </div>
    <div>
        <script
  src="https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js"
  integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI="
  crossorigin="anonymous"
></script>
<h3>Interactive Graph</h3>
<div id="graph-container"></div>
<style>
  :root {
    --g-node: var(--secondary);
    --g-node-active: var(--primary);
    --g-node-inactive: var(--visited);
    --g-link: var(--outlinegray);
    --g-link-active: #5a7282;
  }
</style>

<script src="https://jzhao.xyz/js/graph.abd4bc2af3869a96524d7d23b76152c7.js"></script>

    </div>
</div>






<div id="contact_buttons">
    <footer>
        
        
        <p>Made by Jacky Zhao using <a href="https://github.com/jackyzha0/quartz">Quartz</a>, © 2022</p>
        <ul>
            
            <li><a href="https://jzhao.xyz/">Home</a></li>
            <li><a href="https://twitter.com/_jzhao">Twitter</a></li><li><a href="https://github.com/jackyzha0">Github</a></li></ul>
    </footer>
</div>


</div>
</body>
</html>
