---
title: "LLMs"
date: 2022-12-09
tags:
- sapling
aliases:
- large language model
- large language models
---

Large Language Models (LLMs) are foundational machine learning models that use [[thoughts/machine learning]] to process and [[thoughts/NLP|understand natural language]]. They seem to have [[thoughts/emergent behaviour|emergent properties]] of [[thoughts/intelligence]], though this could just be the  [[thoughts/observer-expectancy effect]]

See also: [[thoughts/transformers]]

## Teaching
The widespread use of ChatGPT poses a [[thoughts/teaching|pedagogical question]]: how do we assess thinking?

I suspect ChatGPT will do to writing what calculators did to math. That is, they made it much more accessible to the masses but in the process of doing so, lost the value in the actual *process* of doing math.

We do math by hand to help internalize it in our minds, to naturalize and practice the mind to thinking in that manner. Similarly, we [[thoughts/writing|write]] to naturalize the mind to critical and thorough thought.

> "The hours spent choosing the right word and rearranging sentences to better follow one another are what teach you how meaning is conveyed by prose. Having students write essays isn’t merely a way to test their grasp of the material; it gives them experience in articulating their thoughts."

## AI generated content
Will produce an influx of AI generated content and be modern day automated content mills. However, this is concerning for a variety of reasons.

Don't shit where you eat! [[thoughts/garbage in garbage out|Garbage in garbage out]]! When it comes time to train GPTx it risks drinking from a dry riverbed.

*[Ted Chiang on ChatGPT](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web)*: "the more that text generated by large language models gets published on the Web, the more the Web becomes a blurrier version of itself ... Repeatedly resaving a _jpeg_ creates more compression artifacts, because more information is lost every time"

Programmers won't be asking many questions on StackOverflow. GPT4 will have answered them in private. So while GPT4 was trained on all of the questions asked before 2021 what will GPT6 train on?

A cautionary tale on AIs to replace human connection: [all the better to see you](https://www.kernelmag.io/2/all-the-better-to-see-you)

## Good-enough content
AI is helpful in situations where you need ‘good enough’ code/art/writing where the *value* of the output outweighs the process.
-   [https://twitter.com/gordonbrander/status/1600469469419036675](https://twitter.com/gordonbrander/status/1600469469419036675)
-   [https://twitter.com/jachiam0/status/1598448668537155586](https://twitter.com/jachiam0/status/1598448668537155586)

I don't think it's ready to replace anything that requires rigorous thought or reasoning quite yet because it is still very prone to confidently hallucinating wrong answers. LLMs should acts as an atlas and not a map (see: [[thoughts/plurality]])

## End-user programming
See also: [[thoughts/cozy software|personal software]]

[Source](https://www.geoffreylitt.com/2023/03/25/llm-end-user-programming.html)

> **I think it’s likely that soon all computer users will have the ability to develop small software tools from scratch, and to describe modifications they’d like made to software they’re already using**

